[{"content":"本博客始于 2024 年 7 月，所有日期在其之前的文章均为补档。\nHugo 可能存在一些奇怪的问题，有时候需要 Ctrl+F5 刷新缓存才能看到最新内容。\n本博客中的文章按内容分为以下几类：\n学习 \u0026amp; 技术 算法竞赛 计算机 数学 其他科目 教程 理论 \u0026amp; 思想 语言 \u0026amp; 语言学 一些想法 杂记 \u0026amp; 生活 回忆录 随感 收集 \u0026amp; 列表 Minecraft 发现 清单 本博客中的文章按形式分为以下几类：\n学习笔记。我的专业领域内的学习笔记、学习总结或解题报告。包含较多自己对知识的理解与总结，同时有可能是应试内容。 摘抄笔记。我业余做的学习笔记、文章摘抄或教程。专业性和可靠性可能较低，一般可以在网络或书中找到源内容。 想法。我的一些主观想法。 记事。对于曾经或当下发生的事的记叙。 收集。就是杂项，包括例如：自己的 MC 作品、自己的小创意、画廊、书/文章/网址/音乐/电影列表。 每篇文章的副标题会标注最新更新时间（若和第一次发布时间不同），如果副标题为“持续更新”则发布时间即为最新更新时间。\n每篇文章的开头会有一个彩色分类卡片，即按上述五种类型分类。卡片内可能会有阅读须知。\n","date":"2024-07-18T00:00:00Z","image":"https://littlereuben.github.io/p/%E5%85%B3%E4%BA%8E%E6%9C%AC%E5%8D%9A%E5%AE%A2/blank.png","permalink":"https://littlereuben.github.io/p/%E5%85%B3%E4%BA%8E%E6%9C%AC%E5%8D%9A%E5%AE%A2/","title":"关于本博客"},{"content":"这是一篇学习笔记。\r$\\gdef\\e{\\mathrm{e}}\\gdef\\d{\\mathrm{d}}\\gdef\\i{\\mathrm{i}}\\gdef\\N{\\mathbb{N}}\\gdef\\Z{\\mathbb{Z}}\\gdef\\Q{\\mathbb{Q}}\\gdef\\R{\\mathbb{R}}\\gdef\\C{\\mathbb{C}}\\gdef\\F{\\mathbb{F}}\\gdef\\E{\\mathbb{E}}\\gdef\\P{\\mathbb{P}}\\gdef\\M{\\mathbb{M}}\\gdef\\O{\\mathrm{O}}\\gdef\\b#1{\\boldsymbol{#1}}\\gdef\\ker{\\operatorname{Ker}}\\gdef\\im{\\operatorname{Im}}\\gdef\\r{\\operatorname{rank}}\\gdef\\id{\\mathrm{id}}\\gdef\\span{\\operatorname{span}}\\gdef\\spec{\\operatorname{spec}}\\gdef\\mat#1{\\begin{bmatrix}#1\\end{bmatrix}}\\gdef\\dat#1{\\begin{vmatrix}#1\\end{vmatrix}}\\gdef\\eps{\\varepsilon}\\gdef\\arcsinh{\\operatorname{arcsinh}}\\gdef\\arccosh{\\operatorname{arccosh}}\\gdef\\arctanh{\\operatorname{arctanh}}\\gdef\\arccoth{\\operatorname{arccoth}}\\gdef\\arcsech{\\operatorname{arcsech}}\\gdef\\arccsch{\\operatorname{arccsch}}\\gdef\\sgn{\\operatorname{sgn}}\\gdef\\sech{\\operatorname{sech}}\\gdef\\csch{\\operatorname{csch}}\\gdef\\arccot{\\operatorname{arccot}}\\gdef\\arcsec{\\operatorname{arcsec}}\\gdef\\arccsc{\\operatorname{arccsc}}\\gdef\\tr{\\operatorname{tr}}\\gdef\\unit#1{\\mathop{}!\\mathrm{#1}}\\gdef\\re{\\operatorname{Re}}\\gdef\\aut{\\operatorname{Aut}}\\gdef\\diag{\\operatorname{diag}}\\gdef\\D{\\mathrm{D}}\\gdef\\p{\\partial}\\gdef\\eq#1{\\begin{align*}#1\\end{align*}}\\gdef\\Pr{\\operatorname*{Pr}}\\gdef\\Ex{\\operatorname*{E}}\\gdef\\Var{\\operatorname*{Var}}\\gdef\\Cov{\\operatorname*{Cov}}\\gdef\\ip#1{\\left\\langle #1\\right\\rangle}\\gdef\\J{\\mathrm{J}}\\gdef\\Nd{\\mathcal{N}}\\gdef\\sm{\\operatorname{softmax}}\\gdef\\fC{\\mathcal{C}}\\gdef\\fF{\\mathcal{F}}\\gdef\\fS{\\mathcal{S}}\\gdef\\argmin{\\operatorname*{argmin}}\\gdef\\argmax{\\operatorname*{argmax}}\\gdef\\pd{\\mathcal{D}}\\gdef\\ERM{\\mathrm{ERM}}\\gdef\\hy{\\mathcal{H}}\\gdef\\VC{\\operatorname{VCdim}}\\gdef\\la{\\mathcal{L}}\\gdef\\cut{\\operatorname{cut}}\\gdef\\rcut{\\operatorname{ratiocut}}\\gdef\\row{\\operatorname{Row}}\\gdef\\col{\\operatorname{Col}}\\gdef\\proj{\\operatorname{proj}}\\gdef\\sp#1{\\mathcal{#1}}$\nCover image credit: AlexNet.\nToC This is a comprehensive note for the Machine Learning course, mainly about classical machine learning theory, fully covering the curriculum in fall 2025 except for the history of AI. Some of the content previously taught but removed this semester is also presented in this note, while the rest is skipped (maybe I\u0026rsquo;ll add some in the future), including: linear coupling, theory for neural networks, Rademacher complexity, proofs of SH algorithm, neural architecture search, differential privacy, ML-augmented algorithms, rectified flow.\nSome of the concepts are not as formally worded as in the official slides. Besides, I also wrote some non-curricular stuff that I was interested in. So don\u0026rsquo;t rely solely on this material for exam preparation.\nContent\rChapter\rTheorem\requivalent condition of $L$-smooth\rOptimization\r1, 2, 3\requivalent condition of $\\mu$-strongly convex4, 5\requivalent condition of $L$-smooth + convex6, 8\rproperty of $L$-smooth + $\\mu$-strongly convex7\rconvergence of GD in $L$-smooth + convex case9\rconvergence of GD in $L$-smooth case10\rconvergence of GD in $L$-smooth + $\\mu$-strongly convex case11, 12\rconvergence of SGD in $L$-smooth + convex case13\rconvergence of SGD in $L$-smooth + $\\mu$-strongly convex case14, 15\rconvergence of SVRG in $L$-smooth + $\\mu$-strongly convex case16\rconvergence of MD17\rconvergence of SGD in general case18\rNFL theorem and its generalized version\rGeneralization\r1, 4\rPAC learning for finite class and some infinite class2, 3\rthe fundamental theorem of statistical learning5\rconvergence of perceptron\rSupervised\r1\rNyquist's theorem2\rtheoretical guarantee of compressed sensing3, 4, 5\rsampling RIP matrix6\rduality7\rdual SVM8\rMercer's theorem9\rconvergence of AdaBoost10\rgeneralization of AdaBoost11, 12\rAdaBoost $\\in$ gradient boosting13\rNN $\\le$ locality sensitive hashing\rUnsupervised\r1\rgraph clustering $\\iff$ spectral clustering2, 3, 4, 5, 6\r$k$-means $\\iff$ graph clustering7\requivalence within contrastive learning\rSelf-Supervised\r1\rDanskin's theorem\rMisc/Robust ML\r1\rcorrectness of greedy filling for provable robust certificate2\rposterior of Gaussian process\rMisc/Hyperparameter\r1\rGD for hyperparameter2, 3\rcorrectness of successive halving for best arm identification4, 5\rproperties and uniqueness of ID\rMisc/Interpretability\r1\rIntroduction Conventions Definitions and theorems restart their numbering in every chapter, except for the Misc chapter, where numbering restarts every section. Bullet lists are dedicated for remarks and PSs. In the Optimization chapter, [xxx] marks the trick used to scale the inequality, as a memory aid. Mathematical notations: Vectors are not bold. $\\nabla$ follows the shape convention: $\\nabla_xf(x)$ has the same shape as $x$, for scalar $f(x)$. $\\nabla^2$ means Hessian. $\\|\\cdot\\|$ is $\\|\\cdot\\|_2$ by default. $A\\preceq B$ means $B-A$ being positive semidefinite. $\\min_x f(x)$ means the minimal value of $f(x)$, while $\\min_x. f(x)$ means the optimization problem of minimizing $f(x)$ w.r.t. $x$. $[\\text{some statement}]$ is the Iverson bracket. I use $\\Pr[\\cdot]$ for probabilities, $\\Ex(\\cdot)$ for expectations, and $\\Ex[\\cdot]$ as shorthand for $\\Ex([\\cdot])$. Basic Principles of ML The minimal description of the framework of supervised learning, the heart of ML, is as follows:\nDistribution of data $\\pd$ Input $X=(x_1,\\cdots,x_n)$ and output $Y=(y_1,\\cdots,y_n)$ (usually with noise), $(x_i,y_i)\\sim \\pd$ Goal: some function $f$, s.t. $f(x_i)\\approx y_i$ (hard to get exact $=$) Hidden goal: $(x,y)\\sim\\pd$, $f(x)\\approx y$ So we see that we learn by examples, everything is discrete.\nBefore finding $f$, we need to evaluate $f$, in order to determine whether some $f$ is a good approximation or not. We design loss function $\\ell$ (usually $L$ denotes average over a dataset), under the guidance of the principles of machine learning:\ngeneralization $\u0026gt;$ optimization continuous $\\gg$ discrete Here we should really pay attention to the second one, trying to design a proper loss function for classification. Since the detailed formulas are well-known, I won\u0026rsquo;t write them out.\nSo the goal of supervised learning now turns to finding $f=\\argmin_f\\set{L(f,X,Y)}$. There are three aspects:\nThe power, the structure of $f$—representation theory (not covered in this course). How to find such $f$—optimization theory Whether having low loss on training data implies having low loss on unseen data—generalization theory Here we talk a little bit more about generalization. Our ultimate goal is to minimize $\\Ex_{(x,y)\\sim\\pd}(L(f,x,y))$, which is not practically computable. Instead we sample another set of data called test data $X_{\\rm test},Y_{\\rm test}$. Here we have:\nEmpirical loss $L_{\\rm train}=L(f,X_{\\rm train},Y_{\\rm train})$ Test loss $L_{\\rm test}=L(f,X_{\\rm test},Y_{\\rm test})$ Population loss $L_{\\rm population}=\\Ex_{(x,y)\\sim\\pd}(L(f,x,y))$ $L_{\\rm test}$ is the estimation of $L_{\\rm population}$. We say $f$ generalizes well if, when minimizing $L_{\\rm train}$, $L_{\\rm test}$ also decreases.\nSome practical tricks for testing generalizability include a validation set and cross-validation.\nThe typical chain of steps in supervised learning is task → dataset → loss → train → validation. Note that it\u0026rsquo;s drastically different from LLM training: unlabeled data → pretrain → labeled/unlabeled data → RL/Fine tuning.\nOverfitting phenomenon representation power generalization $L_{\\rm train}$ $L_{\\rm test}$ underfit low yes high equally high overfit high maybe no $\\to 0$ maybe high The classical approach to reducing overfitting is explicit regularization restricting the representation power, but this is not the right perspective. The modern view focuses only on $L_{\\rm test}$.\nclassical view modern view simple function worse $L_{\\rm train}$ ✓ ✗ complex function better $L_{\\rm train}$ ✗ ✓ The traditional view holds that strong representation power is the original sin. However, in the DL era, it has been observed that $L_{\\rm train}=0$ often does not lead to high $L_{\\rm test}$. Many architectures exhibit implicit regularization, and overparameterization can lead to benign overfitting. Optimization Theory Introduction \u0026amp; Settings Unless mentioned explicitly, the functions are $\\fC^1$, $Q\\subseteq\\R^n$.\nOptimization methods are the engine of ML. The teacher says that humans can only do simple things, and ML is just: $$ \\begin{array}{c} \\text{simple (network) structure}\\\\ \\downarrow\\\\ \\text{simple initialization}\\\\ \\downarrow\\\\ \\text{simple (large amount of) data}\\\\ \\downarrow\\\\ \\color{red}\\text{simple training method}\\\\ \\downarrow\\\\ \\text{complicated model}\\\\ \\end{array} $$ Optimization is the key: a simple method to find a set of parameters to fit the data, but the parameter space is huge.\nWhen facing a convex function, my first reaction is: why not directly use ternary search? You will find that if the dimension is $d$, the complexity of ternary search is $\\O(Nd\\log^d\\epsilon^{-1})$, while the complexity of GD is only $\\O(Nd^2\\epsilon^{-1})$. We have different levels of access to the loss function $f$, depending on the differentiability of $f$. A $0$-th order method means that we only have information about $f(x)$. A $k$-th order method means we have $f(x),\\nabla f(x),\\cdots,\\nabla^k f(x)$. However, since in practice the number of parameters is usually in the millions or billions, $\\ge 3$-rd (or even $\\ge 2$-nd) order methods are not considered.\nThe key difference between parameters and hyperparameters is that the former is (at least one order) differentiable, while the latter is not differentiable.\nBesides Nesterov\u0026rsquo;s classic, a comprehensive collection of convergence results for different descent methods under different assumptions can be found in Handbook of Convergence Theorems for (Stochastic) Gradient Methods.\nSmooth, Convex and Strongly Convex Definition 1. $f:Q\\to R$ is $L$-Lipschitz, iff $\\forall x,y\\in Q$, $\\|f(y)-f(x)\\|\\le L\\|y-x\\|$.\nDefinition 2. $f:Q\\to\\R$ is $L$-smooth, iff $\\forall x,y\\in Q$, $\\|\\nabla f(y)-\\nabla f(x)\\|\\le L\\|y-x\\|$, i.e. $\\nabla f$ is $L$-Lipschitz.\nDefinition 3. $f:Q\\to\\R$ is $\\mu$-strongly convex, iff $\\forall x,y\\in Q$, $f(y)\\ge f(x)+\\ip{\\nabla f(x),y-x}+\\frac\\mu2\\|y-x\\|^2$.\nDefinition 4. $\\fC^{k}(Q)$ is the class of functions from $Q$ to $\\R$, which are $k$ times continuously differentiable. $\\fF^{k}(Q)$ is the convex subclass of $\\fC^{k}(Q)$, and $\\fS^{k}_{\\mu}(Q)$ is the $\\mu$-strongly convex subclass of $\\fC^{k}(Q)$. Correspondingly, we define $\\fC^{k,p}_{L}(Q)$, $\\fF^{k,p}_{L}(Q)$ and $\\fS^{k,p}_{\\mu,L}(Q)$ to satisfy an additional condition: the $p$-th derivative satisfying $L$-Lipschitz condition.\nCase Inequality smooth $1$ $-\\frac L2\\|y-x\\|^2\\le f(y)-f(x)-\\ip{\\nabla f(x),y-x}\\le\\frac L2\\|y-x\\|^2$ convex $1$ $f(y)-f(x)-\\ip{\\nabla f(x),y-x}\\ge 0$ strongly $1$ $f(y)-f(x)-\\ip{\\nabla f(x),y-x}\\ge\\frac\\mu2\\|y-x\\|^2$ smooth $2$ $-\\frac L2\\alpha(1-\\alpha)\\|y-x\\|^2\\le\\alpha f(x)+(1-\\alpha)f(y)-f(\\alpha x+(1-\\alpha)y)\\le \\frac L2\\alpha(1-\\alpha)\\|y-x\\|^2$ convex $2$ $\\alpha f(x)+(1-\\alpha)f(y)-f(\\alpha x+(1-\\alpha)y)\\ge 0$ strongly $2$ $\\alpha f(x)+(1-\\alpha)f(y)-f(\\alpha x+(1-\\alpha)y)\\ge\\frac\\mu2\\alpha(1-\\alpha)\\|y-x\\|^2$ smooth $3$ $-L\\|y-x\\|^2\\le\\ip{\\nabla f(y)-\\nabla f(x),y-x}\\le L\\|y-x\\|^2$ convex $3$ $\\ip{\\nabla f(y)-\\nabla f(x),y-x}\\ge 0$ strongly $3$ $\\ip{\\nabla f(y)-\\nabla f(x),y-x}\\ge\\mu\\|y-x\\|^2$ smooth $4$ $-LI_n\\preceq\\nabla^2 f(x)\\preceq LI_n$ convex $4$ $\\nabla^2f(x)\\succeq O$ strongly $4$ $\\nabla^2f(x)\\succeq\\mu I_n$ smooth $5$ $\\|\\nabla f(y)-\\nabla f(x)\\|\\le L\\|y-x\\|$ When $f\\in\\fC^1$, for each property, its characterizations $1$, $2$, and $3$ are equivalent. If $f\\in\\fC^2$, the equivalence includes $4$ and $5$. However, it seems hard to prove for smoothness, $5\\impliedby 1/2/3$ when only $f\\in\\fC^1$ is given.\nImplication Theorem $\\fC^1$ smooth $5\\implies 1$ 1 $\\fC^1$ smooth $1\\iff 2$ 2 $\\fC^2$ smooth $5\\iff 1\\iff 4$ 3 $\\fC^1$ strongly $1\\iff 2\\iff 3$ 4 $\\fC^2$ strongly $1\\iff 4$ 5 A universal proof strategy for all equivalences is to turn smoothness and strong convexity into convexity (by adding a quadratic function), then use the properties of convex functions.\nTheorem 1 (L 1.2.3 of Nesterov, the same below). $$ f\\in \\fC^{1,1}_L(\\R^n)\\implies\\forall x,y, |f(y)-f(x)-\\ip{\\nabla f(x),y-x}|\\le\\frac L2\\|y-x\\|^2 $$\nProof strategy. $$ \\eq{ f(y)-f(x)-\\ip{\\nabla f(x),y-x}\u0026amp;=\\int_0^1\\ip{\\nabla f(x+t(y-x))-\\nabla f(x),y-x}\\d t\u0026amp;[\\text{integral}]\\\\ \u0026amp;\\le\\int_0^1\\|\\nabla f(x+t(y-x))-\\nabla f(x)\\|\\cdot\\|y-x\\|\\d t\u0026amp;[\\text{Cauchy-Schwarz}] } $$\nTheorem 2. $f\\in\\fC^1(\\R^n)$ then $$ \\eq{ \u0026amp;\\forall x,y,\\forall\\alpha\\in[0,1],\\left\\lvert f(\\alpha x+(1-\\alpha)y)-\\alpha f(x)-(1-\\alpha)f(y)\\right\\rvert\\le\\alpha(1-\\alpha)\\frac L2\\|y-x\\|^2\\\\ \\iff{}\u0026amp;\\forall x,y, |f(y)-f(x)-\\ip{\\nabla f(x),y-x}|\\le\\frac L2\\|y-x\\|^2 } $$ Proof strategy.\n$\\implies$: [limit].\n$\\impliedby$: Let $z=\\alpha x+(1-\\alpha)y$. Apply the inequality on $(x,z)$, $(y,z)$ then add them together.\nBtw, I\u0026rsquo;d like to show the proof idea of $f\\in\\fC_L^{1,1}(\\R^n)\\implies (1)$. Consider $$ \\alpha(f(z)-f(x))+(1-\\alpha)(f(z)-f(y))=\\alpha(1-\\alpha)\\int_0^1\\ip{\\nabla f(x+t(z-x))-\\nabla f(y+t(z-y)),y-x}\\d t $$ Theorem 3 (L 1.2.2). $f\\in\\fC^2(\\R^n)$ then $$ \\eq{ f\\in\\fC^{2,1}_L(\\R^n)\u0026amp;\\iff\\forall x,y,|f(y)-f(x)-\\ip{\\nabla f(x),y-x}|\\le\\frac L2\\|y-x\\|^2\\\\ \u0026amp;\\iff\\forall x,-LI_n\\preceq\\nabla^2 f(x)\\preceq LI_n } $$\nProof strategy 1. [prove by contradiction] assume $\\|\\nabla f(y)-\\nabla f(x)\\|=(L+\\epsilon)\\|y-x\\|$ then use [integral]. Use the definition of eigenvalue to convert the integral to $\\int_0^1\\|\\nabla^2f\\|\\d t$ form, then use [MVT] the Mean Value Theorem. Finally find the direction corresponding to $\\lambda_{\\max}$ and use continuity to derive contradiction.\nProof strategy 2 (wmy). [integral], $$ \\eq{ \\int_0^1\\ip{\\nabla f(x+t(y-x))-\\nabla f(x),y-x}\\d t\u0026amp;=\\ip{\\int_0^1\\int_0^t\\ip{\\nabla^2f(x+s(y-x)),y-x}\\d s\\d t,y-x}\u0026amp;[\\text{integral}]\\\\ \u0026amp;=(y-x)^\\top\\left(\\int_0^1\\nabla^2f(x+s(y-x))\\d s\\right)(y-x) } $$ [limit] take $y\\to x$ from every direction, we can bound the eigenvalues of $\\nabla^2f(x)$.\nTheorem 4 (T 2.1.8 \u0026amp; T 2.1.9). $f\\in\\fC^1(\\R^n)$ then $$ \\eq{ f\\in\\fS^1_\\mu(\\R^n)\u0026amp;\\iff\\forall x,y,\\forall\\alpha\\in[0,1],f(\\alpha x+(1-\\alpha)y)\\le\\alpha f(x)+(1-\\alpha)f(y)-\\alpha(1-\\alpha)\\frac\\mu2\\|y-x\\|^2\\\\ \u0026amp;\\iff\\forall x,y,\\ip{\\nabla f(y)-\\nabla f(x),y-x}\\ge\\mu\\|y-x\\|^2 } $$\n$(1)\\iff (2)$ Proof strategy. [integral] and [limit].\n$(1)\\implies (3)$ Proof strategy. [adding together] Add the definition of strongly convex on $(x,y)$ and $(y,x)$ together.\n$(3)\\implies (1)$ Proof strategy. [integral].\nTheorem 5 (T 2.1.10). $f\\in\\fC^2(\\R^n)$ then $$ f\\in\\fS^2_\\mu(\\R^n)\\iff\\forall x,\\nabla^2f(x)\\succeq\\mu I_n $$\nTheorem 6 (T 2.1.5). $f\\in\\fC^1(\\R^n)$ then $$ \\eq{ f\\in\\fF^{1,1}_L(\\R^n)\u0026amp;\\iff\\forall x,y,0\\le f(y)-f(x)-\\ip{\\nabla f(x),y-x}\\le\\frac L2\\|y-x\\|^2\\\\ \u0026amp;\\iff\\forall x,y,f(y)\\ge f(x)+\\ip{\\nabla f(x),y-x}+\\frac{1}{2L}\\|\\nabla f(y)-\\nabla f(x)\\|^2\\\\ \u0026amp;\\iff\\forall x,y,\\ip{\\nabla f(y)-\\nabla f(x),y-x}\\ge\\frac1L\\|\\nabla f(y)-\\nabla f(x)\\|^2 } $$ $(2)\\implies (3)$ Proof strategy 1. For some $x$, let $g(y)=f(y)-\\ip{\\nabla f(x),y-x}$. Now we relocate the minimum at $x$ while preserving the convexity. $\\forall u,v,g(v)\\le g(u)+\\ip{\\nabla g(u),v-u}+\\frac L2\\|v-u\\|^2$. Let $u=y$, consider $\\min_v\\set{g(y)+\\ip{\\nabla g(y),v-y}+\\frac L2\\lVert v-y\\rVert^2}$, set $\\nabla g(y)+L(v-y)=0\\implies v=y-\\frac1L\\nabla g(y)$. Now, $g(x)\\le g(v)\\le g(y)+\\ip{\\nabla g(y),v-y}+\\frac L2\\|v-y\\|^2=g(y)-\\frac1{2L}\\|\\nabla g(y)\\|^2=g(y)-\\frac1{2L}\\|\\nabla f(y)-\\nabla f(x)\\|^2$.\n$(2)\\implies (3)$ Proof strategy 2. Consider convex conjugate.\n$(3)\\implies (4)$ Proof strategy. [adding together]\n$(4)\\implies (1)$ Proof strategy. [Cauchy-Schwarz], for convexity consider [integral].\nTheorem 7 (T 2.1.11). $$ f\\in\\fS^{1,1}_{\\mu,L}(\\R^n)\\implies\\forall x,y,\\ip{\\nabla f(y)-\\nabla f(x),y-x}\\ge\\frac{\\mu L}{\\mu+L}\\|y-x\\|^2+\\frac{1}{\\mu+L}\\|\\nabla f(y)-\\nabla f(x)\\|^2 $$\nProof strategy 1. Let $g(x)=f(x)-\\frac\\mu2\\|x\\|^2$, $g$ is convex and $L$-smooth, so we can use theorem 5 $(4)$.\nProof strategy 2. Since $\\nabla^2f(x)$\u0026rsquo;s eigenvalues are $\\in[\\mu,L]$, $\\int_0^1\\nabla^2f(x+t(y-x))\\d t$\u0026rsquo;s eigenvalues are also $\\in[\\mu,L]$. So [integral] then we get an inequality of the form $(A-\\mu)(A-L)\\preceq 0$.\nConvex Conjugate Definition 5. The convex conjugate of $f:\\R^n\\to\\R$ is defined as: $$ f^{*}(u)=\\sup_x\\set{\\ip{u,x}-f(x)} $$ Some basic properties that might be covered in other course\u0026rsquo;s note in the future:\nConvex conjugate is always convex, regardless of $f$\u0026rsquo;s convexity. For convex and closed function $f$, $f^{**}=f$. Convex conjugate is closely related to Lagrange duality and the dual of linear programming. In this section, we only consider convex $f$.\nLemma. For strongly convex function $f:\\R^n\\to\\R$, $\\nabla f:\\R^n\\to\\R^n$ is bijection.\nLemma. $u=\\nabla f(x)\\iff x=\\nabla f^{*}(u)$.\nProof. Since $u=\\nabla f(x)$, $x$ achieves the extremum and $f^{*}(u)=\\ip{u,x}-f(x)$. By the Danskin\u0026rsquo;s theorem (mentioned in Robust Machine Learning section), it\u0026rsquo;s valid to calculate $\\nabla f^{*}(u)$ by regarding $x$ as a constant.\nTheorem 8. $f\\in\\fF^1(\\R^n)$ then $$ f\\in\\fC^{1,1}_L(\\R^n)\\iff f^{*}\\in\\fS^1_{1/L}(\\R^n) $$ Proof.\n$\\implies$: $f(x)$ is upper bounded by $$ f(x)\\le\\underline{f(y)+\\ip{\\nabla f(y),x-y}+\\frac L2\\|x-y\\|^2}_{\\phi_y(x)} $$ By the definition of conjugation, $\\forall x,f(x)\\le g(x)\\implies\\forall u,f^{*}(u)\\ge g^{*}(u)$. This motivates us to conjugate $\\phi_y(x)$: $$ \\eq{ \\phi_y^{*}(u)\u0026amp;=\\sup_x\\Set{\\ip{u,x}-\\left(f(y)+\\ip{\\nabla f(y),x-y}+\\frac L2\\|x-y\\|^2\\right)}\\\\ \u0026amp;=\\sup_x\\Set{\\ip{u-\\nabla f(y),x}-\\frac L2\\lVert x-y\\rVert^2}-f(y)+\\ip{\\nabla f(y),y}\\\\ \u0026amp;\\xlongequal{x=y-\\frac1L(u-\\nabla f(y))}\\ip{u,y}+\\frac1{2L}\\|u-\\nabla f(y)\\|^2-f(y) } $$ Let $v=\\nabla f(y)$, thus $y=\\nabla f^{*}(v)$. By definition, $f(y)+f^{*}(v)\\le\\ip{v,y}$. $$ \\eq{ f^{*}(u)\u0026amp;\\ge\\phi_y^{*}(u)\\\\ \u0026amp;=\\ip{u,y}+\\frac1{2L}\\|u-\\nabla f(y)\\|^2-f(y)\\\\ \u0026amp;=\\ip{u,\\nabla f^{*}(v)}+\\frac1{2L}\\|u-v\\|^2-f(y)\\\\ \u0026amp;\\ge\\ip{u,\\nabla f^{*}(v)}+\\frac1{2L}\\|u-v\\|^2+f^{*}(v)-\\ip{v,y}\\\\ \u0026amp;=f^{*}(v)+\\ip{\\nabla f^{*}(v),u-v}+\\frac1{2L}\\|u-v\\|^2 } $$ $\\impliedby$: It\u0026rsquo;s exactly the same except for reversing the inequality sign. Note that according to theorem 6, under convexity, $f(y)-f(x)-\\ip{\\nabla f(x),y-x}\\le\\frac L2\\|y-x\\|^2$ can derive smoothness.\nWe can see similarities between the proof above and the proof of cocoercivity (theorem 6). Unfortunately I\u0026rsquo;m unable to point out the exact correspondence. This theorem also directly leads to theorem 6: just substitute $u=\\nabla f(x)$ and $v=\\nabla f(y)$. The full relationship can be summarized as follows: $$ \\begin{CD} f \\text{ is } L\\text{-smooth} @= \\nabla f \\text{ is } \\tfrac{1}{L}\\text{-cocoercive}\\\\ @|@|\\\\ f^{*} \\text{ is } \\tfrac{1}{L}\\text{-strongly convex} @= \\nabla f^{*} \\text{ is } \\tfrac{1}{L}\\text{-monotone} \\end{CD} $$ Gradient Descent Definition 6 (GD \u0026amp; SGD). Here we use $w$ to denote the parameters, and $f$ to denote the loss function. GD: $w_{t+1}=w_t-\\eta\\nabla f(w_t)$; SGD: $w_{t+1}=w_t-\\eta G_t=w_t-\\eta(\\nabla f(w_t)+\\xi_t)$, with $\\Ex(G_t)=\\nabla f(w_t)$. Here we treat the minibatch trick as adding white noise to the update term, not exploiting further properties of minibatches.\nNote that for a strictly convex function, $\\nabla f$ is only injective; for a convex function, there is no such guarantee. Therefore, bounding $\\|x_T-x_{*}\\|$ can only appear in the strongly convex case. Definition 7. Convergence rate is defined as the asymptotic behavior of $T(\\epsilon)$, to achieve $\\epsilon$ accuracy, i.e. $\\|w_T-w_{*}\\|\\le\\epsilon$ or $f(w_t)-f(w_{*})\\le\\epsilon$. We have:\nSublinear rate, $\\|w_k-w_{*}\\|=\\Omicron(\\mathrm{poly}(k)^{-1})$. Linear rate, $\\|w_k-w_{*}\\|=\\Omicron((1-q)^k)$. Quadratic rate, $\\|w_k-w_{*}\\|=\\Omicron((1-q)^{2^k})$, usually from $\\|w_{k+1}-w_{*}\\|\\le C\\|w_k-w_{*}\\|^2$. Theorem 9. $f\\in\\fF^{1,1}_L(\\R^n)$ then for $0\u0026lt;\\eta\\le \\frac1L$, GD converges at rate $\\frac1T$: $$ f(w_t)-f(w_{*})\\le\\frac{\\|w_0-w_{*}\\|^2}{2\\eta T} $$\nProof.\nLemma (descent lemma). $$ f(w_{t+1})-f(w_t)\\le\\ip{\\nabla f(w_t),w_{t+1}-w_t}+\\frac L2\\|w_{t+1}-w_t\\|^2=\\left(-\\eta+\\frac{L\\eta^2}2\\right)\\|\\nabla f(w_t)\\|^2 $$ So when $0\\le\\eta\\le\\frac{1}{L}$, $f(w_{t+1})-f(w_t)\\le-\\frac\\eta2\\|\\nabla f(w_t)\\|^2$ [quadratic function]. $$ \\eq{ \\quad f(w_{t+1}) \u0026amp;\\leq f(w_t) - \\frac{\\eta}{2}\\|\\nabla f(w_t)\\|^2\u0026amp;[\\text{descent lemma}]\\\\ \u0026amp;\\leq f(w_{*}) + \\ip{ \\nabla f(w_t), w_t-w_{*}} - \\frac{\\eta}{2}\\|\\nabla f(w_t)\\|^2\u0026amp;[\\text{convexity}]\\\\ \u0026amp;= f(w_{*}) - \\frac{1}{\\eta}\\ip{w_{t+1} - w_t, w_t - w_{*}} - \\frac{1}{2\\eta}\\|w_t - w_{t+1}\\|^2\\\\ \u0026amp;= f(w_{*}) + \\frac{1}{2\\eta}(\\|w_t - w_{*}\\|^2 - \\|w_{t+1} - w_{*}\\|^2)\u0026amp;[\\text{completing the square}]\\\\ \\implies\\sum_{i=1}^T(f(w_i)-f(w_{*}))\u0026amp;\\le\\frac{1}{2\\eta}(\\|w_0-w_{*}\\|^2-\\|w_T-w_{*}\\|^2)\\le\\frac{1}{2\\eta}\\|w_0-w_{*}\\|^2\u0026amp;[\\text{telescoping}]\\\\ \\implies T(f(w_T)-f(w_{*}))\u0026amp;\\le\\frac{1}{2\\eta}\\|w_0-w_{*}\\|^2\u0026amp;[\\text{monotonicity}] } $$\nTheorem 10. $f\\in\\fC^{1,1}_L(\\R^n)$ then for $0\u0026lt;\\eta\\le\\frac1L$, GD only guarantees $$ \\min_{i=0}^{T-1}\\|\\nabla f(w_i)\\|^2\\le\\frac{2}{\\eta T}(f(w_0)-f(w_{*})) $$ Theorem 11. $f\\in \\fS^{1,1}_{\\mu,L}(\\R^n)$ then for $0\u0026lt;\\eta\\le\\frac2L$, GD converges at linear rate: $$ \\|w_T-w_{*}\\|^2\\le\\left(1-\\eta\\mu\\right)^T\\|w_0-w_{*}\\|^2 $$ Proof. $$ \\eq{ \\|w_{t+1}-w_{*}\\|^2\u0026amp;=\\|w_{t+1}-w_t\\|^2+2\\ip{w_{t+1}-w_t,w_t-w_{*}}+\\|w_t-w_{*}\\|^2\u0026amp;[\\text{expanding the square}]\\\\ \u0026amp;=\\eta^2\\|\\nabla f(w_t)\\|^2-2\\eta\\ip{\\nabla f(w_t),w_t-w_{*}}+\\|w_t-w_{*}\\|^2\\\\ \u0026amp;\\le\\eta^2\\|\\nabla f(w_t)\\|^2-2\\eta\\left(f(w_t)-f(w_{*})+\\frac\\mu2\\|w_t-w_{*}\\|^2\\right)+\\|w_t-w_{*}\\|^2\u0026amp;[\\text{strong convexity}]\\\\ \u0026amp;\\le\\eta^2\\|\\nabla f(w_t)-\\nabla f(w_{*})\\|^2-2\\eta(f(w_t)-f(w_{*}))+(1-\\eta\\mu)\\|w_t-w_{*}\\|^2\u0026amp;[\\nabla f(w_{*})=0]\\\\ \u0026amp;\\le 2\\eta(\\eta L-1)(f(w_t)-f(w_{*}))+(1-\\eta\\mu)\\|w_t-w_{*}\\|^2\u0026amp;[\\text{smoothness}]\\\\ \u0026amp;\\le(1-\\eta\\mu)\\|w_t-w_{*}\\|^2\u0026amp;[\\text{throwing positive term}] } $$\nMemory trick: for the convex case, use smoothness → convexity → completing the square; for the strongly convex case, use completing the square → convexity → smoothness. Theorem 12. $f\\in \\fS^{1,1}_{\\mu,L}(\\R^n)$ then for $0\u0026lt;\\eta\\le\\frac{2}{\\mu+L}$, GD: $$ \\|w_T-w_{*}\\|^2\\le\\left(1-2\\eta\\frac{\\mu L}{\\mu+L}\\right)^T\\|w_0-w_{*}\\|^2 $$ Proof. $$ \\eq{ \\|w_{t+1}-w_{*}\\|^2\u0026amp;=\\|w_{t+1}-w_t\\|^2+2\\ip{w_{t+1}-w_t,w_t-w_{*}}+\\|w_t-w_{*}\\|^2\u0026amp;[\\text{expanding the square}]\\\\ \u0026amp;=\\eta^2\\|\\nabla f(w_t)\\|^2-2\\eta\\ip{\\nabla f(w_t)-\\nabla f(w_{*}),w_t-w_{*}}+\\|w_t-w_{*}\\|^2\u0026amp;[\\nabla f(w_{*})=0]\\\\ \u0026amp;\\le\\eta\\left(\\eta-\\frac{2}{\\mu+L}\\right)\\|\\nabla f(w_t)\\|^2+\\left(1-2\\eta\\frac{\\mu L}{\\mu+L}\\right)\\|w_t-w_{*}\\|^2\u0026amp;[\\text{theorem 6}]\\\\ \u0026amp;\\le\\left(1-2\\eta\\frac{\\mu L}{\\mu+L}\\right)\\|w_t-w_{*}\\|^2\u0026amp;[\\text{throwing positive term}] } $$ Note that $f(w_T)-f(w_{*})$ can be correspondingly bounded by $\\frac\\mu2\\|w_T-w_{*}\\|^2\\le f(w_T)-f(w_{*})\\le\\frac L2\\|w_T-w_{*}\\|^2$.\nNote that only the strongly convex case can bound $\\|w_T-w_{*}\\|$, because a merely convex function can have flat regions, so $x_{*}$ is not uniquely defined. However, we can notice that whether we bound $f(w_T)-f(w_{*})$ or $\\|w_T-w_{*}\\|^2$, there is always one step that converts between $\\|w_{t+1}-w_{*}\\|^2$ and the expansion of $\\|(w_{t+1}-w_t)+(w_t-w_{*})\\|^2$. Theorem 13. $f\\in\\fF^{1,1}_L(\\R^n)$ then for $0\u0026lt;\\eta\\le \\frac1L$, SGD converges at rate $\\frac{1}{\\sqrt T}$: $$ \\Ex(f(\\overline{w_T}))-f(w_{*})\\le\\frac{\\|w_0-w_{*}\\|^2}{2\\eta T}+\\eta\\sigma^2. $$ where $\\sigma^2\\ge\\Var(G_t)=\\Ex(\\|G_t\\|^2)-\\lVert\\Ex(G_t)\\rVert^2=\\Ex(\\|G_t\\|^2)-\\|\\nabla f(w_t)\\|^2$. Take $\\eta=\\Theta(\\frac{1}{\\sqrt T})$ to get the rate.\nProof. $$ \\eq{ \\Ex(f(w_{t+1}))\u0026amp;\\le f(w_t)+\\ip{\\nabla f(w_t),\\Ex(w_{t+1}-w_t)}+\\frac L2\\Ex(\\|w_{t+1}-w_t\\|^2)\\\\ \u0026amp;=f(w_t)-\\eta\\|\\nabla f(w_t)\\|^2+\\frac{L\\eta^2}2\\Ex(\\|G_t\\|^2)\\\\ \u0026amp;=f(w_t)-\\eta\\|\\nabla f(w_t)\\|^2+\\frac{L\\eta^2\\sigma^2}2+\\frac{L\\eta^2}2\\|\\nabla f(w_t)\\|^2\\\\ \u0026amp;\\le f(w_t)-\\frac\\eta2\\|\\nabla f(w_t)\\|^2+\\frac{\\eta\\sigma^2}2\u0026amp;[\\sim\\text{descent lemma}]\\\\ \\hline \u0026amp;\\le f(w_{*})+\\ip{\\nabla f(w_t),w_t-w_{*}}-\\frac\\eta2\\|\\nabla f(w_t)\\|^2+\\frac{\\eta\\sigma^2}2\u0026amp;[\\text{convexity}]\\\\ \u0026amp;=f(w_{*})+\\ip{\\Ex(G_t),w_t-w_{*}}-\\frac\\eta2\\lVert\\Ex(G_t)\\rVert^2+\\frac{\\eta\\sigma^2}2\\\\ \u0026amp;=f(w_{*})+\\ip{\\Ex(G_t),w_t-w_{*}}-\\frac\\eta2\\Ex(\\|G_t\\|^2)+\\eta\\sigma^2\\\\ \u0026amp;=f(w_{*})-\\Ex\\left(\\frac{1}{\\eta}\\ip{w_{t+1}-w_t,w_t-w_{*}}+\\frac{1}{2\\eta}\\|w_{t+1}-w_t\\|^2\\right)+\\eta\\sigma^2\\\\ \u0026amp;=f(w_{*})-\\frac1{2\\eta}\\Ex(\\|w_{t+1}-w_{*}\\|^2)+\\frac1{2\\eta}\\|w_t-w_{*}\\|^2+\\eta\\sigma^2\u0026amp;[\\text{completing the square}]\\\\ \\implies\\sum_{i=1}^T\\Ex(f(w_i))\u0026amp;\\le Tf(w_{*})+\\frac{1}{2\\eta}\\|w_0-w_{*}\\|^2-\\frac{1}{2\\eta}\\Ex(\\|w_T-w_{*}\\|^2)+T\\eta\\sigma^2\u0026amp;[\\text{telescoping}]\\\\ \\implies \\Ex(f(\\overline{w_T}))\u0026amp;\\le f(w_{*})+\\frac{\\|w_0-w_{*}\\|^2}{2\\eta T}+\\eta\\sigma^2\u0026amp;[\\text{Jensen}] } $$\nTheorem 14. $f\\in \\fS^{1,1}_{\\mu,L}(\\R^n)$ then for $0\u0026lt;\\eta\\le\\frac2L$, SGD converges at rate $\\frac{\\log T}{T}$: $$ \\Ex\\left(\\|w_T-w_{*}\\|^2\\right)\\le\\left(1-\\eta\\mu\\right)^T\\|w_0-w_{*}\\|^2+\\frac{\\eta\\sigma^2}{\\mu} $$ Since $(1-\\eta\\mu)^T\\le\\e^{-\\eta\\mu T}$, take $\\eta=C\\frac{\\log T}{T}$ to get the rate.\nProof. $$ \\eq{ \\Ex(\\|w_{t+1}-w_{*}\\|^2)\u0026amp;=\\eta^2\\Ex(\\|G_t\\|^2)-2\\eta\\ip{\\nabla f(w_t),w_t-w_{*}}+\\|w_t-w_{*}\\|^2\\\\ \u0026amp;\\le\\eta^2\\|\\nabla f(w_t)\\|^2+\\eta^2\\sigma^2-2\\eta\\left(f(w_t)-f(w_{*})+\\frac\\mu2\\|w_t-w_{*}\\|^2\\right)+\\|w_t-w_{*}\\|^2\\\\ \u0026amp;\\le(1-\\eta\\mu)\\|w_t-w_{*}\\|^2+\\eta^2\\sigma^2\\\\ \\implies\\Ex(\\|w_T-w_{*}\\|^2)\u0026amp;\\le(1-\\eta\\mu)^T\\left(\\|w_0-w_{*}\\|^2-\\frac{\\eta\\sigma^2}{\\mu}\\right)+\\frac{\\eta\\sigma^2}{\\mu}\\le(1-\\eta\\mu)^T\\|w_0-w_{*}\\|^2+\\frac{\\eta\\sigma^2}{\\mu}\u0026amp;[\\text{series}] } $$\nThis is basically the same as theorem 9, so it is written briefly. Theorem 15. $f\\in \\fS^{1,1}_{\\mu,L}(\\R^n)$ then for $0\u0026lt;\\eta\\le\\frac{2}{\\mu+L}$, SGD: $$ \\Ex\\left(\\|w_T-w_{*}\\|^2\\right)\\le\\left(1-2\\eta\\frac{\\mu L}{\\mu+L}\\right)^T\\|w_0-w_{*}\\|^2+\\eta\\sigma^2\\frac{\\mu+L}{2\\mu L} $$ Definition 8 (variance reduction). Here we denote the average of $f_i$ as $f$, the average of $g_i$ as $g$.\nSVRG: $w_0=\\tilde w_s$, $w_{t+1}=w_t-\\eta(\\nabla f_i(w_t)-\\nabla f_i(\\tilde w_s)+\\nabla f(\\tilde w_s))$ for random $i$, $\\tilde w_{s+1}=w_t$ for random $t\\in[0,m)$. SAG: $w_{t+1}=w_t-\\eta(\\frac1n\\nabla f_i(w_t)-\\frac1ng_i+g)$ and $g_i:=\\nabla f_i(w_t)$ for random $i$. SAGA: $w_{t+1}=w_t-\\eta(\\nabla f_i(w_t)-g_i+g)$ and $g_i:=\\nabla f_i(w_t)$ for random $i$. It\u0026rsquo;s easy to see that SVRG and SAGA are unbiased, while SAG is biased.\nTheorem 16. $f_i\\in \\fS^{1,1}_{\\mu,L}(\\R^n)$, then for $0\u0026lt;\\eta\u0026lt;\\frac{1}{4L}$, SVRG converges at linear rate: $$ \\Ex\\left(f(\\tilde w_T)-f(w_{*})\\right)\\le\\left(\\frac{1}{\\mu m\\eta(1-2\\eta L)}+\\frac{2\\eta L}{1-2\\eta L}\\right)^T\\left(f(\\tilde w_0)-f(w_{*})\\right) $$ For example, take $\\eta=\\frac1{8L}$, $m=\\frac{64L}{\\mu}$, the coefficient becomes $\\frac12$.\nProof. Denote $G_t=\\nabla f_i(w_t)-\\nabla f_i(\\tilde w_s)+\\nabla f(\\tilde w_s)$. $$ \\eq{ \\Ex\\left(\\|G_t\\|^2\\right)\u0026amp;=\\Ex\\left(\\|\\nabla f_{i_t}(w_t)-\\nabla f_{i_t}(\\tilde w)+\\nabla f(\\tilde w)\\|^2\\right)\\\\ \u0026amp;=2\\Ex\\left(\\|\\nabla f_{i_t}(w_t)-\\nabla f_{i_t}(w_{*})\\|^2\\right)+2\\Ex\\left(\\|\\nabla f_{i_t}(w_{*})-\\nabla f_{i_t}(\\tilde w)+\\nabla f(\\tilde w)\\|^2\\right)\u0026amp;[\\|a+b\\|^2\\le2\\|a\\|^2+2\\|b\\|^2]\\\\ \u0026amp;=2\\Ex\\left(\\|\\nabla f_{i_t}(w_t)-\\nabla f_{i_t}(w_{*})\\|^2\\right)+2\\Ex\\left(\\|\\nabla f_{i_t}(w_{*})-\\nabla f_{i_t}(\\tilde w)-\\Ex(\\nabla f_{i_t}(w_{*})-\\nabla f_{i_t}(\\tilde w))\\|^2\\right)\u0026amp;[\\nabla f(w_{*})=0]\\\\ \u0026amp;\\le 2\\Ex\\left(\\|\\nabla f_{i_t}(w_t)-\\nabla f_{i_t}(w_{*})\\|^2\\right)+2\\Ex\\left(\\|\\nabla f_{i_t}(w_{*})-\\nabla f_{i_t}(\\tilde w)\\|^2\\right)\u0026amp;[\\Var\\le{\\Ex}^2]\\\\ \u0026amp;=4L\\left(f(w_t)-f(w_{*})+f(\\tilde w)-f(w_{*})\\right)\u0026amp;[\\text{theorem 5}] } $$\n$$ \\eq{ \\Ex\\left(\\|w_{t+1}-w_{*}\\|^2\\right)\u0026amp;=\\eta^2\\Ex\\left(\\|G_t\\|^2\\right)-2\\eta\\ip{\\nabla f(w_t),w_t-w_{*}}+\\|w_t-w_{*}\\|^2\u0026amp;[\\text{expanding the square}]\\\\ \u0026amp;\\le4\\eta^2L\\left(f(w_t)-f(w_{*})+f(\\tilde w)-f(w_{*})\\right)+2\\eta\\ip{\\nabla f(w_t),w_{*}-w_t}+\\|w_t-w_{*}\\|^2\\\\ \u0026amp;\\le4\\eta^2L\\left(f(w_t)-f(w_{*})+f(\\tilde w)-f(w_{*})\\right)+2\\eta\\left(f(w_{*})-f(w_t)-\\frac\\mu2\\|w_t-w_{*}\\|^2\\right)+\\|w_t-w_{*}\\|^2\u0026amp;\\text{[convexity]}\\\\ \u0026amp;=(1-\\eta\\mu)\\|w_t-w_{*}\\|^2-2\\eta(1-2\\eta L)\\left(f(w_t)-f(w_{*})\\right) +4\\eta^2 L\\left(f(\\tilde w)-f(w_{*})\\right)\\\\ \u0026amp;\\le \\|w_t-w_{*}\\|^2-2\\eta(1-2\\eta L)\\left(f(w_t)-f(w_{*})\\right) +4\\eta^2 L\\left(f(\\tilde w)-f(w_{*})\\right)\\\\ \\implies2\\eta(1-2\\eta L)\\left(f(w_t)-f(w_{*})\\right)\u0026amp;\\le\\|w_t-w_{*}\\|^2-\\|w_{t+1}-w_{*}\\|^2+4\\eta^2L\\left(f(\\tilde w)-f(w_{*})\\right)\\\\ \\implies2\\eta(1-2\\eta L)\\cdot\\Ex\\left(f({\\tilde w}^\\prime)-f(w_{*})\\right)\u0026amp;\\le\\frac 1m\\left(\\|w_0-w_{*}\\|^2-\\|w_m-w_{*}\\|^2\\right)+4\\eta^2L\\left(f(\\tilde w)-f(w_{*})\\right)\u0026amp;[\\text{telescoping}]\\\\ \u0026amp;\\le\\frac1m\\|\\tilde w-w_{*}\\|^2+4\\eta^2L\\left(f(\\tilde w)-f(w_{*})\\right)\\\\ \u0026amp;\\le\\left(\\frac{2}{\\mu m}+4\\eta^2L\\right)\\left(f(\\tilde w)-f(w_{*})\\right)\u0026amp;[\\text{strong convexity}]\\\\ \\implies\\Ex\\left(f({\\tilde w}^\\prime)-f(w_{*})\\right)\u0026amp;\\le\\left(\\frac{1}{\\mu m\\eta(1-2\\eta L)}+\\frac{2\\eta L}{1-2\\eta L}\\right)\\left(f(\\tilde w)-f(w_{*})\\right) } $$\nThe core idea of SVRG is to show that the function value grows faster than the gradient norm. Then, at the cost of only being able to bound function values, it converts the variance term (originally treated as a constant) into a difference of function values, and in turn telescopes $\\|w_t-w_{*}\\|^2$. Note that when convexity is used for the first time, the $\\eta\\mu$ term becomes useless here. Another issue is how to bound $\\sum(f(w_t)-f(w_{*}))$; this is the same as in SGD. In fact, taking an average is also fine, and randomly selecting one point is also correct, but for the specific choice ${\\tilde w}^\\prime=w_m$, no proof is currently known. method GD SVRG calculation need to calculate $\\nabla f$ on the full batch each iteration need to calculate $\\nabla f$ on the full batch each outer loop complexity $\\O(\\lvert S\\rvert\\cdot\\frac L\\mu\\log\\epsilon^{-1})$ $\\O((\\lvert S\\rvert+\\frac L\\mu)\\log\\epsilon^{-1})$ Both SAG and SAGA leads to linear convergence of $\\|w_T-w_{*}\\|^2$, and their complexities are both $\\O(\\max\\set{|S|,\\frac L\\mu}\\log\\epsilon^{-1})$. For the non-strongly convex case, all three methods have $\\frac1T$ convergence. The proof of SAG is just crooked, while SVRG and SAGA are both simpler. More details can be found here. Definition 9 (Bergman divergence). Given a $1$-strongly convex function $w$, define Bergman divergence $$ V_x(y)=w(y)-w(x)-\\ip{\\nabla w(x),y-x} $$ Definition 10 (mirror descent). $x_{t+1}=\\argmin_y\\Set{\\ip{\\eta\\nabla f(x_t),y-x_t}+V_{x_t}(y)}$.\nNotice that when $w(x)=\\frac12\\|x\\|_2^2$ it\u0026rsquo;s just GD. We can say GD is a special case of MD. Another interpretation of MD is \u0026ldquo;type-safe\u0026rdquo; GD. We know from calculus that $\\nabla f(x)$ is not essentially a vector, but rather a linear functional represented by a vector, so subtracting $\\eta\\nabla f(x_t)$ from $x_t$ does not really make sense. By introducing $w$, we do $x_t\\xrightarrow{\\nabla w(\\cdot)}\\theta_t\\xrightarrow{-\\eta\\nabla f(x_t)}\\theta_{t+1}\\xrightarrow{\\nabla w^{-1}(\\cdot)}x_{t+1}$, which can be easily verified to be equivalent to the definition above. The convexity of $w$ guarantees a bijection between the primal space and the dual space. The intuition of $w$ is that it defines the landscape of the parameter space (primal space)—think of a sphere, where moving on it should always follow the great circle. See 17.2 of this note for a detailed explanation. Lemma. $\\ip{-\\nabla V_x(y),y-u}=V_x(u)-V_y(u)-V_x(y)$.\nTheorem 17. $f\\in\\fF^{1,0}_\\rho(\\R^n)$ then MD converges at rate $\\frac{\\rho}{\\sqrt T}$: $$ f(\\overline{x_T})-f(x_{*})\\le\\frac{V_{x_0}(x_{*})}{\\eta T}+\\frac{\\eta\\rho^2}{2} $$ Take $\\eta=\\Theta(\\frac{1}{\\rho\\sqrt T})$ to get the rate.\nProof. $$ \\eq{ \\eta(f(x_t)-f(x_{*}))\u0026amp;\\le\\eta\\ip{\\nabla f(x_t),x_t-x_{*}}\u0026amp;[\\text{convexity}]\\\\ \u0026amp;=\\eta\\ip{\\nabla f(x_t),x_t-x_{t+1}}+\\eta\\ip{\\nabla f(x_t),x_{t+1}-x_{*}}\\\\ \u0026amp;=\\eta\\ip{\\nabla f(x_t),x_t-x_{t+1}}+\\ip{-\\nabla V_{x_t}(x_{t+1}),x_{t+1}-x_{*}}\u0026amp;[\\text{minimization}]\\\\ \u0026amp;=\\eta\\ip{\\nabla f(x_t),x_t-x_{t+1}}+V_{x_t}(x_{*})-V_{x_{t+1}}(x_{*})-V_{x_t}(x_{t+1})\\\\ \u0026amp;\\le\\eta\\ip{\\nabla f(x_t),x_t-x_{t+1}}-\\frac12\\|x_t-x_{t+1}\\|^2+V_{x_t}(x_{*})-V_{x_{t+1}}(x_{*})\u0026amp;[1\\text{-strongly convexity}]\\\\ \u0026amp;\\le\\frac{\\eta^2}2\\|\\nabla f(x_t)\\|^2+V_{x_t}(x_{*})-V_{x_{t+1}}(x_{*})\u0026amp;[\\text{completing the square}]\\\\ \\implies\\eta\\sum_{i=0}^{T-1}(f(x_i)-f(x_{*}))\u0026amp;\\le\\frac{\\eta^2\\rho^2T}{2}+V_{x_0}(x_{*})-V_{x_T}(x_{*})\u0026amp;[\\text{telescoping}]\\\\ \\implies f(\\overline{x_T})-f(x_{*})\u0026amp;\\le\\frac{\\eta\\rho^2}{2}+\\frac{V_{x_0}(x_{*})-V_{x_T}(x_{*})}{\\eta T}\u0026amp;[\\text{Jensen}] } $$\nMatrix Completion Problem Definition 11. Given a $n\\times m$ matrix $A$ with some missing entries. The matrix completion problem is that you need to determine the missing entries in a reasonable way. Here are some goals:\n$\\min\\r(A)$ $\\min\\|A\\|_{*}$, i.e. nuclear norm of $A$ $\\min\\|P_\\Omega(UV^\\top)-P_\\Omega(A)\\|_F^2$, where $U\\in\\R^{n\\times r}$, $V\\in\\R^{m\\times r}$, $r$ is the desired rank and $P_\\Omega$ means setting the entries of originally unknown positions to $0$. Here are some assumptions:\n$\\min\\r(A)\\ll n,m$, and we have enough observed entries to pass the information lower bound. The observed entries are uniformly sampled. For example, if a whole row is unobserved, then a left singular vector of $A$ is arbitrary. Uniform sampling can prevent this kind of thing. Incoherence. Let the SVD of $A$ be $A=U\\Sigma V^\\top$, then the $2$-norm of every row in $U$ should be $\\le\\sqrt{ur/n}$, and the $2$-norm of every row in $V$ should be $\\le\\sqrt{ur/m}$, where $u$ is a constant. You can get intuition from Section 4 of this course note. It is shown that $\\min\\r(A)$ is NP-hard (by reduction from the Maximum-Edge-Biclique problem), even under the above assumptions and with the goal relaxed to a constant-ratio approximation (see this paper Computational Limits for Matrix Completion).\nThe case where the goal is minimizing the nuclear norm is a (convex) SDP problem, but that problem does not have sufficiently efficient algorithms.\nConsider $\\min\\|P_\\Omega(UV^\\top)-P_\\Omega(A)\\|_F^2$. It is not convex, e.g. consider $A=[1]$:\n$U=\\mat{\\frac12}$, $V=\\mat{2}$, $\\ell=0$ $U=\\mat{2}$, $V=\\mat{\\frac12}$, $\\ell=0$ $U=\\mat{\\frac 54}$, $V=\\mat{\\frac 54}$, $\\ell=\\frac9{16}$. However, if one of $U$ and $V$ is fixed, then it\u0026rsquo;s convex: $$ \\eq{ \u0026amp;\\|P_\\Omega(U_1V^\\top)-P_\\Omega(A)\\|_F^2+\\|P_\\Omega(U_2V^\\top)-P_\\Omega(A)\\|_F^2\\\\ \\ge{}\u0026amp;\\frac12\\|P_\\Omega(U_1V^\\top)+P_\\Omega(U_2V^\\top)-2P_\\Omega(A)\\|_F^2\\\\ ={}\u0026amp;2\\left\\|P_\\Omega\\left(\\frac{U_1+U_2}2V^\\top\\right)-P_\\Omega(A)\\right\\|_F^2 } $$ We can see that it\u0026rsquo;s just a least-squares problem. Here is the alternating least squares minimization method: alternatively fix $U$/$V$ and minimize the other one.\nUnder some reasonable additional assumptions, we can prove that the original rank-$r$ matrix $M$ is uniquely determined, and the method converges to the answer at a linear rate.\nSGD under Non-convex Landscape The reason we suddenly talk about the matrix completion problem is that a bunch of practical problems like matrix completion are proved to have the property called \u0026ldquo;no-spurious-local-minimum\u0026rdquo;, that is, all local minima are equal. In this case, finding a local minimum is equivalent to finding a global minimum. You can refer to a series of papers:\nEscaping From Saddle Points—Online Stochastic Gradient for Tensor Decomposition Matrix Completion has No Spurious Local Minimum How to Escape Saddle Points Efficiently No Spurious Local Minima in Nonconvex Low Rank Problems: A Unified Geometric Analysis Theorem 18. For a bounded, smooth, Hessian smooth and strict saddle function $f$, SGD converges to some local minimum at rate $\\tilde\\O(\\sqrt[4]T)$ w.h.p. More specifically:\nNoise $\\xi$ must satisfy $\\Ex(\\xi^\\top\\xi)=\\sigma^2I$. Hessian smooth means Lipschitz condition on $\\nabla^2f$. $f$ needs to satisfy: if at some point $x$, $|\\nabla f(x)|$ is small, $\\lambda_{\\min}(\\nabla^2f(x))$ is not large negative, then there must be a local minimum near $x$ and $f$ must be strongly convex near $x$. This condition can be further specified by four parameters, whose polynomial determines the constant inside the convergence rate. The rate also depends on $\\log\\zeta^{-1}$ if we want to achieve $1-\\zeta$ probability. Proof strategy.\nWhen $|\\nabla f|$ is large, we can use the methods already taught to show that each step the value of $f$ must decrease by some constant. When close to a local minimum, use martingale-related theory (Azuma\u0026rsquo;s inequality) to show that the probability of leaving the local-minimum neighborhood within a certain number of steps is small. When $|\\nabla f|$ is small but the point is a saddle point/local maximum rather than a local minimum, use the existence of a negative direction in $\\nabla^2 f$ to show that SGD\u0026rsquo;s random perturbation makes $x$ find that negative direction and escape the saddle point (note that if it finds a positive direction, it quickly returns). Specifically, if $\\lambda_{\\min}(\\nabla^2 f(x))\\le-\\gamma$, first assume the neighborhood of $x$ is a perfect quadratic surface (dropping higher-order terms in the Taylor expansion), and use a similar taught method to show escape is guaranteed (the value of $f$ decreases by some constant after several steps). Then use martingale theory to show that the actual trajectory is close to the ideal trajectory with high probability. For the first and third cases, since $f$ is bounded above and below, they cannot happen too many times; therefore, within a certain number of steps, with high probability there is at least one moment near a local minimum, after which we use the second case. Generalization Theory Settings \u0026amp; Notes on Type-safe Requirements There are several objects under the setting of generalization theory:\nDomain of input data $X$ Labeling function $f:X\\to\\set{0,1}$ Probability distribution on data $\\pd\\in\\Delta(X)$ Joint distribution on data and label $\\pd\\in\\Delta(X\\times\\set{0,1})$ Training input $S\\in X^m$ Training data $S\\in\\set{(x,f(x))\\mid x\\in X}^m$ Hypothesis $h:X\\to\\set{0,1}$ Hypothesis class $\\hy\\subseteq\\set{h:X\\to\\set{0,1}}$ Learning algorithm $A:(X\\times\\set{0,1})^{*}\\to(X\\to\\set{0,1})$ Loss function of some distribution and label function $L_{\\pd,f}(h)=\\Ex_{x\\sim\\pd}[h(x)\\ne f(x)]$ Loss function of some joint distribution $L_{\\pd}=\\Ex_{(x,y)\\sim\\pd}[h(x)\\ne y]$ Loss function of some inputs and label function $L_{S,f}=\\sum_{x\\in S}[h(x)\\ne f(x)]/|S|$ This collection of objects can certainly be characterized well in the language of category theory; maybe I\u0026rsquo;ll add it later. The most annoying thing is that the learning algorithm only receives a sequence/set of pairs (labeled data), but this forces us to either use the joint distribution (which needs a stupid realizability claim), or project $S$ to the sequence/set consisting only of inputs, $S|x$, thus complicating the notation. So below, I will treat $S$ ambiguously: it includes labels only when plugged into $A$ or sampled from the joint distribution (in the agnostic PAC case), and at other times it only contains inputs.\nBinary Classification Theorem 1 (no-free-lunch). $\\forall$ learning algorithm $A$ for binary classification, $\\forall m\\le |X|/2$, $\\exists\\pd\\in\\Delta(X),f:X\\to\\set{0,1}$, $$ \\Pr_{S\\sim\\pd^m}\\left[L_{\\pd,f}(A(S))\\ge\\frac18\\right]\\ge\\frac17 $$ Proof. If we can prove $$ \\exists\\pd,f,\\Ex_{S\\sim\\pd^m}\\left(L_{\\pd,f}(A(S))\\right)\\ge\\frac14\\tag{1} $$ then by an argument similar to the proof of Markov inequality, $$ \\eq{ \u0026amp;1\\times\\Pr_{S\\sim\\pd^m}\\left[L_{\\pd,f}(A(S))\\ge\\frac18\\right]+\\frac18\\times\\Pr_{S\\sim\\pd^m}\\left[L_{\\pd,f}(A(S))\\le\\frac18\\right]\\ge\\Ex_{S\\sim\\pd^m}\\left(L_{\\pd,f}(A(S))\\right)\\ge\\frac14\\\\ \\implies{}\u0026amp;\\frac78\\times\\Pr_{S\\sim\\pd^m}\\left[L_{\\pd,f}(A(S))\\ge\\frac18\\right]+\\frac18\\ge\\frac14\\\\ \\implies{}\u0026amp;\\Pr_{S\\sim\\pd^m}\\left[L_{\\pd,f}(A(S))\\ge\\frac18\\right]\\ge\\frac17 } $$ So now let\u0026rsquo;s prove $(1)$. For simplicity assume $|X|=2m$. Just let $$ \\pd(x)=\\frac{1}{2m},\\forall x\\in X $$ There are $2^{2m}$ different $f$. $$ \\eq{ \u0026amp;\\frac1{2^{2m}}\\sum_f\\Ex_{S\\sim\\pd^m}(L_{\\pd,f}(A(S)))\\\\ ={}\u0026amp;\\frac1{2^{2m}}\\sum_f\\frac{1}{(2m)^m}\\sum_SL_{\\pd,f}(A(S))\\\\ \\ge{}\u0026amp;\\frac1{2^{2m}}\\sum_f\\frac{1}{(2m)^m}\\sum_S\\frac1{2m}\\sum_{x\\notin S}[A(S)(x)\\ne f(x)]\\\\ ={}\u0026amp;\\frac{1}{(2m)^m}\\sum_S\\frac1{2^{2m}}\\frac1{2m}\\sum_{f_0,f_1}\\left(\\sum_{x\\notin S}[A(S)(x)\\ne f_0(x)]+\\sum_{x\\notin S}[A(S)(x)\\ne f_1(x)]\\right)\\\\ \\ge{}\u0026amp;\\frac{1}{(2m)^m}\\sum_S\\frac{1}{2^{2m}}\\frac1{2m}2^{2m-1}m\\\\ ={}\u0026amp;\\frac14 } $$\nHere the key step is that we pair every two labeling functions, so that they behave the same on $S$ and behave the opposite on $X\\setminus S$. Like this: $$ \\begin{matrix} x:\u0026amp;\\square\u0026amp;\\triangle\u0026amp;\\diamonds\u0026amp;\\hearts\u0026amp;\\spades\u0026amp;\\bigstar\u0026amp;\\clubs\u0026amp;\\maltese\\\\ \\hline f_0:\u0026amp;\\color{green}0\u0026amp;\\color{green}1\u0026amp;\\color{green}1\u0026amp;\\color{green}0\u0026amp;\\color{red}0\u0026amp;\\color{green}1\u0026amp;\\color{green}0\u0026amp;\\color{red}1\\\\ f_1:\u0026amp;\\color{green}0\u0026amp;\\color{green}1\u0026amp;\\color{green}1\u0026amp;\\color{green}0\u0026amp;\\color{green}1\u0026amp;\\color{red}0\u0026amp;\\color{red}1\u0026amp;\\color{green}0\\\\ A(\\set{\\square,\\triangle,\\diamonds,\\hearts}):\u0026amp;0\u0026amp;1\u0026amp;1\u0026amp;0\u0026amp;1\u0026amp;1\u0026amp;0\u0026amp;0 \\end{matrix} $$\nThis theorem does not mention the hypothesis class, but clearly here $\\hy$ is the full set. Definition 1. W.r.t. some $\\hy,\\pd,f$, the realizability assumption means $\\exists h\\in\\hy$ achieving zero loss on $L_{\\pd,f}$. The Empirical Risk Minimization (ERM) hypothesis class on training set $S$ is $\\ERM_{\\hy}(S)=\\argmin_{h\\in\\hy}L_{S,f}(h)\\subseteq\\hy$.\nThere are two cases where the realizability assumption fails: one is that $f$ is random, i.e., the label is not fixed for the same data point; the other is that $\\hy$ does not cover all $2^{|X|}$ possibilities. Now we have four types of hypotheses from best to worst: the Bayes optimal predictor (which knows, for each data point, the probabilities of the two labels and outputs the more probable one), $\\argmin_{h\\in\\hy}L_{\\pd}(h)$, ERM, and an arbitrary hypothesis. For $h\\in\\hy$, we can decompose its loss as $L_{\\pd}(h)=\\epsilon_{\\rm app}+\\epsilon_{\\rm est}$, where: $\\epsilon_{\\rm app}=\\min_{h\\in\\hy}L_{\\pd}(h)$ is the approximation error, representing the best achievable loss within the current hypothesis class. To optimize it, we need to enlarge $\\hy$, but no matter how much we enlarge it, there is a lower bound: $L_\\pd(\\text{Bayes optimal predictor})$. $\\epsilon_{\\rm est}=L_{\\pd}(h)-\\epsilon_{\\rm app}$ is the estimation error. For hypotheses trained from training data, it measures the distortion caused by minimizing empirical loss (the gap to population loss). To optimize it, we need to increase $m$. Theorem 2. For finite $\\hy$ and $\\delta,\\eps\\in(0,1)$, let $m\\ge\\frac{\\log(|\\hy|/\\delta)}{\\eps}$. $\\forall\\pd,f$ for which the realizability assumption holds, $$ \\Pr_{S\\sim\\pd^m}\\left[\\forall h\\in\\ERM_{\\hy}(S),L_{\\pd,f}(h)\\le\\eps\\right]\\ge 1-\\delta $$ Proof. $$ \\eq{ \u0026amp;\\Pr_{S\\sim\\pd^m}\\left[\\exists h\\in\\ERM_{\\hy}(S),L_{\\pd,f}(h)\u0026gt;\\eps\\right]\\\\ \\le{}\u0026amp;\\sum_{h\\in \\hy\\mid L_{\\pd,f}(h)\u0026gt;\\eps}\\Pr_{S\\sim\\pd^m}[L_{S,f}(h)=0]\u0026amp;[\\text{union bound}]\\\\ ={}\u0026amp;\\sum_{h\\in \\hy\\mid L_{\\pd,f}(h)\u0026gt;\\eps}\\prod_{i=1}^m\\Pr_{x_i\\sim\\pd}[h(x_i)=f(x_i)]\u0026amp;[\\text{independency}]\\\\ \\le{}\u0026amp;\\sum_{h\\in \\hy\\mid L_{\\pd,f}(h)\u0026gt;\\eps}(1-\\eps)^m\\\\ \\le{}\u0026amp;|\\hy|(1-\\eps)^m\\\\ \\le{}\u0026amp;|\\hy|\\e^{-\\eps m}\\\\ \\le{}\u0026amp;\\delta } $$\nIntuitively, failure to learn can happen when representation power is too strong: after fitting the given data, predictions on unseen data can still be arbitrary. Learning succeeds when representation power is not too strong: even if you union-bound all hypotheses that perform well on training data but poorly in reality, the total probability remains small. The key point here is $|\\hy|$. Definition 2. An $\\hy$ is PAC learnable, iff $\\exists m_{\\hy}:(\\eps,\\delta)\\mapsto m$ and a learning algorithm $A$, s.t. $\\forall \\pd\\in\\Delta(X),f$ that satisfies the realizability assumption, $$ \\Pr_{S\\sim\\pd^{\\ge m}}\\left[L_{\\pd,f}(A(S))\\le\\eps\\right]\\ge 1-\\delta $$ Note that the hypothesis that $A$ returns is not necessarily ERM.\nCorollary. Finite hypothesis class is PAC learnable.\nDefinition 3. An $\\hy$ is agnostic PAC learnable, iff $\\exists m_{\\hy}:(\\eps,\\delta)\\mapsto m$ and a learning algorithm $A$, s.t. $\\forall \\pd\\in\\Delta(X\\times\\set{0,1})$, $$ \\Pr_{S\\sim\\pd^{\\ge m}}\\left[L_{\\pd}(A(S))\\le\\min_{h\\in\\hy}L_{\\pd}(h)+\\eps\\right]\\ge 1-\\delta $$ Obviously agnostic PAC learnable is stronger than (implies) PAC learnable. Surprisingly under (binary) classification settings, PAC learnable $\\implies$ agnostic PAC learnable, but the proof is nontrivial.\nTheorem 3. Some infinite hypothesis classes are also PAC learnable, for example $\\hy=\\set{h_a(x)=[x\u0026lt;a]\\mid a\\in\\R\\cup\\set{\\pm\\infty}}$.\nProof strategy. Let $$ m_{\\hy}(\\eps,\\delta)=\\frac{\\lceil\\log\\delta^{-1}\\rceil}{\\eps} $$ and $$ A(S)=h_a\\text{ where }a=\\max_{x\\in S\\mid f(x)=1}x $$ If the learned $a$ is within a neighborhood of $a_{*}$ whose probability mass is $\\le\\eps$, then we are good. The probability of the converse is $(1-\\eps)^m\\le\\delta$.\nIn class, someone asked whether a discrete distribution $\\pd$ causes issues. If we use the above $A$ directly, it indeed can cause problems, e.g., $\\pd(x)=\\delta(x)$. The key detail is that the hypothesis is $[x\u0026lt;a]$; if we change it to $[x\\le a]$, there is no issue. If it must be $[x\u0026lt;a]$, we can proceed in another way, namely by finding the smallest point whose label is $0$. Definition 4. An $\\hy$ shatters some finite set $C\\subseteq X$, iff for each of the label combination in $\\set{0,1}^{|C|}$, there exists a hypothesis in $\\hy$ output it on $C$. The Vapnik–Chervonenkis (VC)-dimension of some $\\hy$ is the maximal size of $C$ shattered by it. Specifically, if $\\hy$ can shatter sets of arbitrary large size, then it has infinite VC-dimension.\nTheorem 4 (generalized no-free-lunch). If some $\\hy$ shatters some set of size $2m$, then $\\forall A$, $\\exists\\pd$, $\\exists h\\in\\hy$ (acts as realizability assumption), $$ \\Pr_{S\\sim\\pd^{\\le m}}\\left[L_{\\pd,f}(A(S))\\ge\\frac18\\right]\\ge\\frac17 $$ Corollary. Infinite VC-dimension hypothesis class is not PAC learnable.\nTheorem 5 (the fundamental theorem of statistical learning). For some $\\hy$, $$ \\VC(\\hy)\u0026lt;\\infty\\iff\\hy\\text{ is PAC learnable}\\iff\\hy\\text{ is agnostic PAC learnable}\\iff\\text{any ERM is a successful (agnostic) PAC learner} $$ Quantitatively, $\\forall\\hy$ such that $\\VC(\\hy)=d\u0026lt;\\infty$, $\\hy$ is agnostic PAC learnable with $$ m_{\\hy}(\\eps,\\delta)=\\Theta\\left(\\frac{d+\\log\\delta^{-1}}{\\eps^2}\\right) $$ and $\\hy$ is PAC learnable with $$ \\Omega\\left(\\frac{d+\\log\\delta^{-1}}{\\eps}\\right)\\le m_{\\hy}(\\eps,\\delta)\\le\\Omicron\\left(\\frac{d\\log\\eps^{-1}+\\log\\delta^{-1}}{\\eps}\\right) $$ Note that the lower bound indicates that there exist some $\\pd$ and $f$ causing the learning algorithm to fail when the size of training data is below some constant $C$ times the quantity.\nThe proof involves Rademacher complexity, so here I only mention the intuition for the bound in the agnostic case. The strategy is to estimate the error rate of every hypothesis using $m$ samples. The requirement is that we should not mix up the best hypothesis with bad hypotheses that have population losses $\u0026gt;\\min L+\\eps$; in other words, the estimation error should be $\\le\\eps/2$ w.h.p. So we can use the Chernoff bound (where $\\eps^2$ appears) and then the union bound.\nRegression TBD\nSupervised Learning Here I skip the part about settings.\nPerceptron Definition 1. For a binary classification problem, perceptron is simply $f_w(x)=\\sgn(w^\\top x)$. There\u0026rsquo;s a learning algorithm for perceptron: when it misclassifies at least one data point, randomly pick some input $x$ on which it fails, $w\\xleftarrow{+}y\\cdot x$, so that $w^\\top x$ moves one step toward the correct sign.\nTheorem 1. When the data is linearly separable, moreover, $\\exists$ unit vector $w_{*}$ and $\\gamma\u0026gt;0$ s.t. $\\forall i$, $y_i(w_{*}^\\top x_i)\\ge\\gamma$ (i.e. there\u0026rsquo;s a $2\\gamma$ gap), if all $\\|x_i\\|\\le R$, then the perceptron learning algorithm converges in $\\O(\\frac{R^2}{\\gamma^2})$ steps.\nProof. For simplicity we assume $w_0=0$. On one hand $$ \\eq{ \\ip{w_t,w_{*}}\u0026amp;=\\ip{w_{t-1}+y_{t-1}x_{t-1},w_{*}}\\\\ \u0026amp;=\\ip{w_{t-1},w_{*}}+y_{t-1}(w_{*}^\\top x_{t-1})\\\\ \u0026amp;\\ge\\ip{w_{t-1},w_{*}}+\\gamma\\\\ \u0026amp;\\ge \\gamma t } $$ On the other hand $$ \\eq{ \\|w_t\\|^2\u0026amp;=\\|w_{t-1}\\|^2+2y_{t-1}\\ip{w_{t-1},x_{t-1}}+\\|x_{t-1}\\|^2\\\\ \u0026amp;\\le\\|w_{t-1}\\|^2+\\|x_{t-1}\\|^2\\\\ \u0026amp;\\le\\|w_{t-1}\\|^2+R^2\\\\ \u0026amp;\\le R^2t } $$ So $$ \\gamma^2t^2\\le\\ip{w_t,w_{*}}^2\\le\\|w_t\\|^2\\le R^2t\\implies t\\le\\frac{R^2}{\\gamma^2} $$\nLinear Regression Definition 2 (Kullback–Leibler divergence). $$ \\mathrm{KL}(p\\parallel q)=H(p,q)-H(p)=\\int p(x)\\log\\frac{p(x)}{q(x)}\\d x $$ Note that this is not a metric since it\u0026rsquo;s asymmetric and violates triangle inequality.\nNote the order. There are two intuitive views: first, the extra bits needed to encode $p$ using the optimal code for $q$; second, the “surprisal” when $p$ is treated as the reference distribution while the actual distribution is $q$. One clear point is that KL divergence penalizes cases where $p(x)\\ne 0$ but $q(x)\\approx 0$. Definition 3. For linear regression problem $f(x)=w^\\top x$, ridge regression comes from the motivation of minimizing $L(f,X,Y)$ while restricting $\\|w\\|_2^2\\le c$, and its actual form is $\\min. L(f,X,Y)+\\frac\\lambda2\\|w\\|_2^2$.\nDefinition 4. If we want to minimize $L(f,X,Y)$ while restricting $\\|w\\|_0\\le c$, then the problem is non-differentiable. $\\|w\\|_1$ can approximate $\\|w\\|_0$, so we finally turn the goal to $\\min. L(f,X,Y)+\\lambda\\|w\\|_1$. Furthermore, regular GD cannot be used because when some parameter is between $\\pm\\eta\\lambda$ it will never converge. So in practice we should use a proximal step, that is $$ w_{t+1}=\\sgn(w_t-\\eta\\nabla L)\\odot\\max(|w_t-\\eta\\nabla L|-\\eta\\lambda,0) $$ and it\u0026rsquo;s called LASSO regression. The name is from \u0026ldquo;least absolute shrinkage and selection operator\u0026rdquo;.\nCompressed Sensing Theorem 2 (Nyquist). $2f_0$ sampling rate is needed to fully reconstruct a signal with no frequency higher than $f_0$.\nProof strategy. Let $y(x)$ and $Y(x)$ be the original function and the function after Fourier transform. The sampling function is $$ \\text{Ш}_{1/f}(x)=\\sum_n\\delta(x-n/f) $$ and its Fourier transform can be proven to be $$ \\fF[\\text{Ш}_{1/f}](x)=f\\text{Ш}_f(x)=f\\sum_n\\delta(x-fn) $$ Since the Fourier transform of a Hadamard product is the convolution of the two Fourier transforms, in frequency space, $\\text{Ш}_{1/f}\\cdot y$ will be the summation of $Y$ shifted by $0$, $\\pm f_0$, $\\pm 2f_0$, etc. In order to make these replicates not overlap causing aliasing, we need $f\\ge 2f_0$.\nDefinition 5. However, real-world signals are usually sparse. For a vector $x\\in\\R^d$ that is sparse (low $\\|x\\|_0$), define the observation vector $y=Ax\\in\\R^n$ where $n\\ll d$ and $A$ is a fat matrix called the measurement matrix. Given only $y$ and $A$, it is usually possible to recover $x$ (uniquely, with the least number of nonzero entries). Thus a high-dimensional sparse vector is compressed into a low-dimensional vector, which is called compressed sensing.\nA real-world example is that $A$ is obtained by multiplying a measurement matrix $M$ and a basis matrix $\\Psi$. For face images, $\\Psi$ is the set of eigenfaces, $x$ is the weight of each eigenface, $\\Psi x$ is the observed image, and $A\\Psi x$ is some compressed result. For signals, $x$ is frequency information, $\\Psi$ is a basis of waves at different frequencies, and $M$ is the sampling matrix. So now the task is $$ \\argmin_{x: Ax=y}\\|x\\|_0\\longrightarrow\\argmin_{x:Ax=y}\\|x\\|_1 $$ by Lagrange multiplier, the function to be minimized becomes $$ \\|x\\|_1-\\lambda(Ax-y) $$ or equivalently, $$ \\|x\\|_1+\\lambda\\|Ax-y\\|_2^2 $$ or we can imagine there is noise $y=Ax+\\xi$, then without Lagrange multiplier the goal is $\\min.\\eta\\|y-Ax\\|_2^2+\\|x\\|_0$. Either of these conversions leads to exactly the same form as LASSO regression, differing only in meaning.\nmeanings $y$ $A$ $x$ $\\lambda$ CS observation measurement signal multiplier/coef on noise LASSO output input weights regularization Definition 6. A matrix $W\\in\\R^{n\\times d}$ is $(\\epsilon,s)$-RIP (restricted isometry property), iff $\\forall x\\in\\R^d$ s.t. $\\|x\\|_0\\le s$, $(1-\\epsilon)\\|x\\|_2^2\\le\\|Wx\\|_2^2\\le(1+\\epsilon)\\|x\\|_2^2$.\nTheorem 3. Let $W$ be a $(\\epsilon,2s)$-RIP matrix with $\\epsilon\u0026lt;1$, then $\\forall x$ with $\\|x\\|_0\\le s$, $$ \\argmin_{v:Wv=Wx}\\|v\\|_0=\\set{x} $$ Proof. If there\u0026rsquo;s $v\\ne x$ such that $Wv=Wx$ and $\\|v\\|_0\\le\\|x\\|_0$ then $W(v-x)=0$, violating $(1-\\epsilon)\\|x-v\\|_2^2\\le\\|W(x-v)\\|_2^2$.\nTheorem 4. Let $W$ be a $(\\epsilon,2s)$-RIP matrix with $\\epsilon\u0026lt;\\frac1{1+\\sqrt2}$, then $\\forall x$ with $\\|x\\|_0\\le s$, $$ \\argmin_{v:Wv=Wx}\\|v\\|_1=\\set{x} $$ Proof. In theorem 5, $x=x_s$.\nTheorem 5. Let $W$ be a $(\\epsilon,2s)$-RIP matrix with $\\epsilon\u0026lt;\\frac1{1+\\sqrt2}$, then $\\forall x$, let $x_s$ be any vector preserving the $s$ largest (in absolute value) elements of $x$ and other elements being $0$, then $$ \\forall \\tilde x\\in\\argmin_{v:Wv=Wx}\\|v\\|_1, \\|\\tilde x-x\\|_2\\le\\frac{2(1+\\rho)s^{-1/2}}{1-\\rho}\\|x-x_s\\|_1\\text{ where }\\rho=\\frac{\\sqrt2\\epsilon}{1-\\epsilon} $$\nNote that if $\\epsilon=\\frac{1}{1+\\sqrt2}$, $\\rho=1$.\nProof. Denote $(x_I)_i=[i\\in I]x_i$. Let $h=\\tilde x-x$.\nPartition the indices $[d]$ into $d/s$ sets $T_0\\sim T_{d/s-1}$. $T_0=\\text{top-}s\\argmax_{i\\in[d]}|x_i|$, and for $i\\ge 1$, $$ T_k=\\text{top-}s\\argmax_{i\\in[d]\\setminus\\bigcup_{j=0}^{k-1}T_j}|h_i| $$ So we need to bound $\\|h\\|_2$ by $\\|x_{\\overline{T_0}}\\|_1$.\nConsider $T_0\\cup T_1$ ($T_{0,1}$ in short); it contains indices of large elements in $x$ and $\\tilde x$. The idea is, $$ \\|h\\|_2\\le\\|h_{T_{0,1}}\\|_2+\\|h_{\\overline{T_{0,1}}}\\|_2 $$ and we bound these two components respectively.\n$$ \\eq{ \\|h_{\\overline{T_{0,1}}}\\|_2\u0026amp;\\le\\sum_{k\\ge 2}\\|h_{T_k}\\|_2\\\\ \u0026amp;\\le\\sum_{k\\ge 2}s^{1/2}\\|h_{T_k}\\|_{\\infty}\\\\ \u0026amp;\\le\\sum_{k\\ge 2}s^{-1/2}\\|h_{T_{k-1}}\\|_1\\\\ \u0026amp;\\le\\sum_{k\\ge 1}s^{-1/2}\\|h_{T_k}\\|_1\\\\ \u0026amp;=s^{-1/2}\\|h_{\\overline{T_0}}\\|_1 } $$ Lemma 1. For disjoint $I,J\\subset[d]$ with size $\\le s$, $\\lvert\\ip{Wv_I,Wv_J}\\rvert\\le\\epsilon\\|v_I\\|_2\\|v_J\\|_2$.\nProof. $$ \\eq{ \\ip{Wv_I,Wv_J}\u0026amp;=\\frac{\\|W(v_I+v_J)\\|_2^2-\\|W(v_I-v_J)\\|_2^2}{4}\\\\ \u0026amp;\\le\\frac{(1+\\epsilon)\\|v_I+v_J\\|_2^2-(1-\\epsilon)\\|v_I-v_J\\|_2^2}{4}\\\\ \u0026amp;=\\frac{\\epsilon}{2}\\left(\\|v_I\\|_2^2+\\|v_J\\|_2^2\\right)\\\\ \\implies\\ip{W\\hat v_I,W\\hat v_J}\u0026amp;\\le\\epsilon\\\\ \\implies\\ip{W v_I,W v_J}\u0026amp;\\le\\epsilon\\|v_I\\|_2\\|v_J\\|_2 } $$ Similarly $\\ip{W v_I,W v_J}\\ge-\\epsilon\\|v_I\\|_2\\|v_J\\|_2$. $$ \\eq{ (1-\\epsilon)\\|h_{T_{0,1}}\\|_2^2\u0026amp;\\le\\|Wh_{T_{0,1}}\\|_2^2\\\\ \u0026amp;=\\ip{Wh_{T_0}+Wh_{T_1},-Wh_{T_2}-Wh_{T_3}-\\cdots}\\\\ \u0026amp;\\le\\epsilon\\left(\\|h_{T_0}\\|_2+\\|h_{T_1}\\|_2\\right)\\sum_{k\\ge 2}\\|h_{T_k}\\|_2\\\\ \u0026amp;\\le\\sqrt2\\epsilon\\|h_{T_{0,1}}\\|_2\\sum_{k\\ge 2}\\|h_{T_k}\\|_2\\\\ \u0026amp;\\le\\sqrt2\\epsilon\\|h_{T_{0,1}}\\|_2s^{-1/2}\\|h_{\\overline{T_0}}\\|_1\\\\ \\implies\\|h_{T_{0,1}}\\|_2\u0026amp;\\le\\frac{\\sqrt2\\epsilon}{1-\\epsilon}s^{-1/2}\\|h_{\\overline{T_0}}\\|_1 } $$ Now $$ \\left\\{ \\eq{ \\|h_{T_{0,1}}\\|_2\u0026amp;\\le\\rho s^{-1/2}\\|h_{\\overline{T_0}}\\|_1\\\\ \\|h_{\\overline{T_{0,1}}}\\|_2\u0026amp;\\le s^{-1/2}\\|h_{\\overline{T_0}}\\|_1 } \\right. $$ Lemma 2. $\\|h_{\\overline{T_0}}\\|_1\\le\\|h_{T_0}\\|_1+2\\|x_{\\overline{T_0}}\\|_1$.\nProof. $$ \\left\\{ \\eq{ \\|x+h\\|_1\u0026amp;\\le\\|x\\|_1\\\\ \\|x\\|_1\u0026amp;=\\|x_{T_0}\\|_1+\\|x_{\\overline{T_0}}\\|_1\\\\ \\|x+h\\|_1\u0026amp;=\\|(x+h)_{T_0}\\|_1+\\|(x+h)_{\\overline{T_0}}\\|_1\\ge\\|x_{T_0}\\|_1-\\|h_{T_0}\\|_1+\\|h_{\\overline{T_0}}\\|_1-\\|x_{\\overline{T_0}}\\|_1 } \\right. $$ Substitute then shift the terms. Here is the visual intuition:\nFurthermore, we have $$ s^{-1/2}\\|h_{\\overline{T_0}}\\|_1\\le s^{-1/2}\\|h_{T_0}\\|_1+2s^{-1/2}\\|x_{\\overline{T_0}}\\|_1\\le\\|h_{T_0}\\|_2+2s^{-1/2}\\|x_{\\overline{T_0}}\\|_1 $$ Now $$ \\eq{ \\|h_{T_{0,1}}\\|_2\u0026amp;\\le\\rho s^{-1/2}\\|h_{\\overline{T_0}}\\|_1\\\\ \u0026amp;\\le\\rho\\left(\\|h_{T_0}\\|_2+2s^{-1/2}\\|x_{\\overline{T_0}}\\|_1\\right)\\\\ \u0026amp;\\le\\rho\\|h_{T_{0,1}}\\|_2+2\\rho s^{-1/2}\\|x_{\\overline{T_0}}\\|_1\\\\ \\implies\\|h_{T_{0,1}}\\|_2\u0026amp;\\le\\frac{2\\rho}{1-\\rho}s^{-1/2}\\|x_{\\overline{T_0}}\\|_1 } $$ and $$ \\eq{ \\|h_{\\overline{T_{0,1}}}\\|_2\u0026amp;\\le s^{-1/2}\\|h_{\\overline{T_0}}\\|_1\\\\ \u0026amp;\\le\\|h_{T_{0,1}}\\|_2+2s^{-1/2}\\|x_{\\overline{T_0}}\\|_1\\\\ \u0026amp;\\le\\frac{2}{1-\\rho}s^{-1/2}\\|x_{\\overline{T_0}}\\|_1 } $$ So $$ \\|h\\|_2\\le\\|h_{T_{0,1}}\\|_2+\\|h_{\\overline{T_{0,1}}}\\|_2\\le\\frac{2(1+\\rho)}{1-\\rho}s^{-1/2}\\|x_{\\overline{T_0}}\\|_1 $$\nTheorem 6. For some $d$, $s$, for some $n=\\Theta(\\epsilon^{-2}s\\log(d/\\delta\\epsilon))$, let $W\\in\\R^{n\\times d}$ where i.i.d. $W_{i,j}\\sim\\Nd(0,1/n)$. w.p. $\\ge 1-\\delta$, $W$ is $(\\epsilon,s)$-RIP.\nThe norms taken below are all $\\ell_2$-norm.\nLemma. $\\exists Q\\subset\\R^d$ of $\\O(\\epsilon^{-1})^d$ points, s.t. $\\forall\\|x\\|\\le 1$, $\\min_{v\\in Q}\\|x-v\\|\\le\\epsilon$.\nProof. Construct $$ Q_0=\\Set{-1,\\frac{1-k}k,\\cdots,0,\\frac1k,\\cdots,1}^d\\cap \\overline B_d(1) $$ so that $$ \\min_{v\\in Q}\\|x-v\\|\\le\\sqrt{\\left(\\frac1{2k}\\right)^2\\cdot d}=\\frac{\\sqrt d}{2k} $$ We can take $k\\ge\\sqrt d/2\\epsilon$. To estimate $|Q_0|$, we associate each point $x$ with the cube $x+[-1/2k,+1/2k]^d$. This implies that $\\overline B_d(1+\\sqrt d/2k)$ must contain all the cubes, so we can comfortably approximate $|Q_0|$ by the following method, without asymptotical error: $$ \\eq{ |Q_0|\u0026amp;\\approx\\frac{V_d}{(1/k)^d}\\\\ \u0026amp;=\\frac{\\pi^{d/2}}{\\Gamma(d/2+1)}k^d\\\\ \u0026amp;\\approx\\frac{\\pi^{d/2}\\e^{d/2+1}}{\\sqrt{2\\pi}(d/2+1)^{d/2-1}}\\frac{d^{d/2}}{2^d\\epsilon^d}\\\\ \u0026amp;\\approx\\left(\\sqrt{\\frac{\\pi\\e}2}\\epsilon^{-1}\\right)^d=\\O(\\epsilon^{-1})^d } $$ Lemma (Johnson–Lindenstrauss). $\\forall Q\\subset\\R^d$, for some $n=\\Theta(\\epsilon^{-2}\\log(|Q|/\\delta))$, let $W\\in\\R^{n\\times d}$ where i.i.d. $W_{i,j}\\sim\\Nd(0,1/n)$, w.p. $\\ge 1-\\delta$, $\\forall x\\in Q$, $(1-\\epsilon)\\|x\\|^2\\le\\|Wx\\|^2\\le(1+\\epsilon)\\|x\\|^2$.\nProof. For the complete proof of JL lemma, refer to this post. I\u0026rsquo;d like to review the proof sketch here.\nWe can normalize $x\\in Q$. Let $w_i$ be the $i$-th row of $W$, then $w_ix\\sim\\Nd(0,1/n)$ and $\\|Wx\\|^2\\sim\\chi_n^2/n$. By some tail bound, $$ \\Pr[\\|Wx\\|^2\\notin[1-\\epsilon,1+\\epsilon]]\\le\\e^{-\\Omega(n\\epsilon^2)} $$ and can be simplified as $\\delta/|Q|$. Then apply union bound.\nLemma. $\\forall Q\\subset\\R^d$ of $s$ orthonormal vectors, for some $n=\\Theta(\\epsilon^{-2}(\\log\\delta^{-1}+s\\log\\epsilon^{-1}))$, let $W\\in\\R^{n\\times d}$ where i.i.d. $W_{i,j}\\sim\\Nd(0,1/n)$, w.p. $\\ge 1-\\delta$, $\\forall x\\in\\span Q$, $(1-\\epsilon)\\|x\\|\\le\\|Wx\\|\\le(1+\\epsilon)\\|x\\|$.\nProof. Let $U\\in\\R^{s\\times|Q|}$ be the matrix consisting of vectors in $Q$ as column vectors. Apply JL lemma on $\\set{Uv\\mid v\\in Q_0}$ where $Q_0$ is the set constructed in the proof of lemma 1. Here we need $n=\\Theta(\\epsilon^{-2}\\log(\\O(\\epsilon^{-1})^s/\\delta))=\\Theta(\\epsilon^{-2}(\\log\\delta^{-1}+s\\log\\epsilon^{-1}))$. The result of JL lemma also implies $(1-\\epsilon)\\|x\\|\\le\\|Wx\\|\\le(1+\\epsilon)\\|x\\|$.\nAssume $\\max_{\\|x\\|=1}\\lVert Wx\\rVert=1+a$. Consider any unit vector $x\\in\\span Q$, $x=Ux_0$. Then by lemma 1, $\\exists v\\in Q_0$ such that $$ \\eq{ \\|Wx\\|\u0026amp;\\le\\|WUv\\|+\\|WU(x_0-v)\\|\\\\ \u0026amp;\\le(1+\\epsilon)\\|Uv\\|+(1+a)\\|U(x_0-v)\\|\\\\ \u0026amp;=(1+\\epsilon)\\|v\\|+(1+a)\\|x_0-v\\|\\\\ \u0026amp;\\le1+\\epsilon+(1+a)\\epsilon\\\\ \\implies1+a\u0026amp;\\le1+\\epsilon+(1+a)\\epsilon\\\\ \\implies a\u0026amp;\\le\\frac{2\\epsilon}{1-\\epsilon} } $$ and $$ \\eq{ \\|Wx\\|\u0026amp;\\ge\\|WUv\\|-\\|WU(x_0-v)\\|\\\\ \u0026amp;\\ge(1-\\epsilon)\\|v\\|-(1+a)\\|x_0-v\\|\\\\ \u0026amp;\\ge(1-\\epsilon)(\\|x_0\\|-\\|x_0-v\\|)-(1+a)\\|x_0-v\\|\\\\ \u0026amp;\\ge1-\\epsilon-(2-\\epsilon+a)\\epsilon\\\\ \u0026amp;\\ge1-3\\epsilon-\\epsilon^2-\\frac{2\\epsilon^3}{1-\\epsilon} } $$ Scale $\\epsilon$ to get the final result.\nProof of the original theorem. Two more details to go.\nBy $[(1-\\epsilon)^2,(1+\\epsilon)^2]\\subset[1-3\\epsilon,1+3\\epsilon]$, restore the square. Enumerate $Q$ over all $s$-element subsets of $\\set{e_1,\\cdots,e_d}$, and apply union bound. Now the probability becomes $1-\\binom ds\\delta$ so we should shrink $\\delta$ by $\\binom ds$ for every individual $Q$. The final $n$ will be $\\Theta(\\epsilon^{-2}\\log(\\binom ds\\delta^{-1})+s\\log\\epsilon^{-1})\\le\\Theta(\\epsilon^{-2}s\\log(d/\\delta\\epsilon))$. This theorem actually addresses the question of why compressed sensing can be used in real-life scenarios. If $v$ is some data that is not sparse but possesses some implicit sparsity, that is, $v=Ux$ for some orthonormal matrix $U$ and sparse vector $x$, then applying measurement to $v$ using some Gaussian matrix $W$ is also applying that to $x$ because $WU$ is also Gaussian. One can easily check that by calculating the variance and covariance. So the main point now becomes finding a set of \u0026ldquo;features\u0026rdquo;.\nIf $v$ is obtained by applying some nonlinear transformation $G(\\cdot)$ on $x$, there are also such kinds of guarantees:\nSupport Vector Machine Definition 7. For a linear classification problem, a support vector machine (SVM) constructs a linear separator, the one with the largest margin. Margin is defined as the distance from the separator to the closest point. Let the classifier be $f(x)=w^\\top x-b$. If there\u0026rsquo;s a point $x_+$ labeled $+$, then $f(x_+)$ should be $\u0026gt;0$ and by geometry, the margin is $\\frac{|w^\\top x_+-b|}{\\|w\\|_2}$. In other words, the problem becomes $$ \\max.\\frac{1}{\\|w\\|_2}\\quad\\text{s.t. }y_i(w^\\top x_i-b)\\ge 1 $$\nIf the data is not linearly separable, a penalty term is added, converting it to a relaxed version $$ \\min.\\|w\\|_2+\\lambda\\sum_i[y_i(w^\\top x_i-b)\u0026lt;1] $$ which is NP-Hard. A soft version is using hinge loss: $$ \\min.\\|w\\|_2+\\lambda\\sum_i\\max\\set{1-y_i(w^\\top x_i-b),0} $$ or $$ \\min.\\|w\\|_2+\\lambda\\sum_i\\xi_i\\quad\\text{s.t. } y_i(w^\\top x_i-b)\\ge 1-\\xi_i,\\;\\xi_i\\ge 0 $$ If we regard it as an L2 regularization, it\u0026rsquo;d better be $$ \\min.\\frac{\\|w\\|_2^2}2+\\lambda\\sum_i\\xi_i\\quad\\text{s.t. } y_i(w^\\top x_i-b)\\ge 1-\\xi_i,\\;\\xi_i\\ge 0 $$\nBy convention, below I\u0026rsquo;ll write $w^\\top x+b$ instead of $w^\\top x-b$.\nTheorem 7. For some optimization problem $$ \\min. f(x)\\quad\\text{s.t. }g_i(x)\\le 0,\\;h_j(x)=0 $$ Denote the optimal value as $p^{*}$.\nConsider the Lagrangian $$ \\la(x,\\lambda,\\nu)=f(x)+\\sum_i\\lambda_ig_i(x)+\\sum_j\\nu_jh_j(x) $$ There\u0026rsquo;s weak duality $$ \\max_{\\lambda\\ge 0,\\nu}\\min_x\\la(x,\\lambda,\\nu)\\le p^{*} $$ Under some condition, the inequality can turn into equality, introducing strong duality. When the primal problem is convex (both objective function $f$ and the feasible set are convex) and differentiable, satisfies Slater\u0026rsquo;s condition, and has strong duality, $$ x^{*} \\text{ is optimal}\\iff\\exists \\lambda^{*},\\nu^{*}\\text{ satisfying KKT}. $$ where the KKT conditions are $$ \\left\\{\\eq{ \u0026amp;g_i(x^{*})\\le 0,\\;h_j(x^{*})\\le 0\u0026amp;(\\text{Primal feasibility})\\\\ \u0026amp;\\lambda_i^{*}\\ge 0\u0026amp;(\\text{Dual feasibility})\\\\ \u0026amp;\\lambda_i^{*}g_i(x^{*})=0\u0026amp;(\\text{Complementary slackness})\\\\ \u0026amp;\\nabla_x\\la(x^{*},\\lambda^{*},\\nu^{*})=0\u0026amp;(\\text{Stationarity}) }\\right. $$ Definition 8. The Lagrangian dual of the above optimization problem is $$ \\max.\\left(\\min_x\\la(x,\\lambda,\\nu)\\right)\\quad\\text{s.t. }\\lambda\\ge 0 $$ Theorem 8. The dual problem of SVM, can be simplified as $$ \\max.\\sum_i\\alpha_i-\\frac12\\sum_i\\sum_j\\alpha_i\\alpha_jy_iy_j\\ip{x_i,x_j}\\quad\\text{s.t. }0\\le\\alpha_i(\\le\\lambda),\\;\\sum_i\\alpha_iy_i=0 $$ Proof. First consider linearly separable case. Recall the program $$ \\max.\\frac{1}{\\|w\\|_2}\\quad\\text{s.t. }y_i(w^\\top x_i+b)\\ge 1 $$ equivalently, $$ \\boxed{\\min.\\frac{\\|w\\|_2^2}{2}\\quad\\text{s.t. }1-y_i(w^\\top x_i+b)\\le 0} $$ Lagrangian $$ \\la(w,b,\\alpha)=\\frac{\\|w\\|_2^2}{2}-\\sum_i\\alpha_i(y_i(w^\\top x_i+b)-1) $$ Now use the KKT condition to simplify $\\la$ to be maximized. Take the gradient $$ \\nabla_w\\la(w,b,\\alpha)=w-\\sum_i\\alpha_iy_ix_i=0\\implies w=\\sum_i\\alpha_iy_ix_i $$\n$$ \\p_b\\la(w,b,\\alpha)=-\\sum_i\\alpha_iy_i=0 $$\nSubstitute back, $$ \\la(w_{*},b,\\alpha)=\\frac12\\left\\|\\sum_i\\alpha_iy_ix_i\\right\\|_2^2-\\sum_i\\alpha_iy_ix_i\\left(\\sum_j\\alpha_jy_jx_j^\\top\\right)+\\sum_i\\alpha_i=\\sum_i\\alpha_i-\\frac12\\sum_i\\sum_j\\alpha_i\\alpha_jy_iy_j\\ip{x_i,x_j} $$ Now the relaxed soft version: $$ \\boxed{\\min.\\frac{\\|w\\|_2^2}2+\\lambda\\sum_i\\xi_i\\quad\\text{s.t. } y_i(w^\\top x_i+b)\\ge 1-\\xi_i,\\;\\xi_i\\ge 0} $$ Lagrangian $$ \\la(w,b,\\xi,\\alpha,\\kappa)=\\frac{\\|w\\|_2^2}2+\\lambda\\sum_i\\xi_i-\\sum_i\\alpha_i(y_i(w^\\top x_i+b)-1+\\xi_i)-\\sum_i\\kappa_i\\xi_i $$\n$\\nabla_w$ part and $\\p_b$ part are the same. $$ \\nabla_\\xi\\la=\\lambda1-\\alpha-\\kappa=0\\implies\\alpha_i+\\kappa_i=\\lambda $$ Thus $$ \\eq{ \\la(w_{*},b,\\xi,\\alpha,\\kappa)\u0026amp;=\\frac12\\left\\lVert\\sum_i\\alpha_iy_ix_i\\right\\rVert_2^2+\\sum_i(\\alpha_i+\\kappa_i)\\xi_i-\\sum_i\\alpha_iy_ix_i\\left(\\sum_j\\alpha_jy_jx_j^\\top\\right)+\\sum_i\\alpha_i-\\sum_i\\alpha_i\\xi_i-\\sum_i\\kappa_i\\xi_i\\\\ \u0026amp;=\\sum_i\\alpha_i-\\frac12\\sum_i\\sum_j\\alpha_i\\alpha_jy_iy_j\\ip{x_i,x_j} } $$ which is the same as the separable case.\nMoreover: interpretation of $\\alpha_i$:\n$\\alpha_i=0$: the corresponding point is outside the margin (or coincidentally, on the margin) and can be deleted without affecting the result. $0\u0026lt;\\alpha_i\u0026lt;\\lambda$: the corresponding point is on the margin, and is the \u0026ldquo;supporting point\u0026rdquo;. $\\alpha_i=\\lambda$: the corresponding point is inside the margin / on the hyperplane / wrongly classified (or coincidentally, on the margin). To get $w$, calculate $\\sum_i\\alpha_iy_ix_i$. To get $b$, by complementary slackness condition, if there\u0026rsquo;s some $\\alpha_i\\in(0,\\lambda)$, then $b-y_iw^\\top x_i$. Otherwise it\u0026rsquo;s the degenerated case, for example: $(x_1,y_1)=(1,1)$, $(x_2,y_2)=(-1,-1)$, $\\lambda=0.25$. The dual problem is $$ \\max.\\alpha_1+\\alpha_2-\\frac12(\\alpha_1+\\alpha_2)^2\\quad\\text{s.t. }0\\le\\alpha_1,\\alpha_2\\le0.25,\\alpha_1-\\alpha_2=0 $$ Obviously we should choose $\\alpha_1=\\alpha_2=0.25$, thus $w=0.5$, and $b$ can be arbitrarily within $[-0.5,0.5]$. This scenario corresponds to that the penalty is so small that the optimal solution would rather violate the $y_i(w^\\top x_i+b)\\ge 1$ constraint than making $\\|w\\|$ big.\nQ: In principle, why do we ever consider the dual SVM?\nA: There are two evident reasons. First, usually there are only a few supporting points, thus $\\alpha$ is sparse; second, the kernel trick can only be applied to dual SVM.\nDefinition 9. Kernel trick is an extension of SVM in the scenario where input points are originally inseparable but can be transformed by some nonlinear function to some higher-dimensional space and separated (think of a disk region, $f(x,y)=(x,y,x^2+y^2)$). Here the transformation is called $\\phi$. The codomain of $\\phi$ may have too high a dimension to be stored explicitly. Kernel trick is about not writing out the transformation result explicitly, and only calculating $\\ip{\\phi(x_i),\\phi(x_j)}$. Specifically,\n$\\la$ only involves calculating such inner products. To classify inputted point $x$, we need to calculate $w^\\top x=\\sum_i\\alpha_iy_i\\ip{\\phi(x_i),\\phi(x)}$. The point is that $\\ip{\\phi(x_i),\\phi(x_j)}$ can usually be computed in a faster way than adding the products of each component together. Note that in the primal SVM, there\u0026rsquo;s no such benefit.\nExample. $\\phi(x_1,\\cdots,x_d)=(1,\\sqrt2x_1,\\cdots,\\sqrt2x_d,x_1^2,\\cdots,x_d^2,\\sqrt2x_1x_2,\\cdots,\\sqrt2x_{d-1}x_d)\\in\\R^{\\O(d^2)}$. $$ \\ip{\\phi(x),\\phi(y)}=1+2\\sum_ix_iy_i+\\sum_ix_i^2y_i^2+\\sum_i\\sum_jx_ix_jy_iy_j=(\\ip{x,y}+1)^2 $$ Theorem 9 (Mercer). Any positive semidefinite kernel\u0026rsquo;s matrix can be realized as a Gram matrix.\nDecision Tree Definition 10. A decision tree is a decision support recursive partitioning structure that uses a tree-like model of decisions and their possible consequences (taken from Wikipedia).\nDefinition 11. The greedy method of constructing a decision tree is as follows: now there are $n$ datapoints, each containing some inputs (attributes) and an output (correct answer). Select one of the input fields as the separating variable, which has the minimal weighted Gini index, then recursively call the division algorithm. For all the datapoints with some specific value on the specific input field ($x_k=x$ for some $k,x$), let the output be $y_{t_1},\\cdots,y_{t_n}$, then the Gini index / Gini impurity is defined as $$ 1-\\sum_y\\left(\\frac{\\#[y_{t_i}=y]}{n}\\right)^2=1-\\sum_y\\Pr_i[y_i=y\\mid x_{i,k}=x]^2 $$ and the weighted Gini index is the weighted average across all $x_i=j$, i.e. $$ \\sum_x\\frac{\\#[x_k=x]}{N}\\mathrm{Gini}_{k,x}=\\sum_x\\Pr_i[x_{i,k}=x]\\left(1-\\sum_y\\Pr_i[y_i=y\\mid x_{i,k}=x]^2\\right) $$ So it\u0026rsquo;s like an empirical version of information entropy.\nDefinition 12. Bagging is sampling random datapoints and random features (with replacement) and run (weak) learner on the sampled data. Random forest is to learn multiple (decision tree) models by bagging, then average/take the majority over the models when doing prediction.\nDecision tree can overfit arbitrarily, while random forest / boosting reduces overfitting (in some strongest sense) and is even comparable to DL methods nowadays in some specific tasks.\nDefinition 13. Boosting is an optimized way of combining weak classifiers. Different from the random forest, boosting considers building trees sequentially, dynamically adjusting the probability distribution on training data according to the previous performance. AdaBoost is an algorithm that specifies the weight adjusting strategy:\n$D_1$ is the uniform distribution over the datapoints. Every round, train on the $D_t$ using weak learner, to get the weak classifier $h_t$. Let $\\epsilon_t$ be the empirical loss (on $D_t$) of $h_t$. Let $\\alpha_t=\\frac12\\ln \\frac{1-\\epsilon_t}{\\epsilon_t}$. $D_{t+1}(i)\\propto D_t(i)\\cdot\\exp(-\\alpha_ty_ih_t(x_i))$. This means that if the prediction of $h_t$ is correct on datapoint $i$, scale down the weight assigned on it, otherwise scale up the weight. The final classifier is $H_{\\rm final}(x)=\\sgn(\\sum_t\\alpha_th_t(x))$ Notice that here $\\epsilon_t$ should be $\u0026lt;1/2$ so that $\\alpha_t\u0026gt;0$, meaning that $h$ cannot be some random guess.\nTheorem 10. Let $\\gamma_t=\\frac12-\\epsilon_t$. $L({H_{\\rm final}})\\le\\exp(-2\\sum_t\\gamma_t^2)$. Thus if $\\forall t$, $\\gamma_t\\ge\\gamma\u0026gt;0$, then $L(H_{\\rm final})\\le\\exp(-2T\\gamma^2)$.\nProof. Denote the normalization coefficient of $D_{t+1}$ as $Z_t$. Assume the algorithm runs for $T$ rounds.\nFirst, unwrap the definition recurrence of $D_{T+1}$: $$ D_{T+1}(i)=\\frac1m\\frac{\\exp\\left(-\\sum_{t=1}^T\\alpha_ty_ih_t(x_i)\\right)}{\\prod_{t=1}^TZ_t} $$ Second, expand the definition of $L(H_{\\rm final})$: $$ \\eq{ L(H_{\\rm final})\u0026amp;=\\frac1m\\sum_i[y_i\\ne H_{\\rm final}(x_i)]\\\\ \u0026amp;=\\frac1m\\sum_i\\left[y_i\\sum_t\\alpha_th_t(x_i)\\le 0\\right]\\\\ \u0026amp;\\le\\frac1m\\sum_i\\exp\\left(-y_i\\sum_t\\alpha_th_t(x_i)\\right)\\\\ \u0026amp;=\\sum_iD_{T+1}(i)\\prod_tZ_t\\\\ \u0026amp;=\\prod_tZ_t } $$ Finally, bound $Z_t$. Intuitively, since the loss is $\u0026lt;1/2$, $Z_t$ should be $\u0026lt;1$. $$ \\eq{ Z_t\u0026amp;=\\sum_iD_t(i)\\exp(-\\alpha_ty_ih_t(i))\\\\ \u0026amp;=\\exp(-\\alpha_t)\\sum_{i:h_t(i)=y_i}D_t(i)+\\exp(\\alpha_t)\\sum_{i:h_t(i)\\ne y_i}D_t(i)\\\\ \u0026amp;=\\exp(-\\alpha_t)(1-\\epsilon_t)+\\exp(\\alpha_t)\\epsilon_t\\\\ \u0026amp;=\\sqrt{\\frac{\\epsilon_t}{1-\\epsilon_t}}(1-\\epsilon_t)+\\sqrt{\\frac{1-\\epsilon_t}{\\epsilon_t}}\\epsilon_t\\\\ \u0026amp;=2\\sqrt{\\epsilon_t(1-\\epsilon_t)}\\\\ \u0026amp;=2\\sqrt{\\frac14-\\gamma_t^2}\\\\ \u0026amp;=\\sqrt{1-4\\gamma_t^2}\\\\ \u0026amp;=1-\\frac12(4\\gamma_t^2)-\\frac{1}{8(1-\\xi)^{3/2}}(4\\gamma_t^2)\\\\ \u0026amp;\\le1-2\\gamma_t^2\\\\ \u0026amp;\\le\\exp(-2\\gamma_t^2) } $$ Definition 14. AdaBoost is adaptive, in the sense that there\u0026rsquo;s no need to know $\\gamma$ in order to determine any hyperparameter of the algorithm, contrary to the GD family (need $L$, $\\mu$, etc.).\nExperiments have shown that AdaBoost does not suffer from overfitting, which can also be explained by the following two theorems.\nTheorem 11. It implies low population loss when the obtained classifier fits the training data with a considerable margin. Formally, w.p. $1-\\delta$ over training data $S\\sim D^m$, $\\forall f$ being convex combination of hypotheses, $$ \\Pr_{(x,y)\\sim D}[yf(x)\\le0]=\\Pr_{(x,y)\\sim U(S)}[yf(x)\\le\\theta]+\\O\\left(\\frac1{\\sqrt m}\\left(\\frac{\\log m\\log|\\hy|}{\\theta^2}+\\log\\frac1\\delta\\right)^{1/2}\\right) $$ Theorem 12. The margin of AdaBoost increases with the number of iterations. Formally, let $f(x)=\\sum_t\\alpha_th_t(x)/\\sum_t\\alpha_t$ (so $H_{\\rm final}(x)=\\sgn(f(x))$ still), $$ \\Pr_{(x,y)\\sim U(S)}[yf(x)\\le\\theta]\\le2^T\\prod_t\\sqrt{\\epsilon_t^{1-\\theta}(1-\\epsilon_t)^{1+\\theta}} $$ When $\\theta\\le 2\\gamma$, by monotonicity, $$ 2^T\\prod_t\\sqrt{\\epsilon_t^{1-\\theta}(1-\\epsilon_t)^{1+\\theta}}\\le2^T\\prod_t\\sqrt{\\left(\\frac12-\\gamma\\right)^{1-\\theta}\\left(\\frac12+\\gamma\\right)^{1+\\theta}}=\\left(\\sqrt{(1-2\\gamma)^{1-\\theta}(1+2\\gamma)^{1+\\theta}}\\right)^T $$ When $\\theta\u0026lt;-\\frac{\\log(1+2\\gamma)+\\log(1-2\\gamma)}{\\log(1+2\\gamma)-\\log(1-2\\gamma)}\\impliedby\\theta\u0026lt;\\gamma$, the term $\u0026lt;1$. So intuitively, the margin is at least $\\frac12-\\epsilon$, which is how better is the weak learner than random guess.\nProof. It\u0026rsquo;s basically the same as the proof of theorem 10. $$ \\eq{ \\Pr_{(x,y)\\sim U(S)}[yf(x)\\le\\theta]\u0026amp;=\\frac1m\\sum_i\\left[y_i\\sum_t\\alpha_th_t(x_i)\\le\\theta\\sum_t\\alpha_t\\right]\\\\ \u0026amp;\\le\\frac1m\\sum_i\\exp\\left(-y_i\\sum_t\\alpha_th_t(x_i)+\\theta\\sum_t\\alpha_t\\right)\\\\ \u0026amp;=\\exp\\left(\\theta\\sum_t\\alpha_t\\right)\\prod_tZ_t\\\\ \u0026amp;=\\prod_t\\sqrt{\\left(\\frac{1-\\epsilon_t}{\\epsilon_t}\\right)^\\theta}2^T\\prod_t\\sqrt{\\epsilon_t(1-\\epsilon_t)}\\\\ \u0026amp;=2^T\\prod_t\\sqrt{\\epsilon_t^{1-\\theta}(1-\\epsilon_t)^{1+\\theta}} } $$ The inequalities $\\epsilon_t^{1-\\theta}(1-\\epsilon_t)^{1+\\theta}\\le\\epsilon^{1-\\theta}(1-\\epsilon)^{1+\\theta}$ and $\\gamma\\le-\\frac{\\log(1+2\\gamma)+\\log(1-2\\gamma)}{\\log(1+2\\gamma)-\\log(1-2\\gamma)}$ can both be proven by taking derivative.\nDefinition 15. Coordinate descent is to minimize along the coordinate direction at each step. A coordinate selection rule is needed.\nDefinition 16. Gradient boosting is the generalization of AdaBoost, or we can regard it as a unification of boosting and the additive model. The setting is an online descent process. Informally, consider a function $f$ that does not fit the points $(x_1,y_1)\\sim(x_n,y_n)$ very well. It is straightforward to think that we should try to fit $(x_1,y_1-f(x_1)),\\cdots,(x_n,y_n-f(y_n))$ using another model $h$ and let $f^\\prime=f+h$. If $h$ is weak, we may iteratively find $h$ and add it to $f$.\nHere comes the point. Such a process is a special case under a more general framework. For now regard $f$ as a variable. The goal is to minimize $L(f,X,Y)=\\sum_i\\ell(f,x_i,y_i)$. By GD, we expect $f^\\prime=f-\\eta\\frac{\\p L}{\\p f}$; more concretely, $h(x_i)\\approx\\frac{\\p\\ell(y_i,f(x_i))}{\\p f(x_i)}$ and $f^\\prime=f-\\eta h$. So the idea previously mentioned is just $\\ell(y,\\hat y)=(y-\\hat y)^2/2$. For general gradient boosting, $\\eta$ is chosen adaptively (this is natural since the partial derivative is a local property) so that $L(f^\\prime,X,Y)$ is minimized.\nTheorem 13. AdaBoost is the case of (discrete version of) gradient boosting under $\\ell(y,\\hat y)=\\e^{-y\\hat y}$.\nProof. Here we use $\\alpha$ instead of $\\eta$. Let $f_{m-1}=\\sum_{i=1}^{m-1}\\alpha_ih_i$, then the current goal is to minimize $$ L(f_m,X,Y)=\\sum_i\\exp(-y_i(f_{m-1}+\\alpha_mh_m)(x_i))=\\sum_i\\exp(-y_if_{m-1}(x_i))\\cdot\\exp(-\\alpha_my_ih_m(x_i)) $$ We\u0026rsquo;ve found the first correspondence $D_m(i)\\propto\\exp(-y_if_{m-1}(x_i))$, meaning that the probability distribution is equivalent to part of the loss function.\n$h_m$ is obtained from an oracle instead of explicitly asking $h_m(x_i)\\approx\\p\\cdots$. In this situation, it may be the greedy method for constructing the decision tree. The last step is choosing $\\alpha_m$: $$ \\alpha_m=\\argmin_\\alpha\\sum_iD_m(i)\\exp(-\\alpha y_ih_m(x_i)) $$ So $$ \\eq{ 0\u0026amp;=\\frac{\\p}{\\p\\alpha}\\left(\\sum_iD_m(i)\\exp(-\\alpha y_ih_m(x_i))\\right)\\\\ \u0026amp;=-\\sum_iD_m(i)y_ih_m(x_i)\\exp(-\\alpha y_ih_m(x_i))\\\\ \u0026amp;=\\e^\\alpha\\sum_{h_m(x_i)\\ne y_i}D_m(i)-\\e^{-\\alpha}\\sum_{h_m(x_i)=y_i}D_m(i)\\\\ \u0026amp;=\\e^\\alpha\\epsilon_m-\\e^{-\\alpha}(1-\\epsilon_m)\\\\ \\implies\\e^{2\\alpha}\u0026amp;=\\frac{1-\\epsilon_m}{\\epsilon_m} } $$\nUnsupervised Learning Principle Component Analysis Just a brief summary since we\u0026rsquo;ve learned that in the previous course.\nGiven a set of points $\\set{x_1,\\cdots,x_n}$ satisfying $\\sum x_i=0$, the goal of PCA is to find a subspace spanned by some orthonormal basis $\\set{v_1,\\cdots,v_k}$ such that the variance of the points is maximally preserved. That is to maximize $$ \\sum_i\\sum_j\\ip{x_i,v_j}^2=\\sum_i\\sum_jv_j^\\top x_ix_i^\\top v_j=\\|V^\\top X X^\\top V\\|_1 $$ So $V$ should contain the top-$k$ right singular vectors.\nAnother definition of PCA is to minimize the reconstruction error $$ \\sum_i\\left\\|x_i-\\sum_j\\ip{x_i,v_j}v_j\\right\\|^2=\\sum_i\\left(\\|x_i\\|^2-\\sum_j\\ip{x_i,v_j}^2\\right) $$ So obviously they are equivalent.\nNearest Neighbor Definition 1. Nearest neighbor is a classification method, that assign the label of an input point according to the labels of its neighbors in the given dataset. Actually it\u0026rsquo;s neither a supervised learning method, nor an unsupervised one, because it\u0026rsquo;s a non-parametric model, meaning that it does not actually \u0026ldquo;learn\u0026rdquo; anything but rather directly utilize the data.\nThree main topics about NN were covered in the class:\nHow does kNN works? How to build a data structure that support kNN queries efficiently? How to learn a mapping that maps the original data to some special space, where kNN really performs great? Only the last part is unsupervised learning.\nThere\u0026rsquo;s nothing much to say about the first part. There\u0026rsquo;re some ways to aggregate the labels of the $k$-nearest neighbors of the queried point, like uniform (=majority voting) and weighting by distance.\nFor the second part, firstly there\u0026rsquo;re two principles:\nExact kNN in high-dimensional space is impossible, so we care about approximation. For the 2D case there is Voronoi diagrams. For low-dimensional space there are k-D trees and their variants (a data structure called Balanced Box-Decomposition Trees achieves $\\O(dn\\log n)$ preprocessing time and $\\O(d\\log n)$ worst-case query time, which is strange that I haven\u0026rsquo;t heard of). But by some cell-probe lower bound, the worst-case query time is lower bounded by $\\tilde\\Omega(d)$. Nearest neighbor is equivalent to near neighbor (find some point within distance $r$ from $p$). Reduction can be binary search / doubling (倍增). So the following part focus on approximate near neighbor.\nDefinition 2. A hash function $h:\\R^d\\to\\R$ maps a point to a scalar (actually the codomain can be arbitrary since only equality matters). A hash function family $\\hy$ is called $(R,cR,P_1,P_2)$-sensitive (or locality-sensitive overall) iff $\\forall p,q\\in\\R^d$, $\\|p-q\\|\\le R\\implies\\Pr_{h\\in\\hy}[h(p)=h(q)]\\ge P_1$, $\\|p-q\\|\\ge cR\\implies\\Pr_{h\\in\\hy}[h(p)=h(q)]\\le P_2$ and $P_2\u0026lt;P_1$. Furthermore we may use $h\\sim\\hy$ in some weighted construction.\nDefinition 3. Randomized $c$-approximate $R$-near neighbor, or $(c,R)$-NN, is the problem that given a set $P$ of $\\R^d$ points, every time the query is a point $q$, which asks for any $cR$-near neighbor of $q$ in $P$ w.p. $1-\\delta$, if there exists some $R$-near neighbor of $q$ in $P$. Obviously once some constant $\\delta$ exists, it can be arbitrarily reduced.\nTheorem 1. Given an $(R,cR,P_1,P_2)$-sensitive hash family $\\hy$, one can solve $(c,R)$-NN.\nProof. The algorithm:\nGenerate an $L\\times k$ table of hash functions, each entry $h_{i,j}$ independently sampled from $\\hy$. Build $L$ hash tables, $S_i$ stores $p_j$ with key $g_i(p_j)=(h_{i,1}(p_j),\\cdots,h_{i,k}(p_j))$. For a query $q$, check the first $2L+1$ elements of $\\bigcup_i\\operatorname{query}(S_i,g_i(q))$. Let $n=|P|$.\nFor a $R$-near neighbor $p\\in P$ of $q$, $\\Pr[g_1(p)=g_1(q)]\\ge P_1^k$, thus $\\Pr[\\exists i,g_i(p)=g_i(q)]\\ge 1-(1-P_1^k)^L\\ge 1-\\e^{-LP_1^k}$.\nFor a $cR$-far non-neighbor $p\\in P$ of $q$, $\\Pr[g_1(p)=g_1(q)]\\le P_2^k$, thus $\\Ex\\left(\\sum_i\\sum_{\\text{non-neighbor }p}[g_i(p)=g_i(q)]\\right)\\le nLP_2^k$. By Markov inequality, $\\Pr\\left[\\sum_i\\sum_{\\text{non-neighbor }p}[g_i(p)=g_i(q)]\u0026gt;2nLP_2^k\\right]\u0026lt;\\frac12$.\nNow, we want to have $\\e^{-LP_1^k}$ small and $2nLP_2^k\\le 2L$. Take $k=-\\log_{P_2}n$ and $L=-\\log_{P_2}P_1$, by union bound, $$ \\Pr\\left[\\bigcup_i\\operatorname{query}(S_i,g_i(q))\\text{ contains}\\ge 1\\text{ neighbors and}\\le 2L\\text{ non-neighbors}\\right]\\ge\\frac12-\\frac1\\e $$\nExample. In discrete space $\\set{0,1}^d$ with metric being Hamming distance, $\\hy=\\set{h_i(x)=x^i}$ is a $(R,cR,1-R/d,1-cR/d)$-sensitive hash family.\nExample. In $\\R^d$, $\\hy_w=\\set{h_{r,b}(x)=\\lfloor(\\ip{r,x}+b)/w\\rfloor}$ where $r\\sim\\Nd(0,I_d)$, $b\\sim U[0,w)$. Consider two points $p,q$, $$ \\eq{ \\Pr\\left[h(p)=h(q)\\right] \u0026amp;=\\Pr\\left[\\left\\lfloor\\frac{\\ip{r,p}+b}{w}\\right\\rfloor=\\left\\lfloor\\frac{\\ip{r,q}+b}{w}\\right\\rfloor\\right]\\\\ \u0026amp;=\\Ex\\left(\\max\\Set{1-\\frac{\\lvert\\ip{r,p-q}\\rvert}w,0}\\right)\\\\ \u0026amp;=2\\int_0^1f\\left(t\\middle|\\mu=0,\\sigma=\\frac{\\|p-q\\|_2}{w}\\right)(1-t)\\d t\\\\ \u0026amp;=\\sqrt{\\frac2\\pi}\\frac{w}{\\|p-q\\|_2}\\int_0^1\\exp\\left(-\\frac12\\left(\\frac{w}{\\|p-q\\|_2}t\\right)^2\\right)(1-t)\\d t } $$ The key point is that $\\ip{r,x}\\sim\\Nd(0,\\|x\\|_2^2)$.\nHere is the plot when $w=1$. For $\\|p-q\\|_2=1$, the probability is about $0.369$.\nThe third part is actually the most important. In ML, in which space we do kNN is the most important thing, rather than how to do it efficiently. That\u0026rsquo;s why kNN is put in the unsupervised learning chapter. For example, consider image classification. If we just use the pixel space, semantically similar images may not be near each other. We\u0026rsquo;d like to have a dimension-reducing projection, called semantic mapping, not to maintain the pairwise distance, but to make the images having similar \u0026ldquo;meaning\u0026rdquo; near each other. Quantitatively, the goal is like: if $f(x_i)$\u0026rsquo;s nearest neighbor is $f(x_j)$, their preimages should have the same label.\nBut NN is a discrete thing, so the goal is not differentiable. Hinton proposed an algorithm called NCA. The idea is that every point is a near neighbor, but in the sense of different weights.\nDefinition 4. The weight of a pair of point $x_i,x_j$ in NCA, can be regarded as \u0026ldquo;the probability of $x_j$ being neighbor of $x_i$\u0026rdquo;, is $$ p_{j\\mid i}=\\frac{\\exp\\left(-\\|f(x_j)-f(x_i)\\|_2^2\\right)}{\\sum_{k\\ne i}\\exp\\left(-\\|f(x_k)-f(x_i)\\|_2^2\\right)},p_{i\\mid i}=0 $$ and the loss $$ L=-\\sum_i\\sum_{y_j=y_i}p_{i,j} $$ Definition 5. Another proposal is LMNN, the general idea is defining loss as: $$ L=\\sum_i\\max(0,\\|f(x)-f(x_+)\\|_2-\\|f(x)-f(x_-)\\|_2+r) $$ $r$ is the margin. Should pick $x_+$ not so close, and $x_-$ not so far, but there\u0026rsquo;s no need to pick $\\max\\|f(x)-f(x_+)\\|_2$ or $\\min\\|f(x)-f(x_-)\\|_2$.\nA practical instantiation is to make $f(x)=Ax$ so $\\|f(x_i)-f(x_j)\\|_2^2=(x_i-x_j)^\\top A^\\top A(x_i-x_j)$, thus we can use a positive semidefinite matrix $M$ in place of $A^\\top A$. Denote $d(x_i,x_j)=(x_i-x_j)^\\top M(x_i-x_j)$. Design the loss as $$ L=\\sum_i\\sum_{y_j=y_i}d(x_i,x_j)+\\lambda\\sum_i\\sum_{y_j=y_i}\\sum_{y_k\\ne y_i}\\max\\set{d(x_i,x_j)-d(x_i,x_k)+1,0} $$ So that the optimization problem is in the form of semidefinite programming.\nClustering In this section, I will slightly abuse the notation $S_i$. It contains either points/vertices or indices of points/vertices, depending on the context.\nDefinition 6. $k$-means problem is that, given $n$ points $\\set{x_1,\\cdots,x_n}$ in $\\R^d$, we want to partition them into $k$ groups $S_1,\\cdots,S_k$, $$ \\min.\\sum_{i=1}^k\\sum_{x\\in S_i}\\left\\|x-\\underline{\\frac{1}{|S_i|}\\sum_{y\\in S_i}y}_{\\mu_i}\\right\\|^2 $$ which is NP hard (the proof). An empirical method is Lloyd\u0026rsquo;s algorithm: Initially select centers at random. Every iteration assign each point to its nearest center, then recompute the centers by the averaging the points within every cluster, until the partition fixes. Obviously the loss is monotonic, and empirically the algorithm converges really fast. But it does not guarantee a minimal solution, even not a local minimum. Consider $X=\\set{(0,0),(2,0),(0,1),(2,1)}$ and centers $c_1=(1,0), c_2=(1,1)$.\nHowever, $\\ell_p$-distance is usually not the best metric. A group may contain dissimilar points, like this:\nSo consider turn the problem into graph clustering problem: connect the near point pairs in a \u0026ldquo;similarity graph\u0026rdquo; and run clustering. There\u0026rsquo;re several heuristic methods constructing the graph:\n$w_{i,j}=[\\|x_i-x_j\\|\\le\\epsilon]$ $w_{i,j}=[x_j\\in\\mathrm{kNN}(x_i)\\lor x_i\\in\\mathrm{kNN}(x_j)]$ $w_{i,j}=\\exp(-\\|x_i-x_j\\|^2/2)$ The formation of the graph, or say, adjacency matrix, is not unique, also there is no single canonical definition of graph clustering. But some specific version of this is equivalent to $k$-means. For now, let\u0026rsquo;s just forget about $k$-means and learn about different definitions of graph clustering and spectral clustering.\nThe general idea of graph clustering is to make intra-group edges having large weights and inter-group edges have small weights.\nDefinition 7. The Laplacian matrix for an undirected simple weighted graph $G$ is defined as: $$ (L_G)_{i,j}=\\begin{cases}-w_{i,j},\u0026amp;i\\ne j\\\\ d_i=\\sum_jw_{i,j},\u0026amp;i=j\\end{cases} $$ Theorem 2. Let $G$ be an undirected graph with non-negative weights, where $w_{i,j}=0$ means $(i,j)\\notin E$. Multiplicity of $\\lambda=0$ is the number of connected components, and $E_0=\\span\\set{1_{C_1},\\cdots,1_{C_k}}$ where $C_i$s are the components and $1_S$ is the indicator vector.\nProof strategy. $$ v^\\top Lv=\\frac12\\sum_{i,j}w_{i,j}(v_i-v_j)^2 $$ This looks useless—why not use DFS/BFS? The importance of Laplacian is that, it provides a continuous description of \u0026ldquo;connectivity\u0026rdquo;. For example, two cliques $K_n$ connected by few edges can be identified by a small but nonzero eigenvalue of the Laplacian. The eigenvalues of such Laplacian is $\\set{0,n(\\times 2n-3),(n+2\\pm\\sqrt{n^2+4n-4})/2}$, and $(n+2-\\sqrt{n^2+4n-4})/2\\approx 2/n$.\nDefinition 8. Spectral clustering is a heuristic method motivated by the spectral method under the ideal situation. It finds the eigenvectors corresponding to the bottom $k$ eigenvalues, denoted by $v_1,\\cdots,v_k$, and run $k$-means on the $n$ rows of $\\mat{v_1\u0026amp;\\cdots\u0026amp;v_k}$, obtaining the clustering. Specifically, the bottom $k$ eigenvalues and eigenvectors are computed by power method on $L-\\lambda_{\\max}I$.\nWhy is such algorithm reasonable, when the input is noisy graph from real-world data? There\u0026rsquo;re two perspectives: The \u0026ldquo;take bottom $k$ eigenvalues\u0026rdquo; step can be understood under another setting, which is the part focused on in class. There\u0026rsquo;re mathematical guarantees for the correct clustering of graphs deviating a small portion from the ideal disconnected graph. Definition 9. The minimum ($k$-)cut problem (on a graph) is to find a partition of vertices $S_1,\\cdots,S_k$, $$ \\min.\\sum_i\\cut(S_i,\\overline{S_i}) $$ This is not a good optimization objective because isolating single vertices is usually optimal.\nDefinition 10. The ratio cut problem is similar to the above one, but different at the goal $$ \\min.\\sum_i\\frac{\\cut(S_i,\\overline{S_i})}{|S_i|} $$ Both mincut and ratiocut are NP-hard if $k$ is not constant.\nTheorem 3. For $k=2$, minimizing ratio cut is equivalent to minimizing $v^\\top Lv$, under some extra constraints on $v$.\nProof. Suppose the partition is $(S,\\overline{S})$. Let $$ v_i^S=\\begin{cases}\\sqrt{\\frac{|\\overline S|}{|S|}},\u0026amp;i\\in S\\\\ -\\sqrt{\\frac{|S|}{|\\overline S|}},\u0026amp;i\\notin S\\end{cases} $$ then $$ (v_i^S)^\\top L v_i^S=\\frac12\\sum_{i,j}w_{i,j}(v_i-v_j)^2=\\sum_{i\\in S,j\\notin S}w_{i,j}\\left(\\sqrt{\\frac{|\\overline S|}{|S|}}+\\sqrt{\\frac{|S|}{|\\overline S|}}\\right)^2=\\cut(S,\\overline S)\\left(\\frac{|\\overline S|}{|S|}+\\frac{|S|}{|\\overline S|}+2\\right)=n\\rcut(S,\\overline{S}) $$ So the constraint is $v$ must be induced by some $S$.\nConsider relaxing the constraint, finally we can get the goal $$ \\min. v^\\top Sv\\quad\\text{s.t. }v\\perp 1,\\|v\\|_2=\\sqrt n $$ This is the same goal as in definition 8.\nTheorem 4. For general $k$, minimizing ratio cut is equivalent to minimizing $\\tr(H^\\top LH)$ where $H\\in\\R^{n\\times k}$, s.t. $H^\\top H=I$ and some other constraints.\nProof. Suppose the partition is $(S_1,\\cdots,S_k)$. Let $$ H_{i,j}=\\frac{1}{\\sqrt{|S_j|}}[i\\in S_j] $$ then $$ (H^\\top LH)_{i,i}=\\sum_{j\\in S_i,k\\notin S_i}\\frac{w_{j,k}}{|S_i|}=\\frac{\\cut(S_i,\\overline{S_i})}{|S_i|} $$ So $\\tr(H^\\top LH)=\\rcut(S_1,\\cdots,S_k)$ (of course only when $H$ is induced by some $(S_1,\\cdots,S_k)$).\nTheorem 5. The solution of $\\min.\\tr(H^\\top LH)\\text{ s.t. }H^\\top H=I$ can be the matrix composed by the bottom $k$ eigenvectors of $L$.\nProof. The following proof has already appeared in the 计智应数 class.\nSince $L$ is positive semidefinite, we can assume $L=W^\\top W$. Let $W=\\mat{w_1\\\\ \\vdots\\\\w_n}$ and $H=\\mat{h_1\u0026amp;\\cdots\u0026amp;h_k}$, then $$ \\tr(H^\\top LH)=\\tr((WH)^\\top(WH))=\\|WH\\|_{\\rm F}=\\sum_i\\left\\lVert\\proj_{\\col(H)}w_i\\right\\rVert_2^2=\\sum_i\\sum_j\\ip{w_i,h_j}^2 $$ This implies that, only $\\col(H)$ really matters.\nNow let\u0026rsquo;s use induction.\nLet $V_k$ be the space spanned by the bottom $k$ eigenvector $\\set{v_1,\\cdots,v_k}$, and $V^\\prime\\ne V_k$ be another space of dimension $k$. By dimensionality, there exists unit vector $ v^\\prime\\in V^\\prime\\cap V_{k-1}^\\perp$. It can be extended to an orthonormal basis of $V^\\prime$, denoted as $\\set{v_1^\\prime,\\cdots,v_{k-1}^\\prime,v^\\prime}$. Since the alternative definition of eigenvector is $$ v_k=\\argmin_{v\\perp v_1,\\cdots,v_{k-1},\\|v\\|_2=1}v^\\top L v $$ we have $v_k^\\top Lv_k\\le{v^\\prime}^\\top Lv^\\prime$. Plus, by induction hypothesis, $$ \\tr\\left(\\mat{v_1\u0026amp;\\cdots\u0026amp;v_{k-1}}^\\top L\\mat{v_1\u0026amp;\\cdots\u0026amp;v_{k-1}}\\right)\\le\\tr\\left(\\mat{v_1^\\prime\u0026amp;\\cdots\u0026amp;v_{k-1}^\\prime}^\\top L\\mat{v_1^\\prime\u0026amp;\\cdots\u0026amp;v_{k-1}^\\prime}\\right) $$ combining these two inequalities, we finally get $$ \\tr\\left(\\mat{v_1\u0026amp;\\cdots\u0026amp;v_{k-1}\u0026amp;v_k}^\\top L\\mat{v_1\u0026amp;\\cdots\u0026amp;v_{k-1}\u0026amp;v_k}\\right)\\le\\tr\\left(\\mat{v_1^\\prime\u0026amp;\\cdots\u0026amp;v_{k-1}^\\prime\u0026amp;v^\\prime}^\\top L\\mat{v_1^\\prime\u0026amp;\\cdots\u0026amp;v_{k-1}^\\prime\u0026amp;v^\\prime}\\right) $$ Theorem 6. Denote the Laplacian of the ideal graph (clusters are completely disconnected) as $L_0$, and the actual noisy graph as $L=L_0+E$. Suppose by calculating the spectral decomposition and taking the bottom $k$ eigenvectors, we get $H$. Let $H^{*}$ be the real indicator of the clusters (induced by the partition), then there exists a rotation matrix $R$ and some constant $C$, $$ \\|H-H^{*}R\\|_{\\rm F}\\le C\\frac{\\|E\\|}{\\gamma} $$ where $\\gamma$ is the eigengap and $C$ depends on the norm taken on $E$. Thus, running $k$-means on $H$ is valid, since right multiplying $R$ does not change the row pattern.\nObviously the proof will be some variant of the Davis–Kahan theorem.\nNow let\u0026rsquo;s go back to $k$-means.\nTheorem 7. $k$-means is equivalent to ratiocut.\nProof. Recall the optimization objective of $k$-means: $$ \\sum_{i=1}^k\\sum_{x\\in S_i}\\|x-\\mu_i\\|_2^2=\\sum_x\\|x\\|_2^2-\\sum_{i=1}^k|S_i|\\|\\mu_i\\|_2^2\\tag{1} $$ Let $X=\\mat{x_1\u0026amp;\\cdots\u0026amp;x_n}$, $H=\\mat{1_{S_1}\u0026amp;\\cdots\u0026amp;1_{S_k}}$, $D=\\diag(|S_1|,\\cdots,|S_k|)$. It can be easily verified that $XHD^{-1}=\\mat{\\mu_1\u0026amp;\\cdots\u0026amp;\\mu_k}$. So $(1)$ can be rewritten as $$ \\tr\\left(X^\\top X-H^\\top X^\\top XHD^{-1}\\right) $$ Here, $\\tr(X^\\top X)$ is constant and $\\tr(H^\\top X^\\top XHD^{-1})=\\tr(D^{-\\alpha}H^\\top X^\\top XHD^{\\alpha-1})$ for any $\\alpha$ since we only consider trace. Here taking $\\alpha=1/2$ can simplify the following derivation. So now the goal is $$ \\max.\\tr\\left(D^{-1/2}H^\\top X^\\top XHD^{-1/2}\\right)\\quad\\text{s.t. }H=\\mat{1_{S_1}\u0026amp;\\cdots\u0026amp;1_{S_k}},D=\\diag(|S_1|,\\cdots,|S_k|) $$ which is equivalent to $$ \\max.\\tr\\left({\\hat H}^\\top X^\\top X\\hat H\\right)\\quad\\text{s.t. }\\hat H_{i,j}=\\frac{1}{\\sqrt{|S_j|}}[x_i\\in S_j] $$\nwhich is equivalent to $$ \\min.\\tr\\left({\\hat H}^\\top L\\hat H\\right)\\quad\\text{s.t. }\\hat H_{i,j}=\\frac{1}{\\sqrt{|S_j|}}[x_i\\in S_j] $$ where $$ L_{i,j}=\\begin{cases}-\\ip{x_i,x_j},\u0026amp;i\\ne j\\\\ \\sum_{k\\ne i}\\ip{x_i,x_k},\u0026amp;i=j\\end{cases} $$ is a valid Laplacian.\nIn conclusion, the logic is Stochastic Neighbor Embedding Definition 11. Dimension reduction is the transformation of data from a high-dimensional space into a low-dimensional space so that the low-dimensional representation retains some meaningful properties of the original data. Here we focus on preserving neighborhoods. For example, PCA is a linear method for dimension reduction.\nDefinition 12. SNE is a nonlinear method for dimension reduction, motivated by NCA. NCA is supervised with labels, while SNE is unsupervised. SNE inherits the probability construction measuring nearness. For the given points $x_1\\sim x_n$: $$ p_{j\\mid i}=\\frac{\\exp\\left(-\\|x_j-x_i\\|_2^2/2\\sigma_i^2\\right)}{\\sum_{k\\ne i}\\exp\\left(-\\|x_k-x_i\\|_2^2/2\\sigma_i^2\\right)},p_{i\\mid i}=0 $$ Let $y_i=f(x_i)$ be the reduced points (usually 2D/3D), $$ q_{j\\mid i}=\\frac{\\exp\\left(-\\|y_j-y_i\\|_2^2\\right)}{\\sum_{k\\ne i}\\exp\\left(-\\|y_k-y_i\\|_2^2\\right)},p_{i\\mid i}=0 $$ The loss is defined as $$ L=\\sum_i\\mathrm{KL}(p_i\\parallel q_i)=\\sum_i\\sum_jp_{j\\mid i}\\log\\frac{p_{j\\mid i}}{q_{j\\mid i}} $$ The parameters $\\sigma_i$ controls perplexity: $$ \\mathrm{perp}(p_i)=2^{H(p_i)},H(p_i)=-\\sum_jp_{j\\mid i}\\log p_{j\\mid i} $$\nHigher perplexity → more uniform $p_i$ → larger $\\sigma_i$. Higher perplexity → more effective neighbors considered → denser view. The reason using separate $\\sigma_i$s is because different $x_i$s may be in dense/sparse regions, and we want to fix the number of neighbors considered across all the points. In low dimension, $\\sigma$ is not used because: 1. We shouldn\u0026rsquo;t use different $\\sigma_i$ for each point since we want the dense clusters to look dense and the sparse clusters to look sparse. 2. A uniform $\\sigma$ is useless because we can just scale the points. Definition 13. t-SNE is an adjusted version of SNE, solving crowding problem. It applies the following modification: $$ p_{ij}=\\frac{p_{j\\mid i}+p_{i\\mid j}}2 $$\n$$ q_{ij}=\\frac{\\left(1+\\|y_i-y_j\\|_2^2\\right)^{-1}}{\\sum_k\\sum_{l\\ne k}\\left(1+\\|y_k-y_l\\|_2^2\\right)^{-1}},q_{ii}=0 $$\n$$ L=\\sum_{i\\ne j}p_{ij}\\log\\frac{p_{ij}}{q_{ij}} $$\nHere $q$ is calculated using Student\u0026rsquo;s $t$ distribution with one degree of freedom (which is also the Cauchy distribution). Its benefit is that it\u0026rsquo;s heavy-tailed. Relative differences in distance are diluted.\nHere I use an example to illustrate the advantage of using a heavy-tailed distribution. Since in high dimensions there\u0026rsquo;s a scaling factor $\\sigma_i$, considering relative density may be more convincing. For some point $x$, there\u0026rsquo;re $2^d$ times more points within distance $2r$ from $x$ than within distance $r$. In low dimensions, this would require the same ratio between the $2\\sigma_ir$ neighborhood and the $\\sigma_ir$ neighborhood, which is impossible since the space ratio is only $2^2$ or $2^3$. But under Student\u0026rsquo;s $t$ distribution, the ratio between the two corresponding distances in low dimensions is far larger than $2^2$ or $2^3$. Visualization of t-SNE is available here.\nSelf-Supervised Learning The three greatest ideas of ML are:\nConverting discrete quantities into continuous. Sampling a small batch of data within the whole data space, which can be regarded as some kind of general SGD. Caring about relations, rather than absolute \u0026ldquo;meanings\u0026rdquo;. As a saying goes, a French pupil may not know $2+3=5$, but he must know $2+3=3+2$. In self-supervised learning, the model is not explicitly told the labels of images, but it learns to recognize semantic meanings by being trained to predict the relationship between two images. Contrastive Learning This part centers around the paper Contrastive Learning Is Spectral Clustering On Similarity Graph.\nDefinition 1. Contrastive learning is a self-supervised learning method that makes a model learn to understand data by training on similar and dissimilar data pairs. Specifically, the approach trains a neural network to map a set of objects into an embedding space, ensuring that similar objects are closely positioned while dissimilar objects remain far apart.\nDefinition 2. SimCLR is a simple framework for contrastive learning of visual representations. It trains a neural network $f:\\sp X\\to\\sp Z$ that maps an image from pixel space to feature space. The loss is defined as follows: For each original image $x_i$, augment it to two images $\\tilde x_{2i-1}$ and $\\tilde x_{2i}$. The augmentation method is sampled from an augmentation function class $\\sp T$. Let $z_i=f(\\tilde x_i)$. The loss is InfoNCE loss $$ L=\\sum_i-\\log\\frac{\\exp\\left(-\\|z_i-z_{j=i-(-1)^i}\\|^2/2\\tau\\right)}{\\sum_{k\\ne i}\\exp\\left(-\\|z_i-z_k\\|^2/2\\tau\\right)} $$ Definition 3. To analyze SimCLR, here we define a theoretical model, which is some kind of generalization. These are the objects in the model:\n$\\pi$, the similarity matrix in the original space, having dimension $|\\sp X|\\times|\\sp X|$. $\\pi$ is defined by the augmenting strategy, and is not explicitly written out since $|\\sp X|$ is usually large (like $256^{3wh}$). In SimCLR, $\\pi_{i,j}$ is the probability that image $i$ and $j$ being sampled together. $\\pi$ can sometimes be regarded as a stochastic matrix. $\\pi$ is not necessarily symmetric, although in SimCLR it is. $K_Z$, the similarity matrix in the feature space. The definition is ${K_Z}_{i,j}=\\ip{\\phi(f(X_i)),\\phi(f(X_j))}_{\\sp H}$, where $\\phi:\\sp Z\\to\\sp H$ is the \u0026ldquo;feature map\u0026rdquo; (this \u0026ldquo;feature\u0026rdquo; is unrelated to the semantic feature of the images) and $\\sp H$ is the reproducing kernel Hilbert space. The motivation here is, we are not limited to using $\\ell_2$-norm in the feature space, but we can define more complex similarity function as long as it satisfies some basic properties. The sampling process. Each matrix defines a weighted graph, and the idea here is to sample a subgraph $W$. The subgraph must satisfy some property, expressed by an indicator function $\\Omega:\\sp W\\to \\set{0,1}$. Here, we consider the graph to be directed, and specify $\\Omega(W)$ to be \u0026ldquo;every vertex in $W$ has out degree $1$\u0026rdquo;. Note that it\u0026rsquo;s not SimCLR anymore. Now the distribution is defined as $\\Pr[W;\\pi]\\propto\\Omega(W)\\prod_{(i,j)}\\pi_{i,j}^{W_{i,j}}$ (define $0^0=1$). Under the assumption that each row of $\\pi$ sums to $1$ and the specification of $\\Omega$, $\\propto$ can be replaced by $=$. Note that this \u0026ldquo;probability\u0026rdquo; is not even similar to normal subgraph sampling since in normal sampling, $W_{i,j}=0$ should contribute $1-\\pi_{i,j}$ to the probability. The loss. We use cross entropy function to compare $\\pi$ and $K_Z$: $H_{\\pi}^k(Z)=-\\Ex_{W_X\\sim\\Pr[\\cdot;\\pi]}(\\log\\Pr[W_Z=W_X;K_Z])$. Here $W_X$ is sampled according to $\\pi$ and $W_Z$ is sampled according to $K_Z$. $k$ on the superscript is the kernel function $\\ip{\\phi(\\cdot),\\phi(\\cdot)}_{\\sp H}$. The high-level mechanism of contrastive learning is that $\\pi$ gives guidance, a sketch of representation learning, which is not complete (for example, if images $i$ and $j$ represent two different dogs of the same breed, $\\pi_{i,j}=0$ since they cannot be obtained by augmentation), and $f$ learns the feature and automatically generalizes to other real-world images by some generalization guarantee. Contrastive learning is powerful because it does not require labels or a huge amount of data, but depends solely on data synthesis. However, I think it\u0026rsquo;s unimpressive that the following theory does not provide a more accurate description of this intuition. Theorem 1. Minimizing $H_\\pi^k(Z)$ is equivalent to (a modified/idealized version) SimCLR, and is also equivalent to spectral clustering on $\\pi$.\nProof. Equivalence to SimCLR: $$ \\eq{ H_\\pi^k(Z)\u0026amp;=-\\Ex_{W_X\\sim\\Pr[\\cdot;\\pi]}\\left(\\log\\prod_i\\Pr[{W_Z}_i={W_X}_i;K_Z]\\right)\\\\ \u0026amp;=-\\Ex_{W_X\\sim\\Pr[\\cdot;\\pi]}\\left(\\sum_i\\log\\Pr[{W_Z}_i={W_X}_i;K_Z]\\right)\\\\ \u0026amp;=-\\sum_i\\Ex_{j\\sim\\pi_{i,\\cdot}}\\left(\\log\\frac{{K_Z}_{i,j}}{\\sum_k{K_Z}_{i,k}}\\right)\\\\ \u0026amp;=-\\sum_i\\Ex_{j\\sim\\pi_{i,\\cdot}}\\left(\\log\\frac{k(f(X_i),f(X_j))}{\\sum_tk(f(X_i),f(X_j))}\\right) } $$ Comparing with the SimCLR\u0026rsquo;s objective, the only difference is that here, for every possible image in $\\sp X$, we sample its counterpart, while in SimCLR a subgraph is considered.\nEquivalence to spectral clustering:\nDenote $R(Z)=\\sum_{W}\\Omega(W)\\prod_{(i,j)}{K_Z}_{i,j}^{W_{i,j}}$. $$ \\eq{ \\log\\Pr[W_Z=W_X;K_Z]\u0026amp;=\\log\\frac{\\prod_{(i,j)}{K_Z}_{i,j}^{{W_X}_{i,j}}}{R(Z)}\\\\ \u0026amp;=\\sum_{i,j}{W_X}_{i,j}\\log K(Z_i,Z_j)-\\log R(Z)\\\\ \u0026amp;=-\\sum_{i,j}{W_X}_{i,j}\\frac{\\|Z_i-Z_j\\|^2}{2\\tau}-\\log R(Z)\\\\ \u0026amp;=-\\frac{1}{\\tau}\\tr(Z^\\top L(W_X)Z)-\\log R(Z)\\\\ \\implies-\\Ex_{W_X\\sim\\Pr[\\cdot;\\pi]}(\\log\\Pr[W_Z=W_X;K_Z])\u0026amp;=-\\frac1\\tau\\tr(Z^\\top L(\\pi)Z)+\\log R(Z) } $$ This is the optimization objective of ratiocut, with that $Z^\\top Z=1$ constraint replaced by a regularization term $\\log R(Z)$.\nSimCLR only sample a subgraph with $2n$ vertices and $n$ edges. The paper Momentum Contrast for Unsupervised Visual Representation Learning attempted to train on larger subgraphs (more negative samples) and found that the model performs better with larger subgraph. This is nontrivial since this contrasts to normal minibatch sampling, where increasing minibatch size does not significantly improve the performance. Misc Rotary Position Embedding Don\u0026rsquo;t ask me why it is taught in this course. I don\u0026rsquo;t know.\nIn order to encode position information and add it to the word embeddings in transformer, consider RoPE: $$ q_m^\\prime=q_mR_m=x_mW_qR_m,k_n^\\prime=k_nR_n=x_nW_kR_n,q_m^\\prime{k_n^\\prime}^\\top=x_mW_qR_{m-n}W_k^\\top x_n^\\top=q_mR_{m-n}k_n^\\top $$ (Here $x_m$ is row vector) where $$ R_m=\\mat{\\cos m\\theta_0\u0026amp;-\\sin m\\theta_0\u0026amp;\\cdots\u0026amp;0\u0026amp;0\\\\ \\sin m\\theta_0\u0026amp;\\cos m\\theta_0\u0026amp;\\cdots\u0026amp;0\u0026amp;0\\\\ \\vdots\u0026amp;\\vdots\u0026amp;\\ddots\u0026amp;\\vdots\u0026amp;\\vdots\\\\ 0\u0026amp;0\u0026amp;\\cdots\u0026amp;\\cos m\\theta_{\\frac d2-1}\u0026amp;-\\sin m\\theta_{\\frac d2-1}\\\\ 0\u0026amp;0\u0026amp;\\cdots\u0026amp;\\sin m\\theta_{\\frac d2-1}\u0026amp;\\cos m\\theta_{\\frac d2-1}},\\;\\theta_i=10000^{-\\frac{2i}d} $$ It can be understood as adding signals at different scales of frequency (so that the model can distinguish different orders of distances). This matrix is not arbitrarily designed, it has several advantages:\nLight computation cost. Preserving length. No need to use complex numbers (compared to $\\diag(\\e^{\\i m\\theta_0},\\cdots,\\e^{i m\\theta_{\\frac d2-1}})$). Note that we don\u0026rsquo;t want $m\\theta_{\\frac d2-1}\\ge 2\\pi$, otherwise it will cause \u0026ldquo;aliasing\u0026rdquo;—$R_m$ fails to help the model identify the distance uniquely (although $R_0\\ne R_{20000\\pi}$, their lowest frequency signal will be the same / very close geometrically, confusing the model).\nRobust Machine Learning Definition 1. An adversarial example is an instance with small, intentional feature perturbations that cause a machine learning model to make a false prediction (taken from this book). Below is an example from the paper Explaining and Harnessing Adversarial Examples illustrating this kind of example:\nDefinition 2. Adversarial attacks can be defined as an optimization problem. Recall the original supervised learning goal: $$ \\min_\\theta.\\ell(f_\\theta(x),y) $$ Here the goal is changed to $$ \\max_\\delta.\\ell(f_\\theta(x+\\delta),y)\\quad\\text{s.t. }\\delta\\in\\Delta $$ where $\\Delta$ is a small region near $0$. Of course it can be optimized by GD methods, with constraints, called PGD: $$ \\delta_{t+1}=\\proj_{\\Delta}\\left(\\delta_t+\\eta\\nabla_x\\ell(f_\\theta(x+\\delta_t,y))\\right) $$ but the problem is that, since such optimization is \u0026ldquo;unexpected\u0026rdquo;, the loss landscape w.r.t. $\\delta$ may be pathological. Some components of the gradient may be extremely small, but drastically change after some steps. So, we may want to simply set $\\eta\\to\\infty$ and $\\Delta=\\set{\\delta\\mid\\lVert\\delta\\rVert_\\infty\\le\\epsilon}$ (If use $\\ell_2$ norm, a small fraction of components will dominate). Under this settings, $\\delta$ will simply be $\\epsilon\\sgn\\left(\\nabla_x\\ell(f_\\theta(x),y)\\right)$. This is called fast gradient sign method, or FGSM. Using this as a subroutine, we can run multiple steps of FGSM, each step using a small $\\epsilon$ and set a overall larger $\\epsilon$. This has no mathematical guarantee but empirically producing useful adversarial examples.\nThe paper Universal and Transferable Adversarial Attacks on Aligned Language Models showcases some hilarious adversarial examples jailbreaking LLMs.\nDefinition 3. Adversarial training is training the model to be robust against adversarial examples. The goal is: $$ \\min_\\theta.\\Ex_{x,y}\\left(\\max_{\\delta\\in\\Delta}\\ell(f_\\theta(x+\\delta),y)\\right) $$ which is seemingly hard to optimize.\nTheorem 1 (Danskin). Let $g(y)=\\max_{x\\in Q}f(x,y)$ where $Q$ is compact, $f$ is continuous and $\\frac{\\p}{\\p y}f(x,y)$ is continuous, $$ g^\\prime(y)=\\max_{x^{*}\\in\\argmax_{x\\in Q}f(x,y)}\\frac{\\p}{\\p y}f(x_{*},y) $$ If $y$ is multivariate, for any direction $v$, $$ \\nabla_vg(y)=\\max_{x^{*}\\in\\argmax_{x\\in Q}f(x,y)}\\nabla_vf(x_{*},y) $$ Now we do two steps of relaxation: first we only consider one of the $\\argmax$, second we do not require $x^{*}$ to be exact. Then we just need to solve this: $$ \\frac1N\\frac{\\p}{\\p\\theta}\\ell(f_\\theta(x_i+\\delta_i^{*}),y_i)=0 $$ where $\\delta_i^{*}$ is an adversarial example constructed for $(x_i,y_i)$, approximating $\\argmax$. In this way, we can do GD just like normal classification training, only adding an adversarial construction step before every minibatch update. The key point here is recomputing $\\delta_i^{*}$ every step. By experiment, if one uses the same $\\delta_i^{*}$ across all update steps, the outcome won\u0026rsquo;t be good.\nOther than directly training robust methods, there\u0026rsquo;re several shortcuts, or hotfixes, but they eventually turned out to be vulnerable.\nDefinition 4. FGSM and PGD rely on gradients. Obfuscated gradients are defense methods that try to protect a neural network by breaking or hiding the gradient information that attackers use:\nShattered gradients, like including input discretization, JPEG compression, thresholding, etc. The main idea is to introduce a nondifferentiable \u0026ldquo;preprocessing\u0026rdquo; function $g(x)\\approx x$, and feed $g(x)$ into the non-robust model $f(x)$. Stochastic gradients, to introduce randomness during inference, like $g(x)=x+(\\delta\\sim\\Nd)$, or random dropout. Exploding and vanishing gradients, to make the neural network extremely deep. But these methods are just giving so-called \u0026ldquo;false sense of security\u0026rdquo;. Advanced attackers can bypass them by:\nApproximating $\\nabla_x(f_\\theta\\circ g)(x)$ by $(\\nabla_xf_\\theta)\\circ g(x)$. Taking average of the gradients over many random trials. Leaving only the actually robustly-trained model alive. Even cooler, authors of the paper Synthesizing Robust Adversarial Examples built real-world objects whose photos from different perspectives all successfully confused non-robust models.\nDefinition 5. A simple provable robust certificate was introduced in class. A robust model $g(x)$ is obtained by augmenting the original model $f(x)$ by $$ p(x)_{\\hat y}=\\int_\\delta[f(x+\\delta)=\\hat y]w(\\delta)\\d\\delta $$ and $g(x)=\\text{majority or absolute majority of }p$. Here $w(\\delta)$ is a probability weight function like $[\\|\\delta\\|_2\\le r]/V_r$ or Gaussian, and the integral is evaluated using sampling in practice. Under this setting, let $y$ be the correct label, if $p(x)_y$ is large, it is mathematically guaranteed that in some neighborhood of $x$, the prediction $g(x^\\prime)$ is always correct.\nTheorem 2. For a data $(x,y)$, denote $c(x^{\\prime})=p(x^{\\prime})_y$. Knowing $c(x)$, the lower bound of $c(x+\\delta)$ can be calculated as follows: Sort all the points $y$ by $k(y)=\\frac{w(y-x)}{w(y-x-\\delta)}$. Find a threshold $T$ that $\\int_{k(y)\\ge T}w(y-x)\\d y=c(x)$, then $$ c(x+\\delta)\\ge\\int_{k(y)\\ge T}w(y-x-\\delta)\\d y $$ This is called greedy filling and the correctness is self-evident.\nIf $w(\\delta)=[\\|\\delta\\|_2\\le r]/V_r$, then by first filling $B_r(x)\\setminus B_r(x+\\delta)$ then $B_r(x)\\cap B_r(x+\\delta)$, we can see $c(x+\\delta)=\\max\\set{c(x)-\\lvert B_r(x)\\setminus B_r(x+\\delta)\\rvert/V_r,0}$.\nIf $w(\\delta)$ is Gaussian, the contours of $k(y)$ are hyperplanes and $c(x+\\delta)=\\Phi(\\Phi^{-1}(c(x))-\\|\\delta\\|_2)$ where $\\Phi$ is the CDF.\nHyperparameter Hyperparameter tuning is usually hard because the function doesn\u0026rsquo;t have nice structure and the queries have high (real-world) costs. Several techniques are introduced in class, including:\nApproach Theorem Graduate student Descent / Bayesian inference 1 Gradient Descent 2, 3 random search / grid search / multi-armed bandit based algorithms 4, 5 neural architecture search / When we have no prior knowledge of the loss landscape in hyperparameter space, the best choice is random search.\nDefinition 1. Gaussian process is a type of infinite-dimensional Gaussian distribution. A Gaussian process, denoted as $f$, is defined on a continuous domain $D$. For every $x\\in D$, $f(x)$ follows Gaussian distribution. Furthermore:\n$\\forall x_1,\\cdots,x_n\\in D$, their joint distribution is also a Gaussian. There\u0026rsquo;s a covariance function $K(\\cdot,\\cdot)$ defining the process. We know that a multivariate Gaussian can be defined by its covariance matrix. In the infinite-dimensional case, $\\forall x_1,x_2\\in D$, $\\Cov(x_1,x_2)=K(x_1,x_2)$. Obviously we usually consider nearer points to have higher covariance. Here we also require $\\Ex(f(x))=0$ for every $x$. Definition 2. For general hyperparameter optimization, one approach is to use Bayesian inference. We use a Gaussian process over the hyperparameter space to model the prior. After a sample is given, update the posterior, and use the posterior distribution to guide the selection of the next sample point.\nTheorem 1. The posterior of Gaussian process has analytical form. Given $m$ observations $(x_i,y_i)$, $$ f(x)\\sim\\Nd\\left(k_{*}^\\top\\Sigma^{-1}y,K(x,x)-k_{*}^\\top\\Sigma^{-1}k_{*}\\right)\\text{ where }k_{*}=\\mat{K(x_1,x)\\\\ \\vdots\\\\K(x_m,x)},y=\\mat{y_1\\\\ \\vdots\\\\y_m} $$ GP methods become ineffective when the dimension is large (more than tens), due to sample inefficiency and kernel learning failures in high-dimensional spaces.\nFor some continuous hyperparameters, we can use GD, that is, computing the gradient of the loss w.r.t. the hyperparameters. Take GD process as an example. To optimize $\\eta$, first recall the gradient update: $$ w_{t+1}=w_t-\\eta\\nabla^\\top L(w_t) $$ The naïve way to calculate $\\nabla_\\eta L$ is storing every $w_t$, which takes $\\O(Tdw)$ ($w$ is the size of a word) space.\nTheorem 2. For gradient descent, we can maintain $\\nabla_\\eta L$ alongside the gradient update.\nProof. Here I don\u0026rsquo;t follow the shape convention, so I explicitly use $\\nabla^\\top$ to denote column vector-shaped gradient. First, $$ \\nabla_\\eta L(w_T)=\\nabla L(w_T)\\cdot\\nabla_\\eta w_T $$ where $\\nabla L(w_T)=(\\nabla L)(w_T)$. Then, $$ \\eq{ \\nabla_\\eta w_T\u0026amp;=\\nabla_\\eta(w_{T-1}-\\eta\\nabla^\\top L(w_{T-1}))\\\\ \u0026amp;=\\nabla_\\eta w_{T-1}-\\nabla^\\top L(w_{T-1})-\\eta\\nabla_\\eta\\nabla^\\top L(w_{T-1})\\\\ \u0026amp;=\\nabla_\\eta w_{T-1}-\\nabla^\\top L(w_{T-1})-\\eta\\nabla^2L(w_{T-1})\\nabla_\\eta w_{T-1}\\\\ \u0026amp;=(I-\\eta\\nabla^2L(w_{T-1}))\\nabla_\\eta w_{T-1}-\\nabla^\\top L(w_{T-1}) } $$\nwhich is a first-order recurrence. This is called Forward-Mode Differentiation. The problem with it is that, if there\u0026rsquo;re not just one, but thousands of hyperparameters $\\eta_1,\\cdots,\\eta_k$, we need to store $\\nabla_{\\eta_i}w_T$ for each $\\eta_i$, costing $\\O(kdw)$ space.\nDefinition 3. The process of momentum gradient descent (with variable learning rate) is:\nFirst initialize $w_0$. Every step let $g_t=\\nabla_{w_t}L(w_t,\\theta,t)$, where $\\theta$ contains the configuration of the training loss. Then $v_{t+1}=\\gamma_tv_t-(1-\\gamma_t)g_t$, $w_{t+1}=w_t+\\alpha_tv_{t+1}$. Note that this formula is slightly different from the one presented in class: in the slides it is $w_{t+1}=w_t+\\alpha_tv_t$. So the following recurrence formulas are also slightly different. Theorem 3. Using momentum gradient descent, we can trace back to the gradient of intermediate parameters with respect to the hyperparameters, from the final state.\nProof. The hyperparameters are: $w_1$, $\\theta$, $\\gamma_t$, $\\alpha_t$. Denote the test loss as $f(w_T)$. Now we can calculate the gradients by chain rule. Initially we only have $v_T$, $w_T$ and $\\nabla_{w_T}f(w_T)$.\n$w_t=w_{t+1}-\\alpha_tv_{t+1}$ $g_t=\\nabla_{w_t}L(w_t,\\theta,t)$ $v_t=(v_{t+1}+(1-\\gamma_t)g_t)/\\gamma_t$ $\\nabla_{\\alpha_t}f(w_T)=\\nabla_{w_{t+1}}f(w_T)\\nabla_{\\alpha_t}w_{t+1}=\\nabla_{w_{t+1}}f(w_T)v_{t+1}$ $\\nabla_{\\gamma_t}f(w_T)=\\nabla_{v_{t+1}}f(w_T)\\nabla_{\\gamma_t}v_{t+1}=\\nabla_{v_{t+1}}f(w_T)(v_t+g_t)$ $\\nabla_\\theta f(w_T)\\xleftarrow{+}\\nabla_{v_{t+1}}f(w_T)\\nabla_{g_t}v_{t+1}\\nabla_\\theta g_t=-\\nabla_{v_{t+1}}f(w_T)(1-\\gamma_t)\\nabla_\\theta\\nabla_{w_t}L(w_t,\\theta,t)$ $\\nabla_{w_t}f(w_T)=\\nabla_{v_{t+1}}f(w_T)\\nabla_{g_t}v_{t+1}\\nabla_{w_t}g_t=-\\nabla_{v_{t+1}}f(w_T)(1-\\gamma_t)\\nabla_{w_t}\\nabla_{w_t}L(w_t,\\theta,t)$ $\\nabla_{v_t}f(w_T)=\\nabla_{w_t}f(w_T)\\nabla_{v_t}w_t+\\nabla_{v_{t+1}}f(w_T)\\nabla_{v_t}v_{t+1}=\\nabla_{w_t}f(w_T)\\alpha_{t-1}+\\nabla_{v_{t+1}}f(w_T)\\gamma_t$ This procedure is called Reverse-Mode Differentiation, or simply backpropagation.\nTo analyze the space used by this method, we need to take precision into consideration. If we use floating point expression and keep dividing $v$ by $\\gamma$, after a number of time, $v$ will be full of noise produced by the precision error which is initially tiny. If we use fractional expression, by information theory we need to store at least $\\O(T\\log\\gamma^{-1})$ bits, which is far less than storing every $w_t$, or using forward-mode differentiation.\nDefinition 4. The best arm identification problem is to identify the one with the maximum expectation, among $n$ random variables $X_1,\\cdots,X_n$, under limited number of sampling of these variables.\nDefinition 5. The successive halving (SH) algorithm is as follows: Let the budget be $B$. Run $\\log_2n$ rounds with round $i$ sampling each remaining variables $\\frac{2^iB}{n\\log_2n}$ times and preserving the half with the largest empirical averages. Empirical average is defined as the average of sampling results across all the previous rounds. For hyperparameter tuning, SH is simplified to just looking at the current loss.\nTheorem 4. Assume $\\Ex(X_1)\u0026gt;\\Ex(X_2)\\ge\\cdots\\ge\\Ex(X_n)$. Let $H_2=\\max_{i\u0026gt;1}i/(\\Ex(X_1)-\\Ex(X_i))^2$. $$ \\Pr\\left[\\text{SH returns the best arm with }B=\\O\\left(H_2\\log n\\log\\frac{\\log n}\\delta\\right)\\right]\\ge 1-\\delta $$ Theorem 5. For hyperparameter tuning, assume $v_i=\\lim_{t\\to\\infty}\\ell_i(t)$. Let $\\gamma_i(t)=\\max_{t^\\prime\\ge t}|\\ell_i(t^\\prime)-v_i|$ and $\\gamma^{-1}(\\alpha)=\\min\\set{t\\mid \\gamma(t)\\le\\alpha}$. Assume $v_1\u0026lt;v_2\\le\\cdots\\le v_n$ and let $\\bar\\gamma(t)=\\max_i\\gamma_i(t)$. SH returns the best arm if $$ B\\ge 2\\log_2n\\left(n+\\sum_{i\u0026gt;1}\\bar\\gamma^{-1}\\left(\\frac{v_i-v_1}{2}\\right)\\right) $$\nInterpretability Interpretability is the ability to explain why a machine learning model makes a specific decision rather than just accepting its output as a black box. Good interpretability typically involves attribution methods, which assign weights to input variables to show how much each factor influenced the final result.\nDefinition 1. LIME, Local Interpretable Model-agnostic Explanations, is a technique that approximates any black box machine learning model with a local, interpretable model to explain each individual prediction (taken from this post). The intuition is, although the whole prediction landscape is nonlinear, a linear interpretation around some certain point that we care about is plausible and viable. Here are the notations:\n$f$ is the trained model and $g$ is a linear model, both mapping the inputs to some labels. When we focus on some specific label, $f$ may stand for the corresponding component of the predicted distribution. $\\Pi_x$ is a sampling mechanism near $x$. It assigns greater values to those samples near $x$. $L(f,g,\\Pi_x)$ is the loss of linear model $g$ on the sampled points based on $\\Pi_x$, with reference to $f$. $\\Omega(g)$ measures the complexity of $g$, which acts as a regularization term in the objective function. The final objective is $$ \\min_g. L(f,g,\\Pi_x)+\\Omega(g) $$ For example:\n$\\Omega(g)=[\\|w\\|_0\u0026gt;s]\\cdot+\\infty$, which should be converted to LASSO-like soft regularizer. $\\Pi_x(z)=\\exp(-D(x,z)^2/\\sigma^2)$ where $D$ is some distance metric. $L(f,g,\\Pi_x)=\\sum_z\\Pi_x(z)\\cdot(f(z)-g(z))^2$. Definition 2. LIME explains an image classification by the following process:\nUse a segmentation algorithm to partition the image into $m$ superpixels $S_1,\\cdots,S_m$. Sample images by sampling binary vectors $z\\in\\set{0,1}^m$. The corresponding image is obtained by masking those superpixels $S_i$ for $z_i=0$, denoted as $\\sum z_iS_i$ in shorthand. Train, say $g_\\theta(z)=\\sigma(\\theta^\\top z+b)$, by $L(f,g_\\theta,\\Pi_x)=\\sum_z\\exp(-(\\text{\\# of 0s in }z)^2/\\sigma^2)\\cdot(f(\\sum z_iS_i)-g_\\theta(z))$. Recognize the top-$k$ components of $\\theta$ as the indicators responsible for the label. Why don\u0026rsquo;t simply use ablation? Because LIME takes interactions between components, and nonlinearity into account. Consider an extreme example: A dog is classified only by its two ears $S_1,S_2$, but either of its ears is enough. So $f(S_1+S_2)=1$ but also $f(S_1)=f(S_2)=1$. Ablation fails to account for this, but in LIME we face such equation set, so that the importance of both ears is equally stressed: $$ \\begin{cases} \\sigma(\\theta_1+\\theta_2+\\text{others})\\approx 1\\\\ \\sigma(\\theta_1+\\text{others})\\approx 1\\\\ \\sigma(\\theta_2+\\text{others})\\approx 1\\\\ \\sigma(\\text{others})\\approx 0 \\end{cases} $$ In practice we don\u0026rsquo;t always sample by replacing part of the input by zero/black, but rather do some small perturbation. This will expose the deficiencies of LIME: it only finds a tangent hyperplane, and the gradient is local while the information itself is not (think of vanishing gradient problem). LIME also suffers from other drawbacks e.g. instability, lack of interaction handling etc. The following part centers around the paper Axiomatic Attribution for Deep Networks.\nDefinition 3. The Integrated Gradients Algorithm attributes the contribution of each component $i$ of the input $x$ to the following integral: $$ \\mathrm{IntegratedGrads}_i(x)=(x_i-x_i^\\prime)\\int_0^1\\frac{\\p f(x^\\prime+\\alpha(x-x^\\prime))}{\\p x_i}\\d\\alpha $$ where $x^\\prime$ is the baseline, for example a pure black image in the case of image classification. In practice the integral is approximated by some finite element method.\nTheorem 1 (informal). The Integrated Gradients Algorithm is the only algorithm that satisfies the following properties (or axioms, in the original paper):\nSensitivity. If for every input and baseline that differ in one feature but have different predictions then the differing feature should be given a non-zero attribution. If the function implemented by the deep network does not depend (mathematically) on some variable, then the attribution to that variable is always zero. Implementation invariance. The attributions should always be identical for two functionally equivalent networks, i.e. the input-output mappings are the same while the implementation could possibly differ. Completeness. The attributions add up to the difference between the output of $f$ at the input $x$ and the baseline $x^\\prime$. Linearity. The attributions for $af_1+bf_2$ should be the weighted sum of the attributions for $f_1$ and $f_2$ with weights $a$ and $b$ respectively. Symmetry-preserving. If two input variables are symmetric w.r.t. $f$ (e.g. $f(x,y)=\\sigma(x+y)$), they should receive identical attributions. Definition 4. The SHAP algorithm is a method that attributes contribution of every discrete element of the input, while following the similar properties of IG algorithm as listed above. For some prediction $f(\\set{x_1,\\cdots,x_n})$, SHAP assigns $$ \\phi_i(f)=\\sum_{S\\subseteq[n]\\setminus\\set{i}}\\frac{|S|!(n-|S|-1)!}{n!}(f(S\\cup\\set{i})-f(S)) $$ The combinatorial meaning is enumerating every permutation of $x_1,\\cdots,x_n$, adding the elements following the permutation and averaging the change of prediction. For element $i$, there are $|S|!(n-|S|-1)!$ permutations of the form $S,i,[n]\\setminus(S\\cup\\set{i})$, all contributing $f(S\\cup\\set{i})-f(S)$.\nBoth IG and SHAP focus on global attribution, so sometimes they exhibit poor local fidelity.\nSelective Exercises Problem 1. Prove that for $f\\in\\fF^1(\\R^n)$ and $g\\in\\fF^0(\\R^n)$, at $x_{*}=\\argmin_x\\set{f(x)+g(x)}$, $\\forall x$, $g(x)\\ge g(x_{*})-\\ip{\\nabla f(x_{*}),x-x_{*}}$. Avoid using subgradient.\nSolution (wmy). Let $x=x_{*}+tu$ where $\\|u\\|=1$. By Taylor expansion, $$ f(x)=f(x_{*})+t\\ip{\\nabla f(x_{*}),u}+\\omicron(t) $$ Also $$ f(x)+g(x)\\ge f(x_{*})+g(x_{*}) $$ so $$ g(x)-g(x_{*})\\ge -t\\ip{\\nabla f(x_{*}),u}+\\omicron(t)\\implies\\frac{g(x_{*}+tu)-g(x_{*})}t\\ge-\\ip{\\nabla f(x_{*}),u}+\\omicron(1) $$ We know that $(g(x_{*}+tu)-g(x_{*}))/t$ is monotone, so $$ \\frac{g(x_{*}+tu)-g(x_{*})}{t}\\ge \\lim_{t^\\prime\\to 0^{*}}\\frac{g(x_{*}+t^\\prime u)-g(x_{*})}{t^\\prime}\\ge -\\ip{\\nabla f(x_{*}),u} $$ Problem 2. In MD, if we add a constraint on $x$, that is, consider a convex set $Q$, $x_{t+1}=\\argmin_{y\\in Q}\\set{\\cdots}$. How to modify the proof, to get the same result?\nSolution. Recall that $x_{t+1}=\\argmin_{y}\\set{\\ip{\\eta\\nabla f(x_t),y-x_t}+V_{x_t}(y)}$. The error appears at line 2/3 in the proof of theorem 15: $$ \\ip{\\eta\\nabla f(x_t),x_{t+1}-x_{*}}=\\ip{-\\nabla V_{x_t}(x_{t+1}),x_{t+1}-x_{*}} $$ For arbitrary $Q$, it\u0026rsquo;s hard to write the Lagrange multiplier. Here\u0026rsquo;s a way only using properties of convex set: Let $g(y)=\\ip{\\eta\\nabla f(x_t),y-x_t}+V_{x_t}(y)$, $h(\\alpha)=g(x_{t+1}+\\alpha(x_{*}-x_{t+1}))$. Since $x_{t+1}$ is argmin, $h^\\prime_+(0)\\ge 0$: $$ \\ip{\\nabla g(x_{t+1}),x_{*}-x_{t+1}}=\\ip{\\eta\\nabla f(x_t)+\\nabla V_{x_t}(x_{t+1}),x_{*}-x_{t+1}}\\ge 0 $$ i.e. $$ \\ip{\\eta\\nabla f(x_t),x_{t+1}-x_{*}}\\le\\ip{-\\nabla V_{x_t}(x_{t+1}),x_{t+1}-x_{*}} $$ Problem 3. On probability vectors, define $w(x)=\\sum x^i\\log x^i$, $V_x(y)=\\sum y^i\\log\\frac{y^i}{x^i}$. Prove that $V_x(y)\\ge\\frac12\\|x-y\\|_1^2$, that is, it is $1$-strongly convex w.r.t. to $1$-norm.\nSolution 1 (mjy). By Taylor expansion, $\\exists\\xi=x+\\theta(y-x)$, $$ V_x(y)=w(y)-w(x)-\\ip{\\nabla w(x),y-x}=\\frac12(y-x)^\\top\\nabla^2w(\\xi)(y-x) $$ Surprisingly, $$ \\nabla^2 w(\\xi)=\\diag\\left(\\frac{1}{\\xi^1},\\cdots,\\frac{1}{\\xi^d}\\right) $$ by Cauchy inequality, $$ (y-x)^\\top\\nabla^2w(\\xi)(y-x)=\\sum_{i=1}^d\\frac{(y^i-x^i)^2}{\\xi^i}=\\left(\\sum_{i=1}^d\\frac{(y^i-x^i)^2}{\\xi^i}\\right)\\left(\\sum_{i=1}^d\\xi^i\\right)\\ge\\left(\\sum_{i=1}^d|y^i-x^i|\\right)^2=\\|x-y\\|_1^2 $$\nSolution 2 (standard proof of Pinsker\u0026rsquo;s inequality that can be generalized to infinite-dimension case). First, for $0 \\le p, q \\le 1$, let $f(p,q) = q\\log\\frac{q}{p} + (1-q)\\log\\frac{1-q}{1-p} - 2(q-p)^2$. $$ \\frac{\\partial f}{\\partial p} = -\\frac{q}{p} + \\frac{1-q}{1-p} + 4(q-p) = (q-p)\\left(4-\\frac{1}{p(1-p)}\\right)\\begin{cases}\\le 0,\u0026amp;q\\le p\\\\ \\ge 0,\u0026amp;q\\ge p\\end{cases} $$ when $p=q$, $f(p,q)=0$. So $f(p,q) \\ge 0$. Now, $$ \\eq{ \\sum_{i=1}^n y_i \\log\\frac{y_i}{x_i} \u0026amp;= \\sum_{y_i \\le x_i} y_i \\log\\frac{y_i}{x_i} + \\sum_{y_i \u0026gt; x_i} y_i \\log\\frac{y_i}{x_i}\\\\ (\\text{by convexity of }y\\log \\frac yx)\u0026amp;\\ge \\left(\\sum_{y_i \\le x_i} y_i\\right) \\log \\frac{\\sum_{y_i \\le x_i} y_i}{\\sum_{y_i \\le x_i} x_i} + \\left(1 - \\sum_{y_i \\le x_i} y_i\\right) \\log \\frac{1 - \\sum_{y_i \\le x_i} y_i}{1 - \\sum_{y_i \\le x_i} x_i} \\\\ \u0026amp;\\ge 2\\left(\\sum_{y_i \\le x_i} (y_i - x_i)\\right)^2 \\\\ \u0026amp;= \\frac{1}{2}\\|y-x\\|_1^2 } $$\nProblem 4. Let $\\hy=\\set{h_a(x)=[\\sin(ax)\u0026gt;0]\\mid a\\in\\R}$. Prove that $\\VC(\\hy)=\\infty$.\nSolution. Consider $\\set{1,2,4,\\cdots,2^n}$. If we want label $2^i$ with $b_i$, then take $$ a=\\pi\\sum_{i=0}^n(1+\\epsilon-b_i)2^{-i} $$ I claim that this $a$ satisfies the requirement. We can consider $\\set{1,2,4,\\cdots}$ on $h_a(x)=[\\sin(ax)\u0026gt;0]$ as labeling $2^i$ with $[2^id\\bmod 2\\in(0,1)]$ where $d=a/\\pi$. $$ 2^id\\equiv\\sum_{j=0}^n(1+\\epsilon-b_j)2^{i-j}\\equiv 2^{i+1}(1-2^{-n-1})\\epsilon+(1-b_i)+\\sum_{j=i+1}^n(1-b_j)2^{i-j}\\pmod2 $$ $0\\le\\sum_{j=i+1}^n(1-b_j)2^{i-j}\\le 1-2^{i-n}$, and we can take small enough $\\epsilon$ so that the value $\\in(0,1)$ when $b_i=1$ and $\\notin(0,1)$ when $b_i=0$. This exactly match the requirement of the labels.\nProblem 5. For a $2n\\times m$ matrix $A$, show that $\\max\\|e_i^\\top U\\|_2=\\frac{1}{\\sqrt n}$ if $A$ has equal numbers of two linearly independent rows. WLOG assume the first $n$ and the rest rows are the same respectively.\nSolution 1. Suppose $A=U\\Sigma V^\\top$, $U=\\mat{u_1\u0026amp;u_2}$, $\\Sigma=\\operatorname{diag}(\\sigma_1,\\sigma_2)$, $V=\\mat{v_1\u0026amp;v_2}$. $\\forall 1\\le i,j\\le n$, since the top $n$ rows are the same, $$ A^\\top(e_i-e_j)=0\\implies u_1^\\top(e_i-e_j)=u_2^\\top(e_i-e_j)=0 $$ the same for $n+1\\le i,j\\le 2n$. So we can assume $$ U=\\mat{a\u0026amp;c\\\\ \\vdots\u0026amp;\\vdots\\\\a\u0026amp;c\\\\b\u0026amp;d\\\\ \\vdots\u0026amp;\\vdots\\\\b\u0026amp;d} $$\nwhere $a^2+b^2=c^2+d^2=\\frac1n$, $ac+bd=0$. From this we get $a^2+c^2=b^2+d^2=\\frac1n$. So $\\max\\|e_i^\\top U\\|_2=\\frac1{\\sqrt n}$.\nSolution 2 (qkx). You may go through problem 6 first. $U U^\\top$ is the projection matrix onto the column space of $A$, so $UU^\\top$ can be calculated by any basis for the column space. The simplest basis is $$ \\Set{u_1^\\prime=\\mat{\\frac1{\\sqrt n}\\\\ \\vdots\\\\ \\frac1{\\sqrt n}\\\\0\\\\ \\vdots\\\\0},u_2^\\prime=\\mat{0\\\\ \\vdots\\\\0\\\\ \\frac1{\\sqrt n}\\\\ \\vdots\\\\ \\frac1{\\sqrt n}}} $$ Let $U^\\prime=\\mat{u_1^\\prime\u0026amp;u_2^\\prime}$. $$ UU^\\top=U^\\prime{U^\\prime}^\\top=\\mat{\\frac1n I_n\u0026amp;O\\\\O\u0026amp;\\frac 1nI_n} $$ Problem 6. How to calculate incoherence of $A$ without SVD?\nSolution. Assume $A=U\\Sigma V^\\top$, then $\\|e_i^\\top V\\|^2=(VV^\\top)_{i,i}$. Notice that $$ A^\\top(AA^\\top)^{-1}A=V\\Sigma U^\\top(U\\Sigma^2U^\\top)^{-1}U\\Sigma V^\\top=VV^\\top $$\nA simple way to understand this is that $V^\\top$ corresponds to the row space of $A$, and $e_i^\\top V$ is the projection of the standard orthonormal basis onto the row space of $A$. Then least squares suffices. Problem 7. Find a locality sensitive hash family under $\\ell_p$-norm.\nSolution. Recall the construction for $\\ell_2$-norm. The idea is to sample some $r\\in\\R^d$, where i.i.d. $r_i\\sim\\pd(0,1)$, and it needs to satisfy $\\ip{r,p-q}\\sim\\pd$, specifically, $\\ip{r,p-q}\\sim\\pd(0,\\|p-q\\|_p^p)$ (oops, I overloaded $p$, whatever\u0026hellip;). Formally, the two required properties are:\nIf $X\\sim\\pd_\\alpha$, then $cX\\sim\\pd_{|c|^p\\alpha}$. If $X\\sim\\pd_\\alpha$, $Y\\sim\\pd_\\beta$, then $X+Y\\sim\\pd_{\\alpha+\\beta}$. Such a distribution is called a $p$-stable distribution, and it can be proven to exist only for $p\\in(0,2]$. For $p=2$ the distribution is Gaussian $f(x)=\\frac{1}{\\sqrt{2\\pi}}\\e^{-x^2/2}$ and the characteristic function is $\\e^{-t^2/2}$. For $p=1$ the distribution is Cauchy $f(x)=\\frac1\\pi\\frac1{1+x^2}$ and the CF is $\\e^{-|t|}$. No analytical expression exists for other $p$ under skewness $0$.\n","date":"2026-02-20T00:00:00Z","image":"https://littlereuben.github.io/study/course-machine-learning/cover.png","permalink":"https://littlereuben.github.io/study/course-machine-learning/","title":"Machine Learning (机器学习笔记)"},{"content":"这是一篇学习笔记。\r西方音乐史 古希腊与罗马。用的是文字谱。例如塞基洛斯的墓志铭。 中世纪（5~14,15世纪），这时音乐不是为了娱乐，而是作为宗教仪式中的工具。 文艺复兴（14~16世纪），歌曲盛行：英国圣诞颂歌（行进式）、法国尚松、意大利牧歌。歌曲的繁荣为歌剧作准备。 巴洛克Baroque（17世纪~1750），歌剧，即若干歌曲的有机联合，诞生了。交响乐是从歌剧中萌芽，具体而言，歌剧中的乐队独立出来。 古典主义Classicism（1750~1820），交响乐的成熟阶段，范式确定。其中最主要的就是维也纳古典主义（第一维也纳乐派）的三位作曲家：海顿、莫扎特、贝多芬。 浪漫主义Romanticism（1790~1910），交响乐的繁荣阶段。这时出现了交响诗、交响音画。有肖邦（当然他主要是写钢琴曲的）、李斯特（创立单乐章交响诗）。 19、20 世纪之交：有法国印象主义impressionism、德奥晚期浪漫主义、俄罗斯神秘主义、意大利真实主义。是交响乐的创新阶段。 20 世纪现代主义modernism：表现主义、新古典主义、民族主义等。是交响乐的探索阶段。 对比交响乐雏形与当代交响乐 16 世纪末，佛罗伦萨卡梅拉塔Florentine Camerata社团（卡契尼、佩里、文森佐·伽里莱、利努契尼等）的成员创作了最早的歌剧opera：达芙妮Dafne，还有尤丽迪茜Euridice。\n尤丽迪茜\rEuridice\rJacopo Peri, Giulio Caccini\r歌剧的第一部分称为序曲overture。亚历山德罗·斯卡拉蒂Alessandro Scarlatti（1660~1725）确立了意大利歌剧序曲的结构：快—慢—快，也就是众所周知的 ABA。例：\nCain, ovvero Il primo omicidio\rAlessandro Scarlatti\r我们可以明显听出序曲的结构。\n作为其儿子，多梅尼科·斯卡拉蒂Domenico Scarlatti（1685~1757）继承父业，他与拉莫、亨德尔、巴赫并称巴洛克晚期的四位大师，同时也是古典奏鸣曲式的先驱。相比父亲，他作品更加明快移动，很多和声偏向当代。\nTolomeo et Alessandro, ovvero La corona disprezzata\rDomenico Scarlatti\r伊戈尔·斯特拉文斯基是现代主义代表人物，也是反叛、创新的代表人物。现代主义音乐从可听性转向研究性，例如：\n春之祭\rThe Rite of Spring\rIgor Stravinsky\r斯卡拉蒂—斯特拉文斯基：开创者—开拓者\n\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\r作曲的基本结构 音乐结构发展逻辑：乐汇cell、动机motif→乐节sub-phrase→乐句phrase→乐段period→单曲式simple form→复曲式compound form→奏鸣曲式sonata form→套曲suite。具体定义：\n乐汇：音乐语言中最小的单位，可能只是两三个音符，本身可能没有完整的意义。 动机：具有鲜明特征（节奏、旋律或和声）的乐汇，例如贝五开头的 G−G−G−E♭。也包括主导动机（瓦格纳歌剧中代表特定人物或事物的旋律）、固定乐思（柏辽兹《幻想交响曲》中贯穿全曲、代表爱人的旋律）。 乐节：由动机或乐汇组成的片段。有停顿，但没有和声终止式（听起来没完结）。 乐句：有明显的旋律停顿和和声终止式。 乐段：几个乐句组成一个乐段。 再现单三部曲式ternary form：三个乐段，结构为呈示段(A)→对比段(B)→回归段(A1)。每个乐段由两个乐句组成，每个乐句 4 个小节。 再现复三部曲式compound ternary form：三个单曲式，也是 A→B→A1。A 是单三部或单二部，B 是三声中部（结构上也是单三部或单二部，但与 A 在情绪、调性或织体上形成显著对比）或插部（不是一个结构完整、封闭的乐段，而是由多个零散的动机或乐句组成的片段）。 奏鸣曲式：整体模式还是一样的，呈示部→展开部→再现部，但并非每个部分都是一个复三部。奏鸣曲比复三部更有深度，更宏大，而复三部更工整稳定。 呈示部：主部主题→连接部→副部主题→结束部。主部与副部是形象对比、性格对比、调性对比，但无明显具体曲式结构；连接部负责过渡，提供新材料或展开材料；结束部巩固副部地位。 展开部：引入→中心→属准备。主部、副部材料拆碎后交替展开，进行各种调性上的剧烈变换。解决矛盾，推动情绪达到顶峰。 再现部：结构和呈示部一样，但副部调性回归主调，主、副部主题的矛盾得到统一。 前古典主义时期 不是……巴洛克晚期真就一点也不讲？\n受到第一次工业革命和启蒙运动的影响，出现了前古典主义时期（1750~1827）：交响乐从歌剧序曲中脱胎。约翰·斯塔米茨Johann Stamitz，推动交响乐的繁荣，确定了交响乐的套曲形式：\n第一乐章：快或急板 第二乐章：行板性质的慢板 第三乐章：小步舞曲 第四乐章：更快的终曲 以弦乐队写作为主。同时，创作思维由巴洛克及之前的复调向主调音乐转变。复调音乐象征着宗教，主调音乐是面向大众的，因为主旋律清晰，更容易被大众接受。\nD 大调交响曲\rSymphony in D major, Op. 5 No. 2\rJohann Stamitz\r维也纳古典主义 海顿与莫扎特 很多人把约瑟夫·海顿Joseph Haydn（1732~1809）叫做交响乐之父，因为创作的交响乐数量之多，有 108 部。在 1781 年时认识了沃尔夫冈·阿玛多伊斯·莫扎特Wolfgang Amadeus Mozart（1756~1791），成为了忘年交。众所周知，莫扎特父亲也是作曲家，莫扎特是 6 岁就登台的神童。相比稳重的海顿，他性格不羁，一生都和贵族作斗争，只活了 35 岁。他对协奏曲concerto和歌剧的贡献多于对交响乐的贡献，确立了钢琴协奏曲的曲式结构。\n海顿确定了交响乐四个乐章movement的曲式form：\n第一乐章：快板，奏鸣曲式 第二乐章：行板或慢板，三部曲式 第三乐章：带三声中部的小步舞曲minuet或谐谑曲scherzo（后者由贝多芬引入），复三部曲式 第四乐章：急板，回旋曲rondo式、奏鸣曲式或回旋奏鸣曲式 伦敦交响曲\rSymphony No. 104 in D major \"London\"\rFranz Joseph Haydn\r会发现第一乐章快板之前有一个慢板的阶段，叫引入，这能引起一个戏剧性的突变。在莫扎特那里就没有了。\n第 40 号交响曲\rSymphony No. 40 in G minor, K. 550\rWolfgang Amadeus Mozart\r海顿：器乐化旋律；莫扎特的旋律富有歌唱性，同时失去了一定的交响性，更通俗易懂。\n\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\r贝多芬 路德维希·凡·贝多芬Ludwig van Beethoven的人生：\n波恩时期（1770~1792）：他的父亲和祖父都是音乐家，但父亲嗜酒，对他很严厉，导致他一直有轻微的抑郁。他 4 岁开始学乐器，13 岁当上宫廷乐师，20 多岁受到了贵族的认可，当时他非常自信，自认为无人能敌。他当时的音乐创作体裁有：三重奏、四重奏、钢琴变奏曲、歌曲。 维也纳时期（1792~1802）：随海顿学习作曲，与阿尔布莱西贝尔格学习对位（复调）。同时 1798 年耳疾出现。 贝一、二 创作成熟期（1803~1814）：开创了单一主题展开的技术，对第三乐章进行改革（小步舞曲转化为谐谑曲）。这一时期末他几乎完全失聪，但作为指挥家必须向别人隐瞒这个事，于是在指挥歌剧时就出现了很多事故，名声慢慢变差。 贝三（英雄，写给拿破仑）、四、五（命运，“单一主题展开”的教科书）、六（田园，五乐章）、七、八 创作晚期（1815~1827） 贝九（第四乐章欢乐颂，合唱第一次加入交响乐）体现了贝多芬心中世界大同的美好愿望。 贝一—八（合集）\rLudwig van Beethoven\r贝九\rLudwig van Beethoven\r贝多芬属于时代与时代之间转变的阶段，继承了古典，开启了浪漫，尤其是贝五被很多音乐家认为是古典和浪漫的分界线（因为其中开始出现很多戏剧性）。他的音乐中有时代性，宏大的声响。相比来说海顿属于中庸之道。\n这是课件里的一个小节数统计：\n作品 引子 呈示部 展开部 再现部 尾声 共计 海顿 94 17 90 47 94 10 258 莫扎特 41 0 120 68 120 5 313 贝多芬 3 2 149 246 155 139 691 从小节数的角度来看，说明浪漫派已经来临。展开部的长度说明贝多芬的能力比其他两者强，因为难写，要借呈示部的内容来写。\n浪漫主义 无论是音乐、美术还是文学，都有古典主义和浪漫主义时期，体现出相对照的特征：\n古典：形式严谨、逻辑缜密、和谐完美（统一、秩序、形式与内容平衡） 浪漫主义：突破边界、自由延展、情感至上（个性、朦胧暧昧、暗示隐喻） 古典主义集中在形式美，浪漫主义注重人的情感感受、内在心理活动，这也预示着后来的印象派。\n针对浪漫主义的艺术，有话说道：\nMusic is the most romantic of all arts. —E. T. A. Hoffmann\n当然，浪漫主义对古典主义的承续大于对立。它们有共同的声响概念、共同的和弦与和声基础、共同的曲式规范。\n老师说，中世纪的音乐是写给神听的、浪漫主义是写给人听的，印象派是写给自然听的，现代主义是写给鬼听的（（\n舒伯特 弗朗茨·舒伯特Franz Schubert（1797~1828）是浪漫主义早期作曲家。出生及去世于维也纳。家境不好。五岁开始跟父亲学钢琴，十几岁考上唱诗班，接触到了海顿和莫扎特的作品。他还跟萨利耶里学作曲，学了一两年回去父亲的学校当老师。1816 年辞职，以音乐创作为终身事业，卖作品为生。\n舒伯特在艺术歌曲art song上的成就远大于交响乐，被称为艺术歌曲之王。\n第八交响曲是舒伯特加入格拉茨音协，为感谢其写的。但这首交响曲只有两个乐章，他辞世三十多年后，门德尔松发现了第三乐章的手稿，于是这首交响曲就被认为是“未完成的交响曲”。但是现在一些观点根据这两个乐章的内容结构认为这是已完成的。\n第八（未完成）交响曲\rSymphony No. 8 in B minor \"Unfinished\"\rFranz Schubert\r两分半时，抒情的主题一下子陷入恐惧，古典主义不会这样干，这是典型的浪漫主义。\n舒曼 罗伯特·舒曼Robert Schumann（1810~1856），音乐评论家、作曲家、钢琴家。小时候爱好文学，也学习音乐。大学学的法律。受到帕格尼尼和李斯特的影响，决定做钢琴家，并创作钢琴音乐。然而由于右手无名指被自己练伤了，就只能作曲了……\nA 小调钢琴协奏曲\rPiano Concerto in A minor, Op. 54\rRobert Schumann\r这是写给他妻子的。\n第一交响曲“春天”\rSymphony No. 1 in B-flat major, Op. 28 \"Spring\"\rRobert Schumann\r记录和克拉拉刚结婚时出去旅行的见闻。\n舒曼第三交响曲和贝六、贝三有些联系。\n第三交响曲“莱茵”\rSymphony No. 3 in E-flat major, Op. 97 \"Rhenish\"\rRobert Schumann\r协奏曲不是交响乐。首先有个独奏乐器（钢琴/小提琴），然后有一个大的交响乐队竞奏，不是陪衬。独奏乐器与上百人的乐队做抗衡，所以作曲者首先要很熟悉交响乐。协奏曲属于交响乐，但不是交响曲。\n写协奏曲的顺序：作曲者要倾其所有技术在上面，所以演奏难度高。作曲者必须要有较高的演奏水平，能驾驭这首曲子。先写独奏钢琴，再写乐队部分，先写其中第二架钢琴。\n协奏曲的乐队和交响曲的乐队的区别：交响乐有很清晰的铜管组，协奏曲中的乐队是很克制的。铜管出来啥都听不见了。\n格林卡 米哈伊尔·伊万诺维奇·格林卡Михаил Иванович Глинка（1804~1857）被称为俄罗斯音乐之父，他主要作的是歌剧和管弦乐。他的风格是取材于俄罗斯民间音乐，吸取城市音乐文化养分，同时借鉴西欧古典、浪漫乐派的音乐成果。他是民族主义的代表人。他的出现标志着俄罗斯专业音乐的成熟，为俄罗斯音乐后续的发展奠定了基础。鲁斯兰与柳德米拉：\n鲁斯兰与柳德米拉序曲\rRuslan and Ludmilla (Overture)\rMikhail Glinka\r门德尔松 费利克斯·门德尔松Felix Mendelssohn（1809~1847）是德国的作曲家、指挥家、音乐评论家、音乐教育家。他创作了 5 部交响曲、7 部管弦乐序曲、钢琴套曲《无词歌》，还有许多钢琴协奏曲、小提琴协奏曲。他 17 岁时作的《仲夏夜之梦》称为“标题性”序曲，与文学作品产生关联。《仲夏夜之梦》是单乐章奏鸣曲式，专为音乐会独立演奏。\n仲夏夜之梦\rA Midsummer Night's Dream\rFelix Mendelssohn\rE 小调小提琴协奏曲\rViolin Concerto in E MinorOp. 64\rFelix Mendelssohn\r门小协，最有名的 Hahn 的版本。\n三乐章，快、慢、快。有一个特点是乐章间连续演奏。\n和声、和弦、配器、曲式共同作用，带给我们立体的听觉感受。\n交响乐一般标题和曲子关系不大，因为标题是后取的。\n柏辽兹 艾克托尔·柏辽兹Hector Berlioz（1803~1869）出生于法国的医生家庭，小时候没机会学音乐，不会弹钢琴，但学了长笛、吉他。12 岁尝试作曲。1821 年进入巴黎医科学院，后放弃，26 岁才进入音乐学院。\n对音乐界最大的贡献：标题化（命名）交响曲。他还开启了在总谱上标文字（描述所写场景等）的形式。他希望自己的音乐和文学、戏剧发生深刻的关联。他大量的音乐作品都包含标题、构思、解释，希望构建宏大的叙事，于是作品结构都很庞大，长达一个多小时。\n幻想交响曲：自导自演的幻想闹剧。讲的是个很狗血的故事，这里就不展开了，柏辽兹自身精神也有点问题……\n幻想交响曲\rSymphonie Fantastique\rHector Berlioz\r其特点在于固定乐思：用同一组旋律表示一个主角，可以理解为是对贝多芬《命运》的继承。例如会发现，描写女主和女巫的旋律实质上是同一条。听第一乐章时，似乎能感觉到一种说话的语气。\n第五乐章最后一段特别牛。\n勃拉姆斯 约翰内斯·勃拉姆斯Johannes Brahms（1833~1897）和巴赫、贝多芬并称德国的音乐三巨匠，三 B。他是浪漫时代古典音乐的守护者，不喜欢当时浪漫主义新兴的标题性音乐，还是坚持古典主义。一生作了四部交响曲，每部都做了十几年甚至几十年。\n勃拉姆斯和舒曼以及舒曼的妻子克拉拉有很紧密的关系，这里就不展开了。\n可以对比一下舒曼写给克拉拉的钢琴协奏曲和勃拉姆斯的：\nA 小调钢琴协奏曲\rPiano Concerto in A minor, Op. 54\rRobert Schumann\rD 小调钢琴协奏曲\rPiano Concerto No. 1 in D minor, Op. 15\rJohannes Brahms\r勃一用的是古典动机发展手法。对单一主题展开的继承很彻底，可以说是对贝一的延续，而且在结尾借用了贝九的内容。所以又被称为“贝十”。开头持续音，典型的古典主义。巴洛克复调对位技巧。\n第一交响曲\rSymphony No. 1 in C minor, Op. 68\rJohannes Brahms\r最有名的勃四，据说是他看古希腊悲剧《俄狄浦斯王》时写的。\n第四交响曲\rSymphony No. 4 in E minor, Op. 98\rJohannes Brahms\r强力集团 俄国的强力集团Могучая кучка（由当时的音乐评论家斯塔索夫命名）是格林卡的第一代继承。以巴拉基列夫为首，剩下四个都并非专业作曲。他们形成一个圈子，经常聚在一起讨论音乐。\n只有三个人的才华是受到音乐界公认的：鲍罗丁、里姆斯基·科萨科夫、穆索尔斯基。\n巴拉基列夫Балакирев（1837~1910）是职业作曲家、钢琴家、指挥家，强力集团发起人与领导者。他的音乐教育能力和活动能力大于创作能力。理论能力很强。代表作是交响诗《塔玛拉》：\n塔玛拉\rTamara\rMily Balakirev\r居伊Кюи（1835~1918）是工程师，同时也是音乐批评家，音乐评论胜过创作。主要创作题材包括声乐浪漫曲、室内乐。\n穆索尔斯基Мусоргский（1839~1881）是军官。最有名的两个作品是交响音画《荒山之夜》和钢琴套曲《图画展览会》。法国作曲家拉威尔后来将《图画展览会》进行配器成为管弦乐，震惊了世界。《荒山之夜》的配器也是他死后科萨科夫给他配的。\n荒山之夜\rNight on Bald Mountain\rModest Mussorgsky\r图画展览会\rPictures at an Exhibition\rModest Mussorgsky\r和德奥体系不同的点：德奥体系的作品即使到了浪漫主义是严谨、结构工整、思辨（比作论文）；而俄罗斯民间音乐很有场面感（比作小说）。\n鲍罗丁Бородин（1833~1887）是化学家和院士，研究之余写音乐。交响音画《在中亚细亚草原上》，第二交响曲《勇士》。\n在中亚细亚草原上\rIn the Steppes of Central Asia\rAlexander Borodin\r第二交响曲“勇士”\rSymphony No. 2 in B Minor, Op. 5 \"Bogatyr\"\rAlexander Borodin\r前者明显能听出中东的曲调，强弱是拱形结构。当时评论家对他的作品评论是：具有巨大的力量。但老师认为写得作品比较简单，只有一个乐章，像半成品，有些地方就写了几个旋律的单音，没有和声，没有对位。《勇士》也没有把勇士的特征写出来，才华不够。\n里姆斯基-科萨科夫Римский-Корсаков（1844~1908）也是军官，不过最后进入音乐学院转为专业作曲。他还是音乐理论家，著有两本有名的教材《和声学实用教材》《管弦乐法原理》，他还教过斯特拉文斯基。他作了 14 部歌剧，还有管弦乐《西班牙随想曲》、交响组曲《天方夜谭》——尽管是交响组曲，但结构遵循交响曲。\n天方夜谭\rScheherazade, Op. 35\rNikolai Rimsky-Korsakov\r强力集团维持了十年然后解散，因为在作曲理念上有了分歧。\n李斯特 新德意志学派的主要人物是柏辽兹、李斯特、瓦格纳。这个学派的特点是受到贝多芬的很大影响。他们与勃拉姆斯的共同点是单一主题展开，和勃拉姆斯的不同点是他们推崇标题音乐，而后者反对。\n弗朗茨·李斯特Franz Liszt（1811~1886）出生于匈牙利，是钢琴神童。他师从车尔尼（who 师从贝多芬），是钢琴家、指挥家、作曲家、评论家。他是浪漫主义钢琴技术巅峰。他是交响诗symphonic poem的创始者，一共写了 13 首。\n“音乐能再现当代诗歌巨作中的光辉形象”\n“标题描绘或说明乐曲所隐含的和它要引起的情感”\n“自己的音乐和标题文字所表现的思想融合为一个整体”\n最有名的是《塔索》，following 歌德的同名戏剧。\n塔索\rTasso: Lamento e Trionfo\rFranz Liszt\r会发现开头一直在“不断发问”。\n李斯特用的一个主要技术是主题变形，其实就是贝多芬的单一主题展开。\n瓦格纳 理查德·瓦格纳Richard Wagner（1813~1883）是德国的作曲家、戏剧家。他出生时父亲就去世了。他自学音乐，喜欢文学，性格和柏辽兹、李斯特一致。博览群书。他的梦想是创作乐剧Musikdrama（自创的词，现在人们还是管他的作品叫歌剧），这是一种整体艺术Gesamtkunstwerk，将诗词、音乐、表演、舞台结合在一起。他的歌剧比前人的复杂，他自己连舞美、换景都要管，一个歌剧能演好几天，例如最有名的《尼伯龙根的指环》。一个主题贯穿整一幕。他还在市政的帮助下建了一个只能演他乐剧的剧院，即拜罗伊特节日剧院。\n汤豪塞：序曲\rTannhäuser: Overture\rRichard Wagner\r特里斯坦与伊索尔德：序曲\rTristan und Isolde: Prelude\rRichard Wagner\r瓦格纳使用了半音化和声，从他开始，到斯特劳斯、德彪西、拉威尔，调性开始模糊，走向泛调性音乐。\n柴可夫斯基 彼得·伊里奇·柴可夫斯基Пётр Ильич Чайковский（1840~1893）是俄国的伟大作曲家，是和强力集团同时代的。家庭条件还不错，从小受到音乐教育，能接触到西欧音乐。但没有进音乐学院，学的是法律，19 岁就开始工作。后来进入圣彼得堡音乐学院学习音乐，师从鲁宾斯坦。25、26 岁这样毕业进入莫斯科音乐学院任教。后来辞职，周游世界演出，同时受到梅克夫人资助。\n他被称为“旋律大师”，他的音乐具有深刻的抒情性与强烈的戏剧性。他是新中国作曲家的作曲教科书，音乐理念和中国创作理念很相似，或者说是中国学习他的。他的作品有很多民族民间的特点，且和西方的创作技术有机结合起来。\n与此相对比的是 20 世纪开始的现代主义。西欧现在甚至反对写旋律，目前这在国内是行不通的。\n创作阶段：\n创作早期，60 年代中~70 年代中。 第一交响曲《冬日的梦幻》 幻想序曲《罗密欧与朱丽叶》 《第一钢琴协奏曲》，引子非常宏大，有两三分钟长。开头四个圆号，第二乐章拨弦。\n这个协奏曲一开始写出来时，他给鲁宾斯坦听。引子当然很好，但呈式部受到否定。但柴可夫斯基不加修改就发表，第一次演奏就受到巨大欢迎。 大提琴和乐队《洛可可主题变奏曲》 舞剧《天鹅湖》 钢琴组曲《四季》 创作中期，77 年~80 年代后。 《第四交响曲》，第一、二乐章和第一钢琴协奏曲的特征一样。第三乐章全是拨弦，第四乐章像格林卡。写的是抗争。 歌剧《叶甫根尼·奥涅金》 《D 大调小提琴协奏曲》 《1812》序曲 创作晚期，80 年代末~90 年代初。 《第五交响曲》 《第六交响曲“悲怆”》 歌剧《黑桃皇后》 舞剧《睡美人》 舞剧《胡桃夹子》 第一钢琴协奏曲\rPiano Concerto No. 1 in B-flat minor, Op. 23\rPyotr Ilyich Tchaikovsky\r柴四—六（合集）\rPyotr Ilyich Tchaikovsky\r斯美塔那 贝德里赫·斯美塔那Bedřich Smetana（1824~1884）被称为捷克音乐之父，开创了捷克民族主义音乐。他的音乐大部分是自学的（当然，是因为当时中欧的环境）。小时候学习钢琴和小提琴。1843 年到布拉格音乐学院，跟着普罗克学习作曲，同时因为经济困难，1844 年，在贵族的家庭任音乐教师教钢琴。他在学习过程中认识了李斯特和柏辽兹，还遇到了舒曼。他同时支持布拉格的革命运动，失败后去瑞典定居。晚年，他像贝多芬一样受到耳聋的折磨。\n他最著名的作品是：歌剧《被出卖的新嫁娘》（取材自捷克民间音乐，有五声调式的痕迹）和交响诗套曲《我的祖国》。后者包含六个部分：\n维谢赫拉德城堡 沃尔塔瓦河——最有名 莎尔卡 捷克的田野和森林 塔波尔小镇 布拉尼克山 被出卖的新嫁娘：序曲\rThe Bartered Bride: Overture\rBedřich Smetana\r我的祖国\rMá vlast\rBedřich Smetana\r德沃夏克 安东·德沃夏克Antonín Dvořák（1841~1904）可以认为是斯美塔那开创的捷克音乐的继承者。也是自学音乐。1858 年到斯美塔那办的歌剧乐团拉中提，1871 年辞去乐队工作，全职作曲。晚年，他被聘为美国国家音乐学院院长，到美国后，写了第九交响曲《自新世界》，其融合了捷克民族音乐和美国黑人和原住民音乐，后来常常成为美国的电影配乐。第二乐章进入中国后成为脍炙人口的《念故乡》。\n第九交响曲“自新世界”\rSymphony No. 9 \"From the New World\"\rAntonín Dvořák\rbtw《送别》也是从美国民间音乐来的：Dreaming of Home and Mother。感觉其实无论是俄国、美国还是中国的民间音乐，风格上很多都是共通的。\n同时他在美国还写了 B 小调大提琴协奏曲。第一乐章是双呈示部。\nB小调大提琴协奏曲\rCello Concerto in B Minor\rAntonín Dvořák\r圣桑 夏尔·卡米尔·圣桑Charles Camille Saint-Saëns（1835~1921）是法国浪漫主义作曲家。他是古典传统的继承者，音乐创作受李斯特影响。晚年甚至反对新兴的印象派。他在 1871 年创办了法国民族音乐协会。\n双钢琴与乐队《动物狂欢节》：\n动物狂欢节\rThe Carnival of the Animals\rCharles Camille Saint-Saëns\r小提琴与乐队《引子与回旋随想曲》：\n引子与回旋随想曲\rIntroduction and Rondo Capriccioso\rCharles Camille Saint-Saëns\r印象派 德彪西 克洛德·德彪西Claude Debussy（1862~1918）是印象派音乐的创始人。他连接传统与现代交响乐的纽带，影响了一代作曲家，甚至爵士音乐也是受他影响。\n印象派音乐是一种不写实，没有对象的音乐，它更像一种“纯音乐”的状态。特点有：\n旋律地位丧失。简短、片段、零碎的主题动机占主导地位。 结构松散自由，段落界限模糊。 和声摆脱大小调束缚，五声音阶、全音阶、高位叠置和弦及四五度叠置和弦。 音乐织体丰富多彩，音响透明、清晰、丰满。不同音区、音色的对比组合。 管弦乐《牧神午后》：\n牧神午后前奏曲\rPrélude a L'Après-midi d'un Faune\rClaude Debussy\r交响素描《大海》：\n大海\rLa Mer\rClaude Debussy\r找不到旋律，但听得到自然中的声音，例如树叶、海浪、风声。\n拉威尔 莫里斯·拉威尔Maurice Ravel（1875~1937）是印象派音乐的继承者。\n管弦乐《包莱罗》，小军鼓反复重复一组两个小节的节奏，乐队在此基础上变奏。\n波莱罗舞曲\rBoléro\rMaurice Ravel\r《G 大调钢琴协奏曲》室内乐的写法，不宏大但细腻，钢琴作为一个声部。有一个小号的 solo。钢琴的地位似乎动摇，但并不是，作曲家想把他的乐思传递给每个乐器。这就是 20 世纪的创作方式。第二乐章是摇篮曲。第三乐章炫技。\nG 大调钢琴协奏曲\rPiano Concerto in G Major\rMaurice Ravel\r德奥晚期浪漫主义 布鲁克纳 安东·布鲁克纳Anton Bruckner（1824~1896）是奥地利的作曲家，不算最一流的作曲家。早年是管风琴师，24 岁才开始学作曲。特别崇拜瓦格纳并且效仿他，后来就在维也纳当作曲教师。特点是不温不火，中庸。他很会听别人的意见，改作品，就导致第三交响曲有很多个版本，因为改了好几年。\n第九交响曲\rSymphony No. 9 in D minor\rAnton Bruckner\r马勒 古斯塔夫·马勒Gustav Mahler（1860~1911）也是奥地利人，出身于波希米亚的卑微犹太家庭，当时世界局势动荡，6 岁学琴，15 岁进入维也纳音乐学院。他受到布鲁克纳和瓦格纳很大的影响。20 岁开始指挥活动，他在指挥上作出的工作是大于作曲的。37 岁任维也纳宫廷歌剧院总监，很年轻，而且任了 10 年，他任期内，该歌剧院达到欧洲歌剧历史上的最高水准。但他一直与剧院的保守势力作斗争，最后不得不辞职，后受邀执掌美国纽约大都会歌剧院。\n他写了很多交响曲和歌曲，特点是“歌曲化的交响曲”或“交响化的歌曲”，将人声与庞大乐队结合，规模宏大到千人编制。音乐充满强烈的抒情性与戏剧对比。他家庭不幸，作品中多有悲观色彩。马勒五就是动了场接近死亡的大手术后写的。\n第五交响曲\rSymphony No. 5\rGustav Mahler\r老师说他认为第四乐章是交响乐中最美的乐章（\n马勒的交响曲结构往往是块状拼接，不同于贝多芬式的主题发展逻辑。\n施特劳斯 理查德·施特劳斯Richard Strauss（1864~1949），父亲为慕尼黑宫廷乐团圆号手，自幼受古典音乐熏陶，19 岁写了首部交响曲。21 岁开启指挥生涯，师。他热衷于新德意志学派的作曲家，同时创作受到尼采哲学影响，他的作曲风格是乐观主义的，与马勒的悲观色彩对比。他以被誉为“音诗大师”，主要的音诗作品有《死与净化》《查拉图斯特拉如是说》。\n死与净化\rTod und Verklärung, Op. 24\rRichard Strauss\r查拉图斯特拉如是说\rAlso sprach Zarathustra, Op. 30\rRichard Strauss\r拉赫玛尼诺夫 谢尔盖·拉赫玛尼诺夫Сергей Рахманинов（1873~1943）是俄罗斯作曲家、钢琴家和指挥家。出身音乐家庭，4 岁学琴，毕业于莫斯科音乐学院。1897 年他的第一交响曲首演惨败，他得了抑郁症，停止创作。后来通过心理治疗康复，并在 1901 年写出第二钢琴协奏曲，其中充满大量的积压的感情。这个作品一举成名。此后他历任剧院指挥。俄国革命后移居美国。\nC 小调第二钢琴协奏曲\rPiano Concerto No. 2 in C minor, Op. 18\rSergei Rachmaninoff\r第二交响曲\rSymphony No. 2 in E minor, Op. 27\rSergei Rachmaninoff\r现代主义 派别 作曲家 表现主义 勋伯格、贝尔格、威伯恩 新古典主义 斯特拉文斯基、兴德米特 新民族主义 巴托克、科达伊 折中主义 肖斯塔科维奇、布里顿、蒂皮特 表现主义出现于一战前夕的德奥。印象主义体现的是对外界的主观感知，例如自然、光线的印象；而表现主义则是刻画内心的体验，灵魂、感觉、情绪等。它们都是当时对艺术和社会形式的反抗。可以通过两幅画作对比两个流派的区别：\n\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\r新古典主义出现于两次世界大战之间。特点有，美学上均衡、完美、稳定，情感上理智、适度、普遍，形式结构上复调、避免半音音阶、配器透明清晰。有点像回到了最早的追求形式美的作曲。\n勋伯格 阿诺德·勋伯格Arnold Schönberg（1874~1951）是奥地利裔美国作曲家，被誉为“无调性音乐之父”。他早期作品还是晚期浪漫主义风格，后来创立了十二音作曲法。代表作是《乐队变奏曲》。\n这个十二音作曲法又叫序列主义，我是没法理解，感觉就是怎么抽象怎么来，然后作品的旋律必须严格在 48 条序列范围内。\n乐队变奏曲\rVariations for Orchestra\rArnold Schoenberg\r\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\r斯特拉文斯基 伊戈尔·斯特拉文斯基Игорь Стравинский（1882~1971）是 20 世纪最具影响力的作曲家之一，生于俄罗斯，后入法国籍并移居美国。他的创作生涯分为三个阶段：\n俄罗斯时期，三部芭蕾舞剧《火鸟》《彼得鲁什卡》《春之祭》取材于俄罗斯民间音乐。春之祭引发了很大的轰动和争议； 新古典主义（受一战的影响），追求清晰、克制的形式，如《C 大调交响曲》体现理性与泛调性特点； 晚年在美国，受到勋伯格、布里顿等的影响，采用序列主义。 春之祭\rThe Rite of Spring\rIgor Stravinsky\r兴德米特 保罗·兴德米特Paul Hindemith（1895~1963）是德国作曲家。和同时代其他作曲家不同，兴德米特还是坚持协和的重要性。创立了一套独特的多调性体系，融合巴洛克对位，采用与巴赫的作品类似的形式，但又不按传统大小调来写。虽然都归为新古典主义，但他和斯特拉文斯基差的很多。他不用十二音。\n代表作歌剧《画家马蒂斯》通过文艺复兴画家格吕内瓦尔德的故事，暗喻艺术家在动荡时代的处境与坚守。\n画家马蒂斯\rMathis der Maler\rPaul Hindemith\r巴托克 贝拉·巴托克Béla Bartók（1881~1945）是匈牙利作曲家。他的音乐既扎根于民间音调与节奏，又融合了现代和声与结构创新，形成新民族主义。\n乐队协奏曲\rConcerto for Orchestra\rBéla Bartók\r勋伯格和巴托克都对音乐技术有重要贡献。\n肖斯塔科维奇 德米特里·肖斯塔科维奇Дмитрий Шостакович（1906~1975）是苏联时期最重要的作曲家之一。早年学习钢琴，后转向作曲，19 岁时以《第一交响曲》毕业并轰动乐坛。毕业后创作歌剧、舞剧等，但因现代主义歌剧《姆钦斯克县的麦克白夫人》被斯大林批判而一度身败名裂。《第五交响曲》是他的“自救”，风格靠向传统，重新获得认可，但是很难给该作品的风格一个明确的归类。\n总的来说，他的音乐风格复杂矛盾，既有尖锐的讽刺、沉重的悲剧性，也包含新古典主义与马勒式的宏大叙事。\n第五交响曲\rSymphony No. 5 in D minor, Op. 47\rDmitri Shostakovich\r布里顿 本杰明·布里顿Benjamin Britten（1913~1976）是英国作曲家，以歌剧和声乐作品闻名。他的作品还是比较传统的，也融合了 20 世纪出现的新的手法，但仍保有面向大众的可听性，没有特别极端的个人风格。代表作：歌剧《彼得·格赖姆斯》，大型合唱与乐队作品《战争安魂曲》，管弦乐作品《青少年管弦乐队指南》。\n青少年管弦乐队指南\rYoung Person's Guide to the Orchestra, Op. 34\rBenjamin Britten\r考试曲库 这个网易云音乐歌单包括了所有上课讲到过的作品，我尽量是选 Berliner Philharmoniker 的版本。\n考试是听曲写曲名。提前两周给了 84 段交响乐曲库（有分乐章的也有不分的），都是上课讲过的。最后抽 20 段放开头一分钟，放两轮。要求写 (作曲家, 曲名, 第几乐章)。全对就 A+ 了。建议每节课上完就听，堆到最后两周容易记不住。\n作曲家 曲名 海顿 104“伦敦” 莫扎特 40 贝多芬 贝三 舒伯特 八“未完成” 舒曼 A 小调钢协 格林卡 鲁斯兰与柳德米拉 门德尔松 E 小调小协 勃拉姆斯 勃四 柏辽兹 幻想交响曲 鲍罗丁 在中亚细亚的草原上 穆索尔斯基 荒山之夜 里姆斯基科萨科夫 天方夜谭 李斯特 塔索 瓦格纳 汤豪舍 柴可夫斯基 降 B 小调第一钢协 柴可夫斯基 D 大调小协 柴可夫斯基 柴四 柴可夫斯基 柴六 德彪西 大海 拉威尔 波莱罗 马勒 马勒五 施特劳斯 查拉图斯特拉如是说 拉赫玛尼诺夫 拉二 拉赫玛尼诺夫 C 小调第二钢协 勋伯格 乐队变奏曲 兴德米特 画家马蒂斯 巴托克 乐队协奏曲 肖斯塔科维奇 肖五 布里顿 青少年管弦乐队指南 斯特拉文斯基 春之祭 ","date":"2026-02-11T00:00:00Z","image":"https://littlereuben.github.io/study/course-symphony/cover.jpg","permalink":"https://littlereuben.github.io/study/course-symphony/","title":"交响音乐赏析笔记"},{"content":"这是一篇收集。\rShot on iPhone 15.\n以后有机会一定专门学摄影。\nP.S. HEIC 格式没法直接放上来，转成 JPG 之后色差很大，想要原图可以联系我。\n推荐点开大图看。\n","date":"2025-10-05T00:00:00Z","image":"https://littlereuben.github.io/collection/thu-photo/cover.jpg","permalink":"https://littlereuben.github.io/collection/thu-photo/","title":"THU 的一些风景"},{"content":"这是一篇收集。\rShot on iPhone 15.\n2024.8.13 北京 2024.10.1 2024.12.21 北京 2025.1.15 北海公园 2025.3.25 颐和园 2025.6.20~21 坝上草原 2025.7.24~29 深圳 一些天空 2025.11.1 武汉 2025.11.23 西山公园 ","date":"2025-10-05T00:00:00Z","image":"https://littlereuben.github.io/collection/on-the-way-photo/cover.jpg","permalink":"https://littlereuben.github.io/collection/on-the-way-photo/","title":"旅途的一些风景"},{"content":"这是一篇摘抄笔记。\r引入 paper，APSP 近似的一些其他情形 sys 的笔记\n问题 对于 APSP 问题，记 $\\pi(u,v)$ 为最短路，$d(u,v)$ 为 $\\pi(u,v)$ 的长度。如果有一个算法能得到近似 $\\delta(u,v)$ 满足 $d(u,v)\\le\\delta(u,v)\\le m\\cdot d(u,v)+a$，那么就称为一个 $(m,a)$ 近似。$a=0$ 时称为 stretch $m$ 近似，$m=1$ 时称为 surplus $a$ 近似，下文中简写作 $m$ 近似与 $+a$ 近似。\ndistance oracle 指的是以常数时间（？）回答一组 $\\delta(u,v)$ 的算法，这样避免了输出的 $\\Omega(n^2)$ 界，可以（在稀疏图中）做到平方以下。\n下文中“非确定性算法”指必然正确且以高概率在对应时间内运行结束的算法；期望时间算法可以并列运行 $\\log$ 个，通过 Chernoff bound 变成非确定性。\n一些上下界 大家都知道准确的带权 APSP 被猜想是 $\\tilde\\Omega(n^3)$ 的，而不带权的可以归约矩乘做。 $2-\\epsilon$ 近似不弱于 01 矩乘，有向图的任意近似都不弱于 01 矩乘。 当 $m=\\Theta(n)$ 时，oracle 有 $\\tilde\\Omega(m^{5/3})$ 的时空下界（基于一些 fine-grained complexity 的猜想）。 已知无向无权图的 $(2,1)$ 近似可以 $\\tilde\\Omicron(n^2)$，所以现在不确定的是，无权/有权的 $2$ 近似能不能 $n^2$，以及 oracle 能不能 sub-$n^2$。 无权 已知结果 [DHZ00] 存在非确定性与确定性的算法，能在线性时间内得到一张图中所有度 $\\ge s$ 点的 hitting-set，大小 $\\tilde\\Omicron(n/s)$。 [DHZ00] 无权无向图的 $+\\log n$ 近似 APSP 可以在时间 $\\tilde\\Omicron(n^2)$ 内求解。 [BK10] 非负整数权无向图的 $2$ 近似 APSP 可以在时间 $\\tilde\\Omicron(mn^{0.5}+n^2)$ 内用非确定性算法求解。 [Zwi02] $\\langle n,n^r,n\\rangle$ 的 $(\\min,+)$ 矩阵乘法的 $1+\\epsilon$ 近似能在时间 $\\tilde\\Omicron(n^{\\omega(r)}\\epsilon^{-1}\\log W)$ 内求解，其中 $\\omega(r)$ 是 $\\langle n,n^r,n\\rangle$ 的普通矩阵乘法复杂度，原矩阵值域为 $[W]\\cup\\set{\\infty}$。 整体处理思路 我们希望找到一些关键点，只求关键点到全体的最短路，将必经关键点的最短路作为近似结果。\n如果 $\\pi(u,v)$ 经过大度点，可以通过 hitting-set 的套路做到 $+2$ 近似（优于 $2$ 近似）。 对于 hitting-set $S$ 内的点，做 MSSP。 求形如 $\\delta(u,v)=\\min_{x\\in S}\\set{d(u,x)+d(x,v)}$ 的 $(\\min,+)$ 矩乘。 否则是稀疏图上的 APSP。 这里 1.1 中的 MSSP 我们固定用 Dijkstra，那么剩余的就是需要指定矩乘和稀疏图 APSP 的算法。如果取度数阈值为 $n^{1-r}$ 的话，那么时间就是 $$ \\tilde\\Omicron(mn^r+T_{1.2}(n,n^r,n)+T_2(n,n^{2-r})) $$ 接下来认为 $m=\\Omicron(n^2)$。\n倍增优化 考虑进一步分治。如果 $\\pi(u,v)$ 经过度数在 $[a,b)$ 内的点，那么用第 1 部分的方法，Dijkstra 是点数 $n/a$，边数 $nb$。因此如果我们取一列区间 $$ [n^{1-r},2n^{1-r}),[2n^{1-r},4n^{1-r}),\\cdots $$ 分别交给第 1 部分做，时间就降为 $$ \\tilde\\Omicron(n^2+T_{1.2}(n,n^r,n)) $$\n近似归约 我们知道 $(\\min,+)$ 矩乘是没法做的，所以只能近似。如果有 $(m,a)$ 近似的矩乘，那么第 1 部分整体就是 $(m,a+2m)$ 近似。由于只需考虑 $d\\ge 2$ 的情况，$(m,a+2m)$ 近似就必然是 $(2m,a)$ 近似。\n于是根据已知 4，第 1 部分存在一个 $2+\\epsilon$ 近似，时间关于 $\\epsilon^{-1}$ 线性。 取 $\\epsilon=1/\\log n$。如果 $d(u,v)\u0026lt;\\log n$，$2+\\epsilon$ 近似相当于 $2$ 近似；否则调用已知 2。\n套用算法 全部用朴素做法，取 $r=0.5$ 得 $\\tilde\\Omicron(n^{2.5})$。 第 2 部分用已知 3，就是 $n^2+n^{2+r}+n^{2.5-r}$，取 $r=0.25$ 得 $\\tilde\\Omicron(n^{2.25})$。 上一条基础上，第 1 部分用已知 4，就是 $n^2+n^{\\omega(r)}+n^{2.5-r}$，可以平衡到 $\\tilde\\Omicron(n^{2.032})$。 还已知一个 parameterized 的算法是做 $+k$ 近似的，与矩乘结合得到一个 $(1+\\epsilon,k)$ 近似算法。 有权 已知结果 [TZ01], [TZ05] 对于“密度” $p$，存在非确定性算法能在 $\\tilde\\Omicron(m/p)$ 的时间内得到一组大小为 $\\tilde\\Omicron(np)$ 的关键点集并计算出每个束内的基本信息，满足束和簇的大小均不超过 $\\tilde\\Omicron(1/p)$。 [EN22] 非负整数权无向图的 $1+\\epsilon$ 近似 MSSP 能在时间 $\\tilde\\Omicron(m^{1+\\omicron(1)}+n^{\\omega(r)}\\epsilon^{-\\Omicron(1)}\\log W)$ 内求解，其中起点集合大小 $n^r$，边权值域 $[W]$。 整体处理思路 同样取一些关键点，但是现在我们考虑这样的结构：对于点 $u$，找到与它距离最近的关键点 $p(u)$，将距离比 $d(u,p(u))$ 小的点，和 $p(u)$ 一起组成 $u$ 的束（branch）$B(u)$。束的逆称为簇 $C(v)=\\set{u\\mid v\\in B(u)}$。\n蓝色点表示最近关键点，称为“枢轴”\r通过束的定义以及三角不等式，可以放缩得到一些近似。首先有个 $3$ 近似：若 $v\\notin B(u)$，则 $$ d(u,p(u))+d(p(u),v)\\le d(u,p(u))+d(p(u),u)+d(u,v)\\le 3d(u,v) $$ 若 $v\\in B(u)$，已知 1 的做法里能算出 $u$ 到 $B(u)$ 各点的最短路，所以就不用管了。\n我们现在称 $\\pi(u,v)\\setminus(B(u)\\cup B(v))$ 中的点为“束间点”。\n（情况 1）如果 $\\pi(u,v)$ 有束间点 $x$，那么 $d(u,x),d(x,v)$ 中至少有一个 $\\le d(u,v)/2$，不妨设为 $d(u,x)$，则 $$ d(u,p(u))+d(p(u),v)\\le 2d(u,p(u))+d(u,v)\\le 2d(u,x)+d(u,v)\\le 2d(u,v)\\tag{1} $$ 剩余的情况（情况 2）是关注的重点。\n暴力做法 若 $\\pi(u,v)$ 无束间点，那么 $\\pi(u,v)$ 一定形如 $u\\rightsquigarrow u^\\prime\\to v^\\prime\\rightsquigarrow v$，其中 $u^\\prime\\in B(u)$，$v^\\prime\\in B(v)$。这样的 $(u,u^\\prime,v^\\prime,v)$ 的数量是 $m|C|^2=\\tilde\\Omicron(m/p^2)$。总的时间：\n情况 1 从关键点出发跑 Dijkstra，$\\tilde\\Omicron(nmp)$。 情况 2 暴力更新，$\\tilde\\Omicron(m/p^2)$。 两类情况取 $\\min$，$\\Omicron(n^2)$。 我们可以做一个 oracle，省去 3，取 $p=n^{-1/3}$ 得 $\\tilde\\Omicron(mn^{2/3})$。\n注意到如果暴力做无束间边（$\\tilde\\Omicron(n/p^2)$），而恰有一条束间边的情况归到情况 1，可以得到一个 $\\tilde\\Omicron(nm^{2/3})$ 的 $(2,\\max w)$ 近似。\n稠密情况 对于情况 1 用已知 2 的 $1+\\epsilon/2$ 近似，得到 $2+\\epsilon$ 近似。\n对于情况 2，分两步做（各束边指的是，每个 $u$ 向 $B(u)$ 内点连边权为距离的边）：\n② 对应第 1 次 Dijkstra，③ 对应第 2 次\r对每个 $v^\\prime$，保留其邻边与各束边，跑 Dijkstra，得到 $d^\\prime(v^\\prime,u)$。 对每个 $u$，保留各束边，建边 $(u,v^\\prime)$ 权 $d^\\prime(v^\\prime,u)$，跑 Dijkstra。 时间均为 $\\tilde\\Omicron(n^2/p)$，这样算出来的是准确 SP。若 $p=n^{r-1}$，则总时间为 $$ \\tilde\\Omicron(n^{3-r}+n^{\\omega(r)}\\epsilon^{-\\Omicron(1)}\\log W) $$ 可以平衡到 $n^{2.213}$。\n注意到建束内边对非稠密图过于激进了，接下来的做法进行了进一步的平衡。\n倍增优化 相比情况 2，情况 1 更容易优化。注意到有权图的“束”结构与无权图的简单的 hitting-set 结构有以下共同点：\n通过一个中介点 $x$，三角不等式放缩多出两倍的 $d(x,?)$（在无权图中就是 $+2$），得到 $2$（或 $2+\\epsilon$） 近似。 关键点出发全图跑 MSSP，这使我们无法不受限制地增加关键点数，否则这部分会成为瓶颈。 不借助中介点 借助中介点 无权图 去除大度点 必经大度点 无权图做法 跑稀疏图 APSP 找 hitting-set，MSSP + 矩乘 有权图 $\\pi(u,v)$ 无束间点 $\\pi(u,v)$ 有束间点 有权图做法 暴力松弛 MSSP 对数尺度；每个格子的右边界为该格算法的关键点密度\r在无权图中，通过考虑子问题：经过度数在 $[a,b)$ 间点的最短路，对其分治，得到倍增做法，减少了边数，使得 Dijkstra 总时间由 $mn^r$ 降至 $n^2$。在有权图中，模仿这一思路：考虑关键点集 $S_{i+1}\\subset S_i$，现在需要对于所有 $(u,v)$ 满足 $\\pi(u,v)$ 在 $S_{i+1}$ 下无束间点，而在 $S_i$ 下有束间点的情况，去求 $d(u,v)$ 的近似。同样，我们的目标是减少关键点出发 MSSP 的边数，同时保证近似的论证不失效。\n仍然假定 $d(p_i(u),u)\\le d(u,v)/2$。回顾不等式 $(1)$： $$ d(u,p(u))+\\boxed{d(p(u),v)}\\le d(u,p(u))+\\boxed{d(p(u),u)+d(u,v)} $$ 实际不需要准确求出 $d(p_i(u),v)$，而只求一个近似的 $\\delta(p_i(u),v)\\in[d(p_i(u),v),d(p_i(u),u)+d(u,v)]$ 即可。进一步，如果 $\\pi(u,v)$ 形如 $u\\rightsquigarrow u^\\prime\\to x\\rightsquigarrow v$，其中 $u^\\prime\\in B_{i+1}(u)$，$x\\notin B_{i+1}(u)$，那么可以拆成 $$ d(p_i(u),u)+d(u,u^\\prime)+w(u^\\prime,x)+d(x,v) $$\n建立这样的图：$p_i(u)$ 向所有与 $B_{i+1}(u)$ 相邻的点（及上述 $x$ 这样的点）连边，边权 $$ \\delta^\\prime(p_i(u),x)=\\min_{u^\\prime}\\set{d(p_i(u),u)+d(u,u^\\prime)+w(u^\\prime,x)} $$ 另外对于所有的点 $v$，将与 $v$ 相邻的权 $\\le d(v,p_{i+1}(v))$ 的边加入。跑 Dijkstra。设 $\\pi(x,v)=x\\to\\cdots\\to v_1\\to v$。由于 $x\\in B_{i+1}(v)$，故 $(v_1,v)$ 是保留的；由于 $d(v_1,p_{i+1}(v_1))+w(v_1,v)\\ge d(v,p_i(v))$，故 $x\\in B_{i+1}(v_1)$，所以 $(v_2,v_1)$ 也保留，以此类推。\n求 $\\delta^\\prime$ 所需的时间是 $$ \\sum_{u^\\prime}\\mathrm{deg}_{u^\\prime}|C_{i+1}(u)|=\\tilde\\Omicron(m|C_{i+1}|) $$ 我们相当于把菊花形的各束边改成了第二类边，它们的数量这么考虑：如果 $S_{i+1}$ 是以 $q$ 的概率选点的话，那么对于不在 $S_{i+1}$ 中的点，将其邻边按边权从小到大扫描，每次有 $q$ 的概率把剩余的扔掉。因此期望边数为 $\\sum (1-q)^i\\le 1/q$，用 Chernoff bound 一类的东西放缩下就是高概率 $\\tilde\\Omicron(n/q)$。从这个意义上来看，束结构也是限制度数的，基本打通了无权和有权的思想。\n因此总的复杂度是 $$ \\tilde\\Omicron\\left(\\frac mq+|S_i|\\frac nq+n^2\\right)=\\tilde\\Omicron\\left(\\frac{mn}{|S_{i+1}|}+\\frac{n^2|S_i|}{|S_{i+1}|}\\right) $$ 考虑关键点集包含链 $V=S_0\\supset S_1\\supset\\cdots\\supset S_k$。其中 $S_i$ 中的每个点以 $1/2$ 概率出现在 $S_{i+1}$ 中。如果 $\\pi(u,v)$ 在 $S_k$ 的下仍有束间点，那么就只能用原来情况 1 的做法，从 $S_k$ 出发跑 MSSP；否则一定存在某个 $S_{i}-S_{i+1}$ 交界，就用上面的方法。设 $k=(1-r)\\log_2n$，则 $|S_k|=\\tilde\\Theta(n^r)$，时间为 $\\tilde\\Omicron(mn^{1-r}+n^2+T_1(n,m,n^r))$，$T_1$ 是 MSSP 的复杂度。\n实际实现时，第一类边权的 $\\min$ 只需要拿 $B_k(u)$ 内所有点的邻边去松弛就行，那么为了保证 $|C_k(u)|$ 的大小，需要强制往 $S_k$ 里加已知 1 里的构造，不过这个不影响复杂度。总的做法：\n求出 $\\set{S_i}$，建出束结构。 对于每个 $u$，每个 $i$，每个 $B_k(u)$ 内点的邻边，更新 $\\delta^\\prime(p_i(u),x)$。 对于每个 $p_i(u)$ 建图跑 Dijkstra。 对于 $S_k$ 在原图上跑 MSSP。 对每个 $(u,v)$ 求答案。 套用算法 MSSP 直接用 Dijkstra，时间 $mn^r$，取 $r=0.5$ 得 $\\tilde\\Omicron(mn^{0.5}+n^2)$，这就是 [BK10]。 MSSP 用已知 2，这样是 $2+\\epsilon$ 近似，是 $mn^{1-r}+n^2+n^{\\omega(r)}\\epsilon^{-\\Omicron(1)}\\log W$，对于稠密图的平衡结果，和稠密情况那个一样。 ","date":"2025-09-14T00:00:00Z","permalink":"https://littlereuben.github.io/study/paper4/","title":"读论文系列 #4——stretch 2 APSP 的最新进展"},{"content":"这是一篇摘抄笔记。\r引入 paper，部分讲解视频\n$\\gdef\\b#1{\\boldsymbol{#1}}$下文中 $d$、$m$ 代表常数。\n考虑运行时间为 $t(n)$ 的 $d$ 带图灵机，我们考虑的问题是可以用多少空间的多带图灵机模拟它。这一问题的重要性在于：\n如果 $\\forall\\varepsilon\u0026gt;0$，$\\mathsf{TIME}[t(n)]\\subseteq\\mathsf{SPACE}[t(n)^\\varepsilon]$，则 $\\mathsf{P}\\ne\\mathsf{PSPACE}$。\n最新的这篇文章做到了 $\\mathsf{TIME}[t(n)]\\subseteq\\mathsf{SPACE}[\\sqrt{t(n)\\log t(n)}]$，大致的思路是缝合了空间模拟时间的基本思想，以及一个 $\\mathsf{L}\\text{ vs }\\mathsf{P}$ 方面的最新进展。\n单带情况 在限制空间的情况下，其实显而易见的思路只有一条，就是做一个 time-space tradeoff，以重复计算的代价换取不存储完整纸带的能力。\n考虑每时每刻，只在 $M^\\prime$ 中存储 $M$ 的纸带上的一小段，在上面进行模拟。如果读写头离开了当前段进入其他部分，就 recover 另一小段的当前情况，继续模拟。\n具体到单带图灵机上，考虑小段长为 $b(n)$，那么在跨段时，需要重新模拟新进入段的所有历史操作，但模拟过程不能递归依赖其他段的信息。为此，只需存储历史上每次跨段时的信息即可，这所需记录条目数是平均 $\\frac{t(n)}{b(n)}$ 的，每个条目需要记录段号与状态，是 $\\log\\frac{t(n)}{b(n)}+\\Omicron(1)$ 的，如果改成记录 $\\pm 1$ 就是 $\\Omicron(1)$（这个和四毛子优化 RMQ 是一样的）。为了避免 $M$ 在段边界反复横跳导致卡到最劣，可以枚举分段起始点的偏移，根据鸽巢原理一定存在一个偏移量满足跨段次数 $\\le\\frac{t(n)}{b(n)}$。\n显然这里取 $b(n)=\\sqrt{t(n)}$，平衡到 $\\Omicron(\\sqrt{t(n)})$ 的空间复杂度。\n但是这个思路在多带完全不行：各带读写头的跨段没法同步，就算同步了，考虑 $(x,y)$ 表示当前第一条纸带的读写头在第 $x$ 段，第二条在 $y$，那么比如当前在 $(2,3)$ 恢复所需要的历史操作可能是 $(2,1)$、$(2,2)$、$(1,3)$、$(3,3)$ 这些情形，它就爆炸了。简而言之，依赖关系从单带的链，变成多带的 DAG。\n多带历史思路 首先展开说一下多带跨段的同步以及标准化。我们希望将位置和时间同时分块：\n对于多带图灵机，存在等效的多带“分块图灵机” with 块大小 $b(n)$，时间 $\\Theta(t(n))$（实际上要求 $\\log t(n)\\le b(n)\\le t(n)$，以及 $t(n)$、$b(n)$ time-constructible，不过这些不太重要）。分块图灵机指的是，各纸带划分为 $b(n)$ 长的小段，读写头跨段只能出现在 $b(n)$ 倍数的时刻。 构造思路\r加的一条带作为“时钟”，读写头持续在 $b(n)$ 的范围内来回移动，如果其他头需要跨段但“时钟”未到“整点”（下文我称时间的分段为时间块），就等着到整点再动。但这仍然会遇到段边界反复横跳的问题。处理方法是，扩展字母表/带数使得每带的每段都记录相邻两段的信息，这样就无需等待，只需在当前时间块完成后，额外花若干（常数个）时间块把更新的信息复制到相邻段即可。\r设纸带数为 $d$。\n刻画多带的历史依赖关系的结构被称为 computation graph：每个时间块 $i$ 对应一个节点，其存储 $\\text{content}_i$，内容为该时间块结尾时：\n图灵机的状态 $q_i$； 各读写头位置 $h_{i,1}\\sim h_{i,d}$； 各读写头所在纸带段的最终内容 $c_{i,1}\\sim c_{i,d}$。 空间为 $\\Omicron(b(n)+\\log t(n))$。\n为了得到 $\\text{content}_i$，我们需要 $\\text{content}_{i-1}$，以及另外某些 $\\text{content}_{k_1,\\cdots,k_d}$。如果对于某纸带 $j$， $$ \\left\\lfloor\\frac{h_{i,j}}{b(n)}\\right\\rfloor=\\left\\lfloor\\frac{h_{k,j}}{b(n)}\\right\\rfloor\\land\\forall k^\\prime\\in(k,i),\\left\\lfloor\\frac{h_{i,j}}{b(n)}\\right\\rfloor\\ne\\left\\lfloor\\frac{h_{k^\\prime,j}}{b(n)}\\right\\rfloor $$ 也就是说，$\\text{content}_k$ 中有时间块 $i$ 所需的纸带 $j$ 的最新信息，那么连边 $k\\to i$。因此，每个点入度 $\\le d+1$。\n两个注：\n发现不强制标准化分块也是可以的，就是要每带记录两个块，入度 $\\le 2d+1$。 处理输入有两种思路，一种是加个只存输入的 $\\text{content}_0$，一种是在每个点额外存历史首次访问到的段的内容。 假定已知 computation graph 的结构，待求 $\\text{content}_{t(n)/b(n)}$。当前的模型形如：给定一张 DAG，指定源和汇。每次如果一个点是源，或它的所有入点上都有石子，可以在这个点上也放石子；也可以任意拿掉石子。问使得汇上有石子，最少需要备多少石子。这被称为 (standard/black) pebble game。\n例如这张图应该至少需要四个石子：\n+0, +1, +2, -1, +3, -0, +4, -3, +0, +1, +2, -0, -1, +5 记 $P_k(n)$ 为最大入度为 $k$ 的 $n$ 点图中，最多的所需石子数（可以任意指定一个汇）。[HPV75] 中证明了对于常数 $k$，$P_k(n)=\\Omicron(n/\\log n)$。\n证明\r记 $R_k(n)$ 为最大入度为 $k$，所需 $n$ 个石子的图中，最少的边数。只需证明 $R_k(n)=\\Omega(n\\log n)$ 即可，考虑用割 + 归纳的证法。取这样一张图 $G=(V,E)$ 中，用 $\\le n/2$ 个石子就能达到的所有点 $V_1$，剩余为 $V_2$。如果将 $V_2$ 的导出子图拿出，入度为 $0$ 的点可以随意放石子，那么这部分需要至少 $n/2-k$ 个石子。这是因为，在整张图中，如果要将 $V_2$ 中的一个入度为 $0$ 的点上放上石子，就需要在 $V_1$ 中至多 $k$ 个点上放石子，就需要备至多 $n/2+k-1$ 个石子。如果 $V_2$ 部分只需 ${{}\u003c{}}n/2-k$，两者相加就与需要 $n$ 个石子矛盾了（似乎常数项可以更紧一点？）。另外 $V_1$ 中一定有需 $\\ge n/2-k$ 个石子的点，因此\r$$\rR_k(n)\\ge 2R_k\\left(\\frac n2-k\\right)+\\text{cut}(V_1,V_2)\r$$\r只需 $\\text{cut}(V\\_1,V\\_2)$ 不太小（$=\\Theta(n)$）就行。如果 $\\text{cut}(V_1,V_2){{}\u003c{}}n/4$，那么可以在 $V_1$ 中与 $V_2$ 有边的节点上全留石子，因此 $V_2$ 部分单独拿出来做，需要至少 $3n/4$ 的石子。于是\r$$\rR_k(n)\\ge\\min\\Set{2R_k\\left(\\frac n2-k\\right)+\\frac n4,R_k\\left(\\frac n2-k\\right)+R_k\\left(\\frac{3n}4\\right)}\r$$\r归纳可证 $R_k(n)\\ge cn\\log n$。\r另外存在卡到 $\\Theta(n/\\log n)$ 的构造，详见 Space bounds for a game on graphs，似乎是形如 FFT 电路。\n这就意味着无论怎么取 $b(n)$，空间被限制在 $\\Omega(n/\\log n)$。为完成整个证明，还需解决两个问题：\n如何求出 computation graph？直接枚举每个头每个时间块的位置，是 $\\Omicron\\big(\\frac{t(n)}{b(n)}\\log\\frac{t(n)}{b(n)}\\big)$ bits，当然也可以枚举差分。如果模拟过程中发现读写头走的方向与枚举的不符，就返回 FAIL。 如何求出一组达到 $\\Omicron\\big(\\frac{t(n)}{b(n)}/\\log\\frac{t(n)}{b(n)}\\big)$ 的放石子顺序？直接枚举的话递归栈大小会爆，但无论如何每次猜一步，总还是 $\\mathsf{NSPACE}\\big[\\frac{t(n)}{b(n)}\\big]$ 的。$b(n)$ 稍微取大点，用下 Savitch 即可。 小结 整体的思想是，局部纸带段—历史跨段记录的平衡。 computation graph 是对整个结构的很本质的刻画，但是直接在这上面跑组合算法是没前途的。 两个细节处理的 trick：分块化，以及猜 computation graph。 容易感受到，之前研究者们都偏向于相信，$n/\\log n$ 没法再优化了。\ntree evaluation problem 如果把 computation graph 展开，我们可以得到一棵高度为 $\\Omicron\\big(\\frac{t(n)}{b(n)}\\big)$，$\\Omicron(d)$ 叉的树。尽管看似变得冗余了，但是树上的这一问题有代数做法，这就给了突破口。tree evaluation problem (TEP) 指的是，给定一颗高度为 $h$ 的满 $d$ 叉树，每个节点 $u$ 上有 $b$ 位 $01$ 串 $\\text{content}_u$。初始给定叶子的串，以及每个节点由其各儿子串决定其本身串的函数，即 $(\\set{0,1}^b)^d\\to\\set{0,1}^b$ 的函数，求根的串。\n输入的长度是 $\\Theta(b2^{bd}d^h)=2^{\\Theta(b+h)}$ 的，而这一问题是否 $\\in\\mathsf{NL}$ 还是 open 的（大家偏向于否）。但是 [CM24] 提出了一个空间 $\\Omicron(db+h\\log(db))$ 的做法，对于大小为 $n$ 的输入而言，这是 $\\Omicron(\\log n\\log\\log n)$ 的（据说还能多除个 $\\log\\log\\log n$？）。\n一般的 dfs 做法需要 $\\Omicron(dhb)$ 的空间：\n紫色为当前节点，黄色为需存储节点\r而 [CM24] 的想法是，把上面各层的信息给叠起来，但利用单位根的性质（说白了就是单位根反演）把叠起来的垃圾抵消了。\n具体而言，每个节点的函数可以看作 $b$ 个 $\\mathbb{F}_2^{bd}\\to\\mathbb{F}_2$ 的函数，具体来说，如果原函数是 $f(\\b x_1,\\cdots,\\b x_d)$（每个 $\\b x_i$ 是一个儿子的 $b$ 位），那么对应的函数是： $$ \\tilde{f}(\\b x_1,\\cdots,\\b x_d)_i=\\sum_{\\b a_1,\\cdots,\\b a_d\\in\\mathbb{F}_2^b}f(\\b a_1,\\cdots,\\b a_d)_i\\prod_{j=1}^d\\prod_{k=1}^b(\\b x_{j,k}-\\b a_{j,k}+1) $$ 这个东西的想法和拉格朗日插值/CRT 是一样的，在特征为 $2$ 的域中，$x-y+1$ 等价于 $[x=y]$。我们将定义域和值域扩到 $\\mathbb{F}_{2^q}$，公式不变。\n现在只需存储 $(d+1)b$ 个 $\\mathbb{F}_{2^q}$ 内的元素便可以计算。记这些寄存器为 $\\b x_1,\\cdots,\\b x_{d+1}\\in\\mathbb{F}_{2^q}^b$。\n$\\text{calc}(u,\\b y):$\n——将 $\\text{content}_u$ 加给 $\\b y$，其他寄存器的内容不变。方便起见记其他寄存器为 $\\b x_1\\sim\\b x_d$。\n$\\text{for }i=0\\to m-1:$\r$(1)$ 对于每个儿子调用 $\\text{calc}$，使 $\\b x_j$ 变为 $\\omega_m^i\\b x_j+\\text{content}\\_{\\text{son}_{u,j}}$\r$\\b y\\xleftarrow{+}\\tilde f(\\b x_1,\\cdots,\\b x_d)$\n原样撤回 $(1)$\n这里 $\\omega_m$ 是 $m$ 次单位根，有性质：\n对于 $\u0026lt;m$ 次多项式 $P$，$\\displaystyle\\sum_{i=0}^{m-1}P(\\omega_m^iu_1+v_1,\\cdots,\\omega_m^iu_k+v_k)=P(v_1,\\cdots,v_k)$。 证明很简单：考虑 $P(x_1,\\cdots,x_k)=x_1^{p_1}\\cdots x_k^{p_k}$，那么 $$ \\displaystyle\\sum_{i=0}^{m-1}P(\\omega_m^iu_1+v_1,\\cdots,\\omega_m^iu_k+v_k)=\\sum_{q_1,\\cdots,q_k}\\left(\\sum_{i=0}^{m-1}\\omega^{i\\cdot\\sum_{j=1}^kq_j}\\right)\\prod_{j=1}^k\\binom{p_j}{q_j}u_j^{q_j}v_j^{p_j-q_j}=v_1^{p_1}\\cdots v_k^{p_k} $$ 只有 $m\\mid\\sum q_j$ 时打括号的和式才非零，而且特征为 $2$，$m$ 是奇数，所以后一个就直接取等过去了。\n空间是（再次注意，这里不计输入）：\n$u$，全局记着就是 $h\\log d$ 所有寄存器，$(d+1)bq$ 局部循环变量，$h\\log(d^2b)$ 求 $\\tilde f$ 时所需的临时空间，$db+q$ 现在只要求 $db\u0026lt;m\u0026lt;2^q$，因此总共 $\\Omicron((h+db)\\log(db))$。一个显而易见的优化空间是，可以把若干 $01$ 位压到 $\\tilde f$ 的一个参数里：考虑 $\\set{0,1}^p\\to\\mathbb{F}_{2^q}$ 的单射，设值域为 $S$。这时对于 $x,y\\in S$， $$ [x=y]=\\frac{\\prod_{z\\in S\\setminus\\set{y}}(x-z)}{\\prod_{z\\in S\\setminus\\set{y}}(y-z)} $$ 因此 $\\deg\\tilde f=db2^p/p$，寄存器的空间是 $(d+1)bq/p$，只需要 $db/p\u0026lt;2^{q-p}$ 即可，那索性取 $p=\\log(db)=q/2$。这样空间就优化到 $\\Omicron(h\\log(db)+db)$。\n假定 computation graph 已知，直接套用，代入 $h=t(n)/b(n)$，$b=b(n)$，就直接平衡到了惊人的 $\\Omicron(\\sqrt{t(n)\\log t(n)})$。\n细节处理 仍然将原图灵机先分块化。 为了处理输入 $\\text{content}_0$ 在 $t(n)=\\omicron(n^2)$ 时过长，需要将它再分块。所以索性将所有节点存储的信息都缩减成单带的一段。现在节点有两种：$(h,i)$ 表示第 $h$ 带的第 $i$ 时间块，$(h,0,i)$ 表示第 $h$ 带初始时第 $i$ 段。连边还是类似的。 枚举 computation graph。只需枚举每个时间块结束时每个读写头怎么移动，总共是 $(\\log_23)d\\frac{t(n)}{b(n)}$ bits。没必要把图显式建出，求儿子可以枚举后暴力区间求和检验。 在调用上述 TEP 算法过程中，求 $\\tilde f$ 时需要对于 $f$ 的每组输入模拟。如果输入中有 FAIL 直接返回 FAIL，否则可以原地模拟，再检查最后一步的走向是否与枚举的相符，不符也返回 FAIL。 TEP 算法中的 $u$ 是不是可以直接用节点号描述啊……反正瓶颈不在这。另外 computation graph 对应的树不是满的，补补齐就行。 另外有个小细节，我们不要求 $t(n)$ 是 time/space-constructible 的，因为我们可以在整个模拟外套上枚举 $t(n)$ 的循环。 多维推广 设维数为 $m$。将每个纸带划分为边长为 $b(n)$ 的超立方体。论文里说多维不存在分块图灵机，我不太理解，应该也可以用类似上面叠相邻块内容的方法啊？\n不分块也没什么问题。同一时间块内，每一维可能跨两段，因此访问到的总段数不超过 $2^m$，从而 computation graph 中每个节点的入度不超过 $(2^m+1)d$，每个节点的 content 仍包括：状态、时间块结束时读写头位置（$d\\log t(n)$）、访问到的段的相对位置及内容（$2^db(n)^d$ 或 $3^db(n)^d$），因此位数是 $\\Theta(b(n)^d+d\\log t(n))$ 的，方便起见认为 $\\log t(n)=\\omicron(b(n))$。代入 TEP 的复杂度： $$ \\Omicron\\left(\\frac{t(n)}{b(n)}\\log b(n)+b(n)^d\\right) $$ 取 $b(n)=\\sqrt[d+1]{t(n)\\log t(n)}$ 得 $\\Omicron((t(n)\\log t(n))^{1-\\frac{1}{d+1}})$。\n推论 对于 space-constructible 的 $t(n)$， $$ \\mathsf{TIME}[t(n)]\\subseteq\\mathsf{SPACE}[\\sqrt{t(n)\\log t(n)}]\\subsetneq\\mathsf{SPACE}[t(n)^{\\frac12+\\varepsilon}] $$ 特别地，$\\mathsf{SPACE}[n]$ 中有语言 $\\notin\\mathsf{TIME}[n^{2-\\varepsilon}]$ 及 $\\notin\\mathsf{TIME}[n^2/\\log^{\u0026gt;1}n]$。可以考虑一个“$\\mathsf{SPACE}[n]$-complete”的例子： $$ \\set{\\langle M,x,1^k\\rangle\\mid \\lvert M\\rvert\\le k\\text{ 且 }M\\text{ 在 }k\\text{ 空间内停机}} $$ 另外，如果 $\\mathsf{TIME}[t(n)]\\subseteq\\mathsf{SPACE}[t(n)^{\\frac12-\\varepsilon}]$，那么交替图灵机和随机存取图灵机都可以在时间 $t(n)^{1-2\\varepsilon}$ 内模拟 $t(n)$ 的图灵机。\n","date":"2025-09-14T00:00:00Z","permalink":"https://littlereuben.github.io/study/paper5/","title":"读论文系列 #5——多带图灵机中的空间换时间"},{"content":"这是一篇学习笔记。\r$\\gdef\\e{\\mathrm{e}}\\gdef\\d{\\mathrm{d}}\\gdef\\i{\\mathrm{i}}\\gdef\\N{\\mathbb{N}}\\gdef\\Z{\\mathbb{Z}}\\gdef\\Q{\\mathbb{Q}}\\gdef\\R{\\mathbb{R}}\\gdef\\C{\\mathbb{C}}\\gdef\\F{\\mathbb{F}}\\gdef\\E{\\mathbb{E}}\\gdef\\P{\\mathbb{P}}\\gdef\\M{\\mathbb{M}}\\gdef\\O{\\mathrm{O}}\\gdef\\b#1{\\boldsymbol{#1}}\\gdef\\ker{\\operatorname{Ker}}\\gdef\\im{\\operatorname{Im}}\\gdef\\r{\\operatorname{rank}}\\gdef\\id{\\mathrm{id}}\\gdef\\span{\\operatorname{span}}\\gdef\\spec{\\operatorname{spec}}\\gdef\\mat#1{\\begin{bmatrix}#1\\end{bmatrix}}\\gdef\\dat#1{\\begin{vmatrix}#1\\end{vmatrix}}\\gdef\\eps{\\varepsilon}\\gdef\\arcsinh{\\operatorname{arcsinh}}\\gdef\\arccosh{\\operatorname{arccosh}}\\gdef\\arctanh{\\operatorname{arctanh}}\\gdef\\arccoth{\\operatorname{arccoth}}\\gdef\\arcsech{\\operatorname{arcsech}}\\gdef\\arccsch{\\operatorname{arccsch}}\\gdef\\sgn{\\operatorname{sgn}}\\gdef\\sech{\\operatorname{sech}}\\gdef\\csch{\\operatorname{csch}}\\gdef\\arccot{\\operatorname{arccot}}\\gdef\\arcsec{\\operatorname{arcsec}}\\gdef\\arccsc{\\operatorname{arccsc}}\\gdef\\tr{\\operatorname{tr}}\\gdef\\unit#1{\\mathop{}!\\mathrm{#1}}\\gdef\\re{\\operatorname{Re}}\\gdef\\aut{\\operatorname{Aut}}\\gdef\\diag{\\operatorname{diag}}\\gdef\\D{\\mathrm{D}}\\gdef\\p{\\partial}\\gdef\\eq#1{\\begin{align*}#1\\end{align*}}\\gdef\\Pr{\\mathsf{Pr}}\\gdef\\Ex{\\mathsf{E}}\\gdef\\Var{\\mathsf{Var}}\\gdef\\ip#1{\\left\\langle #1\\right\\rangle}\\gdef\\char{\\operatorname{char}}\\gdef\\J{\\mathrm{J}}\\gdef\\Nd{\\mathcal{N}}\\gdef\\Cov{\\operatorname{Cov}}$\n书：概率论与数理统计 (陈希孺)；练习\n就列一下自己不会的知识点。\n贝叶斯公式的意义（P36）\n概率分布函数的定义（P45）\nPoisson 分布的含义：在 $1$ 单位时间内期望发生 $\\lambda$ 次。（P48）\n例子：P49\n负二项分布的含义（P50）\n多维随机向量的 PDF 可能不存在（P65）\n边缘分布的定义（P66）\n注意严格来说，求边缘分布需要先求边缘的 CDF 再求导。（P68）\n注意联合概率密度与条件概率密度的关系的证明（P74）\n二维正态分布的边缘分布是正态分布。各维边缘分布不足以确定完整的分布。（P70）\n随机变量独立性的一些性质（P78）：\n随机变量独立 $\\iff$ 取值事件独立\nPDF 可以分离变量 $\\implies$ 分离的因子是边缘分布的倍数\n随机变量独立 $\\implies$ 分成两组算函数后独立\n证明：\n$\\begin{aligned} \\Pr(Y_1 \\in A, Y_2 \\in B) \u0026amp;= \\Pr(g_1(\\mathbf{X}) \\in A, \\ g_2(\\mathbf{Z}) \\in B) \\\\ \u0026amp;= \\int_{\\mathbb{R}^m} \\int_{\\mathbb{R}^{n-m}} \\mathbf{1}_{g_1(\\mathbf{x}) \\in A} \\cdot \\mathbf{1}_{g_2(\\mathbf{z}) \\in B} \\cdot f_{\\mathbf{X}, \\mathbf{Z}}(\\mathbf{x}, \\mathbf{z}) , d\\mathbf{z} , d\\mathbf{x} \\\\ \u0026amp;= \\int_{\\mathbb{R}^m} \\mathbf{1}_{g_1(\\mathbf{x}) \\in A} \\cdot f_{\\mathbf{X}}(\\mathbf{x}) , d\\mathbf{x} \\cdot \\int_{\\mathbb{R}^{n-m}} \\mathbf{1}_{g_2(\\mathbf{z}) \\in B} \\cdot f_{\\mathbf{Z}}(\\mathbf{z}) , d\\mathbf{z} \\\\ \u0026amp;= \\Pr(Y_1 \\in A) \\cdot \\Pr(Y_2 \\in B) \\end{aligned}$\n随机变量函数的 PDF 求法：\n除以导数/Jacobi 行列式绝对值的倒数（类似于积分换元），或者理解成先得把自因变量关系倒过来，得求逆函数。如果因变量不够需要补全。 先积分算 CDF，再求导。 关于正态分布的几个点：\n正态分布变量拆成两个独立变量，分别是正态（P93）\n卡方分布： $$ k_n(x)=\\frac{1}{\\Gamma(n/2)2^{n/2}}\\e^{-x/2}x^{(n-2)/2}\\quad(x\\ge 0) $$ 证明考虑 $k_m*k_n=k_{m+n}$，会发现积出来一个 $\\Beta$ 函数。\n我在想一个事情：为什么 $\\ge 3$ 维的正态分布也只需要矩阵，而不需要张量之类的东西去刻画？可以通过高维正态分布的一个等价定义来理解：如果 $(x_1,\\cdots,x_n)$ 的任意线性组合都是正态分布，那么它们的联合分布构成 $n$ 维正态分布。证明：\n令 $\\b\\mu$ 为期望，$\\b\\Sigma$ 为协方差矩阵。容易计算得到，对于一组系数 $\\alpha$，$\\Var(\\alpha^\\top\\b x)=\\alpha^\\top\\b\\Sigma\\alpha$，因此 $\\alpha^\\top\\b x\\sim\\Nd(\\alpha^\\top\\b\\mu,\\alpha^\\top\\b\\Sigma\\alpha)$。\n我们知道 $X\\sim\\Nd(\\mu,\\sigma^2)$ 的特征函数为 $\\varphi_X(t)=\\exp\\left(\\i\\mu t-\\frac12\\sigma^2t^2\\right)$，因此 $\\varphi_{\\alpha^\\top\\b x}(t)=\\exp\\left(\\i\\alpha^\\top\\b\\mu t-\\frac12\\alpha^\\top\\b\\Sigma\\alpha t^2\\right)$。而 $\\varphi_{\\b x}(\\b t)=\\Ex(\\e^{\\i\\b t^\\top\\b x})=\\varphi_{\\b t^\\top\\b x}(1)=\\exp\\left(\\i\\alpha^\\top\\b\\mu-\\frac12\\alpha^\\top\\b\\Sigma\\alpha\\right)$。由于特征函数与概率分布意义对应，故 $\\b x\\sim\\Nd_n(\\b\\mu,\\b\\Sigma)$。\n商的 PDF（P98）\nP100~101 的几个公式很重要，在求置信区间时会用到（P193 开始）。\n期望必须要求绝对收敛（P111~112）\n关于统计学三大分布，就两点：一个是 PDF 的推导，从卡方分布出发是容易推的。二是统计学性质，这个的核心是 P102 的引理。\n协方差为 $0$ 不代表独立：P136。而二维正态分布时对应命题是成立的。\n相关系数的定义 $\\rho=\\Cov(X_1,X_2)/\\sigma_1\\sigma_2$ 及其前提：一个重要不等式（P135）\n二维正态分布： $$ f(x_1,x_2)=\\frac{1}{2\\pi\\sigma_1\\sigma_2\\sqrt{1-\\rho^2}}\\exp\\left(-\\frac{1}{2(1-\\rho^2)}\\left(\\frac{(x_1-\\mu_1)^2}{\\sigma_1^2}-\\frac{2\\rho(x_1-\\mu_1)(x_2-\\mu_2)}{\\sigma_1\\sigma_2}+\\frac{(x_2-\\mu_2)^2}{\\sigma_2^2}\\right)\\right) $$\n矩估计和最大似然估计都可能是有偏的，反例一般找估计的方差是 $1/n$ 而不是 $1/(n-1)$ 即可。\n贝叶斯法的 $p(X_1,\\cdots,X_n)$ 可以放着不求，视作一个常数比例系数（P172、P251）\n相应地，拿 $\\sum(X_i-\\overline X)^2/(n-1)=S^2$ 估计 $\\sigma^2$ 无偏，$S$ 估计 $\\sigma$ 就有偏了，且总是偏小（P178），需要一个修正系数（取决于具体分布）。\n均方误差的定义，以及与估计量方差的关系（P180）\n枢轴变量法（P192）\n注意这种方法实操时的逻辑是这样的：我知道对于某个 $\\theta$，$X$ 的分布，于是我可以写出：对某个 $\\theta$，$\\Pr[L(\\theta,\\eps/2)\\le X\\le U(\\theta,\\eps/2)]\\ge 1-\\eps$。通过对这个解方程，我可以得到所需的形式：$\\forall\\theta$，$\\Pr[L^\\prime(X,\\eps/2)\\le\\theta\\le U^\\prime(X,\\eps/2)]\\ge 1-\\eps$。\n区间估计和贝叶斯法的估计是本质不同的，前者是假定知道 $\\theta$，随机 $X$，后者是知道 $X$，随机 $\\theta$。即使有先验概率，也存在关于 $\\set{X_i}$ 的上下界函数，符合第一种估计的要求不符合第二种，也存在符合第二种不符合第一种的。\n有限样本空间的情况下，不放回抽样的方差估计（$/(n-1)$），是对总体 $/(N-1)$ 的方差的无偏估计。用另一种说法，就是 $$ E(\\hat{\\sigma}^2)=\\sigma^2\\cdot\\frac{n-1}{n}\\frac{N}{N-1} $$\n简单提一下 Fisher 信息量 $I_n(\\theta)=\\Ex\\left(\\frac{\\p\\sum\\log f(X_i,\\theta)}{\\p\\theta}\\right)^2$的作用：\nhttps://en.wikipedia.org/wiki/Cram%C3%A9r%E2%80%93Rao_bound 使用极大似然估计去得到 $\\theta$ 的估计 $\\theta^$ 时，在课本范围内可认为 $\\theta^\\to\\Nd(\\theta,1/nI(\\theta))$，在极大似然是无偏时这可以用于估计【估计的误差】，从而得到置信区间。 注意一般 $I(\\theta)=-\\Ex(\\ell_{\\theta\\theta})$ 会比 $I(\\theta)=\\Ex(\\ell_\\theta^2)$ 容易算。 注意假设检验的思想。两个互补的假设，在同一组数据下可能同时接受，这是因为当我们假设一个事情并取 $\\alpha\u0026gt;1/2$ 时，我们就偏向于这个事情成立，而需要强的证据才能否定它。（例子 P220）\n一致最优检验的定义（P216）、拟合优度的定义（P256）\n连续的情况下，检验水平 = 第一类概率 = 第二类错误概率。因此一般在“保一”基础上，是设定一组 $(\\theta_2,\\alpha_2)$ 去限定第二类错误的。甚至有可能都无法限制（P224）\n直觉的理解：置信区间和检验水平都是说的是，如果真正的 $\\theta$ 不在所求区间内/真正的 $\\theta$ 满足假设但不满足检验条件，那么抽到这样性质的 $\\set{X_i}$ 概率太低了，注意这里的“性质”本身就是由检验方法来决定的，一般就是取一些统计量来看。\n我们可以这样理解：这个检验方法是对每个 $\\theta$，在所有可能的样本中划了一刀，保证一侧 $\\ge1-\\alpha$。由于我们考虑的分布一般都是随 $\\theta$ 连续变化的，所以“当前样本属于 $1-\\alpha$ 侧”的 $\\theta$ 构成一个区间。另外我们可能会想，划的方法可能不一样啊？是的，比如对于一组 $\\Nd(\\mu,\\sigma^2)$ 的样本拿平均数和中位数估计就会得到两个置信区间，它们确实是不同的，却都是对的，因为检验方法实际上是“自定义”了一个“抽象样本特征”的规则。\n似然优度检验的两个关键点，一个是 $Z\\sim\\chi_{n-1}^2$，一个是在有参数未知的情况下，首先要检验的是“样本是否符合这样的概率分布规则”（而不是符合这样的某个特定概率分布），求的方法是先根据样本得到最大似然估计，再得到修正的“期望样本”，再与实际样本去比对。后者最常见的就是用来检验独立性（P262）\n检验一致最优性的证明思路是这样的：如果一个检验对于原假设的一点与对立假设中的每个点，都是最优的，且满足原假设的水平的限制，那么它就是一致最优的。这个东西的好处在于，它将连续参数假设变为了两个单点假设，而单点假设的最优性由 Neyman–Pearson 引理保证。（P271）\n“独立性检验”与“齐一性检验”的区别（P265）\n卡方检验的证明：一个是归纳，把最后两个变量合起来，然后证明独立性（https://borisburkov.net/2021-06-17-1/），一个是用神秘的线性代数方法将原式化成一个高维正态分布的转置乘上自身的形式。https://arxiv.org/pdf/1808.09171\n一元线性回归的几个基本内容：\n参数估计的公式 $\\hat{\\beta}_0=\\overline Y$，$\\bar{\\beta}_1=\\sum(X_i-\\overline X)Y_i/\\sum(X_i-\\overline X)^2$。这里将 $X_i$ 统一减去 $\\overline X$ 是为了让两个参数协方差为 $0$（P291）。 估计的无偏性。 $\\hat\\beta_0$ 和 $\\hat\\beta_1$ 的方差 $\\sigma^2/n$ 与 $\\sigma^2/\\sum(X_i-\\overline X)^2$。 $\\hat\\sigma=\\sum(Y_i-\\hat{Y}_i)^2/(n-2)$（证明思路：拆成原误差、$\\beta_0-\\hat\\beta_0$、$\\beta_1-\\hat\\beta_1$ 三部分，P293）。注意 $\\delta_i$ 的意义。 区间估计和预测的区别：估计是对在理论关系函数的估计中代入单点 $x_0$ 后的结果，预测是在此基础上加上外部因素导致的误差项。 自变量与因变量反过来的线性回归并非原线性回归的反函数。二元正态分布的例子（ChatGPT）：\nManipulate[ Module[{cov, pdf, bYgivenX, bXgivenY, range = 4, line2}, (* 协方差矩阵与PDF *) cov = {{σ1^2, ρ σ1 σ2}, {ρ σ1 σ2, σ2^2}}; pdf[{x_, y_}] := 1/(2 Pi Sqrt[Det[cov]]) Exp[-1/2 {x, y}.Inverse[cov].{x, y}]; (* 回归斜率：y 关于 x 与 x 关于 y *) bYgivenX = ρ (σ2/σ1); (* E[y|x] = bYgivenX * x *) bXgivenY = ρ (σ1/σ2); (* E[x|y] = bXgivenY * y =\u0026gt; 若要以 y=f(x) 画出，则 y = x/bXgivenY *) (* 如果 bXgivenY 很小 (接近 0)，则退化为竖直线 x=0 *) line2 = If[Abs[bXgivenY] \u0026lt; 10^-6, (* 画竖直线 x=0 *) Line[{{0, -range}, {0, range}}], (* 否则画 y = x / bXgivenY *) Line[{{-range, (-range)/bXgivenY}, {range, range/bXgivenY}}] ]; (* 主图：密度 + 两条线 *) ContourPlot[ pdf[{x, y}], {x, -range, range}, {y, -range, range}, PlotPoints -\u0026gt; 80, MaxRecursion -\u0026gt; 2, ColorFunction -\u0026gt; Function[{zz}, ColorData[\u0026#34;SunsetColors\u0026#34;][zz]], ColorFunctionScaling -\u0026gt; True, PlotRange -\u0026gt; All, Frame -\u0026gt; True, Axes -\u0026gt; True, Epilog -\u0026gt; { Thick, Blue, Line[{{-range, bYgivenX*(-range)}, {range, bYgivenX*range}}], (* y = bYgivenX x *) Thick, Dashed, Red, line2, (* x = bXgivenY y 以 y=f(x) 或 x=0 的形式显示 *) Black, PointSize[Large], Point[{0, 0}] }, PlotLabel -\u0026gt; Row[{ \u0026#34;二元正态密度 (中心 = (0,0)) ; σ1=\u0026#34;, NumberForm[σ1, {3, 2}], \u0026#34; σ2=\u0026#34;, NumberForm[σ2, {3, 2}], \u0026#34; ρ=\u0026#34;, NumberForm[ρ, {3, 2}] }], ImageSize -\u0026gt; 520 ] ], (* 控件 *) {{σ1, 1, \u0026#34;σ1\u0026#34;}, 0.1, 3, Appearance -\u0026gt; \u0026#34;Labeled\u0026#34;}, {{σ2, 1, \u0026#34;σ2\u0026#34;}, 0.1, 3, Appearance -\u0026gt; \u0026#34;Labeled\u0026#34;}, {{ρ, 0.6, \u0026#34;ρ\u0026#34;}, -0.99, 0.99, Appearance -\u0026gt; \u0026#34;Labeled\u0026#34;}, ControlPlacement -\u0026gt; Left ] 相关分析：\n两个变量的相关系数检验，在 $H_0:\\rho=0$ 有个简单的 $t$ 分布，别的情况不好搞。 偏相关的定义（P326），计算思路是分别去掉线性回归部分，再算 $\\Cov$。有一个一般的公式 $P_{12}/\\sqrt{P_{11}P_{22}}$。如果变量是正态，检验也是一个 $t$ 分布，与上面一条几乎一样。 复相关的定义（P331），计算思路是只取线性回归部分。一般的公式 $\\sqrt{1-|P|/P_{11}}$。如果变量是正态，检验是个 $F$ 分布。 水平、因素数、重复度的定义（P335）。方差分析的思路是：将整体的方差分成误差方差与各因素方差（交叉项 $\\Ex=0$），然后通过因素方差除以误差方差的一个分布，来导出检验方法。\n所谓分区组不一定更好的意思是说，如果 $MS_B\u0026lt;MS_e$，那么（由加权平均的性质）不分时的 $MS_e^\\prime$ 会更小，反而更容易让 $F$ 比大。（P349）\nP102 和 P305 的证明都是这样考虑的：考虑对 $\\set{X_i}$ 做一个正交变换成为 $\\set{Y_i}$，使得需要考虑的统计量被浓缩的到开头几个 $Y$ 里。这时 $\\sum X_i^2=\\sum Y_i^2$，变换一下 PDF 可以得到 $\\set{Y_i}$ 独立，这下把需证明结论中所有跟 $X$ 相关的量都换成跟 $Y$ 相关，$Y$ 的性质很好，就行了。从这个角度也可以理解“自由度”的说法，就是只要求正交无任何具体限制的（后缀部分）$Y$ 的数量。\n书里没讲似然比检验，不过这个看起来比较简单。书里 5.2 的那些“找枢轴变量”导出的准则和似然比检验的准则往往是一样的，特别地，在一致最优检验存在时，似然比检验给出的一定是一致最优检验。\n总结一下统计中遇到的分布：\n知道 $\\sigma$ 估 $\\mu$：$\\Nd$ 不知道 $\\sigma$ 估 $\\mu$：$t_{n-1}$ 不知道 $\\sigma$ 估 $\\mu_1-\\mu_2$：$t_{n+m-2}$ 估 $\\sigma^2$：$\\chi_{n-1}^2$ 估 $\\sigma_1^2/\\sigma_2^2$：$F_{n-1,m-1}$ 指数分布：$\\chi_{2n}^2$ Bernoulli：只能大样本→正态 泊松分布：和还是泊松→用 P243 的方法变成 $\\chi^2$ 均匀分布：Irwin–Hall→正态 $Z$ 值：$\\chi^2$ 回归：残差平方和 $\\chi_{n-p-1}^2$、$\\hat\\beta_0$ 及 $\\hat\\beta_1$ $t_{n-p-1}$，$\\rho=0$ 检验 $t_{n-2}$，方差分析 $F$ ","date":"2025-09-14T00:00:00Z","permalink":"https://littlereuben.github.io/study/prostat-outline/","title":"速通概率论与数理统计"},{"content":"这是一篇摘抄笔记。\r这门课停开，或许是 TCS 将死的迹象之一吧。不过还要感谢这次停开，为我空出了宝贵的时间。\n这篇笔记主要梳理了这门课的思想脉络以及一些没提到的内容，略去了较多细节，适合辅助 sys 的笔记学习。\n思路图中，直角矩形之间的箭头为问题归约，圆角矩形之间的箭头是思路推导。图是 svg，可以拖到新标签页打开放大。\n三度图同构 几个较难理解的部分： 所谓“求群”就是指求一组 poly 大小的生成元。 增量扩展自同构的过程要对上一步的群再加筛选。 博客里“块结构和包含了至少一个 $P_b$ 的子群结构是对应的”不对，应该是对于一个固定的 $b$，这两者一一对应。 我在理解时想到了另一个问题：如果对于一个子群，它同时包含两个 $P_a$ 和 $P_b$，然后用各自的方法构造一个块系统，这两个系统一定一样吗？看起来不太容易解决。 找 2 block system 时，有些 $(a,b)$ 对可能直接把整张图并起来了。因此需要枚举 $(a,b)$ 对，不过都是 poly 的无所谓。 block system 和群的关系的性质，一般通过反证（往往取 $\\tau^{-1}\\sigma$ 之类的构造可达）证明。 这个做法可以扩展到五度图（作业 2.3）。主要的事情是，五度图的 $\\operatorname{Ker}\\pi_i$ 是 $S_2^p\\times S_3^q\\times S_4^r$ 的形式，是可解的，套到 $P$ transitive 的部分，我们实际上只要保证 minimal 的块系统不太大就行了，由 solvable+primitive 的引理，得到 $[P:Q]$ 是 poly 的（$Q$ 是使所有块不动的子群）。论文里提到对任意常数度图都可以做。 OI-wiki 里有讲 Schreier–Sims 算法，比博客里暴力做的 $\\mathrm{O}(n^6)$ 会快一些。我感觉这个算法可以推广到对于任何子群链，只要求每对相邻子群都是 poly-index, poly-recognizable，就是可能会多个一两次方（暴力找在哪个陪集内）？ 图同构做 ZKP 图匹配的代数做法 几个较难理解的部分： 核心的一个过程是倍增消环，这里的逻辑是这样的：初始假设所有边权为 $0$，拿出完美匹配边并后，处理四元环，然后再次拿出最小权完美匹配边并，这时这些边无四元环，然后不断循环。所以保证过程成立的引理不是“MWPM 的边集并的所有 PM 都是 MW”，而是“MWPM 的边集并的所有环 circulation 均非零”。 关于行列式，如果将加、乘运算视作单个节点那么深度是单 $\\log$。确定性构造匹配的方法，行列式内元素的值域是 $2^{2^{\\mathrm{O}(\\log^2n)}}$。这种情况下单次运算是 $\\log^2n$ 的高度，所以总共是 quasi-NC3 的。论文的最新版纠了这个错。关于最开始讲的随机化判断完美匹配存在，值域是 $\\mathrm{poly}(n)$ 的，所以单个运算的高度实际上是 $\\log\\log n$，可以说是介于 NC1 和 NC2 之间。 Schwartz–Zippel 的证明很简单，用概率 + 归纳：考虑 $x_1$，整个式子 $=0$ 的概率不超过 $x_1$ 最高次项系数为零 + $x_1$ 刚好取到根。 加、乘是 NC1 见 https://pages.cs.wisc.edu/~dieter/Courses/2010s-CS710/Scribes/PDF/lecture10.pdf。另外行列式有基于特征值 + 对称多项式的 NC2 做法。 lr 跟我提了个想法：我们知道最大匹配的大小等于 Edmonds 矩阵的秩，这玩意能并行吗？如何构造方案？ 博客里提到的关于一般图的两个点： Tutte 定理。只需证没有 obstruction $\\implies$ 有 PM。反证，不断加边直到再加就有 PM 了，这时可以说明去掉菊花点之后剩下一堆完全图，矛盾。完整证明见 OI-wiki。 PM 的 polytope 恰好等于：邻边和 $=1$ $\\land$ 任何奇子集的割部分 $\\ge 1$ $\\land$ $x\\ge 0$。证明思路是，如果后者有个顶点 $\\boldsymbol{x}$ 不在前者里，只取 $\\boldsymbol{x}_e\\in (0,1)$ 的部分变量，考虑变量最少的一组。这个顶点一定在某个割处取到 $=1$，考虑分别把子集内外缩成一个点，得到对应的图分别有完美匹配（否则就不是变量最少的了）且完美匹配的线性组合可以取到 $\\boldsymbol{x}$ 缩后的部分，两部分对应并起来就可以得到 $\\boldsymbol{x}$ 有完美匹配的线性组合表示的方法。完整证明见 https://www.lix.polytechnique.fr/~vjost/mpri/non-bip-matching-polytope。 一般图匹配 quasi-NC 见 https://jakub.tarnawski.org/ 的 The Matching Problem in General Graphs is in Quasi-NC。 $\\mathrm{GNI}\\in\\mathsf{AM}$ 注意博客里 AM 的定义写错了。\n这玩意的思想无比简单：实际上就是有两个大小相差常数倍的集合，$S$ 可能是其中一种，Merlin 要向 Arthur 说明 $S$ 是大的那种。分两步走，首先用笛卡尔积将常数 $c$ 扩充得足够大，然后再用 $(1-\\epsilon)^n\\approx 1$，$(1-\\epsilon)^{cn}\\approx 0$ 即可。\n","date":"2025-08-21T00:00:00Z","permalink":"https://littlereuben.github.io/study/course-algebra-and-computation/","title":"代数与计算自学笔记"},{"content":"这是一篇想法。\r这篇文章的构思和第一部分是 3 月份完成的，到了 8 月，想法其实变了不少，可能通篇看下来会注意到不少自相矛盾或者脱节的地方，说实在很多相左的观点现在也还在我脑中共存着。就把这篇文章当作不断自我辩论的一些记录好了……不过主要还是写给自己看的……\n直至不到半年前，自己对学习的心态仍在以前久积而成的旧摊子中打转。初高中时我确实自学了很多东西，这一习惯给我的益处不必多说。其实我所做的也无外乎两类事：为了 OI 水平的长期积累，深度钻研某类知识；或是在期中期末/学考之前，速通课本里的要点。从一个角度看，这两者可以说是自学对象的两类极端，但用另一句话来说，它们在此层面上是相同的：都是面对明确的目标，唯一的必然的学习路径。\n这就导致我的自学模式过拟合了这两类情形，而且自认为已经掌握了自学的精髓。具体来说，以下几个特征能够具体刻画我的习惯：\n在正式上课之前提前学（上课再学一遍）。 完整地看书，标记每一处细节，明确各概念的边界情况，容易混淆的东西。 试图读懂每个定理的证明，哪怕课本上是证略，也要从其他书里找到使用更复杂工具的证明。读懂包括两个层面，一是以自己为 Coq，compile 一遍推导；二是理解证明背后的 motivation，并以此出发，试图了解、总结该知识点出发的理解思路与处理技巧，简而言之，以 3b1b 的呈现方式为理解的至高追求。 提出自己对知识点相关的思考，对于有不同理解方式（可能由历史原因造成）的地方提出自己的想法。典型例子如关于微分的理解问题。 考虑凭借自己的思维能力，研究一些有难度的拓展问题。典型例子如复合函数高阶导的公式、群论部分的有限群分类。 做书里的习题，总结较全面的解题套路，类似 OI 时写过的两篇方法总汇。 将自己学习、思考的结果总结成 comprehensive 的笔记，希望在思想解释和一部分内容的难度上，强于课本。以普物 2 笔记和天导笔记为代表。做这事主要是考虑到，学习知识的最好方法是把一个不懂的人讲懂，也就是做一次逻辑链条完整的输出。 Seems fine, doesn't it?\n我相信自己能通过这套方法，啃下任何书和课，无论门槛高低。事实上我也做到了——GTM73 群论部分。\n开学之后，随着大量接触信息，我急遽地意识到自己要学的东西太多了。室友 ycx 是个名词党，和他的聊天使我了解到更多数学领域的方向。我发现有很多非常底层的知识和技能，跟未来科研内容的思维、研究方式有着紧密的联系，而这些知识和技能遍布数学和计算机的所有子领域。这使我感到十分缺乏安全感。于是，在对课内的内容套用以上的方法的同时，我随手选了两门比较基础的数学，范畴论和拓扑学，自己开始啃。理解这些领域基本的思维方式是很费神的事，而且那些书基本从头开始就是比较 high-level 的行文方式，所以进度不可能快。我愈发焦虑。但是普物 2 上强度之后，也就是学期 1/3 左右，我就已经忙于应付课内的笔记，全然顾不上自学了。完整记笔记非常要命的一个事是，一旦在学期开始时开了坑，就没法停下来了，因为我的预期是写一篇完美的“教科书”，而且复习的过程就是内化在写笔记里，如果中止，我的完美主义和学习节奏就会同时爆炸。期中之后的事态发展可想而知。\n那个学期，每当和别人聊到学习，我都会提起两个想法。一个是感觉所有课都在忙乱地赶进度：线性代数速通伴随、谱分解、SVD、Jordan，编入门三节课讲完 OOP，算设把自己学 OI 时了解或没了解过的偏门内容都提了一遍，计入门塞一堆杂货给你，天文学导论更是疯狂。另一个是我希望本科有六年（zby 说他也有类似的想法，不过他想的是五年），前三年静下心来学数学，后三年搞科研。\n分析一下原因吧。\n很明显，这些行为有着浓厚的 OI 训练风格，OI 毕竟特殊。这样太极端。\n一个 explicit 的缘由是与 zhr 的谈话。他论述了关于国内大学教学节奏的问题；他说，若我希望去探寻真正的创新，为了建构正确、扎实的知识体系，仔细地且以合理的顺序咀嚼这些基础知识的思想是很必要的，只有这样才能理解这些工具是为何产生的。他说，如果一门课的老师无法做到在课上使你完全理解这个知识的原理，那他就不是好的老师。他的话使当时着迷于有限群分类的我改变了一些观念。我意识到自学的局限性，以及知识学习的顺序对思维结构的影响。一个形象的解释是，在初学游泳时直接丢进深水区，这种对之前的我可以说是法宝的方式，是不能滥用的。于是我希望静下心来，更从全局思考自己学习的安排。\n如果排除功效的考量，那么说真正驱使我去这么行动的原因，是我愿意花费很多时间，去研究数学中一些简单发展出的复杂模型——就像 OI 中围绕一个知识点能构造出无数优美的问题一样。典型的内容包括：微积分→泰勒展开的组合恒等式推导、Liouville 理论、复杂不定积分技巧、不定积分无初等表示的定积分；线性代数→一些特殊矩阵的行列式与特征值、Markov 过程；物理→一些特定结构下的解析解；抽象代数→有限群、单群、环分类、范畴论（这个应该称为推广）；也包括各种模型的可视化。我很享受通过一些进阶手段推导得到最终那简洁结果的过程，回忆录中的一段话很清晰地表达了这意思：\n……我热衷于发现问题模型和解题算法之间的对应关系，那种关系是多么奇妙，像高维的、千变万化的锁和钥匙，在世界诞生之初就已经确立了神秘的、千丝万缕的联系，却从未为人所知。我见到一把看似平平无奇的锁，在它所对应钥匙被我思索之前，我甚至不能想象出它的形式，我充满着期待，直到我推导出那把钥匙，就如同依据一条短短的迭代公式生成出如画般的图案，通过茫茫星图的无尽线索找到一颗宜居的星球，那精妙而自洽的系统豁然眼前，使我同时感受到发现和创造一体的喜悦。……我意识到，这个客观世界，这宇宙中的“上帝之指纹”，是能通过人类的理性去感知，去把握的，这使我感受到信息学那深邃的力量。\n至于做如此详尽的笔记，在“自己写一遍加深理解”和“方便复习”之下，有一层更深的心理，就是想留下一些文字，希望周围的人或者后人，在学习知识遇到难以解决的困惑时，能从我的博客中得到一些帮助或启发，如此，我的思想得以一直活下去。说到底，还是面对记忆消逝的恐惧而做的自我安慰。\n所以我想否定或肯定哪些想法呢？如今看来并无这种意图。又一个半年过去，我的学习习惯从表面看似乎与过去相差无几，可观念中已发生不少微妙的更迭，于是许多事情的结果也就不同了。\n近期十分惊讶于之前自己思想的守旧，身在起点却无视着许多事实。只能说，过去的成功对自己的禁锢，是潜移默化且不自觉的。22 年末到 24 年初，我显得根本不屑于了解任何有关 llm 的事情。第一次用 ChatGPT 为的是 polish CTS2024 准备的英文自我介绍。\nr1 发布的时候我刚好在看《具体数学》，就试着问了几道中等难度的题，r1 都给了准确而简洁的答案（这些题在网上查不到，且 r1 的做法和标答思路不同，因此可以排除背数据）。我突然就 overwhelmed 了，在电脑前呆坐了一下午，脑中无比混乱。突然暴露在冲击之下使我如同面临末日一般。想起那时的反应，总觉得有一丝荒诞。\n那几道题其实并不难，用标准的，可以机械化的代数方法就可以解，没什么思维含量。我也不是才知道 AI 能做这种题，12 月 o3 达到 CF 2700 的事情就传开了。但在看到 r1 的 CoT 与解答之前，我从未切身感受过 AI 能准确处理数学对象，能应用一般性的解题套路这样的事。此前，所谓\u0026quot;Can machine think?\u0026ldquo;的问题对我来说只是流于理论的思想实验，我没有认真看待过对现实中 AI 能否准确思考问题之类的想法，就是因为没见过，无法想象。我认为当下 AI 做的事都是复杂且平凡的，或者说比较“脏”的；而要到达形式化推理的层面，不可能是量的积累，而需要另辟蹊径。我在潜意识里屏蔽了 o3 的消息，认知中我先是将它归为一种类似围棋 AI 的“特殊类型 AI”（认为它的 approach 是“不好”的，例如反复试错或猜算法，cherry picking，而不是真的“想”到正解），后来听说 OpenAI 拿到 Frontier math 测试集的新闻就默认 CF 的 benchmark 也有猫腻，总而言之就是编一些看似合理的，能缓和事情残酷性的借口来自我蒙蔽。r1 直接将 AI 能够推理的事实砸在了眼前，于是许多设想就不再是浮云，事情就开始变得紧迫起来：\n我发现自己细细研究这些 tricky 的组合问题没意义了，因为 AI 都能解，解起来如此轻松简单。推而广之，我曾经所学习的，一笔笔记下的、绞尽脑汁思考的、数年苦苦练习的这一切，在脑中建起的数学与算法的大厦，通通被碾成二维，它们所在的平面，叫 trivial。\n后来看 Quantum Computing since Democritus，其中讲到“人脑本质上就是一台又热又湿的图灵机”，这不过是个常识罢了，我也知道 Church–Turing 论题，但几条废话般的常识相组合，所得到的“人脑毫无特殊之处”的信条却使我愈发绝望。开学后的一个月里，不管学什么我都感到不安，因为每次想出些成果后，“这 AI 也能做”的念头就紧随而至，压过成就感与喜悦。我的学习计划相应地改变。甚至做 TCS 的想法也动摇了。\n周围的人似乎对这些事少有反应，大概只是麻木了吧……？我应该整理一下自己听到的一部分（有效的）看法：\nAI 将在不远的将来（5~10 年），在任何方面都强于人。 AGI 还很远，终将实现但至少近几十年不必考虑。 AI 目前能解决的问题（包括竞赛），离真正的科研还有很大的鸿沟（我的理解是，AI 以科研需要的方式规划与思考，这件事在算法层面上如何做到，还是无法想象的）。 （ycx）AI 现在能做这些题并不是出乎意料的事，因为应用解题套路也是平凡的。一些真正的研究需要洞见，例如很多数学上的难题需要的是发明新的数学工具。我不认为 AI 具有这种能力。 （strong AI skeptic）AI 不能真正理解命题，人能。 （Penrose）大脑内的微管结构内有量子重力效应，超过图灵可计算的范畴（hypercomputation），计算机无法模拟人脑。 AI 为了达到强于人类，所需要的算力可能超过目前计算机硬件架构的上限。 AI 目前的算法无法使 AI 把握物理世界，需要新的训练思路（世界模型之类）。 其实好几条的意思都基本类似。\n关于什么是“理解”的问题，书里的 4、11 章已经说明充分。Penrose 的说法我确实难以接受。\n关于科研，这张示意图应该就能表达清楚：\n3 和 4 这类问题总而言之，用通俗的话来说，我认为“洞见”是理性与感性共同作用的结果，而感性的源头无外乎是与物理世界的互动（这对于一些外行人认为 AI 不具有人的灵感、精神、生命力量之类的说法也适用），因此最终还是归为 7。这方面目前的研究情况尚不明朗。不过我想根据人脑性质的原则，这也只是 matter of time。\n无论如何，至少可以确定的是，在百年的尺度下，在假定 AI 的技术基础充分发展（而不受社会/资源因素极端限制）的前提下，AI 将在几乎任何方面都强于人。于是可以排除得到所有我们现在可做的有意义的事：\n做科研（如果真如 4 所说，人所超过 AI 的面积仅趋向而不等于 $0$ 的话）。 为做科研做准备，即眼下的学习（仅仅是手段，而自身没有意义） 与物理世界做有效的互动。 帮助推动 AI 发展。 想必有人这时会打断我说，凭什么就开始定义所谓“有意义的事”了？就此打住吧。形而上的问题一会儿再聊。\nCTT2023 之后，面对自己 OI 水平的日益荒废，我内心挣扎了很久。THUPC2024、THUPC2025 考前的复健几乎就是徒劳，为安慰自己而浪费零散的时间去做 CF 题，再没有任何价值了。我总是那么看重当下实力的维持，大概是因为觉得除了实力外，没有什么别的可以证明自己了。不过那时这么想也无可厚非，确实，离开了 OI，剩下的只有那点思维能力和经验了，这经验诚然如此宝贵，但都是不足以支撑自己的虚幻的东西吧。\n我开始看 MC 速通。它在许多方面都与 OI 如此相似（竞赛大都如此吧），以至于我常一边看一边跟着琢磨，玩家平时练习应当采用哪些方法来避免比赛中犯一些错误，然后就会联想到自己曾经训练时一些不怎么美好的回忆（笑）。从 any% 退役一年半后，Feinberg 在 24 年 10 月回归 ranked 开始练习，三天就到了 top 10，这恢复速度是极其惊人的。看着他重新练 magma portal、hard zero，学 boat eye 和 ground zero 时，我就想起了自己之前一次次在考前复习模板的经历。我将自己对 OI 的心理投射到速通上了，那些 tournament 能带给我重回赛场上的感觉，Fein 复出的成绩能减轻我潜意识里对实力退步的焦虑。\n可圈子里的人们总是会散的。几十年后，当这些 speedrunner 们老去而再也无法灵活操作电脑，当他们回望人生时，会怎样看待自己曾经在 Minecraft 1.16.1 上所达到的成就呢？\n我对 OI 的执念在年初时慢慢消解了。lca 的文章和 fsz 进队的事给了我点安慰——OI 社区的发展大概就是由一代代选手的新秀、传承与谢幕的轮回所推动的吧，自己曾经做过的事也算能对此有些贡献，也就满足了；同时，r1 的事使解题技巧和速度在我心中的价值大打折扣，我逐渐能明白去年 zhr 说的对 OI 的观点了——是啊，以现在的眼光来看，OI 中也没什么令人着迷的设计与结构了，其本质是费劲心思组合那一堆已知技巧，并未打破思想的边界。当然，我也不再赋予速通什么意义，而使其回归单纯的消遣。THUPC2025 时我更能清楚地感觉到，自己已经谦卑地接受了实力的一去不复返，对赛场的感情更多是怀念那种氛围，而不是对竞赛解题本身的珍视了。\n思来想去，上面的这些事的背后是同一个问题，即我如何理解学习与研究数学的价值。与 OI 的告别意味着我移除了“竞技性”的滤镜，在此之外，还剩下许多。\n对数学之美的追求贯穿了我的学习生涯。为此我不惜时间，深入每一处证明细节，将所有处理技巧逐一列出。可是，这真是应当追求的目的吗？\n20 世纪前的数学已是无边的海洋，仅用“初等”方法可开拓出的领域就足够研究一生。我若如 OI 时一样，永远在其中迂回盘旋，诚然能体会太多的美，也能获取创造与探索未知的喜悦，然而我的思维却是不自由的——永远局限于无人涉足，却早已被确定必然可解决的范围之中。\n迷失学习的方向，而一味沉浸于数学之美中，现在看来这就如同玩物丧志了。美只是副产品，我应当走向前线，去寻找那些从未被想象过的问题与解，而无论最终的结果是简洁，还是冗长或怪异。\n前段时间看到了 Dijkstra 关于学术研究的准则，我觉得放在这里特别合适：\n\u0026ldquo;Raise your quality standards as high as you can live with, avoid wasting your time on routine problems, and always try to work as closely as possible at the boundary of your abilities. Do this, because it is the only way of discovering how that boundary should be moved forward.\u0026rdquo;\n\u0026ldquo;We all like our work to be socially relevant and scientifically sound. If we can find a topic satisfying both desires, we are lucky; if the two targets are in conflict with each other, let the requirement of scientific soundness prevail.\u0026rdquo;\n\u0026ldquo;Never tackle a problem of which you can be pretty sure that (now or in the near future) it will be tackled by others who are, in relation to that problem, at least as competent and well-equipped as you.\u0026rdquo;\n——The Three Golden Rules for Successful Scientific Research\n去年的自己是多么鼠目寸光啊，我经常想。为什么 zhr 已将这观点如此清晰地向我表达，我却迟迟没有真切的感受？客观地考虑，这其实是一个不可避免的过程：在对高等数学这工具体系的结构没有基本了解时，心态确实是不同的；若是早些就急于了解前沿而疏于数学基础，自己的思维体系上就会漏洞百出。说回这一心态的转变，在我身上，是由 AI 刺激引起的，可很明显整件事和 AI 没有必然联系。如果把所有人类的已知结果与研究能力看成一个“库”的话，以此作为论据所导向的结论也是一样的——我想从竞赛转向科研的人们大概都走过这样的思想路径吧。\n所以其实都是些陈词滥调罢了。\n但问题不在于此。现在的问题在于，数学研究，至少 TCS as a whole，其未来令人悲观。\n于是我再次问自己，寻求更本质的要素：我如何理解学习与研究数学的价值。\nSee, 人总是想追求永恒的东西，并称之为“意义”，以暂时获得精神上的安全感。对这“永恒”有诸般诠释，其体现是如此参差——不必多言“文章之无穷”或“最后一次死亡是被人遗忘”云云，此外其并不止于具象或静态的形式——我还是举些例子来说明吧：好的学习者在学习具体知识之余总是思考更普适的学习方法与理念，例如如何学一门语言，如何练习解题技巧性较强的科目，更一般的说法是如何自学，以及控制学习节奏、管理学习质量的方法，直至以怎样的方式判断应学与不必学的内容。发展了关于此的观念后，他就不惧怕学习任何从未接触过的东西，他就能终身学习。当然，这可以套用到任何一个事业上——对了，事业。人在社会上总是希望做一些事业，或是为了家族，或是为了周围的人们，也有很多是为了家乡、祖国，或者整个社会乃至所有人类。并且随着年龄的增长，他所做工作的层次也不断提高，可能是从具体的技术细节，计划指定，到指导晚辈，分配资源，最后化为思想的引领。这并不是由于老去导致的水平退化，而是因为他相信这一群体会载着他的一份贡献走下去，且不仅如此，他的教诲能被后人所学习，从而具有自传承与发展，形象地说是落地生根，用术语说是 Quine 的性质。又譬如人们总是尊崇一些精神上纯粹的东西，例如爱情、奉献、自由、反抗精神，乃至意识形态、宗教之类，这些是能够在世界上生发出无穷事物的种子。最后，生命——正如我们熟悉的课文中写道：\n人们却不应该为此感到悲观。我们没有时间悲观。我们应该看到生命自身的神奇，生命流动着，永远不朽。地面上的小草，它们是那样卑微，那样柔弱，每个严寒的冬天过去后，它们依然一根根从土壤里钻出来，欢乐地迎着春天的风，好像那刚刚过去的寒冷从未存在。一万年前是这样，一万年以后也是这样！在春天，我们以同样感动的眼光看着山坡上那些小牛犊，它们跳跳蹦蹦，炫耀它们遍身金黄的茸毛。永远的小牛犊，永远的金黄色茸毛！\n感谢生命的奇迹，它分开来是暂时，合起来却是永久。它是一个不懂疲倦的旅客，总是只暂时在哪一个个体内住一会儿，便又离开前去。那些个体消逝了，它却永远存在。它充满了希望，永不休止地繁殖着，蔓延着，随处宣示它的快乐和威势。\n——严文井. 永久的生命\n结果当然是，宇宙中哪有什么永恒呢……于是，我们离虚无主义只差一步之遥了。这时有三条路：第一条是对世界的运作做些假设，对此有很多讨论；第二条是拥抱无常，在 21 年就写过这些1。遗憾的是这两条路并不指导我们还能够做些什么2。第三条是再寻找些确切的东西：\n\u0026hellip; See, consciousness has this weird dual property that, on the one hand, it’s arguably the most mysterious thing we know about, and on the other hand, not only are we directly aware of it, but in some sense it’s the only thing we’re directly aware of. You know, cogito ergo sum and all that.\n是的。然后呢？“过快乐的生活”之类的话显然不是我想找的答案。\nNow, is there anything else that also produces the feeling of absolute certainty? Right–math! Incidentally, I think this similarity between math and subjective experience might go a long way toward explaining mathematicians’ “quasi-mystical” tendencies. \u0026hellip; This is a good thing for physicists to understand: when you’re talking to a mathematician, you might not be talking to someone who fears the real world and who’s therefore retreated into intellectual masturbation. You might be talking to someone for whom the real world was never especially real to begin with!\n——(both) Scott Aaronson. Quantum Computing since Democritus\n这是最后一件能说服我是永恒的东西，如果有的话——至少目前是这样。3\n于是有一段时间，我迫使自己避免考虑任何社会与生活上的事，将全部的精力集中于数学学习中；后来纷扰的世事更令我将这一行为推向极端——我甚至想，自己宁愿永远住到南半球的无人小岛上，日夜浸于书卷之中。\n就这样，我将自己夹在两道崖壁之间：一面是意义的消解，一面是能力的消解。当然这状态毕竟无法长久维持，我必须想清了。\n近月越来越清晰地预感到，TCS 的死亡将会早于自己所希望的时间到来。我们还有很多可以做的，可是我已变得常常不知所措。\n这里我并没有写成“数学的死亡”，是因为自己对纯数学的研究并不了解。shj 告诉过我，寻找不同数学领域之间的联系并将它们统一起来是目前的一大图景。这样又好些，将不可言说的东西变为可言说的东西，正如上面提到的，所需的创造力往往源于对自然世界的感知，AI 到达这一步的时间可能还晚些。\n这里的“死亡”是指什么呢？当然，我总是可以去 appreciate 解决那些难题而精巧设计的解答，但我指的是，如果未来纯理智所涉及的土地彻底被 AI 接管（即使其中仍有尚待解决的问题），就无人会愿意踏足其中了，客观上我没有条件与力量对其作研究了。\n或许该早早放弃对“有为”的执念吧？\n先退一步：假设 10 年内世界模型无法完成。但至少符号推演已经死去。对此情形，周围有许多人已经给出了答案，我却翻来覆去无法想通：他们告诉我，一切数学中的发现都受推动于解决现实中问题的需要，所有抽象的概念都发源于自然；他们说，理论应当根植在实践当中并反哺实践，找不到应用的研究永远是空中楼阁。必须承认这都是历尽检验的真理，可接受它们总使我不安：\n我怎愿意徒然做功于这转瞬即逝的物质世界呢？\n我很困惑。我相信他们也曾思考过我想的这些问题，他们是怎样回答自己的内心的呢？\nReason is, and ought only to be the slave of the passions, and can never pretend to any other office than to serve and obey them.\n——休谟\nThe intellect says: \u0026lsquo;Ostensibly there is color, ostensibly sweetness, ostensibly bitterness, actually only atoms and the void\u0026rsquo;, to which the senses retort: \u0026lsquo;Poor intellect, do you hope to defeat us while from us you borrow your evidence? Your victory is your defeat.\u0026rsquo;\n——Democritus. In Schrödinger. What is Life?\n关于 AI，zby 关于观化4的论证中的一段略加修改就足以说明我的想法。其中提到一方面“知理终可穷而不必穷”，那么同样，如果有一个严格强于我们的思想机器，它能无休止地推演理之边界，那我们也相当于知道我们所有能知道的终将被知道，也就不妨止于此了。于是最终又来到了这一看法：将 AI 视作我们的后代或演化的产物就罢。\n面对自身，大概必须向后退一步，回到确切的意识，细细品味我们所感受与经历的一切，如同记录实验般观察宇宙当下发生的万千变迁。正如 ycx 说的，见证 AI 的演进与它掀起的种种效应，正是我们这代人的命运；也正如 zby 写到的观化。事物的发展哪有绝对的高低与方向性呢？外界的动荡只是对前序状态所作出的反射，自身观念的所谓“成熟”相当于思想格式塔的转换。5感知这一切时就毫无好恶或判断，只觉趣味了。\n要时刻谨记自己的位置啊，方能平息所有无谓的用心。\n我自己. 一些想法. 发在 Solvay, 2021.11.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n严格来说，第一条路中有些观点可以指导行为，但都不够 general 以使我信仰。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n值得强调的是，与文中的观点一致，针对物理规律，我认为不足以是永恒的。用通俗易懂的说法表述是，我认同《死神永生》中的说法，但不认同《镜子》中的。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nzby. 万佛湖心论道. 2025.5.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n这并非相对主义。读过《科学革命的结构》更能容易理解这句话。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2025-08-19T00:00:00Z","permalink":"https://littlereuben.github.io/theory/lifethoughts1/","title":"一些 CoT"},{"content":"这是一篇学习笔记。\r$\\gdef\\ker{\\operatorname{Ker}}\\gdef\\im{\\operatorname{Im}}\\gdef\\F{\\mathbb{F}}\\gdef\\M{\\mathbb{M}}\\gdef\\i{\\mathrm{i}}\\gdef\\id{\\mathrm{id}}\\gdef\\span{\\operatorname{span}}\\gdef\\aut{\\operatorname{Aut}}\\gdef\\cha{\\operatorname{char}}\\gdef\\P{\\mathbb{P}}\\gdef\\Q{\\mathbb{Q}}\\gdef\\C{\\mathbb{C}}$封面图：复平面上的代数数，大小与按最小多项式系数最大绝对值负相关。红二次，绿三次，蓝四次。\n前言 学环论的时候还是想，按照群论的方式只记一些理解性的笔记，但后面感觉效率太低，就决定直接过一遍书的内容。所以从模论开始就是抄书 + 一些自己的理解。\n上课用的是 Dummit \u0026amp; Foote 的书，明显感觉比 GTM 73 更适合初学，不过代价就是很冗长。相比 GTM 73，其中的定理更容易用直觉理解，印象最深的是明白了正规子群（理想）的概念是从“能成为 $\\ker$”来的。群论和环论的基础都比较清楚，不过上课只花了四节课讲域论，还是不容易形成对 Galois 理论整体的把握，可能选 GTM 73 或者把 Dummit Chapter 13, 14 完整看一遍会比较好。\n这里列举一下个人认为关键的知识路线：\n环的一些概念细节，例如子环含不含单位元、一些环需不需要交换/含幺，同态下哪些会保持之类的。环的这种细节、反例比群多很多。 极大理想、素理想、不可约元、素元、ED、PID、UFD 这堆东西之间的定理，尤其是每个定理能在什么限制的环下成立。这部分其实没什么思维含量，就是各种按定义推导。 多项式环。主要关注不同环下多项式性质的关系。这里有重要的一个思想，就是在扩张下考虑一些性质。这个跟后面域有很重要的衔接关系。\n环的部分做题其实难点就是跟一些代数技巧（主要是数论）结合，感觉跟数竞关系更大。 域扩张的刻画，整个域论的基础。 分裂域、可分扩张、正规扩张、纯不可分扩张、循环扩张、分圆扩张，它们的性质。这些东西和 Galois 理论是两条线，互相有关联，最终，高次方程可解问题依赖于这两者。 Galois 理论。主要就是得理解基本定理，其他就是 Galois 扩张和其他这些扩张的关系。 根式扩张，即五次方程可解问题。 我感觉很重要的一点是明白 Galois 理论是怎么来的，显然我并没有想清楚这件事，而是一头扎进一堆定理里去了。所以建议先看数学史（雾）。历史上抽象代数是这么来的：为了解决高次方程可解问题，先有了 Galois 理论，同时需要用到群论，然后再出现域论和环论，最后遍地开花。所以其实书里是倒着学的。之前书里说群体现的是对称关系，我还以为这只是群的几何/组合意义解释罢了，实际上我因果倒置了，是先有了根的对称关系，才拿群去刻画的。\n扯远了，核心的 principle 大概来说就是，一个高次方程的解是对域的扩张，这样的一个扩张，可以由扩张域的自同构刻画，而自同构可以由根之间允许的置换来刻画，而这些置换与它的根式解之间有对应关系——因为根式对应的自同构就是轮换。所以 Galois 理论相关的东西，就是在说这些内容：\nGalois 理论基本定理，就是在证明上面讲的这个 principle。 分裂域与闭包，就是在凑 Galois 扩张，为了能用这个 principle。 正规、可分、纯不可分这一分支，处理非零特征的情况，最后还是为了凑 Galois 扩张。 求多项式的 Galois 群，就是实操，确定对称性。对称性的显式体现就是一些判别式是否 $\\in K$，通过这个看根之间能否互相区分。 循环扩张和分圆扩张为根式扩张做准备，而根式扩张就对应最简单的一种对称性。 这篇文章说得比较好：https://www.zhihu.com/question/473033315/answer/1923314360878629688。\n由于 GTM73 的 notation 比较奇怪，然后我跟 Dummit 的混着用了，所以下文中 $\u0026lt;,\\le,\\subset,\\subseteq$ 都表示子群，$\\lhd,\\unlhd$ 都表示正规子群，不需要是真包含。\n环论 1. 环的概念 大纲 环的定义与基本推论。 交换环、幺环、无零因子环、整环、除环、域、群环的定义，注意整环和除环不能是平凡环。（左右）零因子、（左右）可逆元的定义。 环同态（等）的定义。 特征的定义。 笔记 整环、除环、域都不能是平凡环。零因子不包括零元。 在有限环中，一个元素要么是零因子/零元，要么是单元。 环可以只有单侧幺元。例如 $(a,b)+(c,d)=(a+b,c+d)$，$(a,b)(c,d)=(ac,ad)$。 无左零因子等价于有左消去律。证：无左零因子时，$ab=ac\\Rightarrow a(b-c)=0\\Rightarrow b-c=0$。有左消去律时，如果 $ab=0$（$a\\ne 0$）则 $ab=a0\\Rightarrow b=0$。 左可逆元不一定是右可逆元，且可能有多个左逆，其实这个不需要是环，考虑半群就行。考虑所有 $\\N\\to\\N$ 的映射，运算为复合，$f:x\\mapsto x+1$ 有无数个左逆 $x\\mapsto x-1,0\\mapsto\\forall$，无右逆。如果一定要是环的话，考虑无穷序列 $\\set{a_0,a_1,\\cdots}$（加法为对应位置加）的自同态环，$f:\\set{a_0,a_1,\\cdots}\\mapsto\\set{0,a_0,a_1,\\cdots}$ 同样。 左可逆元如果不是右零因子，则只有唯一左逆元。这个直接用右消去律。 单元（既有左逆元又有右逆元）的左右逆一定相等，这个已经说过很多遍了。 零元等于幺元当且仅当环大小为 $1$。 子环的幺元不一定是原环的幺元，例如 $\\Z\\times\\set{0}\\subset\\Z\\times\\Z$。 环同态 $f:R\\to S$ 不保持幺元。例如 $\\Z_2\\to\\Z_6$，其中 $1\\mapsto 3$。一般地（https://math.stackexchange.com/a/270911），如果 $R$ 是交换环，且有元素 $e$ 满足 $e^2=e$，那么 $x\\mapsto xe$ 是一个不保幺元的自同态。但以下情况是保幺元的： $f$ 是满射。显。 存在 $R$ 的一个单元 $u$，$f(u)$ 是 $S$ 的单元。这种情况下，$u1=u\\Rightarrow f(u)f(1)=f(u)$，而 $f(u)$ 存在逆元，故 $f(1)=1$。同时 $f(u^{-1})=f(u)^{-1}$。 $\\ker f\\ne R$ 且 $S$ 无零因子。这时 $1\\cdot1=1\\Rightarrow f(1_R)\\cdot(f(1_R)-1_S)=0_S$（我们只在容易混淆的时候标出零元和幺元是哪一侧的），如果 $f(1)=0$ 则 $\\forall r\\in R$，$f(r)=f(r1)=f(r)f(1)=0$，这个不对，因此只有可能 $f(1_R)=1_S$。\n进一步地，在不给出 $S$ 存在幺元的前提下，我们也能说明 $f(1)$ 是 $S$ 的幺元：$\\forall s\\in S$，$f(1)s=f(1)^2s$，故 $f(1)(s-f(1)s)=0$，故 $s=f(1)s$。 2. 理想 大纲 （左右）理想的定义，理想的初步性质：真理想不含幺元、除环无真理想、理想的交仍为理想。 生成理想、主理想、主理想环、主理想整环的定义。主理想的刻画。 理想的和、积的定义及在和、积下的封闭性。 理想和正规子群的类比，商环的定义。环的四个同构定理。 素理想的定义及（几乎等价的）性质。 极大理想的定义及存在性。 素理想与极大理想从商环角度的刻画，及它们的关系。 环的直积。环的中国剩余定理。 笔记 子环必含 $0$，不一定含 $1$。 原环本身不是素理想。 注意理想的积的定义不是简单地取各自的一个元素相乘！ $\\Z_n$ 的理想就是加法群的子群，单元是所有与 $n$ 互质的元素，素元是所有与 $n$ 的 $\\gcd$ 为质数的元素，不可约元是所有与 $n$ 的 $\\gcd$ 为质数且这个质数的平方整除 $n$ 的元素。 幺环是除环当且仅当无真左理想。如果除环有真左理想，那么它必包含幺元，就爆了。如果一个环它包含 $a\\ne0$ 不存在逆元，那么 $a$ 的左主理想 $\\set{ra\\mid r\\in R}$ 不包含 $1$，于是 $a$ 的左主理想是一个真左理想。如果一个环无真左理想，除了可能是除环以外，还有唯一的可能是 $R^2=\\set{0}$。考虑反证，如果 $\\exists cd\\ne0$，考虑左理想 $\\set{r\\in R\\mid rd=0}$，它只能是 $\\set{0}$，又因为 $Rd$ 也是个左理想，故 $Rd=R$，故 $\\exists e$ 使 $ed=d$，另外 $\\set{rd}$ 是不重的。现在再考虑 $\\set{r\\in R\\mid Rr=\\set{0}}$，它是个理想且不包含 $d$，因此只能是 $\\set{0}$，因此可以对每个 $r\\in R$ 使用上面的论述，得到 $R$ 无零因子，因此有消去律：$ed=d\\Rightarrow red=rd\\Rightarrow re=r$，$re=r\\Rightarrow rer^\\prime=rr^\\prime\\Rightarrow er^\\prime=r^\\prime$，$e$ 是幺元，从而 $R$ 是除环。 （省略“真”）有左理想，有右理想，但无双侧理想的例子：考虑除环 $D$ 上的 $n\\times n$ 矩阵环。只有某列非零的矩阵组成左理想，只有某行非零的矩阵组成右理想。如果 $I$ 是一个双侧理想，那么 $\\forall A\\in I$，$E^{i,j}AE^{k,l}=A_{j,k}E^{i,l}$，所以说如果 $I$ 中的矩阵中出现的所有数为 $S$，那么 $I$ 应当恰好是所有各位置元素均 $\\in S$ 的矩阵，所以至少 $S$ 得是个 $D$ 的理想，但 $D$ 是除环，就爆了。 根据上面的推理，环应该不会出现无真左理想但有真右理想的情况，但是会出现左右理想数量不同的情况：https://math.stackexchange.com/q/211977。 在非交换环 $R$ 中：① 极大理想不等价于商环为域，而是商环为除环 $\\Rightarrow$ 极大。② 素理想 $P$ 不一定满足 $ab\\in P\\Rightarrow a\\in P\\lor b\\in P$。还是上面矩阵的那个例子，$\\set{0}$ 是极大理想同时也是素理想，但这个环本身（即商掉 $\\set{0}$）并不是除环，它是有零因子环。 若 $R^2\\ne R$，极大理想不一定是素理想。考虑 $2\\Z$ 的极大理想 $4\\Z$ 并不是素理想。https://math.stackexchange.com/q/169188。 如果 $R$ 非交换环但 $R^2=R$，极大理想一定是素理想吗？没找到反例。 无幺环可能没有极大理想。这个很简单（想不到反例纯属学傻了，比如我），就是 $\\Z_{p^\\infty}$，乘法的结果全部为 $0$。https://math.stackexchange.com/q/154547。 即使交换环满足 $R^2=R$，素理想也不一定是极大理想。书里的反例是 $\\set{0}\\subset\\Z$，一个更不平凡的反例：https://math.stackexchange.com/a/693807。 关于理想之交和理想之积的关系：对于交换幺环 $R$ 的理想 $I$，$J$，$I+J=R\\Rightarrow IJ=I\\cap J$。证明：$IJ$ 中的元素形如 $\\sum ij$，由于各自是理想，故 $ij\\in I\\cap J$，故 $IJ\\subseteq I\\cap J$。任何 $k\\in I\\cap J$，取 $i+j=1$，则 $k=(i+j)k=ik+kj$，因此 $I\\cap J\\subseteq IJ$。参考：https://math.stackexchange.com/q/2901265。 对于交换环，应该容易证明 $(a)(b)=(ab)$，为什么书里写 $(a)(b)\\subset(ab)$？ 对于交换幺环中，极大理想为素理想，一个更简单的证明是，极大 $\\Leftrightarrow$ 商为域 $\\Rightarrow$ 商为整环 $\\Leftrightarrow$ 素。 幺环的直积的理想可以写成各自理想的直积。证明：取 $(0,\\cdots,0,1,0,\\cdots,0)$ 和理想中的一个元素相乘，于是可以得出这个组成部分的所有取值，再由加法的封闭性。对于无幺的情况不对，很简单，考虑 $\\Z_2^2$ 中乘法定义为结果恒为 $(0,0)$，然后取 $\\langle(1,1)\\rangle$。 CRT 的部分，要求 $R^2+A_i=R$ 以及 $A_i+A_j=R$。后者明显就是要求互质，但是前者呢？有前者不满足就无法构造的反例吗？注意到 CRT 本体中没有出现任何乘法。 3. 交换环中的分解 大纲 整除、相伴、不可约元、素元的定义。 素元、素理想、不可约元、极大理想之间的关系。 唯一分解整环、欧几里得环的定义。唯一分解整环的一些性质。 主理想整环、欧几里得整环均是唯一分解整环。 最大公因子的定义、存在性以及裴蜀定理。 笔记 这章的所有东西都定义在交换环上。 考虑唯一分解时我们只考虑整环，为什么？因为比如 $\\Z_6$ 中，$2=2\\cdot 4=2\\cdot 4\\cdot 4=\\cdots$。 欧几里得整环 $\\subsetneq$ 主理想整环 $\\subsetneq$ 唯一分解整环。$\\Z[(1+\\sqrt{19}\\i)/2]$ 是主理想整环不是欧几里得整环，$\\Z[x]$ 是唯一分解整环不是主理想整环。 升链条件是最重要的，它保证了分解的存在性。 在《具体数学》中说到，裴蜀定理是一切整除、互质定理（例如 $a\\perp b\\land a\\perp c\\Rightarrow a\\perp bc$）的基础，而其中裴蜀定理的证明是靠 exgcd，是构造性的。这章就给出了个非构造性的：首先存在性由全序保证，其次 $\\Z$ 是主理想整环由取模反证（这个是最简单的循环群里的内容），那么设 $\\sum(a_i)=(d)$，显然 $d$ 整除每个 $a_i$，且如果有别的公因子 $d^\\prime$，由于整除的可加性不依赖于裴蜀定理，故 $d^\\prime\\mid d$。 习题 2：https://math.stackexchange.com/a/150848、https://planetmath.org/EquivalentDefinitionsForUFD、https://zhuanlan.zhihu.com/p/519069426。 定理 条件 反例 理想 $P$ 素 $\\Longrightarrow$ $ab\\in P\\Rightarrow a\\in P\\lor b\\in P$ 交换 $\\M_{n\\times n}(D)$ 理想 $P$ 素 $\\Longleftrightarrow$ $R/P$ 整 交换、幺 $\\set{0}\\lhd\\M_{n\\times n}(D)$ 极大真理想存在 幺 $\\Z_{p^\\infty}$，$ab\\equiv0$ 极大理想 $\\Longrightarrow$ 素 交换、$R^2=R$ $4\\Z\\lhd2\\Z$ 理想 $M$ 极大 $\\Longrightarrow$ $R/M$ 域 交换、幺 $\\set{0}\\lhd\\M_{n\\times n}(D)$、$4\\Z\\lhd2\\Z$ 理想 $M$ 极大 $\\Longleftarrow$ $R/M$ 除 幺 ？ 域 $\\Longleftrightarrow$ 无真理想 交换、幺 $\\M_{n\\times n}(D)$ 直积的理想 $\\Longrightarrow$ 理想的直积 幺 $\\Z_2^2$，$ab\\equiv0$ 中国剩余定理 $R^2+A_i=R$、$A_i+A_j=R$ 不互质 相伴 $\\Longrightarrow$ 通过乘单元可互转 整 link $a$ 不可约 $\\Longleftarrow$ $(a)$ 是极大主理想 整 ？ $a$ 不可约 $\\Longleftrightarrow$ $(a)$ 是极大理想 主理想整 $(x)\\subset(x,2)\\lhd\\Z[x]$ 素元 $\\Longrightarrow$ 不可约元 整 $2\\in\\Z_6$ 素元 $\\Longleftarrow$ 不可约元 唯一分解整 $2,3,4\\pm\\sqrt{10}\\in\\Z[\\sqrt{10}]$ ACC 主理想 link：$\\Z+x\\Q[x]$，$(x)\\subset(x/2)\\subset(x/4)\\subset\\cdots$ 最大公因子存在 唯一分解整 link：$3(1\\pm\\sqrt{5}\\i)\\in\\Z[\\sqrt{5}\\i]$ 最大公因子可表出为线性组合 主理想整 $2,x\\in\\Z[x]$ 局部环 $\\Longleftrightarrow$ 非单元形成理想 交换幺 ？ $f=gh\\Longrightarrow f(c)=g(c)h(c)$ 交换 $R[[x]]$ 的非单元恰为 $(x)$ 除 $R[[x]]$ 为局部环 域 $n$ 次多项式至多有 $n$ 个根 整 $x^2\\equiv1\\pmod8$ 4. 商环与局部化 大纲 乘性子集、分式环的定义。分式环良定义的证明。 分式环、环嵌入分式环的性质。 分式环的 universal 性。 理想取分式之后的性质（略）。 局部环的定义及性质。 笔记 同样还是默认 $R$ 交换。分式环的三个层级：交换幺（无特殊性质）、整（$R$ 无零因子）、域（$R$ 无零因子且 $S=R\\setminus\\set{0}$）。嵌入的三个层级：同态（无特殊性质）、单同态（$S$ 不含零元及零因子）、同构（$R$ 幺且 $S$ 由单元组成）。\n我不太明白局部化和局部环的关系。现在我只知道，就是 $P$ 本身的局部化存在唯一极大理想，然后存在唯一极大理想的环叫局部环。有什么更深的理解吗？\n分式环不一定变大，例如 $\\set{2,4}^{-1}\\Z_6\\cong\\Z_3$。如果 $S$ 中包含 $0$，那么 $S^{-1}R=\\set{0}$，这就从一个角度解释了为什么能有 $\\sqrt{-1}$ 但不能除以零。\n$S^{-1}\\Z=\\Q$ 当且仅当任何质数都有一个倍数在 $S$ 中。相关问题 https://math.stackexchange.com/q/3451090 中的这段话很有意思，把这节的几个知识点联系在一起了：\nMore generally call a submonoid $M\\subseteq\\Z$ saturated when $ab\\in M\\Longleftrightarrow a,b\\in M$. Then it is easy to show that localizing at $S$ is the same as localizing at its saturation (smallest saturated monoid containing $S$), and, further, the complement of a saturated monoid is the union of the prime ideals that don\u0026rsquo;t meet it. So localizations are characterized by the prime ideals that survive.\n5 \u0026amp; 6. 多项式、形式幂级数、多项式的分解 大纲 多项式与形式幂级数相关的定义、扩张的可交换性。 多项式的 universal 性。 形式幂级数环中的单元、不可约元的性质。 多项式除法，分离单个根的方法，域上的多项式有唯一分解。 容度、本原多项式的定义。 多项式环下，元素性质的关系：关于根、互素、不可约、容度、相伴等的保持。 唯一分解环上的多项式环有唯一分解。 Eisenstein 准则。 笔记 基于书中的定义，应该就算 $R$ 非交换，也有 $R[x][y]\\cong R[y][x]\\cong R[x,y]$。 习题 5.7：https://math.stackexchange.com/q/263413。不能构造 $b_0^{n+m}$，因为可能幂零。 $(x-c)\\mid f\\Longrightarrow f(c)=0$ 这个不要求 $R$ 交换，详见 https://math.stackexchange.com/q/3084508。 Remainder theorem 可以不依赖于多项式除法：$x^k-a^k=(x-a)(x^{k-1}+\\cdots+a^{k-1})$。但不能靠直接代入证。 关于 6.10 的第三条，一个例子：https://math.stackexchange.com/q/3806042。 最后的一部分做的思路是这样的：首先通过 $\\varphi=\\deg$ 说明域上的多项式可唯一分解，然后让这个域是分式域，推到一般的唯一分解环上。要证明引理，保证不可约性和相伴性不变，然后归到单变量本原多项式上，干的就是死命通分。其中一个经典的操作是，已知在分式域的 $F[x]$ 上本原多项式 $f$ 和 $g$ 相伴，则 $f=ug$，设 $u=a/b\\Rightarrow bf=ag\\Rightarrow b\\approx C(bf)\\approx C(ag)\\approx a$，因此 $f\\approx g$（$D$ 是整的）。 唯一分解为什么是唯一分解为不可约元而不是素元？ 为什么 $x^p-a$ 无根 $\\Longrightarrow$ $x^p-a$ 不可约这个事情不用扩域没法证？关于这个问题，我其实可以类比 $D[x]$ 的唯一分解性以及拉格朗日插值来理解。就是如果在分式域/扩域下证明了唯一性，再证明这个唯一的解的系数不属于 $D$，就可以说明不存在。对于这类扩大范围能解决的问题，可以看这个：https://www.zhihu.com/question/1888657881399817045。 寻找所有不可约多项式似乎很难，$\\F_p$ 上不可约多项式的数量见 https://mathoverflow.net/q/297618、https://zhuanlan.zhihu.com/p/486528229，判定见 https://en.wikipedia.org/wiki/Factorization_of_polynomials_over_finite_fields#Rabin's_test_of_irreducibility，快速分解见 https://en.wikipedia.org/wiki/Berlekamp's_algorithm。 模论 1. 模、模同态、正合列 D 1.1（模）：对于环 $R$ 与阿贝尔群 $A$，称 $A$ 为左 $R$-模为：增加对 $A$ 封闭的，$R$ 与 $A$ 之间的“数乘”运算，满足结合律与双侧分配律。如果 $R$ 为幺环且 $1_Ra=a$，则 $A$ 称为幺左 $R$-模；如果 $R$ 为除环且 $1_Ra=a$，则 $A$ 称为左向量空间。\n记忆时可以将 $R$ 视作“标量”。\n幺环非幺模：https://math.stackexchange.com/q/464000。\nEx 1.17：对于幺环 $R$ 的一个 $R$-模 $A$，$A=B\\oplus C$，其中 $B$ 是幺 $R$-模，$C$ 满足 $RC=0$。\nP：考虑 $f:a\\mapsto 1_Ra$，发现 $B=\\im f$，$C=\\ker f$。因为 $1_R(1_Ra)=(1_R1_R)a=1_Ra$，从而，$1_R(a-1_Ra)=0$。\n如果 $R$ 为交换环，不区分左右模。\n但是仍然有可能有多个 $R$-模。\nE：阿贝尔群 $A$ 可视作一个 $\\Z$-模。\nE：环是子环上的模，反之不然；特殊地，理想是环上的模。\nD 1.2（模同态）：保两个性质。向量空间的同态称为线性变换。\nD 1.3（子模）：不仅要求 $B$ 是 $A$ 的子群，还要求 $B$ 在数乘下封闭。向量空间的子模称为子空间。\n例如其实 $\\Z^n$ 也是 $\\R^n$ 的子群，但是 $\\Z^n$ 不能是 $\\R$-模，不能作为向量空间。\nE：核和像分别是子模。\nD 1.4（生成子模）：略。\n注意生成子模的定义意味着对于无穷个生成元，它们的有限个的组合才是生成子模中的元素。\nT 1.5（生成子模的刻画）：分有幺与无幺，略。\nT 1.6（商模）：$B$ 为 $A$ 的子模，$A/B$ 也是一个 $R$-模，满足 $r(a+B)=ra+B$。\nP：只需证明所有原先的运算在 $=$ 下是良定义的即可。\nT 1.7, 1.8, 1.9, 1.10（四大同构定理）：略。\nT 1.11, 1.12, 1.13（直积与直和）：同一个 $R$，对于一族 $R$-模 $\\set{A_i}$，$\\prod A_i$ 是对应 $R$-模范畴里的直积，$\\sum A_i$ 是余直积。$\\sum A_i$ 指有限个分量非零，$\\prod A_i$ 反之。\n注意这里的不同，核心在于如果指标集无限，$\\prod\\to\\sum$ 会被撑爆，无法构造正确的同态，为避免要求此态射存在，直积必须是 $\\prod$，余直积必须是 $\\sum$。\nT 1.14（外直和）：$A\\cong A_1\\oplus\\cdots\\oplus A_n\\Longleftrightarrow\\exists \\pi_i:A\\to A_i,\\iota_i:A_i\\to A,\\text{s.t. }\\pi_i\\iota_j=[i=j]\\land\\sum\\iota_i\\pi_i=1$\nT 1.15（内直和）：$A_i\\lhd A\\land\\sum A_i=A\\land A_i\\cap\\sum_{j\\ne i}A_j=0\\Longrightarrow A\\cong\\sum A_i$\nD 1.16（正合列）：模范畴中的一个列 $A_0\\xrightarrow{f_1}A_1\\xrightarrow{f_2}\\cdots\\xrightarrow{f_n}A_n$，如果 $\\im f_i=\\ker f_{i+1}$ 则称为正合的。$0\\to A\\xrightarrow fB\\xrightarrow gC\\to 0$ 称为短正合列。还有 cokernel 与 coimage。\n在开头加 $0$，就要求第一个 $f$ 是单的；在结尾加 $0$，就要求最后一个 $f$ 是满的。\n以下三个短正合列中，前两个本质上在说同一个东西，第三个需要一定的条件才能和前两个相同：\n$0\\to A\\xrightarrow fB\\xrightarrow gC\\to 0$\n$0\\to A\\xrightarrow i B\\xrightarrow p B/A\\to 0$\n$0\\to A\\xrightarrow\\iota A\\oplus B\\xrightarrow\\pi B\\to 0$\nT 1.17（短五引理）：上下都是短正合列： $$ \\begin{CD}0@\u0026gt;\u0026gt;\u0026gt;A@\u0026gt;f\u0026gt;\u0026gt;B@\u0026gt;g\u0026gt;\u0026gt;C@\u0026gt;\u0026gt;\u0026gt;0\\\\ @. @VV\\alpha V @VV\\beta V @VV\\gamma V @.\\\\ 0@\u0026gt;\u0026gt;\u0026gt;A^\\prime @\u0026gt;f^\\prime\u0026gt;\u0026gt;B^\\prime @\u0026gt;g^\\prime\u0026gt;\u0026gt;C^\\prime @\u0026gt;\u0026gt;\u0026gt;0\\end{CD} $$ $\\alpha$、$\\gamma$ 单/满/双 $\\Longrightarrow$ $\\beta$ 单/满/双。同时可以定义两个短正合列的同构。\nP：单，考虑 $\\beta^{-1}(0)=\\set{0}$；满，考虑 $\\exists\\beta^{-1}(\\forall b^\\prime)$。都先导第二个方形，再导第一个。\nT 1.18（分裂引理）：对于短正合列 $0\\to A\\xrightarrow{f}B\\xrightarrow{g}C\\to 0$，$f$ 左分裂 $\\Longleftrightarrow$ $g$ 右分裂 $\\Longleftrightarrow$ $B\\cong A\\oplus C$。\nP：若 $gh=\\id_C$，则由直积的定义，$A\\xrightarrow{f}B$ 与 $C\\xrightarrow{h}B$ 对应了 $A\\oplus C\\xrightarrow{\\varphi}B$。于是得到一组可以套用短五引理的交换图。若 $kf=\\id_A$，则用余直积。反过来显然。\n初读时你可能会想：既然 $f$ 是单的，那它一定有一个单向的逆啊？主要问题是要求反的也是一个同态。不分裂的短正合列如：https://math.stackexchange.com/a/3166454。\n2. 自由模与向量空间 基的定义略。这节前半部分比较重要。如果在考虑域扩张时总是感觉怪怪的，为什么能定义扩张的维数，说明没有完全理解这里。\nT 2.1（自由模的刻画）：对于幺 $R$-模 $F$，$F$ 有非空基 $\\Longleftrightarrow$ $F$ 是若干（与 $R$ 同构的）循环 $R$-模的内直和 $\\Longleftrightarrow$ $F\\cong R^?$ $\\Longleftrightarrow$ $F$ 在幺 $R$-模范畴中是个自由对象。\n这样的 $F$ 称为自由 $R$-模，默认是幺模。非幺环/幺环但非幺模也可以定义，但相应范畴下的自由对象，不一定有直和的刻画。下文中部分自由模可以推广到非幺模的情况，但我这里就不考虑了。\nP：$2\\Leftrightarrow 3\\Rightarrow 1$ 显，构造需要有单位元。$1\\Rightarrow 4$ 直接通过线性表示构造，$4\\Rightarrow 3$：构造 $R^{|X|}$，根据 $3\\Rightarrow 1$，它有基 $\\set{\\theta_x}$，大小等于 $|X|$，然后由自由的定义。\nT 2.2：任何 $R$-模都是一个自由 $R$-模的同态像。\n注意自由模的子模不一定是自由模，例如 $\\Z_6$-模 $\\Z_6$ 的子模 $2\\Z_3$。\n另一个例子：https://math.stackexchange.com/a/74953。\nT 2.3：向量空间 $V$ 的极大线性无关组 $X$ 是 $V$ 的一组基。\nP：若 $\\span X\\ne V$，取 $a\\in V\\setminus\\span X$，通过逆元的存在性证明 $X\\cup\\set{a}$ 也是线性无关的。\nT 2.4（向量空间 = 自由模）：$D$ 上的向量空间是自由 $D$-模。$V$ 的任一线性无关组一定包含于一组基中。\nP：只需证明“极大者”存在，用 Zorn 引理（把链上的各元素并起来）。最后用 T 2.3。\nT 2.5：若 $X$ 生成 $V$，则 $X$ 包含 $V$ 的一组基。\nT 2.6（无限基的大小）：自由 $R$-模 $F$ 的基，如果是无限的，则各基基数相同。\nP：设 $X$ 是一组无限基，若 $Y$ 是有限基，则 $X$ 可表出 $Y$ $\\Rightarrow$ $X$ 有有限子集可以生成 $F$，与基的线性无关性矛盾。现在 $X$ 的每个元素都可以唯一表示为 $Y$ 的有限个元素的线性组合，可以通过不断正反线性表出证明，对于 $Y$ 的每个有限子集，能表出的 $X$ 中的元素数是有限的，于是 $|X|\\le |Y|$，反过来再证一次。\nT 2.7（有限基的大小）：向量空间的所有基都有相同的基数。\nP：如果 $X$ 和 $Y$ 都是基，$|X|\u0026lt;|Y|\u0026lt;\\infty$，那么可以通过线性表出的手段将 $X$ 中的元素逐一替换为 $Y$ 中的元素，于是 $Y$ 就是线性相关的了。\nT 2.7 的证法是线性空间维数良定义的标准证法，在线性代数中有一个 Replacement theorem 也是同样的证法。一般的线代教材都会从解方程组的角度去证这个事情。\nD 2.8（秩）：如果环 $R$ 的任意自由 $R$-模的基大小都唯一，则称 $R$ 有 invariant dimension property。对应的 $R$-模的基大小称为维度或秩，对于除环 $D$，记作 $\\dim_D$。\nT 2.9（自由模的唯一性）：如果 $R$ 有 IDP，则两个自由 $R$-模同构 $\\Longleftrightarrow$ 秩相等。\nT 2.10（商环上的模的秩）：$I\\subset R$ 是个理想，$F$ 是自由 $R$-模，令 $\\pi:F\\to F/IF$ 为标准满同态，则 $\\pi$ 把 $F$ 的基映射到 $F/IF$ 的基且大小不变。\nP：通过来回转换证明 $\\pi(X)$ 生成 $F/IF$、线性无关、是双射。\nT 2.11（商环下 IDP）：$R/I$ 有 IDP $\\Longrightarrow$ $R$ 有 IDP。\nT 2.12（交换幺环有 IDP）：如果 $R$ 有一个同态像为除环，则 $R$ 有 IDP；特别地，交换幺环有 IDP。\nP：交换幺环有极大主理想，且商掉之后是个域。于是用 T 2.11。\n这一节的思路是这样的：\n首先讨论自由模，然后定义基。 除环具有很好的性质（主要见 T 2.3、T 2.7），可以保证任何向量空间都是自由模。 在只考虑自由模的情况下，定义秩和 IDP。 回到除环，说明向量空间的秩相关的一些性质。 T 2.13：$\\dim_DV=\\dim_DW+\\dim_D(V/W)$。\nT 2.14：$\\dim_DV=\\dim_D\\ker f+\\dim_D\\im f$。\nT 2.15：$\\dim_DV+\\dim_DW=\\dim_D(V\\cap W)+\\dim_D(V+W)$。\nT 2.16：对于除环 $R\\subseteq S\\subseteq T$，$\\dim_RT=(\\dim_ST)(\\dim_RS)$。\n3. 投射模与内射模 这部分往后就没有仔细看了。\nD 3.1（投射）：$R$-模 $P$ 是一个投射模，意思是，对于任何图\n其中 $g$ 是满的。存在 $h$ 使得\n交换。\n如果 $P$ 是幺模，那么 $A$ 和 $B$ 也只需考虑是幺模的情况。\nT 3.2（投射模是一种推广）：自由模是投射模。\nP：考虑 $X\\xrightarrow\\iota F\\xrightarrow fB\\xrightarrow{g^{-1}}A$，其中 $g^{-1}$ 是任选一个。现在得到了一个 $X\\to A$，由 $F$ 的自由性可以得到 $F\\xrightarrow{h}A$。现在 $F$ 到 $B$ 有两条路径，由自由性，$g\\circ h=f$。\nT 3.4：$P$ 是投射 $\\Longleftrightarrow$ 每个短正合列 $0\\to A\\xrightarrow fB\\xrightarrow gP\\to 0$ 分裂 $\\Longleftrightarrow$ 存在一个自由模 $F$ 和模 $K$ 使得 $F\\cong K\\oplus P$。\nD 3.6（内射模）：$R$-模 $P$ 是一个内射模，意思是，对于任何图\n其中 $g$ 是单的。存在 $h$ 使得\n交换。\n内射与投射是对偶的概念，就像直积和余直积一样。\nT 3.8：幺 $R$-模 $J$ 是内射 $\\Longleftrightarrow$ 任意 $R$ 的左理想 $L$ 视作 $R$-模，任意模同态 $L\\to J$ 都可以扩展到模同态 $R\\to J$。\nT 3.9：阿贝尔群 $D$ 可除 $\\Longleftrightarrow$ $D$ 是个内射 $\\Z$-模。\nEx 3.11：阿贝尔群 $D$ 可除 $\\Longleftrightarrow$ $D$ 是一堆 $\\Q$、$\\Z(p^\\infty)$ 的直和。\n知道定义就行……\n域论 1. 域扩张 D 1.1（域扩张）：域 $F$ 是域 $K$ 的域扩张，意为 $K$ 是 $F$ 的子域。\n域 $F$ 的子环不要求对逆元封闭，子环可能不是域（$\\Z\\subset\\Q$），甚至可能不是幺环。所以这里要强制限定 $K$ 也是域。\n$1_F=1_K$。\n在 $F$ 中，$1_K1_K=1_K=1_K1_F$，用消去律即可。\n域扩张（环扩张也是）是保特征的。\n$F$ 可以视作一个 $K$ 上的向量空间。记 $[F:K]=\\dim_KF$。\nT 1.2（维度的大小）：$F/E/K$，$[F:K]=[F:E][E:K]$。\n这里称 $E$ 为中间域。\nD：对于域 $F$，它是域 $K$ 的域扩张，对于 $X\\subset F$，所有包含 $K\\cup X$ 的子域（子环）的交，称为 $X$ 在 $K$ 上生成的子域（子环），记作 $K(X)$（$K[X]$）。对于有限的 $X$，可以直接在括号里把元素列出来。$K(u)$ 称为单扩张。\n也就是说，我们说扩张时，必须要在一个大的域上去说，多项式环除外，不然就循环定义了。\nT 1.3（域扩张的刻画）：$K[X]=\\Set{h(u_1,\\cdots,u_n)\\mid n\\in\\N_+,h\\in K[x_1,\\cdots,x_n],u_1,\\cdots,u_n\\in X}$；$K(x)=\\Set{\\frac{h(u_1,\\cdots,u_n)}{k(u_1,\\cdots,u_n)}|n\\in\\N_+,h,k\\in K[x_1,\\cdots,x_n],u_1,\\cdots,u_n\\in X}$。\nP：① 上述元素是必要的；② 上述元素对运算封闭。\n这里交换性是不可缺少的，不然两个多项式相乘代入就爆炸了。\nD：子域 $L$ 与 $M$ 的复合：$LM=L(M)=M(L)$。\n注意子域的交仍为子域。\nD 1.4（代数与超越）：$F/K$。定义 $u\\in F$ 在 $K$ 上是代数的，为 $u$ 是 $K[x]$ 中多项式的根；反之，为超越的。$F$ 是 $K$ 的代数扩张，意为 $F$ 中的所有元素都是 $K$ 上的代数元；反之，为超越扩张。\nE：$\\R$ 是 $\\Q$ 的超越扩张；$\\C$ 是 $\\R$ 的代数扩张。\nE：$K(x_1,\\cdots,x_n)\\setminus K$ 中的元素在 $K$ 上都是超越的。\n$\\mathrm{e}$ 是超越数：https://zhuanlan.zhihu.com/p/47709039；$\\pi$ 是超越数：https://zhuanlan.zhihu.com/p/56607777。\nT 1.5（超越单扩张的刻画）：$u$ 是超越元，则 $K(u)\\cong K(x)$。\nP：构造 $\\varphi:K(x)\\to F$，$f/g\\mapsto f(u)/g(u)$。通过 $u$ 不是根，证明 $\\varphi$ 是单射。而 $\\im\\varphi=K(u)$。\nT 1.6, D 1.7（代数单扩张的刻画）：$u$ 是代数元，则：\n$K(u)=K[u]$。 $K(u)\\cong K[x]/(f)$，不可约且首一的 $f$ 称为 $u$ 的最小多项式，它整除任何以 $u$ 为根的多项式。 $[K(u):K]=\\deg f=n$。 $\\set{1,u,\\cdots,u^{n-1}}$ 是 $K$ 上的向量空间 $K(u)$ 的一组基，$n$ 也称为 $u$ 的度。 P：考虑 $\\varphi:K[x]\\to K[u]$。$K[x]$ 是欧几里得整环 $\\Rightarrow$ 主理想整环，于是 $\\ker\\varphi=(f)$ 即 (ii)。为了说明 $f$ 不可约，由于 $K[u]$ 是整的，故（推一下）$(f)$ 是素的 $\\Rightarrow$ $f$ 素 $\\Rightarrow$ $f$ 不可约。然后 $f$ 不可约 $\\Rightarrow$ $(f)$ 极大 $\\Rightarrow$ $K[x]/(f)$ 为域 $\\Rightarrow$ $K[u]=K(u)$。\n另一方面，$K(u)$ 中任意一个 $\\ge\\deg f$ 的元素都可以取模，而 $\\set{u^{0\\sim n-1}}$ 线性无关不是废话吗。\nE：从另一个角度来说，任意度数 $\u0026lt;n$ 的非零多项式 $g$ 和 $f$ 是互质的，因为否则 $f$ 有非平凡因子可以更小。从而 $g^{-1}$ 可以通过对 $f$ 和 $g$ 跑 exgcd 得到。$f(x)=x^2+c$ 的情况，是一个特殊的，可以直接用平方差公式凑的情况。\n诶呀反正就是你得先把环论，素理想/极大理想 $\\longleftrightarrow$ 素元/不可约元、几种整环的关系，都玩得很明白。\n在这里，$u\\in K(u)$ 就被映到 $x\\in K[x]/(f)$。\nT 1.8（同构在单扩张下的保持）：$\\sigma:K\\to L$ 是域同构，如果 $u$、$v$ 分别是 $K$、$L$ 上的超越元，或分别是 $K[x]$、$L[x]$ 内的多项式 $f$、$\\sigma(f)$ 的根且 $f$ 不可约，则 $K(u)\\cong L(v)$ 且同构映射可以由 $\\sigma$ 扩展得到且 $u\\mapsto v$。\nP：超越元：$\\sigma$ 可以扩展到 $K[x]\\to L[x]$，也可以扩展到 $K(x)\\to L(x)$，于是 $K(u)\\cong K(x)\\cong L(x)\\cong L(v)$。代数元：$\\sigma(f)$ 显然也是不可约的。$K(u)\\cong K[x]/(f)\\cong L[x]/(\\sigma(f))\\cong L(v)$，中间这个同构可以用定义证。\n注意要求 $f$ 不可约，否则比如可以取 $K=L=\\R$，$f(x)=x^3-1$，然后 $u=1$，$v=\\omega$。\nT 1.9（T 1.8 的反面）：$E/K$，$F/K$，$u\\in E$ 和 $v\\in F$ 是 $K$ 上的代数元。$u$ 和 $v$ 是同一个 $K[x]$ 内不可约多项式的根 $\\Longleftrightarrow$ $K(u)\\cong K(v)$ 且这个同构 $\\sigma$ 中 $\\sigma|_K=\\id$，$u\\mapsto v$。\nP：只需证 $\\Longleftarrow$：设 $u$ 是 $f\\in K[x]$ 的根。$0=\\sigma(0)=\\sigma(f(u))=\\sigma(\\sum a_iu^i)=\\sum\\sigma(a_i)\\sigma(u)^i=\\sum a_iv^i=f(v)$。\n我在想一个问题，$K(u)$ 一定包含 $f$ 的其他根吗？这个定理似乎给出了肯定的回答，但有没有构造性的证明呢？\n答案似乎是否定的：https://math.stackexchange.com/a/1714513。$\\Q[x]/(x^3-2)\\cong\\Q(\\sqrt[3]2)\\cong\\Q(\\sqrt[3]2\\omega)$，似乎要么只有 $\\set{1,\\sqrt[3]2,{\\sqrt[3]2}^2}$ 一系的，要么只有 $\\set{1,\\sqrt[3]2\\omega,{\\sqrt[3]2}^2\\omega^2}$ 一系的。\nT 1.10（可以先有多项式再有代数单扩张）：$f\\in K[x]$，存在扩域 $F$，使 $F=K(u)$，$u\\in F$ 是 $f$ 的根。$[K(u):K]\\le\\deg f$，取等当且仅当 $f$ 不可约；如果 $f$ 不可约则 $F$ 唯一。\nT 1.11（有限扩张一定是代数扩张）：$F/K$ 满足 $[F:K]\u0026lt;\\infty$，则 $F$ 是 $K$ 的有限生成代数扩张。\nP：用向量空间的基本性质即可。\nT 1.12（多次代数单扩张）：$F/K$，$X\\subset F$，$F=K(X)$ 且 $X$ 的元素是 $K$ 上的代数元，那么 $F$ 是代数扩张。$|X|\u0026lt;\\infty\\Rightarrow[F:K]\u0026lt;\\infty$。\nP：由定义 $F$ 中的每个元素只能涉及有限个 $X$ 中的元素，所以可以拆成有限次单扩张。\nT 1.13（多次代数扩张）：$F$ 是 $E$ 的代数扩张，$E$ 是 $K$ 的代数扩张 $\\Longrightarrow$ $F$ 是 $K$ 的代数扩张。\nP：$\\forall u\\in F$ 可以由 $u$ 的零化多项式系数以及 $u$ 本身依次作为扩张元得到。\nT 1.14（子代数扩张）：$F/K$，$F$ 中所有代数元组成 $F$ 的子域。\n总的来说，以上事情就是在说，代数扩张、最小多项式、有限维度，这些东西总是一起出现的。\n能否有，对非单扩张的，模多项式（或类似）的刻画呢？\n尺规作图部分：\n可以任意平移旋转一条线段（利用平行线），因此只关心哪些长度可以构造。 单位长度任选，所以认为 $1$ 可构造。 $c$，$d$ 可构造 $\\Rightarrow$ $c\\pm d$ 可构造。 $c$，$d$ 可构造 $\\Rightarrow$ $d/c$ 可构造（利用三角形内的平行线）$\\Rightarrow$ $cd$ 可构造。 $c$ 可构造 $\\Rightarrow$ $\\sqrt{c}$ 可构造（利用 $\\sqrt{(\\frac{c+1}2)^2-(\\frac{c-1}2)^2}$）。 于是首先可构造的一定是个域 $F$。 任何直线、圆的交点，只能在 $F$ 里绕圈或者引入一个 $u\\in F$ 的 $\\sqrt{u}$。于是至多只有以上操作。 也就是从 $Q_0=\\Q$ 出发，每次扩一个开根后的值，那么 $[Q_{i+1}:Q_i]=2$。而 $u\\in Q_n$ 对应的 $\\Q(u)$ 是 $Q_n$ 的子域，从而 $[\\Q(u):\\Q]\\mid[Q_n:\\Q]$ 是 $2$ 的次幂，从而 $u$ 一定是一个 $2^?$ 次有理系数多项式的根。于是所有次数非 $2^?$ 的 $\\Q[x]$ 中的不可约多项式的根都不行。 三等分 $60^\\circ$ 的角需要得到 $8x^3-6x-1$ 的根，用试根法得不可约。立方倍积也一样。 2. Galois 理论基本定理 D 2.1（$K$-同态）：$E/K$，$F/K$。一个 $E\\to F$ 的同态，如果既是域同态，又是 $K$-模同态，就称为 $K$-同态。同构、自同构同理。$F$ 的所有 $K$-自同构显然构成一个 $\\aut F$ 的子群，称为 $F$ 在 $K$ 上的 Galois 群 $\\aut_KF$。\n$\\aut_KF$ 中的映射对 $K$ 中的元素都是不变的，因为是 $K$-模同构；反之使 $K$ 中的元素不变的同构必然是 $K$-模同构。\nE：对于 $K(x)$ 中的分式 $f(x)$，$f(x)\\mapsto f(ax)$ 与 $f(x)\\mapsto f(x+b)$ 都是 $\\aut_KK(x)$ 中的元素，但这两类不交换。\nT 2.2（根在 $K$-自同构下的保持）：$F/K$，$u\\in F$ 是某个 $K[x]$ 中多项式的根，那么 $\\sigma(u)$ 也是这个多项式的根，其中 $\\sigma\\in\\aut_KF$。\n很自然地想到就让 $F=K(u)$。$\\aut_KK(u)$ 内的自同构由 $u\\mapsto{?}$ 决定，因此 $\\aut_KK(u)$ 的大小不超过 $u$ 最小多项式根数。\nE：$\\lvert\\aut_{\\Q}\\Q(\\sqrt[3]2)\\rvert=1$；$\\lvert\\aut\\R\\rvert=1$。\nE：$\\lvert\\aut_{\\R}\\C\\rvert=2$；$\\lvert\\aut_{\\Q}\\Q(\\sqrt3)\\rvert=2$。共轭。\nE：$\\Q(\\sqrt2,\\sqrt3)$ 可以视作 $\\Q$ 上以 $\\set{1,\\sqrt2,\\sqrt3,\\sqrt6}$ 为基的线性空间，分析的思路是当成两次扩张。先得到 $[\\Q(\\sqrt2,\\sqrt3):\\Q]=4$ 再构造。$\\aut_{\\Q}\\Q(\\sqrt2,\\sqrt3)$ 只有可能是 $\\sqrt2\\mapsto\\pm\\sqrt2$、$\\sqrt3\\mapsto\\pm\\sqrt3$，因此它 $\\cong\\Z_2^2$。\nT 2.3（Galois 群的子群与中间域的关系）：$F/K$。\n考虑 $\\aut_KF$ 的一个子群 $H$。在 $H$ 里各个 $K$-自同构下都不动的元素，构成一个中间域。 考虑一个中间域 $E$，所有使得 $E$ 中元素不动的 $K$-自同构，构成 $\\aut_KF$ 的一个子群 $\\aut_EF$。 记 $H$ 对应的中间域为 $H$ 的不动域 $H^\\prime$。记 $\\aut_EF$ 为 $E^\\prime$。我们有 $F^\\prime=\\set{\\id}$，$K^\\prime=\\aut_KF$，$\\set{\\id}^\\prime=F$，但 $(\\aut_KF)^\\prime$ 不一定等于 $K$，例如 $\\Q(\\sqrt[3]2)$。下记 $\\set{\\id}=1$。\nD 2.4（Galois 扩张）：如果 $(\\aut_KF)^\\prime=K$ 或者说 $K^{\\prime\\prime}=K$，则称 $F$ 是 $K$ 的 Galois 扩张。\n将注意力放在自同构群上，确实对没了解过后面的人来说是非常诡异的。直观理解，其实就是根之间的置换。非 Galois 的扩张是怎么回事呢？我也觉得很奇怪。可以理解成扩得不够完整使得根没全部出现吗？\nT 2.5（Galois 理论基本定理）：$F$ 是有限维的 $K$ 的 Galois 扩张。中间域与 $\\aut_KF$ 的子群一一对应。对应由 $E\\to E^\\prime$ 给出。\n两个中间域的相对维数，等于他们对应的子群的相对指数。 中间域 $E$ 是 $K$ 的 Galois 扩张 $\\Longleftrightarrow$ $E^\\prime\\lhd K^\\prime$，这时 $K^\\prime/E^\\prime\\cong\\aut_KE$。 注意没说 $F$ 是 $K$ 的 Galois 扩张的，就默认不要求这个。\nT 2.6：$F/M/L/K$，$H\\subseteq J\\subseteq G=\\aut_KF$。\n$F^\\prime=1$，$K^\\prime=G$。 $1^\\prime=F$。 $M^\\prime\\subseteq L^\\prime$。 $H^\\prime/J^\\prime$。 $L^{\\prime\\prime}/L$，$H\\subseteq H^{\\prime\\prime}$。 $L^\\prime=L^{\\prime\\prime\\prime}$，$H^\\prime=H^{\\prime\\prime\\prime}$。 P：只看 $L^\\prime=L^{\\prime\\prime\\prime}$。一方面，$L^{\\prime\\prime}/L$，说明 $L^{\\prime\\prime\\prime}\\subseteq L^\\prime$；另一方面，$L^\\prime\\subseteq(L^\\prime)^{\\prime\\prime}$。\n定义闭，为 $\\cdot^{\\prime\\prime}=\\cdot$。\nT 2.7（闭条件下的基本定理）：闭中间域与闭 Galois 子群一一对应。\nP：$E\\mapsto E^\\prime\\mapsto E^{\\prime\\prime}=E$。\nT 2.8（相对指数与相对维数的关系 1）：$F/M/L/K$，$[M:L]\u0026lt;\\infty$，则 $[L^\\prime:M^\\prime]\\le[M:L]$。\nP：$M$ 是 $L$ 的代数扩张。取 $u\\in M\\setminus L$，考虑 $L(u)=M$ 的情况（若不然，可归纳）。考虑构造 $M^\\prime$ 在 $L^\\prime$ 中的陪集，到 $u$ 最小多项式各根的单射，由于上面说了 $[M:L]$ 一定不小于根数，就可以得到这个不等式。各陪集都是将 $u$ 映射到另一个根（同一个陪集是使 $M$ 不动的），于是就有了映射。如何证明单射？如果 $\\tau(u)=\\tau^\\prime(u)$，则 ${\\tau^\\prime}^{-1}\\tau\\in M^\\prime$，矛盾。\n注意这里是不需要子群的正规性的。这个证明其实就是照着 T 2.2 在说，或者其实就是 T 2.2 的多步扩张推广。\nT 2.9（相对指数与相对维数的关系 2）：$H\\subseteq J\\subseteq G=\\aut_KF$，$[J:H]\u0026lt;\\infty$，则 $[H^\\prime:J^\\prime]\\le[J:H]$。\nP：假设 $[J:H]=n$，$\\set{\\tau_1 H,\\cdots,\\tau_n H}$ 是所有陪集；若 $[H^\\prime:J^\\prime]\u0026gt;n$，找一组线性无关元 $u_1,\\cdots,u_{n+1}$。考虑方程组 $$ \\Set{\\sum_{j=1}^{n+1}\\tau_i(u_j)x_j=0,|,i=1,\\cdots,n} $$ 它有非零解，找到零的数量最多的一组 $\\boldsymbol x=(a_1,\\cdots,a_{n+1})$。我们可以找到另一组解 $\\sigma\\boldsymbol x$，使得这两组解相减得到更多的零，从而导出矛盾。一方面为了保证更多的零，可以让 $a_1=1$；另一方面为了保证不是全零，找的 $\\sigma$ 要让某个 $a_j$ 变化，也就是 $a_j\\in H^\\prime\\setminus J^\\prime$。那其实 $\\sigma$ 是随便选的，而且根据群论，$\\sigma\\circ\\tau_i$ 就是做了个置换罢了，那就完事了。\n这个证明可能就是比较技术性的那种，没什么好说的。\n总的来说，感觉就是，如果取的中间域/子群“有水分”，那么取 $\\cdot^\\prime$ 之后水分会缩小。\nT 2.10（T 2.8\u0026amp;9 取等条件）：如果 $L$ 是闭的，那么 $M$ 也是闭的且 T 2.8 取等；如果 $H$ 是闭的，那么 $J$ 也是闭的且 T 2.9 取等。从而（自底向上地推），如果 $F$ 是 $K$ 的 Galois 扩张，那么所有东西都是闭的，从而 T 2.5 的前半部分成立。\n注意有限这一条件。\nP：$L$ 是闭的 $\\Rightarrow$ $L^{\\prime\\prime}=L$ $\\Rightarrow$ $[M:L]\\le[M^{\\prime\\prime}:L]=[M^{\\prime\\prime}:L^{\\prime\\prime}]\\le[L^\\prime:M^\\prime]$。对称同理。\n这么本质的一个定理竟然用的是不等式去证，使我大受震撼。\n定义一个中间域 $E$ 是稳定的，为它在 $\\aut_KF$ 的各个同构下都映射到自己，换句话说 $\\aut_KF$ 中的自同构限制在 $E$ 内时也是自同构。\nT 2.11（稳定与正规的关系）：$E$ 稳定 $\\Longrightarrow$ $E^\\prime\\lhd\\aut_KF$；$H\\lhd\\aut_KF$ $\\Longrightarrow$ $H^\\prime$ 稳定。\nP：很简单，$\\sigma\\in\\aut_KF$，$\\tau\\in E^\\prime$，算一下 $\\sigma^{-1}\\tau\\sigma|_E$。反过来也一样，已知 $\\sigma^{-1}\\tau\\sigma|_E=\\id\\Rightarrow\\tau\\sigma|_E=\\sigma|_E$，那就是稳定啊。\n$\\forall$ 中间域 $E$，$F$ 都是 $E$ 上的 Galois 扩张，但 $E$ 不一定是 $K$ 上的 Galois 扩张。那如果考虑 $E$ 所有 $K$-同构，如果这些和 $\\aut_KF$ 有对应关系，那自然就是 Galois 扩张了。那能保证这个的，就是 $E$ 的稳定性。\nT 2.12\u0026amp;13（稳定与 Galois 的关系）：$F/K$ Galois。$E$ 稳定 $\\Longrightarrow$ $E$ 是 $K$ 的 Galois 扩张；$E$ 是 $K$ 的代数的 Galois 扩张 $\\Longrightarrow$ $E$ 稳定。\nP：前者已讲。后者，取 $u\\in E\\setminus K$ 及其最小多项式 $f\\in K[x]$。$f$ 在 $E$ 中的各根在 $\\aut_KF$ 变换下是不动的（只是内部置换），于是 $f$ 在 $\\aut_KF$ 下也是不动的，于是 $u$ 在 $\\aut_KF$ 下仍 $\\in E$。\n现在要做的几乎已经完成了，因为是有限扩域，所以代数这一条件自动满足。\n最后考虑几个自同构群之间的关系。$\\aut_KE$ 中的元素，如果可扩展到 $F$ 上，那么它会是怎样扩展的呢？其实也可以理解成一个分层的结构，就是所有 $K$-自同构，在 $K$ 的各点不动，在 $E$ 上整个不动，那么在 $E$ 内，和在“商”$F/E$ 上，这两部分共同确定了完整的自同构。\n如果 $\\aut_KE$ 中的元素可以扩展为 $\\aut_KF$ 的元素，则称为可扩展的。\nT 2.14（自同构群的大小关系）：$E$ 稳定，$\\aut_KF/\\aut_EF\\cong\\aut_KE$ 中可扩展的部分。\nP：“标准”同态 $\\aut_KF\\to\\aut_KE$，这玩意的核不正是 $\\aut_EF$ 吗？这个不需要 $F$ 是 Galois 扩张的。\n最后我们说明 $F$ 是 Galois 的情况下，$\\aut_KE$ 整个都是可扩展的。考虑从大小的角度去说明。一方面，$\\lvert\\aut_KE\\rvert=[\\aut_KE:\\aut_EE]=[E:K]$，另一方面，$\\lvert\\aut_KF/\\aut_EF\\rvert=[\\aut_KF:\\aut_EF]=[E:K]$。\n为了更好地理解，再考虑 $\\Q(\\sqrt2,\\sqrt3)$。对于 $\\Q(\\sqrt2)$ 这个中间域，对应的不动子群就是在 $\\pm\\sqrt3$ 之间切换的。$\\Q$ 到 $\\Q(\\sqrt2)$，对应的自同构部分是 $\\pm\\sqrt2$，$\\Q(\\sqrt2)$ 到 $\\Q(\\sqrt2,\\sqrt3)$，对应的是 $\\pm\\sqrt3$。\nArtin 的思路是，先有自同构子群，再有 $K$。\nT 2.15（Artin）$G$ 是 $\\aut F$ 的子群，设 $K$ 是 $G$ 的不动域，则 $F$ 是 $K$ 的 Galois 扩张。若 $|G|\u0026lt;\\infty$，则 $F$ 是 $K$ 的有限 Galois 扩张，Galois 群为 $G$。\n考虑 $n$ 元分式域 $K(x_1,\\cdots,x_n)$，对于每个置换 $\\sigma\\in S_n$，$\\sigma^*:f(x_1,\\cdots,x_n)\\mapsto f(x_{\\sigma(1)},\\cdots,x_{\\sigma(n)})$ 为一个自同构，从而 $S_n$ 是 $\\aut K(x_1,\\cdots,x_n)$ 的子群，而且一类“很对称”的分式构成的子域 $E$，在各 $\\sigma^*$ 下不动，$K(x_1,\\cdots,x_n)$ 就是 $E$ 的 Galois 扩张且 Galois 群就是 $S_n$。又由于我们知道任何有限群都是对称群的同态像，因此就有：\nT 2.16：任何有限群都是某个 Galois 群。\n$E$ 到底是什么样的呢？我们称 $E$ 中的元素为对称函数。考虑以下“初等”函数： $$ f_i=\\sum_{S\\subseteq\\set{1,\\cdots,n},|S|=i}\\prod_{j\\in S}x_j $$ 这个显然是对称的。下面说明 $E=K(f_1,\\cdots,f_n)$。\nT 2.17：$x_1\\sim x_k$ 的各初等对称函数，都可以写成关于 $f_1\\sim f_n$，加上 $x_{k+1}\\sim x_n$ 单项，的多项式。\nP：考虑 $x_n$，$f_{i+1}^\\prime=f_{i+1}-f_i^\\prime\\cdot x_n$。\nT 2.18：$E=K(f_1,\\cdots,f_n)$。\nP：已知 $E\\supseteq K(f_1,\\cdots,f_n)$。考虑证明 $[K(x_1,\\cdots,x_n):K(f_1,\\cdots,f_n)]\\le n!$。\n由于 $(y-x_1)\\cdots(y-x_n)=y^n-f_1y^{n-1}+f_2y^{n-2}-\\cdots\\in K(f_1,\\cdots,f_n)$，故 $x_n$ 是个代数数，现在我们可以把 $K(f_1,\\cdots,f_n)$ 代数扩张到 $K(f_1,\\cdots,f_n,x_n)$，而且维数不超过 $n$。根据 T 2.17，可以以此类推，总维数不超过 $n!$。\nTMD 为什么又是拿大小来证啊！！我现在感觉域相关的命题证明思路只有推 $\\le$ \u0026amp; $\\ge$ 或者 $\\subseteq$ \u0026amp; $\\supseteq$，没别的了……\n考虑证明，对多项式环，类似的结论成立。\nT 2.19：$\\set{x_1^{\u0026lt;1}x_2^{\u0026lt;2}\\cdots x_n^{\u0026lt;n}}$ 是 $E$ 上的线性空间 $K(x_1,\\cdots,x_n)$ 的一组基。\nP：T 2.18 的证明 + T 1.6。\nT 2.20：$K[x_1,\\cdots,x_n]$ 是 $K[f_1,\\cdots,f_n]$ 上的向量空间，以 $\\set{x_1^{\u0026lt;1}x_2^{\u0026lt;2}\\cdots x_n^{\u0026lt;n}}$ 为一组基。\nP：想表达的意思其实就是线性组合的系数不是分式嘛。但除了 T 2.19 保证唯一性，没有域的工具可以用了。考虑 $K[x_1,\\cdots,x_n]$ 中的某个元素。如果出现某个 $x_i^{\\ge i}$，由于 $x_i$ 是 $(y-x_1)\\cdots(y-x_i)$ 的根，且这个多项式的系数，上面说了，可以由 $f_1\\sim f_n$、$x_{k+1}\\sim x_n$ 组合得到，因此 $x_i^i$ 可以由这些和 $x_i^{\u0026lt;i}$ 组合得到，这样可以不断地往下消，直到次数 $\u0026lt;i$。那这样就可以了。\n又是扩域再缩回来的技巧。\nGalois 非 Galois 代数 $\\C$ $\\Q[\\sqrt[3]2]$ 超越 $K(x)$（$|K|=\\infty$） $K(x)$（$|K|\u0026lt;\\infty$） 这里看一组和上一节关系大一点的小习题：\nEx 6(b)：$K(x)/F/K$，其中 $F\\ne K$。$[K(x):F]\u0026lt;\\infty$。\nP：既然 $K(x)/F$，那么一定有一个 $u\\in F\\setminus K$，$u=f/g$ 形如一个最简分式。那么 $x$ 是 $K(u)$ 上的代数数，即，$f-gu$ 的根，或者说，最多我加入 $1,x,\\cdots,x^{\\max\\set{\\deg g,\\deg f}-1}$，就足以构成完整的 $K(x)$，因为你把 $u$ 当作一个系数的话，我们至少有 $f-gu=0$，也就是说 $1,x,\\cdots,x^{\\max\\set{\\deg g,\\deg f}}$ 线性相关，再高次的项也可以递推地被低次线性表出。现在 $K(x)$ 是 $K(u)\\subseteq F$ 的有限维扩张，自然是 $F$ 的有限维扩张。\nEx 6(d)：$\\aut_KK(x)=\\Set{x\\mapsto\\frac{ax+b}{cx+d}|ad\\ne bc}$。\n$\\aut_KK(x)$ 的元素由 $x\\mapsto{?}$ 决定，考虑 $x\\mapsto\\theta(x)$。既然希望是自同构，那就希望 $\\set{f(\\theta(x))\\mid f\\in K(x)}=K(x)$，这个东西又可以翻译成 $K(\\theta)=K(x)$，也就是说我们希望，$\\theta$ 通过一通操作可以搞出 $x$，换句话说，还是和上面一样的道理，$x$ 是 $K(\\theta)$ 上度为 $1$ 的代数数。那我们现在知道，如果 $\\theta(x)=p(x)/q(x)$，那么 $x$ 是 $\\theta q(y)-p(y)$ 的根（注意这里是在将 $\\theta$ 看作分式和看作一个独立的元素之间切换）。根据 T 1.6，$\\theta q(y)-p(y)$ 在 $K(\\theta)[y]$ 上不可约的话，$[K(x):K(\\theta)]$ 就等于 $\\deg_y(\\theta q(y)-p(y))$ 了。能不能证明这玩意不可约呢？现在可以把 $\\theta$ 视作一个常数，我们知道取不取分式域，对多项式的可约性是不影响的，所以考虑 $K[\\theta,y]$，$\\theta q(y)-p(y)$ 关于 $\\theta$ 是一次的，而 $q(y)$ 和 $p(y)$ 互质，所以肯定是不可约的。于是现在就要求 $\\deg_y(\\theta q(y)-p(y))=1$。最后尽管 $\\frac{ax+b}{cx+d}$ 是个满自同态，我们还没验证它是自同构，这个很简单——复合逆是 $\\frac{dx-b}{a-cx}$。\nEx 9：$K(x)$ 是 $K$ 的 Galois 扩张 $\\Longleftrightarrow$ $|K|=\\infty$。\n考虑 $(\\aut_KK(x))^\\prime$。对于 $|K|=\\infty$，如果它不止包含 $K$，令 $(\\aut_KK(x))^\\prime=E$，那么 $[K(x):E]$ 有限，且 $\\aut_KK(x)=\\aut_EK(x)$。但是根据 T 2.8，$\\lvert\\aut_KK(x)\\rvert=\\lvert\\aut_EK(x)\\rvert\\le[K(x):E]\u0026lt;\\infty$，与 Ex 6(d) 矛盾。对于 $|K|\u0026lt;\\infty$，$\\lvert\\aut_KK(x)\\rvert\u0026lt;\\infty$，如果 $(\\aut_KK(x))^\\prime=K$，则根据 T 2.9，$[K(x):K]=[\\set{\\id}^\\prime:(\\aut_KK(x))^\\prime]\\le[\\aut_KK(x):\\set{\\id}]\u0026lt;\\infty$，与 $[K(x):K]=\\infty$ 矛盾。\n参考 https://math.stackexchange.com/q/13129、https://pi.math.cornell.edu/~erin/algebra/hungerford_v_5_2.pdf。\n3. 分裂域、代数闭包、正规性 D 3.1（分裂域）：多项式分裂的定义略。$F$ 是非常数多项式 $f\\in K[x]$ 在 $K$ 上的分裂域，意为 $f$ 在 $F[x]$ 上分裂且 $F$ 恰好由 $K$ 扩张 $f$ 的各个根得到。对于包含若干多项式的集合 $S$，定义同样的东西。\n注意这里并没有说明分裂域唯一。\n我们只需关心 $|S|=1$ 和 $|S|=\\infty$ 的情况。后面我们会知道，任何代数 Galois 扩张都是分裂域。\nT 3.2（分裂域的大小）：$f$ 的分裂域的维数不超过 $(\\deg f)!$。\nP：取 $f$ 的一个不可约因子，将其一根扩入 $K$ 之后，就导致维数乘至多 $\\deg f$，归纳。\n实际上这个上界是可以达到的。例如 $f=x^3-2$ 时，$\\Q(2^{1/3},\\omega)$ 的基为 $\\set{1,2^{1/3},2^{2/3},\\omega,2^{1/3}\\omega,2^{2/3}\\omega}$。对于更一般的情况，由于上面说了 $[F:K]=\\lvert\\aut_KF\\rvert$，所以目标就变成构造大的 Galois 群，后面我们会看到这是常见的。\n一个典型的误解是，认为我们是把 $f$ 拆成若干个不可约的因子，每个贡献 $\\deg$ 倍。这会导致以为最大的维数是 $3^{n/3}$。上面这个例子就是这个理解的反例。\nhttps://math.stackexchange.com/q/1149743。\n证明 $|S|=\\infty$ 的分裂域存在是麻烦的。\nT 3.3（代数封闭域）：$F$ 称为代数封闭的，当它满足以下（等价）条件：\n$\\forall f\\in F[x]$ 有至少一个 $F$ 内的根； $\\forall f\\in F[x]$ 所有根都在 $F$ 内； $F[x]$ 内的不可约多项式 $\\deg=1$； $F$ 无代数扩张； 存在 $F$ 的子域 $K$，满足 $F$ 是 $K$ 的代数扩张且 $K[x]$ 中的多项式都在 $F[x]$ 中分裂。 T 3.4（代数闭包）：$F$ 是 $K$ 的代数扩张且代数封闭 $\\Longleftrightarrow$ $F$ 是 $K[x]$ 内所有多项式的分裂域。这样的 $F$ 称为 $K$ 的代数闭包 $\\overline{K}$。\n这个命题的前提是，这样的 $F$ 存在。\n这里唯一要考虑的证明的东西是，$F$ 扩了之后，会不会有以 $F$ 中元素为系数的多项式，它的根不在 $F$ 内？\n答案是否定的，因为 T 1.13 说了，代数扩张的代数扩张还是代数扩张。也就是说一个系数在 $F$ 内的多项式，它的根，也是系数在 $K$ 内的多项式（可能次数会大很多）的根。这个多项式的构造是没有给出的，因为 T 1.13 的证明是从大小上来证的，我都无语了。\n还有一点是，是否存在严格包含代数闭包的，更大的代数封闭的扩张域？答案是肯定的：$\\overline{\\R(x)}$。但这个东西没法正常描述，详见 https://math.stackexchange.com/q/3005909。\n想起来其实有个非常简单的例子：$\\overline{\\Q}\\subsetneq\\C$。\n接下来证明 $F$ 存在。\nT 3.5（代数扩张的大小）：$F/K$ 代数，则 $|F|\\le\\aleph_0|K|$。\nT 3.6（代数闭包存在且唯一）：代数闭包存在，且任何两个代数闭包都是 $K$-同构的。\nP：思路是，考虑用 Zorn 引理找出所有 $K$ 的代数扩张中最大的那个，用 T 1.13 证明它代数封闭。具体一些很无聊的处理，主要在于说明 $E$ 的所有代数扩张形成一个集合（不太大）。第二句话见后。\nT 3.7（分裂域的存在性）：对于任意 $S$，$S$ 在 $K$ 上的分裂域存在。\nT 3.8（同构在分裂域下的保持）：$\\sigma:K\\to L$ 是同构，$S\\subseteq K[x]$ 在 $K$ 下的分裂域同构于 $\\sigma(S)$ 在 $L$ 下的分裂域，且同构可由 $\\sigma$ 扩展得到。\nP：如果 $|S|=1$，那么归纳地使用 T 1.8 即可。可以用 T 3.6 中的方法（对于所有同构的中间域 $(E/K,N/L,\\tau:E\\to N)$）论证无限的情况。\nT 3.9（分裂域的唯一性）：对于任意 $S$，$S$ 在 $K$ 上的分裂域在 $K$-同构意义下唯一。\nD 3.10（可分）：不可约多项式 $f\\in K[x]$ 可分，定义为，$f$ 在 $f$ 在 $K$ 上的分裂域中的根都是单重根。$u\\in F$ 可分，定义为 $u$ 的最小多项式可分。如果 $F$ 中每个元素都可分，则说 $F$ 是 $K$ 的可分扩张。\n这个定义主要是针对特征非零的域来说的。特征为零的域中，不可约多项式都是可分的，这个是因为环的 T 6.10，就是说可以根据导数来区分是否是重根。一个典型的不可约多项式不可分的例子，就在上面 T 6.10 里面那个链接。\n这边值得复习以下多项式环的一个性质：对于 $F/K$，$f,g\\in K[x]$，它们的 $\\gcd$ 在 $K[x]$ 和 $F[x]$ 上是一样的（忽略乘常数）。这个不能直接证，要先除掉 $\\gcd$，然后用裴蜀定理，或者考虑生成理想。\n下面说可分时默认不可约。\nT 3.11（可分与 Galois 的关系）：$F$ 是 $K$ 的代数 Galois 扩张 $\\Longleftrightarrow$ $F$ 是 $K$ 的可分扩张且 $F$ 是 $K[x]$ 内一些多项式的分裂域 $\\Longleftrightarrow$ $F$ 是 $K[x]$ 内一些可分多项式的分裂域。\nP：\n$F$ 是 $K$ 的代数 Galois 扩张时，任取一元素 $u$ 及其最小多项式 $f$，根据 T 2.13 的论证，$f$ 无重根……什么，忘了？就是说假设 $f$ 有不同的根 $u_1=u,u_2,\\cdots,u_r$，那么根据 Galois 扩张的性质，$\\prod(x-u_i)$ 在 $\\aut_KF$ 下只是置换各因子所以不变，所以 $\\prod(x-u_i)\\in K[x]$。因此 $f$ 就等于 $\\prod(x-u_i)$。现在就说明了可分性，剩下的都简单，取一组基即可。 $F$ 可分且 $F$ 是 $S\\subseteq K[x]$ 的分裂域，那么取 $S$ 中各多项式的各不可约因子，组成 $T$，其中每个多项式都是某个最小多项式，从而可分。 $F$ 是可分多项式集合 $T\\subset K[x]$ 的分裂域，代数是废话，只需说明 Galois。对于 $u\\in F$，根据扩张的刻画，$u\\in K(v_1,\\cdots,v_n)$ 这一有限扩张，从而 $u\\in K(f_1,\\cdots,f_n)$，其中 $f_i$ 是 $v_i$ 的最小多项式。记这个域为 $E$，如果能说明 $E$ 是 $K$ 的 Galois 扩张，根据 T 3.8，就可以说明 $u$ 不是 $\\aut_KF$ 下的不动点。\n这里 $\\lvert\\dim_KE\\rvert\u0026lt;\\infty$，考虑归纳证明 $\\lvert\\dim_KE\\rvert=[E:K]$。任取一个中间域 $K(w)$，其中 $f_1(w)=0$。这里其实意思就是 $u$ 可能是一个多步的产物（从而它不是 $T$ 中任何一个多项式的根，而是一个复杂组合之后的根），但 $w$ 好处理许多。根据 T 2.8，$[\\aut_KF:\\aut_{K(w)}F]\\le[K(w):K]=\\deg f_1$，这是通过构造 $\\aut_KF/\\aut_{K(w)}F\\to f_1$ 各根的单射证明的，与此同时由于 $f_1$ 有额外的可分性质，这个单射就可以变成双射。现在我扩了一步 $K(w)$，接下来的步骤为保证 $T$ 里面还都是不可约多项式，可能要去掉一些因子，这都简单。归纳即可。 注意到如果 $\\cha=0$，可分条件都可以去除。\n这个定理其实回答了我之前的一个疑惑，就是代数扩张中，什么时候会出现没有完全扩出一个不可约多项式的各根的情况（就是 $\\Q(\\sqrt[3]2)$ 这种）？这里给出的答案就是 Galois $\\Longleftrightarrow$ 全部扩出。\n往后看了之后发现这个话是错的，应该是 Galois $\\Longrightarrow$ 全部扩出。全部扩出 = 正规。\nT 3.12（无限 Galois 理论基本定理）：$F/K$ 代数 Galois，则中间域与闭子群一一对应，并且：\n两个中间域的相对维数，不一定等于他们对应的子群的相对指数。 中间域 $E$ 是 $K$ 的 Galois 扩张 $\\Longleftrightarrow$ $E^\\prime\\lhd K^\\prime$，这时 $K^\\prime/E^\\prime\\cong\\aut_KE$。 P：要说明中间域都是闭的，只需要用 T 3.11 中代数 Galois 的最后一个等价表述即可。Galois 和正规性的等价，也可以通过 T 2.11\u0026amp;12\u0026amp;13 说明，刚好它们只要求代数没要求有限。但是同构不能用大小来说了。回顾 T 2.14，关键在于说明 $\\aut_KE$ 里的自同构都可以扩展成 $F$ 的自同构——T 3.8 刚好说了这个是能扩展的。\n处理无穷情况的一般方法是 Krull 拓扑。\n似乎不是代数的情况也有证明：https://stacks.math.columbia.edu/tag/0BML。\nD 3.13（正规）：$F/K$ 代数。$F$ 是正规的，定义为如果不可约 $f\\in K[x]$ 有个根在 $F$ 中，那么 $f$ 在 $F[x]$ 中分裂。\nT 3.14（正规与分裂的关系）：$F$ 是 $K$ 的正规扩张 $\\Longleftrightarrow$ $F$ 是 $K$ 的分裂域 $\\Longleftrightarrow$ $\\forall$ 单同态 $\\sigma:F\\to\\overline{K}$，$\\im\\sigma=F$，于是 $\\sigma$ 总是自同构。\nP：\n如果 $F$ 是 $K$ 的正规扩张，那么取 $F$ 在 $K$ 上的一组基，这组基的最小多项式构成 $S$。 如果 $F$ 是 $K$ 的分裂域，那么扩张的根经过 $\\sigma$ 之后仍为根，并且由单同态，不会漏。所以 $\\sigma$ 维持恰好各根，从而是自同构。 如果 $F$ 是 $K$ 的分裂域，在有限扩张情况下，如果不可约的 $f\\in K[x]$ 有根 $u\\in F$ 和 $v\\notin F$，那么可以构造 $K(u)\\cong K(v)$，从而扩展到 $F\\cong F(v)$，矛盾。 如果所有单同态都是自同构，那么任何不可约的 $f\\in K[x]$，$f$ 的一根 $u\\in F$，就可以构造 $K(u)\\cong K(v)$，$v$ 是另一根。这个同构可以扩展到整个 $F$，于是由条件，$v\\in F$。 可分扩张和正规扩张互不包含：https://math.stackexchange.com/a/54566。可分且正规 = 代数 Galois。有超越 Galois 扩张，这里不考虑。\nMark：分裂域但不可分，这种情况不是 Galois，能仔细看一下结构吗？直觉上为什么不 Galois？\nT 3.15（代数 Galois、可分、正规的关系）：$F/K$ 代数。$F$ Galois $\\Longleftrightarrow$ 可分且正规；如果 $\\cha F=0$，那么 $F$ Galois $\\Longleftrightarrow$ 正规。\nT 3.16（正规闭包）：$E/K$ 代数。$\\exists F/E$，$F/K$ 正规，无中间域正规，$E/K$ 可分 $\\Longrightarrow$ $F/K$ Galois，$[F:K]\u0026lt;\\infty\\Longleftrightarrow[E:K]\u0026lt;\\infty$。这样的 $F$ 在 $E$-同构意义下唯一，称为 $E$ 在 $K$ 上的正规闭包。\nP：$F$ 的构造为：$E$ 在 $K$ 上的基的最小多项式的分裂域。最小性显然。$E/K$ 可分则扩的多项式也可分，根据 T 3.11 $F$ Galois。$[E:K]$ 有限则扩的多项式有限，$[F:K]$ 也就有限。根据分裂域唯一，$F$ 唯一。\n注意这里的正规闭包可以仅通过正规性和最小性来定义，也就是说后面两条（含箭头的）可以说是其性质。\n后面会发现，这个把 $E$ 扩到 Galois 的过程是个技巧，就是为了强制将条件推到可以用 Galois 基本定理。\n代数基本定理部分：\n假设：正数可以开平方根、奇数次多项式至少有一个根。\nT 3.17（本原元定理相关）：$F/K$ 有限可分，$K$ 无限，则 $F$ 是单扩张。\nP：我们证明的思路是，如果 $F/K(u)$、$F/K(v)$，那么可以构造单扩张 $\\cong K(u,v)$。考虑所有 $K(u+av)$，$a\\in K$。由于 $F/K$ 有限，故 $\\aut_KF$ 有限（停！如果 $F$ 不是 Galois，取正规闭包即可）。因此所有 $\\set{K(u+av)}$ 里一定有两个相同的，也就是 $u+av,u+bv\\in K(u+av)=K(u+bv)$。那么相减得 $v\\in K(u+av)$，再减得 $u\\in K(u+av)$，完事了。逐一合并即可。\n这个定理总算有点实操性了。$\\Q(\\sqrt2,\\sqrt3)=\\Q(\\sqrt2+\\sqrt3)$。证明：首先 $\\dim=4$，其次构造最小多项式 $\\prod(x\\pm\\sqrt2\\pm\\sqrt3)$。显然发现最小多项式由所有的“共轭”为根得到。那证明能不能简化为直接取 $\\prod_{\\sigma\\in\\aut_KF}(x-\\sigma(u))$ 呢？\n额……如果遇到 $\\Q(\\sqrt2,\\sqrt[3]2)$ 咋办？看到了个 https://www.zhihu.com/question/14897945340/answer/124046589131。\nMathematica 里有个 MinimalPolynomial。\nT 3.18（第一步）：$\\C$ 没有维数为 $2$ 的扩张。\nT 3.19（代数基本定理）：$\\C$ 是代数封闭的。\nP：如果 $\\C$ 有有限扩张 $E$，那么 $E$ 是可分的（因为 $\\cha\\R=0$）。从而可以取 $E$ 的有限扩张 $F$ 使 $F/\\R$ Galois（为什么要取 $\\R$ 而不直接 $\\C$ 呢？为了用第二个假设）。$F/\\R$ 的中间域与 $\\aut_\\R F$ 一一对应，所以考虑群论的手段。如果 $\\lvert\\aut_\\R F\\rvert$ 有奇质因子，那么由 Sylow 定理，有大小为 $2^{v_2(\\lvert\\aut_\\R F\\rvert)}$ 的子群从而有维数为 $\\ge3$ 奇数的中间域，与第二个假设矛盾。从而 Galois 群的大小为 $2^n$。如果 $F\\ne\\C$，那根据 Sylow 定理 $\\aut_\\C F$ 有大小一半的子群，从而对应的中间域是 $\\C$ 的维数为 $2$ 的扩张。\nT 3.20（$\\C$ 的唯一性）：$\\R$ 的代数扩张唯一。\nP：考虑 $F/\\R$。找到扩张用的多项式，可得 $F/\\C$，再用 T 3.19。\n这里难道不能直接利用 T 3.6 代数闭包的唯一性吗？既然考虑 $\\R$ 的代数扩张，就一定 $\\subseteq\\C$，然后 $2$ 是质数就行了啊？\n这里作为对照，写一下常规分析方法证明代数基本定理的思路：主要是通过分析多项式的 dominant 项来控制大小。首先证明存在最小值，然后证明如果最小值不是 $0$，一定存在一个方向，走一个微小量后会变小，从而矛盾。\n4. 多项式的 Galois 群 以下默认 $u_i$ 为根。\nD 4.1（多项式的 Galois 群）：$f\\in K[x]$ 的 Galois 群为 $\\aut_KF$，其中 $F$ 是 $f$ 在 $K$ 上的分裂域。\n分裂域在同构意义下唯一，因此 Galois 群唯一。\n我们知道 $F$ 不一定是 Galois 扩张。在 $\\cha\\ne 0$ 的情况下，有可能会出现不可分的分裂域，就是 T 6.10 那边。\nT 4.2（Galois 群与对称群的关系）：$f$ 的 Galois 群 $G$ 是某个 $S_n$ 的子群。如果 $f$ 可分，那么 $\\deg f\\mid |G|$ 且 $G$ 是 $S_{\\deg f}$ 的一个具有传递性（大概是说每个根都可以置换成另一个根）的子群。\nP：是 $S_n$ 的子群，只需证明单射。当 $f$ 可分时，$F$ 是 Galois 扩张，而且 $f$ 是不可约的从而由 T 1.6 等，有一个中间域扩了一个根，维数为 $\\deg f$，由 T 2.5 就有一个大小为 $n$ 的子群。传递性由 T 1.9。\n再一次，$|G|$ 往往不会是 $n!$，例如 https://math.stackexchange.com/a/191056。\n这里 $f$ 可以有两种性质，一个是不可约（有机会作为“基本情况”处理），一个是可分（Galois）。实际上在后续的一些定理中，可约但可分（$f$ 是若干不可约可分多项式的乘积）的情况也是允许的（根据上面的定理也是 Galois 扩张），不过这种技术性的条件不太重要，再说了可约就归为更低次的情况了，所以我不太想关心。\nT 4.3（二次的 Galois 群）：对于二次多项式 $f$，如果 $f$ 可分（$\\cha K\\ne 2$ 时必然可分）则 $G\\cong\\Z_2$ 否则 $G=1$。\nD 4.4（判别式）：对于特征不为 $2$ 的域 $K$ 及可分多项式 $f\\in K[x]$，设它的根为 $u_1,\\cdots,u_n\\in F$，定义 $\\Delta=\\prod_{i\u0026lt;j}(u_i-u_j)$，判别式 $D=\\Delta^2$。\nT 4.5（判别式的性质）：（4.4 的条件）$D\\in K$。$\\sigma\\in G\\subseteq S_n$，$\\sigma(\\Delta)=\\pm\\Delta$ 且为 $+\\Delta$ 当且仅当 $\\sigma$ 是偶置换。\n这些证明都是靠置换的基本性质，就不写了。对于 $\\cha=2$ 的情况，$\\Delta=-\\Delta$，所以啥都没有。详见 https://math.stackexchange.com/q/90765、https://mathoverflow.net/q/10400。\nT 4.6（判别式的扩张）：（4.4 的条件）之前说了 $G\\subseteq S_n$。中间域 $K(\\Delta)$ 对应着 Galois 群的子群 $G\\cap A_n$。特别地，$G$ 全由偶置换组成 $\\Longleftrightarrow$ $\\Delta\\in K$。\nT 4.7（三次的 Galois 群）：对于可分三次多项式 $f$，$G=S_3$ 或 $A_3$。如果 $\\cha K\\ne 2$，$G=A_3$ $\\Longleftrightarrow$ $D=$ 某个 $K$ 中元素的平方。\nP：$S_3$ 的子群有 $1$、$S_2$、$A_3$ 这三类，然后大小得是 $3$ 的倍数。\n一般我们都会考虑 $\\Q$ 上。$\\R$ 上因为介值定理，从定性角度就没什么可说的了。\nEx 2（实系数三次方程实根数与判别式的关系）：$D\\ne 0$ 时，$D\u0026gt;0$ $\\Longleftrightarrow$ 有三个实根。\nP：（这里不要求 $f$ 不可约）如果 $D\u0026lt;0$，那么我们知道 $f$ 的分裂域中有虚数，从而必有复根，而复根成对。如果 $D\u0026gt;0$，那么由于 $G$ 的元素必须以 $D$ 为不动点，故 $|G|=1$ 或 $3$，这两种情况都不能是从 $\\R$ 扩到 $\\C$。\n这玩意应该有个求导的证法。\n事实上我们可以证明，对于 $\\Q$，取任一根 $\\alpha$，分裂域为 $\\Q(\\alpha,\\Delta)$。https://planetmath.org/galoisgroupofacubicpolynomial。\n现在我们可以用判别式决定 $f$ 的 Galois 群是哪一种。如果是 $S_3$，则：\n（4.4 的条件）由于 $S_3$ 的真子群包括 $A_3$、$\\langle(12)\\rangle$、$\\langle(13)\\rangle$、$\\langle(23)\\rangle$，故中间域也有四个，即 $K(\\Delta)$、$K(u_3)$、$K(u_2)$、$K(u_1)$。\n下面的定理告诉我们如何不求根就得到判别式：\nT 4.8（用系数表示判别式）$\\cha K\\ne 2,3$。可以通过换元去掉二次项，$x^3+px+q$ 的判别式为 $D=-4p^3-27q^2$。\nP：神秘代数变换 https://math.stackexchange.com/a/3596977。\n现考虑可分的四次多项式 $f$。令 $V=\\set{\\iota,(12)(34),(13)(24),(14)(23)}\\cong K_4\\lhd S_4$。\nT 4.9（解式）：令 $\\alpha=u_1u_2+u_3u_4$，$\\beta=u_1u_3+u_2u_4$，$\\gamma=u_1u_4+u_2u_3$。$K(\\alpha,\\beta,\\gamma)$ 对应的 Galois 群子群为 $V\\cap G$，于是 $\\aut_KK(\\alpha,\\beta,\\gamma)\\cong G/(G\\cap V)$。\nP：只需证明这三个东西的稳定化子恰好为 $V$ 即可。注意这三个东西互不相等。\n称 $(x-\\alpha)(x-\\beta)(x-\\gamma)$ 为 $f$ 的解式。\n注意到没有任何一个根属于 $K(\\alpha,\\beta,\\gamma)$，因为 $4\\mid|K(u_i)|$，但是 $[K(\\alpha,\\beta,\\gamma):K]\\mid 6$。\n实际上三次多项式也有解式：$x^2-D$。解式是拉格朗日的成果，相当于是解 $\\le$ 四次方程的中间步骤。详见 https://zhuanlan.zhihu.com/p/582315546。伽罗瓦是在其理论中系统性地用了解式。\n我猜，要引入这个神秘的东西，是不是因为四次方程的判别式没法用多项式系数表示出来了？\nT 4.10（用系数表示解式）：对于 $f=x^4+bx^3+cx^2+dx+e$，解式为 $x^3-cx^2+(bd-4e)x-b^2e+4ce-d^2\\in K[x]$。\n$S_4$ 的大小为 $4$ 倍数的、具有传递性的子群可分为以下几类：$S_4$、$A_4$、$K_4$、$\\Z_4$、$D_4$。\nT 4.11（四次的 Galois 群）：对于可分多项式 $f$，令 $m=[K(\\alpha,\\beta,\\gamma):K]$。那么：\n$m=6$ 时，$G=S_4$。 $m=3$ 时，$G=A_4$。 $m=1$ 时，$G=V$。 $m=2$ 时，如果 $f$ 在 $K(\\alpha,\\beta,\\gamma)$ 上不可约，则 $G\\cong D_4$，否则 $G\\cong\\Z_4$。 这里 $\\cong$ 隐含的意思是 $S_4$ 有多个这个结构的子群。\nP：首先 $m\\mid 6$，而且 $m=|G|/|G\\cap V|$。分析不同子群与 $V$ 的交即可得到各情况。对于最后一种情况，如果 $G\\cong D_4$，由于 $D_4$ 的结构为 $\\set{(1234),(13)}$ 这类（想象正方形沿对角线翻转），因此 $G\\cap V=V$，这就意味着 $u_1\\sim u_4$ 中的每一对可以在 $K(\\alpha,\\beta,\\gamma)$ 扩域上互换，从而由 T 1.9 的反方向，$u_1\\sim u_4$ 是同一个不可约多项式的根，也就是 $f$ 不可约。如果 $G\\cong\\Z_4$，那么 $G\\cap V\\cong\\Z_2$，比如说 $G\\cap V=\\langle(12)(34)\\rangle$，那么 $u_1$ 和 $u_3$ 不能是同一个不可约多项式的根，因为不然的话就可以构造一个自同构属于 $\\aut_{K(\\alpha,\\beta,\\gamma)}F\\cong G\\cap V$，矛盾，从而 $(x-u_1)(x-u_2),(x-u_3)(x-u_4)\\in K(\\alpha,\\beta,\\gamma)$。\nEx：\n$f\\in\\Q[x]$ $G$ $x^4+4x^2+2$ $\\Z_4$ $x^4-10x^2+4$ $V$ $x^4-2$ $D_4$ $x^4-5x^2+6$（可约） $\\Z_2^2$ T 4.12（高次的特殊情况）：对于不可约的，度数为质数的 $f\\in\\Q[x]$，如果 $f$ 有恰好一对复根，那么 $G\\cong S_n$。\nP：$p\\mid|G|$ 保证了存在一个 $p$ 环，复根保证存在一个对换，然后问题就变成证明 $S_n\\cong\\langle(12\\cdots n),(12)\\rangle$。\n5. 有限域 T 5.1（素子域）：令 $P$ 为域 $F$ 的所有子域的交。若 $\\cha F=p\\in\\P$，则 $P\\cong\\Z_p$；若 $\\cha F=0$，则 $P\\cong\\Q$。\n$P$ 称为 $F$ 的素子域，直接记作 $\\Z_p\\subset F$。\nP：直接证就行了。为了说明 $\\cha F=p$ 是 $\\set{m1_F}$ 是个子域，直接用质数的性质即可。\n注意 $1$ 不是个域。\nT 5.2（有限域的加法部分结构）：若 $|F|\u0026lt;\\infty$，则 $\\cha F=p\\ne 0$，$p\\in\\P$，且 $|F|=p^n$。\nP：如果 $\\cha F$ 不是质数，则 $F$ 就不是整环，爆了。现在 $F$ 是有限维 $\\Z_p$-模，因此由模论的 2.4，$F\\cong\\Z_p^n$。\nT 5.3（有限域的乘法部分结构）：有限域的非零部分乘法群为循环群。\nP：设乘法群为阿贝尔群 $G$，则由有限阿贝尔群分类，$G\\cong\\Z_{m_1}\\oplus\\cdots\\oplus\\Z_{m_k}$，$m_1\\mid\\cdots\\mid m_k$。也就是说每个元素都是 $x^{m_k}=1$ 的根。由于这个式子只有至多 $m_k$ 个根，故 $G\\cong\\Z_{m_k}$。\nT 5.4（有限域的扩张描述）：$F$ 是其素子域的单扩张。\nT 5.5（根对加法封闭）：对于 $\\cha F=p$，$\\varphi:u\\mapsto u^{p^r}$ 是一个 $F$ 上的 $\\Z_p$-单自同态。如果 $|F|\u0026lt;\\infty$，则为 $\\Z_p$-自同构，$u\\mapsto u^p$ 称为 Frobenius 自同构。\nP：$(u+v)^{p^r}=u^{p^r}+v^{p^r}$。\nT 5.6\u0026amp;7（质数幂有限域分类）：对于 $p\\in\\P$，有限域 $F$，$|F|=p^n$ $\\Longleftrightarrow$ $F$ 是 $x^{p^n}-x$ 在 $\\Z_p$ 上的分裂域。从而大小为 $p^n$ 的有限域存在且唯一。\nP：$\\Longrightarrow$：根据上面的讨论，$F\\setminus\\set{0}$ 恰为 $x^{p^n-1}=1$ 的各根，加进 $0$ 就是 $x^{p^n}=x$ 的各根。\n$\\Longleftarrow$：$\\cha F=p$。先求导说明 $x^{p^n}-x$ 无重根，然后只需证明 $F$ 里没有其他元素——利用 T 5.5 说明 $x^{p^n}-x$ 的各根均为 $\\varphi$ 下的不动点，从而构成一个域，也就是无需有其他元素。\n这里是我第一次对分裂域在直觉上出现迷惑。就会有一种感觉：你说了一个域，向其中加入一个多项式的所有根，然后就宣称它在同构意义下唯一确定，如果不是已知分裂域（比如 $\\C/\\R$），那这些根其实都是一个“形式”，那这些根的运算表凭什么存在且唯一？\n其实这里的迷惑主要是由于 $x^{p^n}-x$ 可约导致的。它的各根的运算表确实不明朗，但是如果找到一个扩张效果相同的最小多项式，那就可以套用 T 1.6 了。这个后面会讲，先不急。还有一点就是由于是特征非零的域，所以不能简单得从单位元上的 $p^n$ 单位根来类比理解有限域，这个会比较难受。\nT 5.8\u0026amp;9（有限域的有限扩张存在）：对于有限域 $K$，正整数 $n$，存在唯一的单扩张 $F=K(u)$ 使 $[F:K]=n$。从而 $K[x]$ 中有 $\\deg=n$ 的不可约多项式。\nP：直接用多项式 $x^{p^{rn}}-x$ 的根构造即可。下放 $K$ 到 $\\Z_p$ 以方便证明。\nT 5.10（有限域的有限扩张 Galois）：对于有限域 $K$ 的有限维扩张 $F$，$F$ 是 Galois 的，$\\aut_KF$ 是循环群。\nP：同样下放到 $\\Z_p$。由于 $F$ 是可分的分裂域，故 Galois。由于 T 5.5 已经构造出足够多的自同构，故 $\\aut_{\\Z_p}F\\cong\\Z_{\\log_p|F|}$。\n6. 可分性 D 6.1（纯不可分）：$F/K$，如果 $u\\in F\\setminus K$ 在 $K$ 上的最小多项式，在 $F$ 中可以写成 $(x-u)^m$ 的形式，则 $u$ 称为纯不可分元。如果 $F\\setminus K$ 中所有元素都如此则 $F$ 称为纯不可分扩张。\n所以纯不可分元至少得是代数元。另外还有个等价定义是 $\\exists n$，$u^{p^n}\\in K$。这个后面会看到。\n经典的纯不可分例子还是那个 $\\F_p(t)$ 上 $x^p-t$ 的根。不可分且不纯不可分的例子：https://math.stackexchange.com/a/1276333。\nT 6.2：$u$ 同时是可分元、纯不可分元 $\\Longrightarrow$ $u\\in K$。\n然而 $\\cha=0$ 的域中代数元均为可分元，因此纯不可分元在 $\\cha\\ne 0$ 时讨论才是非平凡的。\nT 6.3（次幂总能可分）：$\\cha K=p$，则代数元 $u$ 总能在某个 $u^{p^n}$ 成为可分的。\nP：考虑 $u$ 的最小多项式 $f$。如果 $f^\\prime\\ne 0$，则由于 $f$ 不可约，$\\gcd(f,f^\\prime)=1$，于是 $u$ 就是可分的；如果 $f^\\prime=0$，则 $f(x)=g(x^p)$，归纳（$\\deg$ 降）考虑 $u^p$。\nT 6.4（纯不可分的等价条件）：$F/K$ 是代数扩张。这是纯不可分扩张 $\\iff$ 每个 $F$ 中的元素的最小多项式都形如 $x^{p^n}-a\\in K$ $\\iff$ 若 $u\\in F$ 则 $u^{p^n}\\in K$ $\\iff$ $F\\setminus K$ 均不可分 $\\iff$ $F$ 由一些纯不可分元在 $K$ 上生成。（这里的 $n$ 都是“某个”）\nP：\n$1\\Rightarrow 2$: 对于 $u$，设它最小多项式为 $(x-u)^m$，其中 $m=p^rn$，$(x-u)^m=(x^{p^r}-u^{p^r})^n\\in K[x]$，因此 $x^{(n-1)p^r}$ 项的系数 $-nu^{p^r}\\in K$。然而 $n\\perp p$，故 $u^{p^r}\\in K$。为了使 $(x-u)^m$ 不可约，必须有 $n=1$，最小多项式为 $x^{p^r}-u^{p^r}$。 $3\\Rightarrow 1$：可以构造出关于 $u$ 的一个零化多项式，而最小多项式整除它。 $1\\Rightarrow 4$：T 6.2 $4\\Rightarrow 3$：T 6.3 $5\\Rightarrow 3$：如果一个元素由纯不可分元（通过四则运算）生成，则找到最大的那个 $n$，整体 $p^n$ 次幂，然后用 T 5.5。 $2\\Rightarrow 3$、$1\\Rightarrow 5$：显然 T 6.5：如果 $F/K$ 是有限维纯不可分扩张，则 $[F:K]=p^n$。\nT 6.6：可分元生成的扩张是可分的。\nP：考虑由可分元 $u_1,\\cdots,u_n$ 生成的元素 $v\\in K(u_1,\\cdots,u_n)$。取各自的最小多项式 $f_1,\\cdots,f_n$ 并得到分裂域 $E/K(u_1,\\cdots,u_n)/K$（可以理解为类似一个 Galois 闭包的操作）。由于是可分多项式的分裂域，故是可分的（T 3.11）。\nT 6.7（可分扩张核心定理）：$F/K$ 代数。令 $S$ 为 $F$ 中所有可分元的集合，$P$ 是所有纯不可分元的集合。则：\n$S$ 是可分扩张。 $F/S$ 纯不可分。 $P$ 是纯不可分扩张。 $P\\cap S=K$。 $F/P$ 可分 $\\iff$ $F=SP$。 如果 $F/K$ 正规，则 $S/K$ Galois，$F/P$ Galois 且 $\\aut_KS\\cong\\aut_PF=\\aut_KF$。 注意对于 $\\cha=0$ 的情况，$S=F$，$P=K$。\nP：\n只需证封闭性。 $\\forall u\\in F$，$u$ 的某个 $p^n$ 次幂就可分，于是 $\\in S$，这符合 T 6.4 的第三个命题，于是 $F/S$ 纯不可分。 只需证封闭性，用纯不可分的等价定义。 T 6.2 有一个扩张链 $F/SP/P$。如果 $F/P$ 可分，则 $F/SP$ 也可分，同时 $F/S$ 纯不可分，因此 $F/SP$ 纯不可分，于是 T 6.2 说明 $F=SP$。另一方面如果 $F=SP=P(S)$，就说明 $F$ 是在 $P$ 的基础上加入一些可分元得到的，所以 $F/P$ 可分。 首先 $\\aut_KF$ 的自同构将 $u$ 打到 $u$ 的最小多项式的某根，于是 $P$ 不动。对于 $P$ 以外的元素，由于 $F/K$ 正规，故一定有根 $v\\ne u$，且 $K(u)\\cong K(v)$ 可以扩展到 $F$ 上所以必然在 $\\aut_KF$ 下会动。因此 $\\aut_KF=\\aut_PF$ 且 $F/P$ Galois。$\\aut_KS$ 和 $\\aut_PF$ 的同构直接通过将 $\\sigma\\in\\aut_PF$ 限制在 $S$ 上即可得到，由于自同构保持元素可分性故这么搞合法。一方面，$F/P$ Galois $\\implies$ $F/P$ 可分 $\\implies$ $F=SP$，于是 $F=SP$，故 $\\sigma$ 由它在 $S$ 上的作用决定，因此 $\\aut_PF\\to\\aut_KS$ 是单同态；另一方面，$F/K$ 正规说明 $F/K$ 是分裂域，从而 $F/S$ 是分裂域，而同构（自同构）在分裂域下保持，故每个 $\\sigma\\in\\aut_KS$ 都可以扩展到 $\\aut_PF$，所以 $\\aut_PF\\to\\aut_KS$ 是满同态。如果 $u\\in S$ 是 $\\aut_KS$ 的不动点，它也是 $\\aut_PF$ 的不动点，因此 $u\\in P\\implies u\\in K$。 T 6.8（可分扩张的传递性）：$F/E/K$ 分别可分，则 $F/K$ 可分。\nP：令 $S$ 为 $F$ 中所有在 $K$ 上的可分元的集合，则 $E\\subseteq S\\subseteq F$ 且 $F/S$ 纯不可分。但是 $F/E$ 可分故 $F/S$ 可分，因此 $F=S$。\n现在定义 $F^n=\\set{u^n\\mid u\\in F}$。\nT 6.9（可分的等价条件）：如果 $F/K$ 可分，则 $F=KF^{p^{\\forall n\\ge 1}}$；反之如果 $[F:K]\u0026lt;\\infty$ 且 $F=KF^p$，则 $F/K$ 可分。因此 $u\\in F$ 在 $K$ 上可分的一个等价说法是 $K(u^p)=K(u)$。\nP：如果 $F/K$ 可分，则 $F/(KF^{p^{\\forall n\\ge 1}})$ 可分，同时 $F/F^{p^{\\forall n\\ge 1}}$ 纯不可分（T 6.4 的 3）故 $F/(KF^{p^{\\forall n\\ge 1}})$ 纯不可分，因此 $F=KF^{p^{\\forall n\\ge 1}}$；如果 $[F:K]\u0026lt;\\infty$，则 $F=K(u_1,\\cdots,u_m)$。取可分元子域 $S$，那么存在某个 $n$ 使 $u_i^{p^n}$ 皆属于 $S$，这就说明 $F^{p^n}$ 是 $S$ 的子域，同时 $S$ 在 $F^{p^n}$ 上纯不可分，因此 $S/(KF^{p^n})$ 不可分。但 $S/K$ 可分故 $S/(KF^{p^n})$ 可分，故 $S=KF^{p^n}$，同时根据条件，$F=KF^p=K(KF^p)^p=KK^pF^{p^2}=KF^{p^2}=\\cdots=KF^{p^n}=S$，故 $F/K=S/K$ 可分。\n注意最后的等式展开只是一个符号形式，可以严格验证对于两个子域 $K_1,K_2$ 有 $K_1^pK_2^p=(K_1K_2)^p$。\n另外容易发现一个常用的 argument：$F/K_1$，$F/K_2$，$F$ 关于其中一个可分，另一个纯不可分，则 $F=K_1K_2$。\nD 6.10（可分度\u0026amp;不可分度）：对于代数扩张 $F/K$ 同样定义 $S$，可分度定义为 $[F:K]_s=[S:K]$，不可分度定义为 $[F:K]_i=[F:S]$。\nP：显然 $[F:K]_i=1\\iff$ 可分扩张，$[F:K]_s=1\\iff$ 纯不可分扩张，$[F:K]=[F:K]_s[F:K]_i$。另外由于 $F/S$ 是纯不可分扩张，故 $[F:K]_i$ 是 $p$ 的幂次。\n接下来的部分就不看证明了，简单过一下。\nT 6.11：$N/F/E/K$，其中 $N/K$ 正规。$F\\to N$ 的 $K$-单同态（使 $K$ 不同的域单同态）数量 $=$ $F\\to N$ 的 $E$-单同态数量 $\\times$ $E\\to N$ 的 $K$-单同态数量。\nT 6.12：$N/F/K$，其中 $F/K$ 有限维，$N/K$ 正规。$F\\to N$ 的 $K$-单同态数量 $=[F:K]_s$。\nT 6.13：$F/E/K$，$[F:E]_s[E:K]_s=[F:K]_s$，$[F:E]_i[E:K]_i=[F:K]_i$。\nT 6.14（不可约多项式的分解刻画）：$f$ 是 $K$ 上的不可约首一多项式。令 $F$ 为 $f$ 在 $K$ 上的分裂域，$u_1\\in F$ 为 $f$ 的一根。则 $f$ 形如 $((x-u_1)\\cdots(x-u_n))^{[K(u_1):K]_i}$。明显 $n=[K(u_1):K]_s$。同时 $u_1^{[K(u_1):K]_i}$ 在 $K$ 上可分。\nT 6.15（本原元定理）：$F/K$ 有限维。如果 $F/K$ 可分则 $F/K$ 是单扩张。更一般地，$F/K$ 是单扩张 $\\iff$ 只有有限个中间域。\nP：有限维可分扩张一定只有有限个中间域（T 3.17）。T 5.8 说明了 $|K|\u0026lt;\\infty$ 的情况。$\\impliedby$ T 3.17 已证；$\\implies$：如果 $F=K(u)$，考虑中间域 $E$，$E$ 中 $u$ 的最小多项式设为 $x^n+\\cdots+a_0$。我们可以说明 $E=K(a_0,\\cdots,a_{n-1})$，从而 $E$ 由最小多项式确定，而最小多项式必然整除 $u$ 在 $K$ 中的最小多项式，从而只有有限个。显然 $E\\supseteq K(a_0,\\cdots,a_{n-1})$，其次由于 $u$ 在 $K(a_0,\\cdots,a_{n-1})$ 中的最小多项式和在 $E$ 中的相同，故二者相等。\n有限维扩张可能有无限个中间域：https://www.mathcounterexamples.net/a-finite-extension-that-contains-infinitely-many-subfields/。\n单扩张的可分度和不可分度可能同时 $\u0026gt;1$，例如 $\\F_p(t)$ 上最小多项式为 $x^{2p}-t$ 的单扩张。这个不可约多项式可以写成 $(x-\\sqrt[p]{\\sqrt t})^p(x-\\sqrt[p]{-\\sqrt t})^p$，于是可分度为 $2$，不可分度为 $p$。\n7. 循环扩张 D 7.1（模与迹）：$\\overline{K}/F/K$，$F/K$ 有限维。令 $\\sigma_{1\\sim r}$ 为所有 $F\\to\\overline{K}$ 的 $K$-单同态。定义 $u\\in F$ 的模为 $N_K^F(u)=\\prod\\sigma_i(u)^{[F:K]_i}$，迹为 $T_K^F(u)=[F:K]_i\\sum\\sigma_i(u)$。\n根据 T 6.12，$r=[F:K]_s$。\n如果 $F/K$ 不可分，则迹为 $0$。\n突然想到代数闭包可能不是 Galois 吗（也就是不是可分的）？答案是肯定的：https://math.stackexchange.com/a/158643。\nT 7.2（Galois 扩张下的情况）：如果额外地 $F/K$ Galois，设 $\\aut_KF=\\set{\\sigma_i}$，则 $N_K^F(u)=\\prod\\sigma_i(u)$，$T_K^F(u)=\\sum\\sigma_i(u)$。\nP：T 3.14 说，Galois 扩张的情况下 $F\\to\\overline{K}$ 的 $K$-单同态就是 $K$-自同构。\n在这种情况下，每个 $\\sigma_i$ 都使得 $N_K^F(u)$、$T_K^F(u)$ 不动（因为 $\\sigma_i\\aut_KF=\\aut_KF$），所以两者都 $\\in K$。\nT 7.3：（现在不要求 Galois 了，然后前三条简写 $N$ 和 $T$）\n$N(u)N(v)=N(uv)$，$T(u)+T(v)=T(u+v)$。 若 $u\\in K$ 则 $N(u)=u^{[F:K]}$ 且 $T(u)=[F:K]u$。 $N(u),T(u)\\in K$。如果 $u$ 的最小多项式为 $x^n+a_{n-1}x^{n-1}+\\cdots+a_0$，则 $N(u)=((-1)^na_0)^{[F:K(u)]}$，$T(u)=-[F:K(u)]a_{n-1}$。 对于 $F/E/K$，$N_K^E(N_E^F(u))=N_K^F(u)$，$T_K^E(T_E^F(u))=T_K^F(u)$。 P：对于 3，我们现在有个扩张链 $\\overline{K}/F/K(u)/K$。所有 $F\\to\\overline{K}$ 的 $K$-单同态，根据 T 6.11（上面略了，可以意会一下，就是分两层）可以刻画为：$F\\to\\overline{K}$ 的 $K(u)$-单同态，与 $K(u)\\to\\overline{K}$ 的 $K$-单同态的复合，后者是可以唯一扩展到 $\\overline{K}\\to\\overline{K}$ 的。记前者为 $\\tau_{1\\sim r}$，后者为 $\\sigma_{1\\sim t}$（$rt=n=\\deg f$）。现在 $$ N(u)=\\prod \\sigma_i\\tau_j(u)^{[F:K]_i}=\\prod\\sigma_i(u)^{r[F:K]_i}=\\prod\\sigma_i(u)^{[F:K(u)][K(u):K]_i} $$ 最后一步是根据 T 6.12，$r=[F:K(u)]_s$。同理 $T(u)=[F:K(u)][K(u):K]_i\\sum\\sigma_i(u)$。$\\sigma_i$ 根据定义恰好将 $u$ 打到各个根上，因此根据韦达定理（$u$ 的最小多项式也可以写作 $\\prod(x-\\sigma_i(u))^{[K(u):K]_i}$）：\n$\\prod\\sigma_i(u)^{[K(u):K]_i}=(-1)^{rt}a_0$，$[K(u):K]_i\\sum\\sigma_i(u)=-a_{n-1}$。代入 $N(u)$ 和 $T(u)$ 的定义即可。\n对于 4，直接展开即可，证明和第一段几乎一样。\n这个定理的 3 说明了，$N$ 和 $T$ 的定义不依赖于 $\\overline{K}$（在同构意义下）的选取；进一步地，定义中的 $\\overline{K}$ 可以换成任何包含 $F$ 的 $K$ 的正规扩张（注意到代数闭包必然是正规的）。\n这个证明的主要思路就是，把自同构拆分为和 $u$ 有关（真正置换各个根）的与和 $u$ 无关的（这部分只导致一个幂次）。进一步地，跟 $u$ 有关的又可以拆为可分（对应韦达定理）的和纯不可分的（同样贡献一个幂次）。\nD 7.4 \u0026amp; T 7.5：$S\\subseteq\\aut F$ 称为线性无关，当且仅当 $\\not\\exists\\set{a_i\\in F}$ 非全零，使 $\\sum a_i\\sigma_i=$ 零映射。任何 $S$ 都是线性无关的。\n这个证明上课讲过，感觉跟 T 2.9 的有点像。\n下面的定理用于后文构造最小多项式。\n$F/K$ 是循环的，定义为 $F/K$ 代数 Galois 且 $\\aut_KF$ 是循环群。同样定义阿贝尔扩张。$\\aut_KF\\cong\\Z_n$ 时，称 $F$ 是 $K$ 的度为 $n$ 的扩张。\nT 7.6（循环扩张下的模与迹的性质）：对于度数为 $n$ 的循环扩张 $F/K$，设 $\\aut_KF=\\langle\\sigma\\rangle$。则 $T(u)=0\\iff u=v-\\sigma(v)$ 对于某个 $v\\in F$。（希尔伯特第 90 定理）$N(u)=1\\iff u=v\\sigma(v)^{-1}$ 对于某个 $v\\in F$。\n首先 $\\impliedby$ 很容易直接验证。$\\implies$ 是一个神秘构造：首先由于 $\\aut_KF$ 线性无关，故 $\\exists z$，$T(z)=(1+\\sigma+\\cdots+\\sigma^{n-1})(z)\\ne 0$。取 $w=T(z)^{-1}z$ 就得到 $T(w)=1$。构造 $$ v=\\sum_{i=0}^{n-2}\\left(\\sum_{j=0}^{i}\\sigma^j(u)\\right)\\sigma^{i}(w) $$ 计算 $v-\\sigma(v)$ 时发现错位抵消，最后一项由于 $T(u)=0$ 也变成 $u\\sigma^{n-1}(w)$，然后再代入 $T(w)=1$。\n同理由于线性无关性，映射 $$ f=\\sum_{i=0}^{n-1}\\left(\\prod_{j=0}^i\\sigma^j(u)\\right)\\sigma^i $$ 对于某个 $y$ 非零，令 $v=f(y)$，容易验证 $u=v\\sigma(v)^{-1}$。\n对于 $\\Q(i)$ 的情况，这个定理给出了勾股对的构造。\nT 7.7（循环扩张的分解）：如果 $F/K$ 是度为 $n=mp^t$ 的循环扩张（其中 $p=\\cha K$，$p\\nmid m$），那么扩张可以拆成多次循环扩张 $F/E_0/\\cdots/E_{t-1}/E_t=K$，其中 $F/E_0$ 度为 $m$，$E_i/E_{i+1}$ 度为 $p$。\nP：由于是循环扩张，Galois 群的每个子群都是正规的，这就很好——任何 $F/M/L/K$，都有 $M/L$ 也是循环扩张。因此直接在 $\\Z_n$ 里找子群 $\\Z_m$，商掉，然后反复找 $\\Z_p$ 商掉即可。\n这个定理就简化了讨论。对于循环扩张，我们只需要关心 $\\cha K=0$、$\\cha K\\nmid n$、$\\cha K=n$ 三种基本情况即可。\n对于 $\\cha K=n$ 的情况，不存在 $1$ 以外的 $p$ 次单位根，因为 $x^p-1$ 不可分，所以需要特殊讨论。其余情况就从单位根角度来考虑。\nT 7.8（$\\cha K=n$ 情况的刻画，Artin-Schreier）：$F/K$ 是度为 $\\cha K=p$ 的循环扩张 $\\iff$ $F$ 为不可约多项式 $x^p-x-a\\in K[x]$ 在 $K$ 上的分裂域，且这时 $F=K(u)$，$u$ 为多项式的任一根。\nP：$\\implies$：设 $\\aut_KF=\\langle\\sigma\\rangle$。注意到 $T(1)=p1=0$，因此 $1=v-\\sigma(v)$ 对于某个 $v\\in F$。取 $u=-v$ 则 $\\sigma(u)=1+u$ 故 $u\\notin K$。$\\sigma(u^p)=1+u^p$ 故 $\\sigma(u^p-u)=u^p-u$ 故 $u^p-u\\in K$ 可以设为 $a$。这就说明了 $u$ 的最小多项式为 $x^p-x-a$（因为 $p$ 是质数，这个多项式不会是可约的）。为了说明别的根都可以被 $u$ 生成，考虑到 $\\forall i\\in\\Z_p$，由于 $i^p=i$，故 $(u+i)^p-(u+i)-a=u^p+i^p-u-i-a=u^p-u-a=0$，从而所有根恰好就是 $u\\sim u+p-1$。\n$\\impliedby$：我们先不假设 $x^p-x-a$ 不可约。考虑一根 $u$，我们知道 $u+1\\sim u+p-1$ 也是根且没有别的根，于是 $F=K(u)$ 且 $x^p-x-a$ 的不可约因子都可分，我们知道 Galois 等价于可分分裂，因此 $F/K$ Galois。现在 $\\aut_KF$ 的元素完全由 $u\\mapsto{}?$ 决定。由两种可能，一种是 $\\aut_KF=\\set{\\id}$，另一种是 $\\aut_KF=\\set{u\\mapsto u+i\\mid i\\in\\Z_p}$，后者当且仅当 $x^p-x-a$ 不可约。\nT 7.9：$x^p-x-a\\in K[x]$ 在 $K$ 上要么分裂要么不可约。\n作业 13.5.5 就是说，对于 $K=\\F_p$ 的情况，必然不可约。\n为处理 $\\cha K\\nmid n$ 或 $\\cha K=0$ 的情况，需要引入单位根。定义 $K$ 中的 $n$ 次单位根为 $x^n-1$ 的根，它们的乘法群显然形成 $\\Z_n$ 的子群，且如果恰好是 $\\Z_n$ 则称生成元为 $n$ 次本原单位根。\nT 7.10：若 $K$ 包含 $n$ 次本原单位根 $\\zeta$，则：如果 $d\\mid n$，则 $\\zeta^{n/d}$ 是 $d$ 次本原单位根；如果 $u$ 是 $x^d-a\\in K[x]$ 的根，则 $x^d-a$ 有根 $\\zeta^{kn/d}u$，$k=0\\sim d-1$，同时 $K(u)$ 是 $x^d-a$ 在 $K$ 上的分裂域，且是 Galois 的。\nT 7.11（Kummer）：对于包含 $n$ 次本原单位根的域 $K$，其扩域 $F/K$ 是度为 $d\\mid n$ 的循环扩张 $\\iff$ $F$ 是 $x^n-a$ 在 $K$ 上的分裂域 $\\iff$ $F$ 是 $x^d-b$（$d\\mid n$）在 $K$ 上的分裂域。\nP：\n$2\\Rightarrow 1$：根据 T 7.10 有 $F=K(u)$ 且是 Galois 扩张，$K$-自同构一定形如 $u\\mapsto\\zeta^ku$ 就好了。 $1\\Rightarrow 3$：设 $\\aut_KF=\\langle\\sigma\\rangle$。由于 $N(\\zeta^{n/d})=\\zeta^n=1$，故 $\\zeta^{n/d}=w\\sigma(w)^{-1}$ 对于某个 $w\\in F$。取 $v=w^{-1}$ 则 $\\sigma(v)=\\zeta^{n/d}v$ 故 $v\\notin K$。$\\sigma(v^d)=v^d$ 故 $v^d\\in K$ 可以设为 $b$。所以 $v$ 的最小多项式整除 $x^d-b$，并且 $\\zeta^{kn/d}v$ 都是这个的根，故 $v$ 的最小多项式就是 $x^d-b$，$F$ 是 $x^d-b$ 的分裂域。 $3\\Rightarrow 2$：$F$ 是 $x^n-b^{n/d}$ 的分裂域。 T 7.11 蕴含课上讲到的一对定理，更容易理解：\n含所有 $n$ 次（$p\\nmid n$）单位根的域的扩张，是 $n$ 度循环扩张 $\\iff$ 是 $\\sqrt[n]a$ 单扩张。\n就相当于取 $d=n$。还是一样的道理，$\\impliedby$ 是容易证的，直接看可能的自同构即可。$\\implies$ 必须构造出这个 $w$。Dummit 里讲的 Lagrange resolvent 就是 Hilbert 90 构造的一种特殊情况。\n现在我开始好奇一个事情，如何用根式扩张塔描述不同次的本原单位根？这看起来是个数论的问题？\n8. 分圆扩张 $K$ 上 $x^n-1$ 的分裂域称为 $n$ 阶分圆扩张。如果 $\\cha K=p\\ne 0$，那么 $n$ 阶分圆扩张等价于 $n/\\gcd(n,p^{\\infty})$ 阶分圆扩张。因此可以假设 $p\\nmid n$。\nT 8.1（一般分圆扩张的结构）：$F/K$ 为 $n$ 阶分圆扩张。则 $F=K(\\zeta)$（$\\zeta$ 为 $n$ 次本原单位根），$F$ 是维数为 $d\\mid\\varphi(n)$ 的阿贝尔扩张，当然 $\\aut_KF$ 就是 $\\Z_n^\\times$ 的一个子群。\nP：显然 $x^n-1$ 的各个不可约因子可分，于是 $F/K$ Galois。分析 $\\sigma\\in\\aut_KF$ 的结构：$\\sigma(\\zeta)=\\zeta^i$ 必须满足 $i^{-1}\\bmod n$ 存在。\nEx：$\\R(\\zeta_5)$ 的维数为 $2$，因为 $\\zeta_5$ 不能 $\\mapsto\\zeta_5^2$。\n定义第 $n$ 个分圆多项式 $\\Phi_n(x)=\\prod_{0\\le i\u0026lt;n,i\\perp n}(x-\\zeta^i)$。\nT 8.2（分圆多项式的性质）：$x^n-1=\\prod_{d\\mid n}\\Phi_d(x)$，$\\Phi_n(x)\\in P[x]$ 其中 $P$ 是 $K$ 的素子域。\nP：第一个略。第二个考虑归纳。$\\Phi_n(x)=(x^n-1)/\\prod_{d\\mid n,d\u0026lt;n}\\Phi_d(x)$ 其中右边的各个因子都 $\\in P[x]$，因此 $\\Phi_n(x)\\in P[x]$（根据商的唯一性，或者可以考虑反证）。\n学过莫比乌斯反演，就容易看出 $$ \\Phi_n(x)=\\prod_{d\\mid n}(x^d-1)^{\\mu(n/d)} $$ 分圆多项式的列表见 https://en.wikipedia.org/wiki/Cyclotomic_polynomial#Examples。\nT 8.3（$\\Q$ 上分圆扩张的结构）：当 $K=\\Q$ 时，$\\Phi_n(x)$ 不可约，如果 $F$ 是 $n$ 次分圆扩张，则 $[F:\\Q]=\\varphi(n)$ 且 $\\aut_{\\Q}F\\cong\\Z_n^\\times$。\nP：若 $\\Phi_n(x)=f(x)g(x)$ 其中 $f(x)$ 不可约，那么取 $f(x)$ 的一根 $\\zeta$。对于任一质数 $p\\perp n$，我们要说明 $\\zeta^p$ 也是 $f(x)$ 的根，这样 $f(x)$ 就取满所有根了。假设不然，则 $\\zeta^p$ 是 $g(x)$ 的根 $\\implies$ $\\zeta$ 是 $g(x^p)$ 的根，在 $\\bmod p$ 意义下 $\\zeta$ 就是 $g(x)^p$ 的根。同时在 $\\bmod p$ 意义下 $\\zeta$ 的最小多项式可能不再是 $f(x)$ 但一定是 $f(x)$ 的一个因子 $h(x)$，那么同时 $h(x)\\mid g(x)^p\\implies h(x)\\mid g(x)$，于是 $\\bmod p$ 意义下 $h(x)^2\\mid f(x)h(x)\\mid f(x)g(x)\\mid \\Phi_n(x)$，但 $\\Phi_n(x)$ 不应该有重根，矛盾。\n可以理解为，分圆多项式给出了 $x^n-1$ 更精细的刻画，从而结合数论的手段可以证明一些很牛的东西，例如存在无数个 $kn+1$ 型质数、有限除环为域等等。\n9. 根式扩张 D 9.1（根式扩张）：$F/K$ 是根式扩张，定义为存在有限步扩张 $F=E_n/\\cdots/E_1/E_0=K$，满足 $E_i=E_{i-1}(u)$，$u^m\\in E_{i-1}$。\n显然根式扩张一定是代数扩张。\nD 9.2（根式可解）：$f\\in K[x]$ 可解，定义为 $f$ 的分裂域属于 $K$ 的某个根式扩张。\nT 9.3（正规根式扩张的构造）：根式扩张的正规闭包仍然是根式扩张。\nP：对于根式扩张 $F/K$，设 $F=K(w_1,\\cdots,w_n)$。根据 T 3.16，正规闭包 $N$ 是 $\\set{w_{1\\sim n}}$ 的最小多项式 $\\set{f_{1\\sim n}}$ 的分裂域。现在考虑 $f_i$ 的一个根 $w_i^\\prime$，有 $K$-同构 $\\sigma:K(w_i)\\cong K(w_i^\\prime)$，它可以扩展到 $N$ 的 $K$-自同构 $\\tau$，于是 $F\\cong \\tau(F)$。对于每个根都这样做，我们就得到了一堆 $F$ 的“副本”，它们共同生成了 $N$。\n现在只需证明根式扩张的复合也是根式扩张。对于两个根式扩张 $E_1,E_2/K$，把它们的根式塔接起来就行啦！\nT 9.4（根式扩张 $\\implies$ 可解）：$F/E/K$，若 $F/K$ 是根式扩张，则 $\\aut_KE$ 可解。\nP：\n（将 $E/K$ 归为 Galois）首先如果 $E/K$ 不是 Galois，就取 $K_0=(\\aut_KE)^\\prime$，明显 $F/K_0$ 也是根式扩张，$\\aut_KE=\\aut_{K_0}E$，因此令 $K=K_0$。\n（将 $F/K$ 归为正规）取 $F$ 在 $K$ 上的的正规闭包 $N$，由上个定理 $N/K$ 也是根式扩张，因此令 $F=N$。\n（将 $E$ 归为 $F$）现在 $E/K$ Galois，$E$ 是稳定的；又由正规性 $\\aut_KE$ 内的元素可以扩展到 $\\aut_KF$ 上，因此存在一个 $\\aut_KF\\to\\aut_KE$ 的满同态（投影），而可解群的商群也是可解的，因此只需证 $\\aut_KF$ 可解，所以令 $E=F$。\n（将 $F/K$ 归为 Galois）取 $(\\aut_KF)^\\prime=K_1$，令 $K=K_1$。\n（排除 $\\cha K$ 因子）现在 $F/K$ 是 Galois 根式扩张，设根式塔为 $F=E_n/\\cdots/E_1/E_0=K$，$E_i=E_{i-1}(u_i)$，$u_i^{m_i}\\in E_{i-1}$。如果加根过程遇到了 $p\\mid m_i$ 的（$p=\\cha K$），就有纯不可分元了，这就不对了，所以假定 $p\\nmid m_i$。\n（添加单位根）取 $\\zeta$ 为 $\\prod m_i$ 次本原单位根，加入 $F$。由于 $F(\\zeta)$ 是 $F$ 上的分裂域，故 $F(\\zeta)/K$ 也 Galois，从而 $\\aut_KF\\cong\\aut_KF(\\zeta)/\\aut_FF(\\zeta)$，只需证 $\\aut_KF(\\zeta)$ 可解。因此令 $F$ 包含所需的单位根。\n现在有根式塔 $$ K\\subset K(\\zeta)\\subset K(\\zeta,u_1)\\subset\\cdots\\subset K(\\zeta,u_1,\\cdots,u_n)=F(\\zeta) $$ 根据分圆扩张与循环扩张的性质，每一步对应的 Galois 群都是阿贝尔的。\nDummit 里的证法是直接取 Galois 闭包，是不是能把 2、4 步合并起来？\nT 9.5（多项式的可解性 $\\implies$ Galois 群的可解性）：$f$ 可解则 $f$ 的 Galois 群可解。\nT 9.6（根式扩张 $\\impliedby$ 可解）：$E/K$ 有限 Galois 且 $\\aut_KE$ 可解。如果 $\\cha K\\nmid[E:K]$ 则存在 $K$ 的根式扩张包含 $E$。\nP：对 $[E:K]$ 归纳。任取质数 $p\\mid\\lvert\\aut_KE\\rvert=[E:K]$，根据可解群的性质，$\\aut_KE$ 有一个指数为 $p$ 的正规子群 $H$。由于 $\\cha K\\ne p$，可以向 $E$ 中加入 $p$ 次单位根 $\\zeta$。现在有扩张：\n且类似上面 $E(\\zeta)/K$ 也 Galois。已知 $K(\\zeta)/K$ 是根式扩张，现在需要说明 $E(\\zeta)/K(\\zeta)$ 可以被扩展为根式扩张。如果 $[E(\\zeta):K(\\zeta)]\u0026lt;[E:K]$ 的话，就可以运用归纳。具体而言，由于 $E/K$ Galois，故 $E$ 为稳定域，我们就有同态 $\\theta:\\aut_{K(\\zeta)}E(\\zeta)\\to \\aut_KE$，容易看出它是单同态。严格单的情况用归纳，现只需考虑 $\\theta$ 是同构的情况。这时考虑 $\\theta^{-1}(H)$ 记为 $J$。现在有关系： $$ \\begin{array}{ccccc} 1\u0026amp;\\lhd\u0026amp;J\u0026amp;\\stackrel p{\\lhd}\u0026amp;\\aut_{K(\\zeta)}E(\\zeta)\\\\ E(\\zeta)\u0026amp;\u0026gt;\u0026amp;J^\\prime\u0026amp;\\stackrel p{\u0026gt;}\u0026amp;K(\\zeta) \\end{array} $$ 根据 T 7.11（含单位根的循环扩张必为根式扩张），$\\aut_{K(\\zeta)}E(\\zeta)/J\\cong\\Z_p$ 故 $J^\\prime$ 是 $K(\\zeta)$ 的根式扩张，同时 $E(\\zeta)/J^\\prime$ Galois，显然 $J$ 也可解，于是就可以用归纳了。\n其实总的来说，根式扩张和可解之间的障碍就在于，得先往根式扩张里加根，红色这一步是证明中处理最麻烦的：\n根式扩张 $\\longleftrightarrow$ 单根扩张 $\\color{red}\\longleftrightarrow$ 含单位根的单根扩张 $\\longleftrightarrow$ 循环扩张 $\\longleftrightarrow$ 可解\nT 9.6 中 $[E(\\zeta):K(\\zeta)]\u0026lt;[E:K]$ 的情况就对应 $E$ 里面已经有 $\\zeta$ 了而 $K$ 里面还没有；而取等的情况则对应都需要加入单位根，才能应用循环扩张与单根扩张的对应。\n根据 Ex 2，如果希望将 $p=\\cha K\\ne 0$ 时 $p$ 度循环扩张纳入考虑，可以扩展根式扩张的定义。\nT 9.7（多项式的可解性 $\\impliedby$ Galois 群的可解性）：在 $\\cha K\\nmid(\\deg f)!$ 的情况下，$f$ 可解 $\\iff$ $f$ 的 Galois 群可解。\nP：这种情况下，$f$ 的不可约因子求导后不会有非常数项消失，所以分裂域可分，就是 Galois 的。同时分裂域维数 $\\mid(\\deg f)!$。\nT 9.8（Abel）：对于 $n\\ge 5$ 次方程，没有一般的求根公式。\n对于 $\\cha K=0$，$n\\le 4$ 有求根公式（T 9.6\u0026amp;9.7）；对于 $\\cha K\\ne 0$，需要扩展根式扩张的定义才能做到 $\\iff$。\n如何定义“一般的求根公式”？定义一般多项式 $p_n(x)=x^n-t_1x^{n-1}+t_2x^{n-2}-\\cdots+(-1)^nt_n$ 为 $K(t_1,\\cdots,t_n)[x]$ 内的多项式，其中 $t_{1\\sim n}$ 为不定元（超越扩张）。一般 $n$ 次方程就定义为 $p_n(x)=0$。这样求出来的根就是“公式”。\nP：令根为 $u_{1\\sim n}$，设 $F=K(t_1,\\cdots,t_n)(u_1,\\cdots,u_n)=K(u_1,\\cdots,u_n)$（根据韦达定理），现在我们希望建立一个对应关系： $$ \\begin{array}{ccc} K(t_1,\\cdots,t_n)\u0026amp;\\cong\u0026amp;K(f_1,\\cdots,f_n)\\\\ |\u0026amp;\u0026amp;|\\\\ K(u_1,\\cdots,u_n)\u0026amp;\\cong\u0026amp;K(x_1,\\cdots,x_n) \\end{array} $$ 其中 $f_{1\\sim n}$ 是 $x_{1\\sim n}$ 的初等对称函数。这样一来， $$ \\aut_{K(t_1,\\cdots,t_n)}K(u_1,\\cdots,u_n)\\cong\\aut_{K(f_1,\\cdots,f_n)}K(x_1,\\cdots,x_n)\\cong S_n $$ 在 $n\\ge 5$ 时不可解。这个东西不难：\n建立 $K[t_1,\\cdots,t_n]\\cong K[f_1,\\cdots,f_n]$，直接构造满同态并验证单射即可。 同构可以扩展到分式域，$K(t_1,\\cdots,t_n)\\cong K(f_1,\\cdots,f_n)$。 双方的扩张分别都是 $x^n-a_1x^{n-1}+\\cdots$ 的分裂域，而同构可以扩展到分裂域，于是 $K(u_1,\\cdots,u_n)\\cong K(x_1,\\cdots,x_n)$。 补充 有限域的表示 看起来书里没讲有限域元素的表示……\n这边主要参考 https://www.zhihu.com/column/c_1428677501942427648，列出重要的影响理解的几个结论：\n$\\F_{p^n}$ 的所有子域为 $\\set{F_{p^m}{\\large{}\\mid{}} m\\mid n}$，每个子域都唯一。\n一方面，$\\F_{p^n}$ 是 $\\F_{p}$ 上的 $p^n-1$ 次分圆扩张；另一方面，任何 $n$ 次不可约多项式 $f\\in\\F_p[x]$ 在 $\\F_p$ 上的分裂域都是 $\\F_{p^n}$。\n$\\F_p$ 的 $m$ 次分圆扩张（$p\\nmid m$）是 $\\F_{p^{\\delta_m(p)}}$，$\\delta_m(p)$ 是模 $m$ 意义下 $p$ 的阶。\n$\\aut_{\\F_p}\\F_{p^n}=\\langle\\sigma\\rangle$ 其中 $\\sigma$ 是 自同构。\n所以简而言之，我们随便取一个 $n$ 次不可约多项式 $f\\in\\F_p[x]$ 就可以得到 $\\F_{p^n}$ 的刻画。当然，既然 $\\F_{p^n}^\\times$ 是个循环群，我们肯定希望找到本原元啦，然而 $x$ 不一定是本原元。进一步地，可以定义本原多项式：$\\delta_f(x)=p^n-1$，这样 $x$ 就是本原元。（注意与各项系数 $\\gcd=1$ 的本原多项式定义区分）\n有限域下的不可约多项式和本原多项式密度都不低：https://zhuanlan.zhihu.com/p/1905745887688389673。所以我想机械化计算时应该可以直接随机找吧。\nn 次剩余问题 OI 中我们会碰到求 $x^n\\equiv a\\pmod m$ 的问题。首先通过 CRT 和 Hensel lifting 将 $m$ 归为质数 $p$，再通过多次迭代将 $n$ 归为质数。对于 $n\\nmid(p-1)$ 的情况，$x=a^{n^{-1}\\bmod (p-1)}$；对于 $n\\mid (p-1)$ 的情况无法找到直接的构造。本质上所谓“构造”是指：\n$b^k\\equiv a\\pmod p$ $n\\mid k$ $b$ 容易得到 既然在 $\\F_p$ 下无法找到，我们就得考虑扩域。如果加入一个非 $n$ 次剩余 $u$ 的 $n$ 次根 $\\sqrt[n]u=\\zeta$，那么我们就有（recall T 7.3）： $$ (t+\\zeta)^{1+p+\\cdots+p^{n-1}}=\\prod(t+\\zeta^i)=\\prod\\sigma(t+\\zeta)=N(t+\\zeta)=(-1)^na_0 $$ 而 $t+\\zeta$ 的最小多项式为 $(x-t)^n-u$，故 $N(t+\\zeta)=t^n+(-1)^{n-1}u$。\n现在我们注意到一个关键的事情：$1+p+\\cdots+p^{n-1}$ 是能被 $n$ 整除的（LTE/直接取模证）！而 $t^n+(-1)^{n-1}u$ 有一个自由度。具体来说，显然不能直接取 $u=a$ 否则就是 $n$ 次剩余了；所以考虑取 $u=(-1)^n(t^n-a)$，刚好能把 $t^n$ 抵消掉，随机 $t$ 即可。\n对于 $n=2$ 这就是 Cipolla。当然 $n$ 大的时候运算量就巨大了。\n待研究的问题 二次整数环的性质（哪些是 ED、PID、UFD）以及其中的运算，与数论的关系 非交换除环的性质 判定与生成不可约多项式、本原多项式的机械方法 $\\F_p[x]$ 的多项式因式分解的机械方法 $\\Z_n[x]$（$n$ 非质数）的一些研究 求最小多项式的机械方法 本原多项式与处理有限域运算的机械方法 将对称多项式写成初等对称多项式的组合的机械方法 正 $n$ 边形尺规作图，单位根的根式表示，高次多项式可解根的判定与求解方法 函数的 Liouville 理论 一些特殊丢番图方程，费马大定理相关 一些更进阶的环论与域论： 局部环 Artin 环、Noether 环等 交换代数 有限环分类 模论 超越扩张相关 域分类 域论与群表示论、有限群及单群分类的关系 ","date":"2025-07-04T00:00:00Z","image":"https://littlereuben.github.io/study/gtm73-ring-field-theory/all_234.png","permalink":"https://littlereuben.github.io/study/gtm73-ring-field-theory/","title":"抽代（环、域论部分）自学笔记"},{"content":"这是一篇学习笔记。\r$\\gdef\\suf{\\Longrightarrow}\\gdef\\nec{\\Longleftarrow}\\gdef\\iff{\\Longleftrightarrow}\\gdef\\cha{\\operatorname{char}}\\gdef\\gal{\\operatorname{Gal}}\\gdef\\aut{\\operatorname{Aut}}\\gdef\\Q{\\mathbb{Q}}\\gdef\\C{\\mathbb{C}}$\n强推邓老师的抽代！\n一些有意思的作业题：2.4.18, 3.1.18, 3.3.7, 3.4.5, 3.4.8, 4.1.7, 5.4.8, 5.5.5, 8.3.5, 8.3.8, 9.5.7, 9.3.4, 9.4.20, 13.2.14, 13.2.17, 13.4.6, 14.7.8\n群论比较熟悉所以就没记了，下面是下半学期的考试内容，自己复习的时候写的，只记了自己不是很熟的点，所以这篇文章不适合初学，应该先看过 Dummit \u0026amp; Foote 再看这个。群论笔记、环、域论笔记。\n期中题 期中前有个作业是让每个同学出道题，会选 1~2 道放在考试里。我的可能比较超纲就没被选上。\n[PDF file] Lec 8 Def. 整环 $\\subset$ 交换幺环。\nCor. 有限整环是域。\nDef. 子环的要求：非空、减法与乘法封闭。子域的要求：非空、含单位元、减法与除法封闭。\nDef. 对于无平方因子整数 $D$，可以定义二次域 $\\Q(\\sqrt D)$。它有个子环称为二次整数环：$\\mathcal{O}=\\Z[\\omega]$，$\\omega=\\begin{cases}\\sqrt{D},\u0026amp;D\\not\\equiv1\\pmod4\\\\ \\frac{1+\\sqrt D}2,\u0026amp;D\\equiv1\\pmod4\\end{cases}$，$D\\equiv1$ 是这样定义是因为它刚好能关于乘法封闭（平方模 $4$ 必余 $1$）。定义模 $N(a+b\\omega)=\\begin{cases}a^2-b^2D,\u0026amp;D\\not\\equiv1\\\\ a^2+ab-\\frac{1-D}4b^2,\u0026amp;D\\equiv1\\end{cases}$。\nRemark. 这个模仅仅是有积性，没有 ED 的性质。它可以用来判断单元、不可约元。对于 $D=-1,-2,-3$，$\\cal O$ 是 ED。对于 $\u0026lt;-3$ 的 $D\\not\\equiv1$，可以证明 $\\cal O$ 仅仅是整环（HW 8.3.5）。\nPro. $R$ 是整环 $\\suf$ $R[x]$ 是整环\nDef. 群环：$\\sum (r\\in R)(g\\in G)$\nDef. 左理想定义为 $\\forall r$，$rI\\subseteq I$。注意元素和理想“乘积”定义是直接的。\nDef. $I+J=\\set{i+j\\mid i\\in I,j\\in J}$，$IJ=\\set{\\sum i_kj_k}$ 有限和。在 $I$ 或 $J$ 是理想时，$I+J$ 和 $IJ$ 才一定是子环；在 $I$ 和 $J$ 都是理想时，$I+J=(I,J)$，$IJ$ 也是理想且 $\\subseteq I\\cap J$。\nThm (2nd iso). $A$ 是子环，$B$ 是理想（可减弱为是子环且 $AB,BA\\subseteq B$），则 $(A+B)/B\\cong A/(A\\cap B)$。\nPro. 对于交换环 $R$，$R$ 只有两个平凡的理想 $\\iff$ $R$ 是域。如果不是交换环是不对的，例如四元数环 $\\mathbb{H}$。\nLec 9 Dummit 里的素理想和极大理想都默认定义在幺环上……\nDef. 注意：极大理想和素理想都不能是 $R$ 但可以是 $0$。不可约元和素元都不能是零元或单元。\nPro. 幺环中每个真子环都包含于一个极大子环中。证明见 P254。\nPro. 交换环 $R$ 的理想 $M$ 极大 $\\iff$ $R/M$ 是域。\nPrf. 极大 $\\iff$ 商环 lattice 中没有介于 $R/M$ 和 $R/R$ 之间的别的商环 $\\iff$ $R/M$ 只有两个平凡理想 $\\iff$ 域。\nPro. 交换环 $R$ 的理想 $P$ 素 $\\iff$ $R/P$ 是整环。\nPrf. 素 $\\iff$ $(ab\\in P\\suf a\\in P\\lor b\\in P)$ $\\iff$ $((a+P)(b+P)=0+P\\suf a+P=0+P\\lor b+P=0+P)$ $\\iff$ 整。\nCor. 交换环 $R$ 的极大理想 $\\suf$ 素理想。\nDef. 定义分式环时要求子集对乘法封闭。\nDef. comaximal 理想： $A+B=R$。\nThm (CRT). 对于交换幺环 $R$ 及其理想 $A_{1\\sim n}$，定义环同态 $\\varphi:R\\to (R/A_1)\\times\\cdots\\times(R/A_n)$（映射略）。$\\ker\\varphi=A_1\\cap\\cdots\\cap A_n$。\n如果每对 $A_i,A_j$ 都是 comaximal 的，则 $\\bigcap A_i=\\prod A_i$ 因此 $R/(A_1\\cdots A_n)=(R/A_1)\\times\\cdots\\times(R/A_n)$。\nPrf. 考虑归纳，这里只说明 $A+B=R\\suf AB=A\\cap B$：这种情况下存在 $a+b=1$，因此 $c\\in A\\cap B$ 时 $c=ac+cb\\in AB$。\nPro. 域 $F$ 的 $F[x]$ 是 ED。\nPro. ED 的理想都是主理想。\nDef. GCD 定义在交换环上。两种等价定义：$d\\mid a,b$ 且其他这样的 $d^\\prime$ 都 $\\mid d$；$(a,b)\\subseteq(d)$ 且其他这样的 $(d^\\prime)$ 都 $\\supseteq(d)$。\nDef. 对于一个整环，如果它的每个 $(a,b)$ 都是主理想，则它称为 Bézout domain。\nLec 10 Def. 相伴定义在整环上。\nPro. $(d)=(d^\\prime)\\iff d\\sim d^\\prime$。\nPro. PID $R$ 的非零理想 $P$ 素 $\\suf$ 极大。\nPrf. 假设 $(p)\\subseteq(m)\\Rightarrow p=rm\\Rightarrow rm\\in(p)\\Rightarrow r\\in(p)\\lor m\\in(p)$。后者就结束了，若 $r\\in(p)\\Rightarrow r=sp\\Rightarrow p=spm\\Rightarrow sm=1$，$m$ 就是单元。\n于是 PID 中 $(0)$ 以外素 $\\iff$ 极大。\nCor. 交换环 $R$ 的 $R[x]$ 是 PID $\\suf$ $R$ 是域。\nPrf. $R[x]/(x)\\cong R\\Rightarrow (x)$ 素 $\\Rightarrow (x)$ 极大 $\\Rightarrow R[x]/(x)$ 域。\nDef. 不可约：$ab=r\\suf a\\sim 1\\lor b\\sim 1$。素：$r\\mid ab\\Rightarrow r\\mid a\\lor r\\mid b$。这两个概念定义在整环上（其实也可以在交换幺环上）。\nPro. 整环 $R$ 中素 $\\suf$ 不可约。\n反例：$3\\in\\Z[\\sqrt{-5}]$ 不可约但不是素，因为 $(2+\\sqrt{-5})(2-\\sqrt{-5})=3^2$。\nPro. PID $R$ 中素 $\\iff$ 不可约。\nPrf. 对于不可约元 $p$，若 $(p)\\subset(m)\\subset R\\Rightarrow p=rm\\Rightarrow r\\sim 1\\lor m\\sim 1\\Rightarrow (m)=(p)\\lor (m)=R\\Rightarrow (p)$ 极大 $\\Rightarrow (p)$ 素。\nPro. UFD $R$ 中素 $\\iff$ 不可约。\nThm. PID $\\subset$ UFD。\nSummary.\nField ED PID UFD ID $\\Q$ $\\Z$ $\\Z[(1+\\sqrt{-19})/2]$ $\\Z[x]$ $\\Z[\\sqrt{-5}]$ Pro. 对于环 $R$ 的理想 $I$，$(R/I)[x]=R[x]/(I)$。如果 $I$ 素则 $(I)$ 在 $R[x]$ 中也是素的。\nThm. 域的多项式环是 ED。\nLec 11 Pro (Gauss). UFD $R$ 对应的分式域为 $F$，$p(x)\\in R[x]$ 在 $F[x]$ 中可约 $\\suf$ 在 $R[x]$ 中可约。进一步地，如果 $p(x)=A(x)B(x)$，$A(x)B(x)\\in F[x]$，则存在 $r,s\\in F$，使得 $rA(x),sB(x)\\in R[x]$ 且 $p(x)=(rA(x))(sB(x))$。\nCor. UFD $R$ 对应的分式域为 $F$，各项系数 $\\gcd=1$ 的 $p(x)\\in R[x]$ 在 $F[x]$ 中可约 $\\iff$ 在 $R[x]$ 中可约。\nThm. $R$ 是 UFD $\\iff$ $R[x]$ 是 UFD。\nPrf. 只考虑 $\\suf$。对于 $p(x)\\in R[x]$ 如果 $C(p)\\ne 1$ 可以除一下，现假设 $C(p)=1$。现在 $p(x)$ 在 $F[x]$ 里有唯一分解（因为 $F[x]$ 是 ED），于是用 Gauss 引理可以得到在 $R[x]$ 里的分解，且各个因子的 $C=1$ 于是都不可约。唯一性也是放到 $F[x]$ 里去论证。\nPro. 域上的 $2/3$ 次多项式可约 $\\iff$ 有根。\nPro. 整环 $R$ 有个真理想 $I$。首一多项式 $p(x)\\in R[x]$ 在 $(R/I)[x]$ 内的“投影”如果无法分解为两个度数更小的多项式乘积，则在 $R[x]$ 内也是不可约的。\nRemark. 注意 $R/I$ 可能不是整环。\nPro (Eisenstein). 整环 $R$ 有个素理想 $P=(p)$。考虑多项式 $f(x)=x^n+a_{n-1}x^{n-1}+\\cdots+a_1x+a_0$，如果 $p^2\\nmid a_0$ 且 $p\\mid a_{0\\sim n-1}$，则 $f(x)$ 不可约。\nPrf. 若可约则 $a(x)b(x)=f(x)\\equiv x^n\\pmod p$，但 $p^2\\nmid a_0$。\nCor. 在 $R=\\Z$ 的情况下，我们不仅能说明 $f(x)$ 在 $\\Z$ 中不可约，还可以同时说明在 $\\Q$ 中不可约。\nPro. 域 $F$ 的多项式环 $F[x]$ 中所有极大理想恰为所有不可约多项式的主理想。换句话说，$F[x]/(f(x))$ 是域 $\\iff$ $f(x)$ 不可约。\nPro. 域 $F$ 的多项式环中，$f(x)$ 至多有 $\\deg f$ 个根。\nPro. $K/F$ 则 $K$ 是 $F$ 上的一个向量空间。$F$ 可以看作其素子域上的向量空间。\nPro. 域的同态要么是 $0$ 要么是单同态，因为域无非平凡理想。\nLec 12 Thm. 对于不可约多项式 $p(x)$ 的一个根 $\\alpha$，$F(\\alpha)\\cong F[x]/(p(x))$。\nThm. （这不是交换图）\nPro. $\\alpha$ 是 $F$ 上的代数元 $\\iff$ $[F(\\alpha):F]\u0026lt;\\infty$。\nThm. $L/K/F$，$[L:F]=[L:K][K:F]$。\nPrf. 设 $L/K$ 的一组基是 $\\alpha_{1\\sim m}$，$K/F$ 的一组基是 $\\beta_{1\\sim n}$。易证 $\\set{\\alpha_i\\beta_j}$ 是 $L/F$ 的一组基。\nThm. $K/F$ 有限 $\\iff$ $K$ 可以在 $F$ 上由有限个代数元生成。如果 $K=F(\\alpha_{1\\sim k})$，其中 $\\alpha_i$ 的度为 $n_i$，则 $[K:F]\\le\\prod n_i$。\nCor. $L/F$。$L$ 上所有 $F$ 的代数元构成一个子域。\nPrf. 代数元关于四则运算封闭，因为 $F(\\alpha,\\beta)=F(\\alpha)(\\beta)$，维数有限。反正总的来说这里就是要通过维数来 argue。\nThm. 代数扩张的代数扩张是代数扩张。\nRemark. 注意代数扩张也可能是无限维的。这里的证明是取相关的子域。\nDef. 域复合。\nPro. $K_1,K_2/F$，$[K_1K_2:F]\\le[K_1:F][K_2:F]$。\nPrf. 设出基，两步走。取等 $\\iff$ 两组基之间线性无关。\nCor. 如果 $[K_1:F]\\perp[K_2:F]$，则上式取等。\nPro. $F$ 上 $f(x)$ 的分裂域的维数 $\\le(\\deg f)!$。\nThm. 分裂域的扩展。\nPrf. 归纳，每次用单扩张的扩展。\rCor. 分裂域在同构意义下唯一。\nLec 13 Pro. 代数闭域是代数闭的。\nPro. 任何域的代数闭域存在且唯一。\nPro. $f(x)$ 可分 $\\iff f(x)\\perp\\mathrm{D}_xf(x)$。\nPro. $\\cha=0$ 的域或有限域上，不可约 $\\suf$ 可分。于是可分 $\\iff$ 分解中不可约多项式互不相同。\nPrf. 零特征的情况直接用上一个 Pro。如果是有限域，考虑一个不可约多项式 $f(x)$，如果它不可分，就意味着 $f(x)$ 和 $\\mathrm{D}_xf(x)$ 有非单元公因子，但是 $f(x)$ 是不可约的，这就说明 $\\mathrm{D}_xf(x)=0$。这种情况下，$f(x)=\\sum a_i x^{pi}$ 的形式。然而根据下面的 Cor，$a_i=b_i^p$，于是 $f(x)=\\sum(b_ix^i)^p=(\\sum b_ix^i)^p$ 可约，矛盾。\nRemark. 进一步地，完美域定义为不可约 $\\suf$ 可分的域。完美域的一个等价定义是 $F=F^{\\cha F}$ 或 $\\cha F=0$。\nDef. $\\cha=p$ 的域上，定义 Frobenius 自同态 $\\varphi$ 为 $a\\mapsto a^p$。可以验证这是个同态。\nCor. 上述情况如果是有限域，则 $\\varphi$ 是自同构，因为 $\\varphi$ 是单的。\nPro. $K/F$，$\\alpha$ 是 $F$ 上的代数元。则 $\\forall\\sigma\\in\\gal(K/F)$，$m_{\\alpha,F}(\\sigma\\alpha)=0$。\nPrf. $m_{\\alpha,F}(\\sigma\\alpha)=\\sigma m_{\\alpha,F}(\\alpha)=0$。\nRemark. 这一性质可用于排除 $\\gal(K/F)$ 里面有哪些元素。\nPro. $H\\le\\aut(K)$，$H$ 的不动点形成一个子域。\nPro. $E$ 是 $F$ 上 $f(x)$ 的分裂域，则 $\\lvert\\aut(E/F)\\rvert\\le[E:F]$。取等 $\\nec$ $f(x)$ 可分。\nPrf. 同样考虑归纳，现考虑一个根 $\\alpha$ 及对应的不可约因子 $g(x)$，我们要把中间域 $K$ 的自同构扩展到 $K(\\alpha)$ 上（当然这里默认 $\\alpha\\notin K$），这样的扩展由 $\\sigma(\\alpha)$ 唯一确定，并且 $g(x)$ 的任意根都可以作为 $\\sigma(\\alpha)$。因此我们知道：$[K(\\alpha):K]=\\deg g$，而 $\\#\\sigma=g(x)$ 的不同的根的数量。\nRemark. 为了理解不取等的情况，可以考虑 $x^p-t\\in\\mathbb{F}_p(t)[x]$。另外，如果取等，那么 $f(x)$ 的不可约因子必然可分，$f(x)$ 不一定可分。\nDef. 一个群 $G$ 到一个域的乘法群 $L^\\times$ 的同态称为一个 character。一些 character 线性无关，意思是它们以 $L$ 中元素为系数的线性组合的意义下线性无关。\nThm. 只要 $\\chi_{1\\sim n}$ 互不相同，它们就线性无关。\n假设 $\\sum a_i\\chi_i=0$，其中 $i$ 取遍所有 $a_i\\ne 0$ 并假设最后一个是 $i=m$。我们有 $\\sum a_i\\chi_i(g_0)=0\\cdots(1)$。取 $g$ 使得 $\\chi_i(g)$ 不全相同，也有 $\\sum a_i\\chi_i(gg_0)=\\sum a_i\\chi_i(g)\\chi_i(g_0)=0\\cdots(2)$。取 $(2)-(1)\\cdot\\chi_m(g)$ 得到 $\\sum_{i\\ne m}a_i(\\chi_m(g)-\\chi_i(g))\\chi_i(g_0)=0$ 对每个 $g_0$ 都成立，这样非零参数数量就减少了。无穷递降。\nLec 14 这里的 Galois 扩张都默认有限。\nCor. $K$ 到 $L$ 的不同嵌入线性无关。$K$ 的各个自同构线性无关。\nThm. 有限 $H\\le\\aut(K)$，记 $F$ 为 $H$ 的不动点。上面我们提到 $F$ 是个子域，现在有：$[K:F]=|H|$。\nCor. $K/F$ 有限，$\\lvert\\aut(K/F)\\rvert\\le[K:F]$。取等 $\\iff$ 除了 $F$ 之外没有点在 $\\aut(K/F)$ 下不动。\nPrf. 取不动域 $F_1$。$\\lvert\\aut(K/F)\\rvert=[K:F_1]=[K:F]/[F_1:F]$。\nRemark. 这给出了 Galois 扩张的两种定义，一种是大小取等，一种是不动不变。\nCor. 在上一个 Cor 的语境下，$\\aut(K/F)=H$。\nPrf. 根据定义 $H\\le\\aut(K/F)$。根据不等式 $\\lvert\\aut(K/F)\\rvert\\le[K:F]=|H|$。\nThm. $K/F$ 是 Galois 的 $\\iff$ $K$ 是 $F$ 上某个可分多项式的分裂域 $\\suf$ 如果 $F[x]$ 的不可约多项式在 $K$ 中有根，就有所有根。\nPrf. 可分 $\\suf$ Galois 用前面的那个不等式。\nGalois $\\suf$ 正规：假设不可约首一 $f(x)$ 有根 $\\alpha\\in K$，就考虑 $\\gal(K/F)$ 中的每个自同构作用于 $\\alpha$，我们期望这得到所有根。首先直接推可以得到 $\\sigma\\alpha$ 一定是根。收集所有的 $\\set{\\sigma_i\\alpha}$ 记作 $\\set{\\alpha_i}$，记 $g(x)=\\prod(x-\\alpha_i)$，其在 $\\gal(K/F)$ 的作用下不动于是 $g(x)\\in F[x]$，于是说明 $g(x)=f(x)$ 即可。由于 $f(x)$ 不可约故 $f(x)\\mid g(x)$，由于 $\\alpha_i$ 均为 $f$ 的根故 $g(x)\\mid f(x)$，从而 $f(x)=g(x)$。\nGalois $\\suf$ 可分：取 $K/F$ 的一组基，得到它们的最小多项式，去个重得到所需要的多项式。\nRemark. 这里其实就是在说：有限 Galois $\\iff$ 有限可分 $\\suf$ 正规。\nThm (Galois). 对于 Galois 扩张 $K/F$，中间域与 Galois 群的子群一一对应。且：\n$E_1\\leftrightarrow H_1$，$E_2\\leftrightarrow H_2$，则 $E_1\\subseteq E_2\\iff H_2\\le H_2$。 $E\\leftrightarrow H$ 则 $[K:E]=|H|$，$[E:F]=|G:H|$。 $E\\leftrightarrow H$ 则 $K/E$ 必然 Galois 且 $\\gal(K/E)=H$。 $E\\leftrightarrow H$ 而 $F/E$ Galois $\\iff$ $H\\unlhd G$。这种情况下 $\\gal(E/F)\\cong G/H$。 $E_1\\leftrightarrow H_1$，$E_2\\leftrightarrow H_2$，则 $E_1\\cap E_2\\leftrightarrow\\langle H_1,H_2\\rangle$ 且 $E_1E_2\\leftrightarrow H_1\\cap H_2$。 Prf. 一方面，子群的不动点是子域；另一方面，对于一个子域 $E$，$K$ 可以视作 $E$ 上可分多项式的分裂域，从而 $K/E$ Galois，于是也对应唯一的子群。\nThm. $F(x_1,\\cdots,x_n)/F(s_1,\\cdots,s_n)$ 是 Galois 扩张且 Galois 群为 $S_n$。\nPro. 对于多项式 $f(x)$，其判别式 $D=\\prod_{i\u0026lt;j}(\\alpha_i-\\alpha_j)^2\\in F$。\nPrf. 设分裂域为 $K$。如果 $f$ 不可分，则 $D=0$；否则 $K/F$ Galois，由于 $\\gal(K/F)$ 置换所有根，所以 $D$ 是不动点从而 $\\in F$。\nPro. $\\gal(K/F)\\le A_n\\iff\\sqrt{D}\\in F$。\nExp. 二次多项式 $D=s_1^2-4s_2=a^2-4b$。\n$D$ 是有理平方。这时两个有理根（可能重），平凡扩张。 $D$ 不是有理平方。$G=\\Z_2$。 Exp. 三次多项式。先要将 $D=(\\alpha-\\beta)^2(\\alpha-\\gamma)^2(\\beta-\\gamma)^2$ 表示成各项系数的式子： $$ f(x)=x^3+ax^2+bx+c\\xrightarrow{x=y-a/3}g(y)=y^3+py+q\\to D=-4p^3-27q^2\\to D=a^2-4b^3-4a^3c-27c^2+18abc $$\n$f$ 可约，归到简单情况。 $f$ 不可约。$\\sqrt{D}\\in F$ 则 $G=\\Z_3=A_3$，否则 $G=S_3$。注意由于扩域第一步维数一定是 $3$，故 $3\\mid|G|$。 Thm. $\\C$ 代数封闭。\nPrf. 由于代数闭域代数封闭，故只证明 $f(x)\\in\\R[x]$ 有个根 $\\in\\C$。设 $K=\\R(\\mathrm{i},\\alpha_{1\\sim n})$，考虑 $L_t(x)=\\prod_{i\u0026lt;j}(x-(\\alpha_i+\\alpha_j+t\\alpha_i\\alpha_j))$。由对称性 $L_t(x)$ 在 $\\gal(K/\\R)$ 下不动，$\\deg L_t$ 的 $2$ 因子数比 $\\deg f$ 的少，考虑归纳（基本情况：$\\deg$ 为奇的多项式一定有实根），现在认为 $L_t$ 一定有个根 $\\in\\C$。由于 $t$ 任意，故可以找到 $i,j$ 使得 $\\alpha_i+\\alpha_j+t\\alpha_i\\alpha_j\\in\\C$ 且 $\\alpha_i+\\alpha_j+s\\alpha_i\\alpha_j\\in\\C$，于是 $\\alpha_i+\\alpha_j,\\alpha_i\\alpha_j\\in\\C$，二次多项式的根一定 $\\in\\C$。\nPro. 如果 $\\cha\\ne n$ 的 $F$ 含 $n$ 次单位根，则 $F(\\sqrt[n]{a\\in F})$ 是循环的，Galois 群为 $\\Z_{d\\mid n}$。\nRemark. 如果 $\\cha F=n$，会导致 $x^n-a$ 不可分。\nPro. 如果 $\\cha\\ne n$ 的 $F$ 含 $n$ 次单位根，它的 $n$ 度循环扩张一定形如 $F(\\sqrt[n]{a\\in F})$。\n以下考虑 $\\cha F=0$。\nDef. 称 $F$ 上的代数元 $\\alpha$ 可以用根式表示，为 $\\alpha\\in K$，其中 $K$ 为根（根式）扩张，即，通过 $F$ 有限次单根扩张得到。\nLem. 根扩张的复合是根扩张，因为可以拼接加入的根式。Galois 扩张的复合是 Galois 扩张。\nLem. 对于 Def 里的 $\\alpha$，它属于某个 $F$ 的 Galois 扩张，并且这个扩张也是根扩张，同时每次根扩张都是循环的（也就是已含单位根）。\nPrf. 已知 $\\alpha\\in K$ 是根扩张。将根式塔 $$ F=K_0\\subset K_1\\subset\\cdots\\subset K_n=K $$ 变为 $$ F\\subset F^\\prime\\subseteq F^\\prime K_1\\subseteq\\cdots\\subseteq F^\\prime K_n=F^\\prime K $$ 其中 $F^\\prime$ 为 $F$ 加上所有要用到的单位根。这样。每一步都是一个循环 Galois 扩张。\n但是注意到 Galois 扩张的 Galois 扩张不一定是 Galois 扩张（例如 $\\Q(\\sqrt[4]2)/\\Q(\\sqrt2)/\\Q$），因此我们得先保证 $K$ 是 Galois 扩张。如果不是，取 $K/F$ 的 Galois 闭包（所有包含 $K$ 的 $F$ 之 Galois 扩张中最小的），记为 $L$。我们声称 $L$ 也是根扩张。这是因为 $L$ 是所有 $\\sigma K$ 的复合（$\\prod\\sigma K$ 是 Galois 的因为是正规的）。\nThm (Galois). $f(x)$ 根式可解 $\\iff$ 其 Galois 群可解。\nPrf. 若 $f(x)$ 根式可解，则每个根都有根式塔，复合起来也一样，再用上面的引理（可以先用引理再复合，也可以先复合再用引理）。于是 $f(x)$ 的分裂域包含于一个 Galois 的、根的、每次都是循环的扩张，这个扩张根据基本定理是可解的。$f(x)$ 的 Galois 群是这样一个扩张的商群，所以也是可解的。\n若 Galois 群可解，就有一个循环扩张的域列。虽然是循环的，我们还不知道它是不是单根扩张。所以也要先加入 $n$ 次单位根，再用逆命题（含单位根的循环扩张一定是单根扩张），这样才符合“可以用根式表示”的定义。\nhttps://math.stackexchange.com/a/1575702\n","date":"2025-07-04T00:00:00Z","permalink":"https://littlereuben.github.io/study/course-abstract-algebra/","title":"抽代期中题 \u0026 复习"},{"content":"这是《写作与沟通》课程“美与自我”主题的文章终稿，这里将其归为想法。\r[PDF file] ","date":"2025-06-24T00:00:00Z","permalink":"https://littlereuben.github.io/study/course-writing-essay/","title":"写沟论文：像素艺术的美学"},{"content":"这是一篇学习笔记。\r$\\gdef\\e{\\mathrm{e}}\\gdef\\d{\\mathrm{d}}\\gdef\\i{\\mathrm{i}}\\gdef\\N{\\mathbb{N}}\\gdef\\Z{\\mathbb{Z}}\\gdef\\Q{\\mathbb{Q}}\\gdef\\R{\\mathbb{R}}\\gdef\\C{\\mathbb{C}}\\gdef\\F{\\mathbb{F}}\\gdef\\E{\\mathbb{E}}\\gdef\\P{\\mathbb{P}}\\gdef\\M{\\mathbb{M}}\\gdef\\O{\\mathrm{O}}\\gdef\\b#1{\\boldsymbol{#1}}\\gdef\\ker{\\operatorname{Ker}}\\gdef\\im{\\operatorname{Im}}\\gdef\\r{\\operatorname{rank}}\\gdef\\id{\\mathrm{id}}\\gdef\\span{\\operatorname{span}}\\gdef\\spec{\\operatorname{spec}}\\gdef\\mat#1{\\begin{bmatrix}#1\\end{bmatrix}}\\gdef\\dat#1{\\begin{vmatrix}#1\\end{vmatrix}}\\gdef\\eps{\\varepsilon}\\gdef\\arcsinh{\\operatorname{arcsinh}}\\gdef\\arccosh{\\operatorname{arccosh}}\\gdef\\arctanh{\\operatorname{arctanh}}\\gdef\\arccoth{\\operatorname{arccoth}}\\gdef\\arcsech{\\operatorname{arcsech}}\\gdef\\arccsch{\\operatorname{arccsch}}\\gdef\\sgn{\\operatorname{sgn}}\\gdef\\sech{\\operatorname{sech}}\\gdef\\csch{\\operatorname{csch}}\\gdef\\arccot{\\operatorname{arccot}}\\gdef\\arcsec{\\operatorname{arcsec}}\\gdef\\arccsc{\\operatorname{arccsc}}\\gdef\\tr{\\operatorname{tr}}\\gdef\\unit#1{\\mathop{}!\\mathrm{#1}}\\gdef\\re{\\operatorname{Re}}\\gdef\\aut{\\operatorname{Aut}}\\gdef\\diag{\\operatorname{diag}}\\gdef\\D{\\mathrm{D}}\\gdef\\p{\\partial}\\gdef\\eq#1{\\begin{align*}#1\\end{align*}}\\gdef\\Pr{\\mathsf{Pr}}\\gdef\\Ex{\\mathsf{E}}\\gdef\\Var{\\mathsf{Var}}\\gdef\\ip#1{\\left\\langle #1\\right\\rangle}\\gdef\\J{\\mathrm{J}}\\gdef\\w{\\wedge}$\n封面 from wxf 的课件。\n这次选择以问答的方式做笔记帮助复习。不过事实证明基本定义清楚之后刷题就够了。括号里面的编号表示出自 wxf ppt，如果想知道答案可以评论问。\n多元函数极限与连续 距离，三个公理。对于线性空间，加平移不变性。\n哪三个公理？（1-16）\n范数，三个公理。线性空间下的距离和范数一一对应。\n哪三个公理？（1-18）\n$p$-范数，必须要求 $p\\ge 1$。\n证明 $p\\ge 1$ 可以构成范数，$p\u0026lt;1$ 不行。\n答案\rhttps://www.zhihu.com/question/667693249/answer/3633863935\r对于 $p\u003c1$，$\\|(0,1)+(1,0)\\|\u003e\\|(0,1)\\|+\\|(1,0)\\|$。\r内积，三个公理。内积可以定义范数，范数不一定可以由内积定义。$p$-范数中只有 $2$-范数可以。范数可以由内积得到，当且仅当 $\\|\\b x+\\b y\\|^2+\\|\\b x-\\b y\\|^2=2(\\|\\b x\\|^2+\\|\\b y\\|^2)$。（1-25）\n证明？\n答案\rhttps://math.stackexchange.com/a/43848\r拓扑相关的定义，略。\n当我们讨论连续性和极限时，对定义域的限定不同，具体是怎样的？（1-29）\n答案\r极限要求 $\\b x_0$ 是聚点，连续性要求 $\\b x_0$ 属于定义域。如果直接把连续性定义为极限等于该点的取值，可是可以，但是如果 $\\b x_0$ 是个孤立点，就没法说了。在 wxf 讲的连续性中，孤立点处必连续。\r任意范数在以下意义下与 $\\|\\cdot\\|_{\\infty}$ 等价：$\\exists M_1,M_2$，使得 $\\forall\\b x$，$M_1\\|\\b x\\|_{\\infty}\\le\\|\\b x\\|\\le M_2\\|\\b x\\|_{\\infty}$。（1-32）从而与有界、收敛、连续等相关的定理都可以只证明无穷范数下的情况。\n证明？（1-35）\n答案\r$\\|\\b x\\|\\le C\\|\\b x\\|_{\\infty}$：写出 $\\b x$ 的基的表示，用三角不等式拆开。\r另一个方向：考虑反证，如果有一列 $\\set{\\b x_n}$，$\\|\\b x_n\\|_{\\infty}$ 比 $\\|\\b x_n\\|$ 大得越来越离谱，那么可以找到一个范数的收敛子列，从而是柯西列，从而对应的 $\\b x$ 子列也收敛（这个没有循环论证，可以先证柯西列收敛的），这个极限点处的两种范数就爆了。\r一元微积分里的一些性质在多元情况也成立：柯西收敛定理、致密性定理、最值定理、闭集连续 = 一致连续。多元函数除了没有一元函数的单调性，别的都可以讨论。\n证明？\n证明：$S\\subseteq V$ 是有界闭集，当且仅当 $S$ 中的任何点列的极限也在 $S$ 中。（1-37）\n证明：如果 $S\\subseteq\\R^n$ 既是开集又是闭集，则它只能是全集或空集。\n提示\r找到一条从 $x\\in S$ 到 $y\\notin S$ 的路径 $\\pi$，构造 $f:\\pi\\to\\set{0,1}$。\r证明多元情况下的闭区间套定理。\n在证明多元连续函数的含参积分对参数的连续性时，必须搞出一致连续性才行。（1-41）\n现在我们说 $(x,y_1,\\cdots,y_n)\\in[a,b]\\times A$，$x$ 是被积变量，$\\b y_0=(y_1,\\cdots,y_n)$ 是参数。如何找到一个闭集？\n答案\r如果 $\\b y_0$ 是内点，那选个完全包含在 $A$ 内的闭邻域就行。否则，如果 $A$ 是闭集，那随便选个闭邻域就行。否则，证明起来有点麻烦。我想到的一个思路是，对于一个 $\\eps$，对于每个 $x\\in [a,b]$，找到一个 $\\delta(x)$ 为最大的（$\\sup$），不超过某个阈值的，使邻域内的函数值都 $\\le\\eps/2$ 的 $\\delta$。可以通过测度的三角形不等式证明 $\\delta(x)$ 连续，从而一致连续，从而 $\\inf\\delta(x)\u003e0$ 就是选择的 $\\delta$。\r如何证明，$\\R^2\\setminus\\set{(x,x^2)}$ 是开的？\n提示\r思路 1：通过闭集的充要条件证明 $\\set{(x,x^2)}$ 是闭的；思路 2：对于上方的一个点 $(x_0,y_0)$，考虑 $f(x)=y_0-x^2$，它一定在 $x_0$ 附近 $\u003e0$，就行了。思路 3：构造把抛物线拉平的连续函数 $\\R^2\\to\\R^2$。\r对于多元函数，无论按多少路径逼近是连续/极限相等，都不能说连续/极限存在。​累次极限/大量路径极限存在 $\\not\\Rightarrow$ 连续；因定义域奇形怪状导致的：连续 $\\not\\Rightarrow$ 累次极限存在（如果存在一定等于）、在一个趋近于完整定义域的定义域子集内连续 $\\not\\Rightarrow$ 连续（2-11，$f(x,y)=x^y$）。\n证明连续：用定义证；证明不连续：找到一条路径，极限不对。如何找？如果 $\\to(0,0)$，就分析最低次项；如果不是，把 $x_0$、$y_0$ 减去后同理。注意还是要具体情况具体分析，多元函数中单项式的次数并不绝对说明增长速度，因为 $x$ 和 $y$ 之间可以有不同的关系（2-8，$xy/(x+y)$）。\n无穷小量、渐进关系、同阶，这些概念都与范数的选择无关。wxf 讲的同阶不要求极限存在。（2-13）\n证明：$x,y\\to 0$ 时 $ax^2+2bxy+cy^2$ 与 $x^2+y^2$ 同阶，当且仅当 $b^2\u0026lt;ac$。（2-17）\n提示\r一个方向可以用三角换元。\r双线性映射都是连续的。可以通过拆成基之和的方式来放缩，得到 $\\|B(\\b x,\\b y)\\|\\le C\\|(\\b x,\\b y)\\|^2$，然后再利用双线性性。（2-28）\n二元分式极限的求法：\n极坐标。用于次数不是很大的情况。 换元 $y/x$。齐次的时候会比较好搞，不是齐次也不是不行。 不等式放缩。一般比较难，因为得考虑正负的问题。 渐进估计。用于出现 $\\ln$、$\\sin$、指数等的情况。 取 $y=f(x)$，把 $x$ 的成分减掉。这样可以证明极限不存在。 一定要注意，次数没有意义。哪怕分子的次数比分母大很多，极限仍有可能不存在——因为可以相减抵消，增高次数。\n比较难的例子：$\\lim_{(x,y)\\to (0,0)}\\frac{x^5+y^5}{x^3+y^3}$。这个用 1 可以搞但得分析三角函数的分式；用 2 的话会好处理。注意到 $\\lim_{(x,y)\\to (0,0)}\\frac{x^p+y^p}{x^3+y^3}$ 在 $p=3,5,7,\\cdots$ 时存在，$p=4,6,8,\\cdots$ 时不存在。\n一般性的方法：https://zhuanlan.zhihu.com/p/648080280。\n定义矩阵的范数为 $\\sqrt{\\tr(A^\\top A)}$ 或者 $\\max\\set{\\lvert A_{i,j}\\rvert}$ whatever，证明所有行列式 $\u0026gt;0$ 的实矩阵构成开集、道路连通集。\n答案\r行列式是 $\\M_{n\\times n}(\\R)\\to\\R$ 的连续函数，这个证明和上面一样。于是就是开集。\r道路连通集：思路 1（with psy）：所有初等变换都可以“慢动作”做成连续的，所以可以把 $A$ 变成 $\\diag(\\pm 1)$ 的形式，然后可以用 $\\rm SO(2)$ 里旋转的方式，将任意两个元素同时取负号。所有操作都是可逆的。思路 2（deepseek）：把矩阵极分解啰，正定矩阵是凸集，行列式为 $1$ 的正交矩阵可以通过同上的旋转方法，严谨证明可以见 https://math.stackexchange.com/q/711492。\r可逆矩阵虽然不是道路连通的，但是是稠密开的。考虑 $|A-\\varepsilon I|$。\n证明：设 $A$ 为正定矩阵，证明 $\\b x^\\top A\\b x$ 与 $\\b x^\\top\\b x$ 同阶。（2-32）\n提示\r考虑相减后利用正定的等价定义，相除单位化，或归为范数问题。\r证明实对称矩阵可正交对角化。线性代数里的证明是利用代数基本定理搞出一个特征值，再证明这个特征值是实的（扩域的又一个应用）。\n不通过这个来证明，能找到一个特征值。（3-13）\n提示\r对于所有 $\\b x$ 满足 $\\|\\b x\\|_2=1$，找到 $\\max\\set{\\b x^\\top A\\b x}=\\lambda$。利用反证法，证明 $A\\b x^*-\\lambda\\b x^*=\\b 0$。\r写出压缩不动点的使用条件及证明。（3-18）\n定义矩阵算子范数 $\\|A\\|_p=\\max_{\\|\\b x\\|_p=1}{\\|A\\b x\\|_p}$，每种向量范数都可以导出一种算子范数，例如 $p=1$ 时，对应的算子范数求的是最大的【列的绝对值之和】。证明：https://zhuanlan.zhihu.com/p/30674132。算子范数满足 $\\|AB\\|\\le\\|A\\|\\|B\\|$。\n证明当 $\\|B\\|\u0026lt;1$ 时，$I-B$ 可逆；$\\|(I-B)^{-1}-I\\|\\le\\|B\\|/(1-\\|B\\|)$；$\\|(I-B)^{-1}-I-B\\|\\le\\|B\\|^2/(1-\\|B\\|)$。（3-21）\n提示\r用压缩不动点定理。先证唯一。\r多元函数的微分与偏导 陈述公式 $\\D\\ip{,}(\\b a,\\b b)(\\b x,\\b y)=\\ip{\\b x,\\b b}+\\ip{\\b a,\\b y}$ 的含义。（4-8）\n求 $\\D\\det(A)(B)$。（4-14）\n答案\r行列式是多重线性函数，展开。\r答案为 $\\tr({A^*}^\\top B)$。\r求 $\\D(A^{-1})(B)$。（4-14）\n回顾 $\\b y^\\prime=A(x)\\b y$ 的解系构成的 $Y(x)$，它的行列式称为 Wronsky 行列式。其满足 $|Y(x)|^\\prime=\\tr A(x)|Y(x)|$。毕竟它说到底是个一元的函数，所以上个学期给出了证明，就是直接展开分析。\n现在，通过 2 的答案，给出一个更高大上的推导。注意多元情况下，导数的除法极限定义会很不好搞，用渐进表示可能更容易。当然最终还是对一个变量 $x$ 求导。（4-11）\n证明多元情况下，微分的链索法则 $\\D(g\\circ f)(\\b x)=\\D g(f(\\b x))\\circ\\D f(\\b x)$。（4-16）\n注意这里要求 $g$ 和 $f$ 在对应点都可微，而不仅仅是偏导存在。\n当 $f$ 是 $\\to\\R$ 时，$\\D f$ 会写成 $\\d f$。（4-3）\n这里的链索法则，看似是“一元”的，实际上它是普适的。例如，我们考虑 $\\d\\ip{f(\\b x),g(\\b y)}$，它本质上是笛卡尔积上的映射（4-15） $$ (\\b x,\\b y)\\xrightarrow{(f(\\cdot_1),g(\\cdot_2))}(f(\\b x),g(\\b y))\\xrightarrow{\\ip{\\cdot_1,\\cdot_2}}\\ip{f(\\b x),g(\\b y)} $$ 所以 $$ \\d\\ip{f(\\b x),g(\\b y)}(\\b u,\\b v)=(\\ip{f(\\b x),\\cdot_2}+\\ip{\\cdot_1,g(\\b y)})\\circ(\\d f(\\b x)(\\cdot_1),\\d g(\\b y)(\\cdot_2))(\\b u,\\b v)=\\ip{f(\\b x),\\d g(\\b y)(\\b v)}+\\ip{\\d f(\\b x)(\\b u),g(\\b y)} $$\n如果 $\\b x=\\sum\\xi_i\\b e_i$，那么 $$ \\d f(\\b x_0)(\\b x)=\\sum\\xi_i\\d f(\\b x_0)(\\b e_i)=\\sum\\xi_i\\frac{\\p f}{\\p\\b e_i}(\\b x_0)=\\sum\\frac{\\p f}{\\p x_i}(\\b x_0)\\d x_i(\\b x) $$ 其中 $\\d x_i$ 也是线性映射，即为取第 $i$ 维坐标的投影。因此 $$ \\d f(\\b x_0)=\\sum\\frac{\\p f}{\\p x_i}(\\b x_0)\\d x_k=\\mat{\\frac{\\p f}{\\p x_1}(\\b x_0)\u0026amp;\\cdots\u0026amp;\\frac{\\p f}{\\p x_n}(\\b x_0)}\\mat{\\d x_1\\\\ \\vdots\\\\ \\d x_n} $$ 这个东西和梯度没有任何关系，但是可以以矩阵形式处理复合运算——复合的微分，就是线性变换的复合。例如要求 $\\D(g\\circ f)(\\b x_0)$，那么 $$ \\begin{array}{ccccc} \\D(g\\circ f)(\\b x_0)\u0026amp;=\u0026amp;\\D g(f(\\b x_0))\u0026amp;\\circ\u0026amp;\\D f(\\b x_0)\\\\ \\mat{\\frac{\\p(g\\circ f)_1}{\\p x_1}(\\b x_0)\u0026amp;\\cdots\u0026amp;\\frac{\\p(g\\circ f)_1}{\\p x_k}(\\b x_0)\\\\ \\vdots\u0026amp;\\ddots\u0026amp;\\vdots\\\\ \\frac{\\p(g\\circ f)_n}{\\p x_1}(\\b x_0)\u0026amp;\\cdots\u0026amp;\\frac{\\p(g\\circ f)_n}{\\p x_k}(\\b x_0)}\u0026amp;=\u0026amp;\\mat{\\frac{\\p g_1}{\\p x_1}(f(\\b x_0))\u0026amp;\\cdots\u0026amp;\\frac{\\p g_1}{\\p x_m}(f(\\b x_0))\\\\ \\vdots\u0026amp;\\ddots\u0026amp;\\vdots\\\\ \\frac{\\p g_n}{\\p x_1}(f(\\b x_0))\u0026amp;\\cdots\u0026amp;\\frac{\\p g_n}{\\p x_m}(f(\\b x_0))}\u0026amp;\\cdot\u0026amp;\\mat{\\frac{\\p f_1}{\\p x_1}(\\b x_0)\u0026amp;\\cdots\u0026amp;\\frac{\\p f_1}{\\p x_k}(\\b x_0)\\\\ \\vdots\u0026amp;\\ddots\u0026amp;\\vdots\\\\ \\frac{\\p f_m}{\\p x_1}(\\b x_0)\u0026amp;\\cdots\u0026amp;\\frac{\\p f_m}{\\p x_k}(\\b x_0)}\\\\ \\J(g\\circ f)(\\b x_0)\u0026amp;=\u0026amp;\\J(g)(f(\\b x_0))\u0026amp;\\cdot\u0026amp;\\J(f)(\\b x_0)\\\\ \\displaystyle\\frac{\\p(g\\circ f)_i}{\\p x_j}(\\b x_0)\u0026amp;=\u0026amp;\\displaystyle\\sum_k\\frac{\\p g_i}{\\p t_k}(f(\\b x_0))\u0026amp;\\cdot\u0026amp;\\displaystyle\\frac{\\p f_k}{\\p x_j}(\\b x_0) \\end{array} $$\n我们说线性泛函 $L$ 的梯度向量，是指向量 $\\b b$ 使得 $\\forall\\b x$，$L(\\b x)=\\ip{\\b b,\\b x}$。现在对于一般的（不一定单位正交的）基底 $\\b e_1,\\cdots,\\b e_n$，已知 $L(\\b e_1),\\cdots,L(\\b e_n)$，不一定有 $\\b b=L(\\b e_1)\\b e_1+\\cdots+L(\\b e_n)\\b e_n$。\n用 $\\b e_i$ 和 $L(\\b e_i)$ 表示出 $\\b b$。（4-25、5-26）\n上面那个式子一般而言并不是内积。仅在单位正交基时，内积等于行向量乘列向量。一般而言，设 $\\b b=\\sum c_i\\b e_i$，根据内积的定义， $$ \\ip{\\b b,\\b x}=\\sum_{i,j}c_i\\xi_j\\ip{\\b e_i,\\b e_j}=\\mat{c_1\u0026amp;\\cdots\u0026amp;c_n}\\mat{\\ip{\\b e_1,\\b e_1}\u0026amp;\\cdots\u0026amp;\\ip{\\b e_1,\\b e_n}\\\\ \\vdots\u0026amp;\\ddots\u0026amp;\\vdots\\\\ \\ip{\\b e_n,\\b e_1}\u0026amp;\\cdots\u0026amp;\\ip{\\b e_n,\\b e_n}}\\mat{\\xi_1\\\\ \\vdots\\\\ \\xi_n} $$ 但另一方面，上面我们看到，根据微分的定义， $$ \\d f(\\b x_0)(\\b x)=\\mat{\\frac{\\p f}{\\p x_1}(\\b x_0)\u0026amp;\\cdots\u0026amp;\\frac{\\p f}{\\p x_n}(\\b x_0)}\\mat{\\xi_1\\\\ \\vdots\\\\ \\xi_n} $$ 因此 $$ \\b b=\\mat{c_1\u0026amp;\\cdots\u0026amp;c_n}^\\top=\\mat{\\ip{\\b e_1,\\b e_1}\u0026amp;\\cdots\u0026amp;\\ip{\\b e_1,\\b e_n}\\\\ \\vdots\u0026amp;\\ddots\u0026amp;\\vdots\\\\ \\ip{\\b e_n,\\b e_1}\u0026amp;\\cdots\u0026amp;\\ip{\\b e_n,\\b e_n}}^{-1}\\mat{\\frac{\\p f}{\\p x_1}(\\b x_0)\\\\ \\vdots\\\\ \\frac{\\p f}{\\p x_n}(\\b x_0)} $$\n利用梯度的定义证明 $\\nabla(fg)=g\\nabla f+f\\nabla g$。（4-28）\n$f$ 在某点的各方向导数都存在，哪怕各方向导数能统一写成内积的形式，也不意味着它在该点连续或可微。例如 $f(\\rho,\\theta)=[\\rho\\le\\theta]$（$\\theta\\in(0,2\\pi]$），这个“平台”的分界不是“一致”的，在原点处无法取得一个全 $1$ 邻域。也可以定义路径导数，当可微时，路径 $\\gamma$ 的导数 $\\d f(\\gamma(t))/\\d t=\\nabla f\\cdot\\gamma^\\prime$（链索法则）；一般情况下也行，如果要求方向导数（单位化），就取弧长参数。与连续性相同的是，可能出现各方向导数都一致，但沿某个曲线的方向导数爆炸，例如 $y/x^3(x=0\\rightarrow 0)$。\n求单位球面上的函数 $f$，沿经线与纬线分别的方向导数。（5-16）\n区分沿向量的导数与方向导数，主要是是否单位化的区别。“一个函数沿坐标轴方向的方向导数就是该函数对这个坐标求的偏导数”这句话是错的，因为坐标的基向量可能不是单位的。用公式来表示，就是 $$ \\frac{\\p f}{\\p\\b{\\hat e}_i}\\ne\\frac{\\p f}{\\p\\b e_i}=\\frac{\\p f}{\\p x_i} $$\nJacobi 矩阵行列记忆方法：线性泛函的微分是行向量，因此每行对应值域的一个维度。\n利用复合函数的链索法则，解释多元函数的一阶微分不变性。（5-31）\n对于一个函数 $f$，如果原来它的自变量为 $x,y$，然后换元后成了 $u,v$，那么求相关导数的思路是：将 $x,y$ 视作中间变量——也就是说，要求出 $x,y$ 关于 $u,v$ 的表达式，这样就可以求出 $f_u,f_v$ 等了。如果要将 $f_x,f_y$ 表示成 $u,v$ 相关的，那么要么用 $u,v$ 表示出 $x,y$，要么把第一个问题的东西反解出来（矩阵求逆）。\n多元函数的高阶微分 $\\mathscr{C}^k$ 类函数的定义是？（6-7）\n证明矩阵求逆是 $\\mathscr{C}^\\infty$ 的。（6-8）\n注意高阶偏导数“分母”上顺序与求导的顺序。（6-12）\n简述以下命题的证明思路：\n$f$ 关于 $x$ 连续、$y$ 连续单调 $\\Longrightarrow$ $f$ 连续。 $f$ 在单点处 $x$ 偏导存在，邻域内 $y$ 偏导存在且连续 $\\Longrightarrow$ $f$ 单点可导。（6-5） Clairaut 定理（6-33） Clairaut 定理条件：等式两边的导数都是连续的，允许减弱到一侧连续。反例：https://math.stackexchange.com/a/4603178。\n高阶微分： $$ \\eq{ \\d^kf(\\b x_0)(\\b u_1,\\cdots,\\b u_k)\u0026amp;=\\left.\\frac{\\d}{\\d t}\\left(\\d^{k-1}f(\\b x_0+t\\b u_k)(\\b u_1,\\cdots,\\b u_{k-1})\\right)\\right|_{t=0}\\\\ \u0026amp;=\\left.\\frac{\\d}{\\d t}\\sum_{i_1,\\cdots,i_{k-1}}\\frac{\\p^{k-1}f(\\b x_0+t\\b u_k)}{\\p x_{i_{k-1}}\\cdots\\p x_{i_1}}\\b u_{1,i_1}\\cdots\\b u_{k-1,i_{k-1}}\\right|_{t=0}\\\\ \u0026amp;=\\sum_{i_1,\\cdots,i_k}\\frac{\\p^kf(\\b x_0)}{\\p x_{i_k}\\cdots\\p x_{i_1}}\\b u_{1,i_1}\\cdots\\b u_{k,i_k} } $$\n推导微分方程 $u_{tt}=u_{xx}$ 的解。（6-17）\n简述求拉普拉斯算子在极坐标下表述的思路。（6-25）\n答案\r我们要使用 $r$ 和 $\\theta$ 表示 $u_x$ 和 $u_y$，这个东西如果直接用链式求导法则，会涉及到 $r$ 关于 $x$ 的偏导之类的，会比较麻烦。合适的方式是：\r$$\r\\frac{\\p u}{\\p(r,\\theta)}=\\frac{\\p u}{\\p(x,y)}\\frac{\\p(x,y)}{\\p(r,\\theta)}\r$$\r这样之后，矩阵求逆反解出 $\\p u/\\p(x,y)$ 即可。\r然后会得到 $\\p_x$ 和 $\\p_y$ 被 $\\p_r$ 和 $\\p_\\theta$ 表示的式子，再作用一次即可。对于 $\\p_{yy}$，可以将坐标系关于 $x=y$ 对称一下，直接从 $\\p_{xx}$ 的表达式推得。\r偏导与积分交换的条件：求完偏导的函数中，求偏导的变量关于被积变量一致连续。（6-36）一个充分条件是，函数本身的偏导均连续。不可换序的反例：https://www.zhihu.com/question/661186049。\n证明：多元函数 $f\\in\\mathscr{C}^r\\Longrightarrow g=\\int_tf(t)\\d t\\in\\mathscr{C}^r$。（6-37）\n不用定义证明变上下限积分的偏导。（6-39）\n提示\r考虑把积分写成一个多元（中间变量）函数。\r注意说明链索法则的使用条件。\r对于二重积分的换序，一个充分条件是被积函数是连续的。\n证明这种情况下可以换序。（6-43）\n提示\r考虑利用上一个问题。注意偏导与积分可交换的条件。\r积分换序条件：Fubini 定理。https://wuli.wiki/online/Fubin0.html。\n泰勒展开推导。对于 $f\\in\\mathscr{C}^r$，我们考虑近似 $f(\\b x_0+\\b v)$。\n根据一元泰勒展开， $$ \\eq{ f(\\b x_0+t\\b v)\u0026amp;=\\sum_{i=0}^{r-1}\\frac{1}{i!}\\left.\\frac{\\d^i}{\\d t^i}f(\\b x_0+t\\b v)\\right|_{t=0}t^i+\\frac1{(r-1)!}\\int_0^t\\left.\\frac{\\d^r}{\\d t^r}f(\\b x_0+t\\b v)\\right|_{t=s}(t-s)^{r-1}\\d s\\\\ f(\\b x_0+\\b v)\u0026amp;=\\sum_{i=0}^{r-1}\\frac{1}{i!}\\left.\\frac{\\d^i}{\\d t^i}f(\\b x_0+t\\b v)\\right|_{t=0}+\\frac{1}{(r-1)!}\\int_0^1\\left.\\frac{\\d^r}{\\d t^r}f(\\b x_0+t\\b v)\\right|_{t=s}(1-s)^{r-1}\\d s\\\\ \\text{(Integral)}\u0026amp;=\\sum_{i=0}^{r-1}\\frac{1}{i!}\\sum_{j_1,\\cdots,j_i}\\frac{\\p^i f}{\\p x_{j_i}\\cdots\\p x_{j_1}}(\\b x_0)\\b v^{j_1}\\cdots\\b v^{j_i}+\\frac{1}{(r-1)!}\\int_0^1\\sum_{j_1,\\cdots,j_r}\\frac{\\p^r f}{\\p x_{j_r}\\cdots\\p x_{j_1}}(\\b x_0+s\\b v)\\b v^{j_1}\\cdots\\b v^{j_r}(1-s)^{r-1}\\d s\\\\ \u0026amp;=\\sum_{i=0}^{r-1}\\frac{1}{i!}\\sum_{j_1,\\cdots,j_i}\\frac{\\p^i f}{\\p x_{j_i}\\cdots\\p x_{j_1}}(\\b x_0)\\b v^{j_1}\\cdots\\b v^{j_i}+\\frac{1}{(r-1)!}\\sum_{j_1,\\cdots,j_r}\\frac{\\p^r f}{\\p x_{j_r}\\cdots\\p x_{j_1}}(\\b x_0+\\theta\\b v)\\b v^{j_1}\\cdots\\b v^{j_r}\\int_0^1(1-s)^{r-1}\\d s\\\\ \\text{(Lagrange)}\u0026amp;=\\sum_{i=0}^{r-1}\\frac{1}{i!}\\sum_{j_1,\\cdots,j_i}\\frac{\\p^i f}{\\p x_{j_i}\\cdots\\p x_{j_1}}(\\b x_0)\\b v^{j_1}\\cdots\\b v^{j_i}+\\frac{1}{r!}\\sum_{j_1,\\cdots,j_r}\\frac{\\p^r f}{\\p x_{j_r}\\cdots\\p x_{j_1}}(\\b x_0+\\theta\\b v)\\b v^{j_1}\\cdots\\b v^{j_r}\\\\ \u0026amp;=\\sum_{i=0}^{r}\\frac{1}{i!}\\sum_{j_1,\\cdots,j_i}\\frac{\\p^i f}{\\p x_{j_i}\\cdots\\p x_{j_1}}(\\b x_0)\\b v^{j_1}\\cdots\\b v^{j_i}+\\frac{1}{r!}\\sum_{j_1,\\cdots,j_r}\\left(\\frac{\\p^r f}{\\p x_{j_r}\\cdots\\p x_{j_1}}(\\b x_0+\\theta\\b v)-\\frac{\\p^r f}{\\p x_{j_r}\\cdots\\p x_{j_1}}(\\b x_0)\\right)\\b v^{j_1}\\cdots\\b v^{j_r}\\\\ \\text{(Peano)}\u0026amp;=\\sum_{i=0}^{r-1}\\frac{1}{i!}\\sum_{j_1,\\cdots,j_i}\\frac{\\p^i f}{\\p x_{j_i}\\cdots\\p x_{j_1}}(\\b x_0)\\b v^{j_1}\\cdots\\b v^{j_i}+\\omicron(\\|\\b v\\|^r) } $$ 这里 Peano 余项是通过 $r$ 阶偏导的连续性得到（所以实际上 $r$ 阶可导的 Lagrange 余项，加上连续条件，就可以推出 $r+1$ 阶的 Peano 余项。这个上学期没提到）。\n由于 $f\\in\\mathscr{C}^r$，故偏导的顺序无所谓。可以枚举每个自变量求了几次偏导，这样， $$ \\frac{1}{i!}\\sum_{j_1,\\cdots,j_i}\\frac{\\p^if}{\\p x_{j_1}\\cdots\\p x_{j_i}}(\\b x_0)\\b v^{j_1}\\cdots\\b v^{j_i}=\\sum_{\\alpha_1+\\cdots+\\alpha_k=i}\\frac{\\p^if}{\\alpha_1!\\cdots\\alpha_k!\\p^{\\alpha_1}x_1\\cdots\\p^{\\alpha_k}x_k}(\\b x_0)(\\b v^1)^{\\alpha_1}\\cdots(\\b v^k)^{\\alpha_k} $$ 方便计算。\n证明：$f\\in\\mathscr{C}^r$ 在 Peano 余项形式的泰勒展开中的 $r$ 次多项式唯一。（7-10）从而有更方便的分多步展开方法。\n提示\r相减后通过一些简化的手段，变成单变量的情况。\r默写二元函数极值点的分类讨论，并基于泰勒公式证明。（7-16）\n说明为什么非退化驻点附近的等高线是椭圆或双曲线。\n一个二元函数在某一点上，各个方向该点都是极小值点，该点不一定是极小值点。（7-23）\n进一步地，甚至对于可微的函数，唯一的驻点是极值点，也不一定是最值点：https://math.stackexchange.com/a/3730294。\n一些泰勒展开的套路：\n$f(x,y)=\\left\\{\\begin{aligned}\u0026amp;\\frac{1-\\e^{x(x^2+y^2)}}{x^2+y^2},\u0026amp;(x,y)\\ne(0,0)\\\\ \u0026amp;0,\u0026amp;(x,y)=(0,0)\\end{aligned}\\right.$ $f(x,y)=\\sin(xy)\\e^{x+y}$ $f(x,y)=\\arctan\\frac{1+x+y}{1-x+y}$ $f(x,y)=x^y((x,y)\\to(1,0))$ Hesse 矩阵在 $f$ 不二阶连续时，$(H_f)_{i,j}=f_{i,j}$，先对 $i$ 元求偏导。存疑\n关于多元函数极值的推导（7-14~7-18）：\n从方向导数的角度描述驻点的必要条件，并写成代数语言。\n为什么二阶部分不退化时，Hesse 矩阵的性质是极值点的充要条件？\n写出极大、极小、鞍点的 Hesse 矩阵等价表述。\n证明正定与顺序主子式 $\u0026gt;0$ 的等价性。\n答案\rhttps://zhuanlan.zhihu.com/p/410049589\r用数学语言说明：沿梯度反方向能走到极小值点。进一步说明为什么不太可能走到鞍点，或者说极小值是吸引不动点。进一步给出吸引的速度。（7-34、8-16、8-17）\n共轭梯度法的思路：延续最速下降法的二次截断解极值点，然后只改方向——改为反伸缩时的正交方向。如果有多维，正交方向取负梯度被已有向量 Gram-Schmidt $H_f$-正交化后的结果。\n说明牛顿迭代法是二阶收敛的。\n再次强调凸是向下凸，凹是向上凸。\n多元函数的凸性和任意线段上的凸性是等价的。\n证明 $\\mathscr{C}^2$ 函数在非退化极小值点的一个凸邻域内是严格凸函数。（9-9）\n证明 $\\mathscr{C}^2$ 函数是凸的 $\\Longleftrightarrow$ $H$ 处处半正定；$H$ 处处正定 $\\Longrightarrow$ 严格凸。（9-10）\n证明凸函数的驻点是最小值点，以及严格凸 $\\Longrightarrow$ 最小值点唯一。（9-12）\n写出 Legendre 变换的定义，用 $f$、$\\nabla f$ 及其反函数表示 $f^*$。（9-15~9-17）\nLegendre 变换是对合的。\n证明（deepseek）\rLegendre 变换在多元情形下的对合性证明如下：设 $ f(\\mathbf{x}) $ 为严格凸且二阶连续可导的 $ n $ 元函数，其 Legendre 变换定义为\r$$\rg(\\mathbf{p}) = \\sup_{\\mathbf{x}} \\left[ \\mathbf{p} \\cdot \\mathbf{x} - f(\\mathbf{x}) \\right],\r$$\r其中 $\\mathbf{p} = \\nabla f(\\mathbf{x})$ （梯度）。由严格凸性，Hessian 矩阵 $\\nabla^2 f(\\mathbf{x})$ 正定，故 $\\mathbf{x}$ 与 $\\mathbf{p}$ 一一对应，记 $\\mathbf{x} = \\mathbf{x}(\\mathbf{p})$ ，则 $ g(\\mathbf{p}) = \\mathbf{p} \\cdot \\mathbf{x}(\\mathbf{p}) - f(\\mathbf{x}(\\mathbf{p})) $ 。\r对 $ g(\\mathbf{p}) $ 再次应用 Legendre 变换，得到\r$$\rh(\\mathbf{y}) = \\sup_{\\mathbf{p}} \\left[ \\mathbf{y} \\cdot \\mathbf{p} - g(\\mathbf{p}) \\right].\r$$\r计算 $ g(\\mathbf{p}) $ 的梯度：\r$$\r\\nabla g(\\mathbf{p}) = \\mathbf{x}(\\mathbf{p}) + \\left[ \\mathbf{p} \\cdot \\nabla_{\\mathbf{p}} \\mathbf{x}(\\mathbf{p}) - \\nabla f(\\mathbf{x}(\\mathbf{p})) \\cdot \\nabla_{\\mathbf{p}} \\mathbf{x}(\\mathbf{p}) \\right].\r$$\r由于 $\\mathbf{p} = \\nabla f(\\mathbf{x}(\\mathbf{p}))$ ，第二项抵消，得 $\\nabla g(\\mathbf{p}) = \\mathbf{x}(\\mathbf{p})$ ，即 $\\mathbf{y} = \\nabla g(\\mathbf{p}) = \\mathbf{x}(\\mathbf{p})$ ，故 $\\mathbf{p} = \\mathbf{p}(\\mathbf{y})$ 为 $\\mathbf{y} = \\mathbf{x}(\\mathbf{p})$ 的逆映射。\r将 $ g(\\mathbf{p}) = \\mathbf{p} \\cdot \\mathbf{x}(\\mathbf{p}) - f(\\mathbf{x}(\\mathbf{p})) $ 代入 $ h(\\mathbf{y}) $ ，得\r$$\rh(\\mathbf{y}) = \\mathbf{y} \\cdot \\mathbf{p}(\\mathbf{y}) - \\left[ \\mathbf{p}(\\mathbf{y}) \\cdot \\mathbf{y} - f(\\mathbf{y}) \\right] = f(\\mathbf{y}).\r$$\r因此，两次 Legendre 变换后恢复原函数，即 $ h(\\mathbf{y}) = f(\\mathbf{y}) $ ，证毕。\rYoung 不等式：$x^\\alpha/\\alpha+x^\\beta/\\beta\\ge xy\\;(x,y\u0026gt;0)$，$1/\\alpha+1/\\beta=1$，当且仅当 $x=y^{1/(\\alpha-1)}$ 时取等。（9-19）\n隐函数相关 隐函数定理：$\\mathscr{C}^r\\ni F:\\R^m\\times\\R^n\\to\\R^n$ 写成 $F(\\b x,\\b y)$，$\\b x\\in\\R^m$，$\\b y\\in\\R^n$。已知 $F(\\b x_0,\\b y_0)=\\b 0$ 且 $\\J_{\\b y}F(\\b x_0,\\b y_0)$ 可逆，那么存在 $\\b x_0$ 的一个邻域 $U$ 及 $\\b y_0$ 的一个邻域 $V$，存在 $\\mathscr{C}^r\\ni g:U\\to V$，使得邻域内 $F(\\b x,\\b y)=0\\Longleftrightarrow g(\\b x)=\\b y$。\n证明：（10-9~10-20）\n当 $n=1$ 时（记 $\\b y$ 为 $y$，$F$ 为 $f$），存在 $U$、$V$，使得 $\\b x\\in U$ 时有唯一零点 $y(\\b x)\\in V$。 这样的 $y(\\b x)$ 连续。 这样的 $y(\\b x)$ 可微。 $\\J y(\\b x)=\\dfrac{\\J_{\\b x}f(\\b x,y(\\b x))}{f_y(\\b x,y(\\b x))}$，其中上下两个偏导都是对 $f$ 的变量求导而不是对整个复合函数求导。 当 $n\u0026gt;1$ 时结论也成立，且构造得到的 $G\\in\\mathscr{C}^r$。 提示\r1. 利用 $\\mathscr{C}^1$ 连续性，介值定理。只需 bound 在两个界之间。\r2. 增加 $y$ 的邻域限制。\r3. 先构造 4 中的这个结果，然后考虑直接证可微的定义。利用 $\\mathscr{C}^1$，再进行一些移项，反解出 $y(\\b x)-y_0$ 的界。\r4. 链索法则。\r5. 通过乘上 $\\left[\\J_{\\b y}F(\\b x_0,\\b y_0)\\right]^{-1}$，将 Jacobi 矩阵变成 $I_n$。这样一来可以直接确定 $y$ 的第 $n$ 个分量，依赖于 $\\b x$ 以及前 $n-1$ 个分量。归纳。\r注意隐函数定理的逆命题不一定成立。例如 $\\sqrt[3]x$。\n逆映射定理：$\\mathscr{C}^r\\ni H:\\R^n\\to\\R^n$，若 $\\b y_0=H(\\b x_0)$ 且 $\\J H(\\b x_0)$ 可逆，则在 $\\b x_0$ 的小邻域内，$\\b x$ 可以写成关于 $\\b y$ 的 $\\mathscr{C}^r$ 函数。\n证明隐函数定理和逆映射定理等价。（10-21~10-22）\n整体微分同胚定理：$U$ 是 $\\R^n$ 的开集。$\\mathscr{C}^r\\ni F:U\\to\\R^n$。$F$ 是同胚 $\\Longleftrightarrow$ $F$ 单，且 $\\D F$ 处处可逆。\n这个定理的意思大概说的是，如果处处存在连续逆映射，那么整体就存在。\n写出 $x^3+ax^2+bx-1=0$ 的解的近似表达式（$a\\to 0$ 且 $b\\to 0$）。\n写出 $n$ 维空间中 $m$ 维 $\\mathscr{C}^r$ 曲面的定义。（11-6）$\\set{(x,y,z)\\mid x,y\\ge 0\\land z=x+y}$ 是二维曲面吗？$\\set{(x,y,z)\\mid |x|=|y|}$ 呢？\n答案\r不是，$x=0$ 处没法取邻域；不是，$x=y=0$ 处没法写成函数。\r$\\Sigma=\\set{\\b x\\mid \\b x_1^2+\\cdots+\\b x_n^2=1}\\subset\\R^n$ 是一个 $n-1$ 维球面。这个说法的证明是，每一处一定存在一个非零的 $\\b x_i$，这个 $\\b x_i$ 可以写成关于其他量的根式。\n证明若 $F:\\R^n\\to\\R$，$F^{-1}(0)$ 非空且不含 $F$ 的驻点，则它为一个 $n-1$ 维曲面。（11-10）推广到多个限制的情况。（11-11）\n写出并证明参数曲面相应的命题。（11-15）\n注意以上所有命题都要在开集上——隐函数的 $F$、参数方程中的 $f_i$ 都要定义在开集上。\n当 $\\left(\\sqrt{x^2+y^2}-R\\right)^2+z^2=r^2$ 在 $r\\ge R\u0026gt;1$ 时不再是个曲面。之前用隐函数和参数化对其的证明在哪里出了问题？\n答案\r隐函数：$F$ 在 $x=y=0$ 不可微；参数化：不是单射。\r对于参数化曲面 $\\b x(\\b t)$，证明 $\\span\\J\\b x(\\b t_0)$ 恰好是所有过 $\\b t_0$ 的曲线的切向量。思路是：每个向量都是切向量——构造 $\\b t$ 各分量的线性组合（直线），然后代入 $\\b x$；每个切向量都是向量——对于一个以另一个 $s$ 参数化的曲线，先把它写成一部分 $\\b x$ 分量关于另一部分（一个）$\\b x$ 分量的表达式，再根据后一部分 $\\b x$ 和 $\\b t$ 的可逆关系得出 $\\b t$。现在就得到 $\\b t$ 关于 $s$ 的表达式，再对 $\\b x(\\b t(s))$ 求导。\n参数化曲面的切平面方程：$\\b x=\\b x(\\b t_0)+\\span\\Set{\\frac{\\p\\b x}{\\p t_1}(\\b t_0),\\cdots,\\frac{\\p\\b x}{\\p t_n}(\\b t_0)}$，即（可以理解为 $\\b x$ 的一阶泰勒展开） $$ \\b x-\\b x_0=(\\J\\b x)\\b t\\quad\\text{i.e.}\\quad\\left\\{\\begin{aligned}x-x_0\u0026amp;=\\lambda\\frac{\\p x}{\\p u}+\\mu\\frac{\\p x}{\\p v}+\\cdots\\\\ y-y_0\u0026amp;=\\lambda\\frac{\\p y}{\\p u}+\\mu\\frac{\\p y}{\\p v}+\\cdots\\\\ \\vdots\\end{aligned}\\right. $$ 隐函数曲面的切平面方程：考虑任意一条曲线 $F(\\b x(t))=0\\Rightarrow\\sum F_i\\frac{\\p\\b x_i}{\\p t}=0$，即 $\\nabla F\\cdot\\Delta\\b x=0$。对于多个限制（可以理解为 $F$ 的一阶泰勒展开等于零） $$ (\\J F)(\\b x-\\b x_0)=0\\quad\\text{i.e.}\\quad\\left\\{\\begin{aligned}\\frac{\\p F_1}{\\p x}(x-x_0)+\\frac{\\p F_1}{\\p y}(y-y_0)+\\cdots\u0026amp;=0\\\\ \\frac{\\p F_2}{\\p x}(x-x_0)+\\frac{\\p F_2}{\\p y}(y-y_0)+\\cdots\u0026amp;=0\\\\ \\vdots\\end{aligned}\\right. $$\n条件极值（$\\min F(\\b x)\\text{ s.t. } \\b g(\\b x)=\\b 0$）的思路：其实很简单。就是要求梯度向量在约束曲面上的投影为 $\\b 0$，也就相当于梯度向量在约束曲面的切空间上投影为 $\\b 0$，即 $\\nabla F$ 可以表示为切空间的法向量，即 $\\set{\\nabla\\b g_i}$ 的线性组合。即 $$ \\frac{\\p}{\\p x_i}\\left(F(\\b x)-\\sum_{j=1}^n\\lambda_jg_j(\\b x)\\right)=0 $$ 对于定义域无限的情况，需要考虑无穷远处；否则需要考虑边界。一般处理都是说，当 $\\|\\b x\\|\u0026gt;C$ 时 $F(\\b x)$ 肯定过大。\n条件极值的充分条件：$\\mathcal{L}(\\b x)=F(\\b x)-\\b\\lambda\\cdot\\b g(\\b x)$，在其驻点，如果固定 $\\b\\lambda$ 后关于 $\\b x$ 的 $H_{\\mathcal{L}}$ 在约束曲面的切空间上正定，那么 $\\b x$ 就是极小值点。\n证明（deepseek）\r在多元条件极值问题中，若拉格朗日函数 $ L(x, \\lambda) = F(x) - \\lambda \\cdot g(x) $ 在驻点处关于 $ x $ 的 Hessian 矩阵限制在约束曲面的切空间上正定，则 $ F(x) $ 在该点处取得局部极小值。以下是严格证明：\r步骤 1：设定与隐函数定理的应用\r设 $ x^* $ 是满足 $ g(x^*) = 0 $ 的可行点，且存在 $ \\lambda^* $ 使得 $ \\nabla_x L(x^*, \\lambda^*) = 0 $。根据隐函数定理，若 $ g $ 关于后 $ n $ 个变量的 Jacobian 矩阵 $ J_v g(x^*) $ 非奇异，则存在局部参数化 $ v = G(u) $，其中 $ u \\in \\mathbb{R}^m $ 为前 $ m $ 个变量，$ v \\in \\mathbb{R}^n $ 为后 $ n $ 个变量，使得 $ g(u, G(u)) = 0 $。\r步骤 2：参数化目标函数\r将约束问题转化为无约束优化问题，定义参数化函数：\r$$\rf(u) = F(u, G(u)).\r$$\r目标转化为证明 $ u^* $ 是 $ f(u) $ 的局部极小点，对应 $ x^* = (u^*, G(u^*)) $。\r步骤 3：一阶条件\r由隐函数定理，参数化后的梯度为：\r$$\r\\nabla f(u) = \\nabla_u F + \\nabla_v F \\cdot DG(u),\r$$\r其中 $ DG(u) = -[J_v g]^{-1} J_u g $。在驻点 $ x^* $，由于 $ \\nabla_x L = 0 $，即：\r$$\r\\nabla F(x^*) = \\lambda^{*T} J_g(x^*),\r$$\r代入 $ J_g = [J_u g, J_v g] $，可得 $ \\nabla_u F = \\lambda^{*T} J_u g $ 和 $ \\nabla_v F = \\lambda^{*T} J_v g $。由此验证：\r$$\r\\nabla f(u^*) = \\lambda^{*T} J_u g + \\lambda^{*T} J_v g \\cdot (-[J_v g]^{-1} J_u g) = 0,\r$$\r即 $ u^* $ 是 $ f(u) $ 的临界点。\r步骤 4：二阶条件与 Hessian 分析\r计算 $ f(u) $ 的二阶导数：\r$$\rH_f(u^*) = \\nabla_{uu}^2 F + \\nabla_{uv}^2 F \\cdot DG + DG^T \\cdot \\nabla_{vu}^2 F + DG^T \\cdot \\nabla_{vv}^2 F \\cdot DG + \\nabla_v F \\cdot D^2 G(u^*).\r$$\r其中 $ D^2 G(u^*) $ 由隐函数定理的二阶展开确定：\r$$\rD^2 G = -[J_v g]^{-1} \\left( \\nabla_{uu}^2 g + 2 \\nabla_{uv}^2 g \\cdot DG + DG^T \\cdot \\nabla_{vv}^2 g \\cdot DG \\right).\r$$\r代入 $ \\nabla_v F = \\lambda^{*T} J_v g $，可得：\r$$\r\\nabla_v F \\cdot D^2 G = -\\lambda^{*T} \\left( \\nabla_{uu}^2 g + 2 \\nabla_{uv}^2 g \\cdot DG + DG^T \\cdot \\nabla_{vv}^2 g \\cdot DG \\right).\r$$\r因此，$ H_f(u^*) $ 可整理为：\r$$\rH_f(u^*) = \\left[ \\nabla_{xx}^2 F - \\lambda^{*T} \\nabla_{xx}^2 g \\right] \\bigg|_{\\text{切空间}}.\r$$\r这恰好是拉格朗日函数 $ L $ 的 Hessian $ \\nabla_{xx}^2 L(x^*, \\lambda^*) $ 在切空间上的投影。\r步骤 5：正定性结论\r若 $ \\nabla_{xx}^2 L(x^*, \\lambda^*) $ 在切空间上正定，则 $ H_f(u^*) $ 正定，故 $ u^* $ 是 $ f(u) $ 的严格局部极小点，对应 $ x^* $ 为 $ F(x) $ 在约束 $ g(x) = 0 $ 下的严格局部极小点。\r结论\r当拉格朗日函数 $ L(x, \\lambda) $ 在驻点处的 Hessian 矩阵限制于约束曲面的切空间上正定时，原函数 $ F(x) $ 在该点取得局部极小值。这由二阶充分条件保证，其核心在于参数化后的无约束问题中，Hessian 的正定性与拉格朗日 Hessian 的投影正定性一致。\r（详细步骤解释）在约束优化问题中，关键是将带约束的优化转化为无约束优化，并分析参数化后函数的二阶导数。下面详细解释为什么参数化后的Hessian矩阵 $ H_f(u^*) $ 等于拉格朗日函数Hessian在切空间上的投影。\r1. 参数化函数的二阶导数\r设约束曲面 $ g(x) = 0 $ 在 $ x^* = (u^*, v^*) $ 附近局部可表示为 $ v = G(u) $，其中 $ u \\in \\mathbb{R}^m $，$ v \\in \\mathbb{R}^n $。参数化目标函数为：\r$$\rf(u) = F(u, G(u)).\r$$\r其Hessian矩阵 $ H_f(u) $ 的完整表达式为：\r$$\rH_f(u) = \\underbrace{\\nabla_{uu}^2 F}_{\\text{直接项}} + \\underbrace{\\nabla_{uv}^2 F \\cdot DG + DG^T \\cdot \\nabla_{vu}^2 F}_{\\text{交叉项}} + \\underbrace{DG^T \\cdot \\nabla_{vv}^2 F \\cdot DG}_{\\text{二次项}} + \\underbrace{\\nabla_v F \\cdot D^2 G}_{\\text{隐函数二阶项}}.\r$$\r其中 $ DG = \\frac{\\partial G}{\\partial u} $，$ D^2 G $ 为 $ G $ 的二阶导数。\r2. 隐函数定理的二阶导数公式\r由于 $ g(u, G(u)) = 0 $，对两边求导可得：\r$$\r\\nabla_u g + \\nabla_v g \\cdot DG = 0 \\implies DG = -[\\nabla_v g]^{-1} \\nabla_u g.\r$$\r进一步对 $ u $ 求导，得到 $ D^2 G $：\r$$\rD^2 G = -[\\nabla_v g]^{-1} \\left( \\nabla_{uu}^2 g + \\nabla_{uv}^2 g \\cdot DG + DG^T \\cdot \\nabla_{vu}^2 g + DG^T \\cdot \\nabla_{vv}^2 g \\cdot DG \\right).\r$$\r注意这里用到了链式法则和隐函数定理的二阶展开。\r3. 代入拉格朗日条件\r在驻点 $ x^* $，一阶条件为：\r$$\r\\nabla_x L = \\nabla F - \\lambda^* \\nabla g = 0 \\implies \\nabla F = \\lambda^* \\nabla g.\r$$\r具体分块为：\r$$\r\\nabla_u F = \\lambda^* \\nabla_u g, \\quad \\nabla_v F = \\lambda^* \\nabla_v g.\r$$\r利用这一关系，我们可以将参数化Hessian中的 $ \\nabla_v F \\cdot D^2 G $ 项替换为 $ \\lambda^* \\nabla_v g \\cdot D^2 G $。\r4. 显式展开参数化Hessian\r将 $ D^2 G $ 的表达式代入 $ H_f(u^*) $，并利用一阶条件：\r$$\r\\nabla_v F \\cdot D^2 G = -\\lambda^* \\left( \\nabla_{uu}^2 g + 2 \\nabla_{uv}^2 g \\cdot DG + DG^T \\cdot \\nabla_{vv}^2 g \\cdot DG \\right).\r$$\r因此，参数化Hessian可写为：\r$$\rH_f(u^*) = \\nabla_{uu}^2 F + 2 \\nabla_{uv}^2 F \\cdot DG + DG^T \\cdot \\nabla_{vv}^2 F \\cdot DG - \\lambda^* \\left( \\nabla_{uu}^2 g + 2 \\nabla_{uv}^2 g \\cdot DG + DG^T \\cdot \\nabla_{vv}^2 g \\cdot DG \\right).\r$$\r观察到：\r$$\rH_f(u^*) = \\left[ \\nabla_{uu}^2 F + 2 \\nabla_{uv}^2 F \\cdot DG + DG^T \\cdot \\nabla_{vv}^2 F \\cdot DG \\right] - \\lambda^* \\left[ \\nabla_{uu}^2 g + 2 \\nabla_{uv}^2 g \\cdot DG + DG^T \\cdot \\nabla_{vv}^2 g \\cdot DG \\right].\r$$\r这正是：\r$$\rH_f(u^*) = \\left[ \\nabla_{xx}^2 F - \\lambda^* \\nabla_{xx}^2 g \\right] \\bigg|_{(u, G(u))} \\text{在切空间上的投影}.\r$$\r5. 切空间与Hessian投影\r切空间定义：约束曲面 $ g(x) = 0 $ 在 $ x^* $ 处的切空间由满足 $ \\nabla g(x^*) \\cdot h = 0 $ 的向量 $ h \\in \\mathbb{R}^{m+n} $ 构成。\r参数化切向量：在参数化 $ x = (u, G(u)) $ 下，切向量可表示为 $ h = (du, DG \\cdot du) $，其中 $ du \\in \\mathbb{R}^m $。\rHessian的作用：对任意切向量 $ h $，有：\r$$\rh^T \\cdot \\nabla_{xx}^2 L \\cdot h = h^T \\cdot (\\nabla_{xx}^2 F - \\lambda^* \\nabla_{xx}^2 g) \\cdot h.\r$$\r这正是参数化Hessian $ H_f(u^*) $ 的作用方式。\r6. 关键结论\r参数化后的Hessian $ H_f(u^*) $ 与拉格朗日Hessian $ \\nabla_{xx}^2 L $ 在切空间上的投影完全一致。因此：\r- 若 $ \\nabla_{xx}^2 L $ 在切空间上正定，则 $ H_f(u^*) $ 正定。\r- 由无约束优化的二阶充分条件，$ u^* $ 是 $ f(u) $ 的严格局部极小点，对应 $ x^* $ 为原问题的严格局部极小点。\r总结图示\r$$\r\\boxed{\r\\begin{aligned}\r\u0026\\text{参数化Hessian } H_f(u^*) \\\\\\ \u0026= \\text{拉格朗日Hessian } \\nabla_{xx}^2 L \\text{ 在切空间上的投影} \\\\\\ \u0026= \\left[ \\nabla_{xx}^2 F - \\lambda^* \\nabla_{xx}^2 g \\right] \\bigg|_{\\text{切向量 } h = (du, DG \\cdot du)}.\r\\end{aligned}\r}\r$$\r这里有另一个问题是，既然已知“$\\mathcal{L}$ 在某个驻点处关于 $\\b x$ 的 Hessian 局限在该点约束曲面的切空间上正定，则对应 $F(\\b x)$ 是约束曲面上的极小值点”，那么是否有“$F(\\b x)$ 在 $\\cal L$ 驻点对应的 $\\b x$ 处的 Hessian 局限在该点约束曲面的切空间上正定，则对应 $F(\\b x)$ 是约束曲面上的极小值点”？\n答案应该是否定的，具体反例不太会构造。\n广义含参积分 几个换序定理的条件（继累次极限交换以及 Clairaut）：\n$f$ 连续，$g(\\b x)=\\int_a^bf(t,\\b x)\\d t$，则 $g$ 连续。\n$f_{x_i}$ 连续，$g(\\b x)=\\int_a^bf(t,\\b x)\\d t$，则 $g_{x_i}(\\b x)=\\int_a^bf_{x_i}(t,\\b x)\\d t$ 且连续。\n$f$ 连续，则 $\\int_c^d\\int_a^bf(t,x)\\d t\\d x=\\int_a^b\\int_c^df(t,x)\\d x\\d t$。\n$f$ 连续，$g(\\b x)=\\int_a^\\omega f(t,\\b x)\\d t$ 一致收敛，则 $g$ 连续。\n用连续的定义，将 $\\int_a^\\omega f(t,\\b x)\\d t-\\int_a^\\omega f(t,\\b x_0)\\d t$ 拆成 $\\int_a^b(f(t,\\b x)-f(t,\\b x_0))\\d t$、$\\int_b^\\omega f(t,\\b x_0)\\d t$、$\\int_b^\\omega f(t,\\b x)\\d t$ 三部分放缩。\n$f$ 连续，$\\int_a^\\omega f(t,x)\\d t$ 一致收敛，则 $\\int_c^d\\int_a^\\omega f(t,x)\\d t\\d x=\\int_a^\\omega\\int_c^df(t,x)\\d x\\d t$。\n$\\int_c^d\\int_a^\\omega\\gets\\int_c^d\\int_a^b=\\int_a^b\\int_c^d\\to\\int_a^\\omega\\int_c^d$。\n$f_{x_i}$ 连续，$g(\\b x)=\\int_a^\\omega f(t,\\b x)\\d t$（某单点）收敛，$\\int_a^\\omega f_{x_i}(t,\\b x)\\d t$ 一致收敛，则 $g_{x_i}(\\b x)=\\int_a^\\omega f_{x_i}(t,\\b x)\\d t$ 且连续。\n用定义拆导数，$f(t,\\b x+s\\b e_i)-f(t,\\b x)$ 写成积分，用 5 换序。\n叙述广义积分的一致 Cauchy 条件，并证明 Weierstrass 判别法。（14-20~14-22）\n说明含参积分不一致收敛的几个方法：定义的否命题、一致 Cauchy 条件的否命题、一致收敛 $\\Rightarrow$ 连续的逆否命题。\n关于几个一致收敛判别法的对比（严格证明：https://zhuanlan.zhihu.com/p/700675944）：\n展开\r1. Cauchy 准则（引理）\r定理：$\\int_a^{+\\infty} f(x) \\d x $ 收敛 $\\Longleftrightarrow$ $\\forall \\epsilon \u003e 0$，$\\exists N \u003e a $，$\\forall b, c \u003e N $，$\\left| \\int_b^c f(x) \\d x \\right| \u003c \\epsilon $。\r一致版本：$\\int_a^{+\\infty} f(x, \\theta) \\d x $ 对 $\\theta$ 一致收敛 $\\Longleftrightarrow$ $\\forall \\epsilon \u003e 0$，$\\exists N \u003e a $，$\\forall b, c \u003e N $，$\\forall\\theta$，$\\left| \\int_b^c f(x, \\theta) \\d x \\right| \u003c \\epsilon $。\r2. 比较判别法。\r定理：若 $ |f(x)| \\leq M(x) $ 且 $\\int_a^{+\\infty} M(x) \\d x $ 收敛，则 $\\int_a^{+\\infty} f(x) \\d x $ 绝对收敛。\r证明：对任意 $ b \u003e a $，有 $\\int_a^b |f(x)| \\d x \\leq \\int_a^b M(x) \\d x \\leq \\int_a^{+\\infty} M(x) \\d x $，故 $\\int_a^{+\\infty} |f(x)| \\d x $ 收敛。\r一致版本（Weierstrass 判别法）：若 $ |f(x, \\theta)| \\leq M(x,\\theta) $ 且 $\\int_a^{+\\infty} M(x,\\theta)\\d x $ 对 $\\theta$ 一致收敛，则 $\\int_a^{+\\infty} f(x, \\theta)\\d x $ 对 $\\theta$ 一致收敛。\r证明：由一致收敛的 Cauchy 准则，$\\forall\\epsilon \u003e 0$，$\\exists N \u003e a $，$\\forall b, c \u003e N $，$\\forall \\theta$，$\\int_b^c M(x,\\theta) \\d x \u003c \\epsilon $。从而 $\\left| \\int_b^c f(x, \\theta) \\d x \\right| \\leq \\int_b^c |f(x, \\theta)| \\d x \\leq \\int_b^c M(x,\\theta) \\d x \u003c \\epsilon $，与 $\\theta$ 无关。\r3. Dirichlet 判别法\r定理：设 $ f(x) $ 和 $ g(x) $ 满足 $ F(b) = \\int_a^b f(x) \\d x $ 有界，$g(x)$ 单调且 $\\to 0$，则 $\\int_a^{+\\infty} f(x)g(x) \\d x $ 收敛。\r证明：分部积分得：$\\int_a^b f(x)g(x) \\d x = F(b)g(b) - F(a)g(a)-\\int_a^b F(x)g^\\prime(x) \\d x $。当 $ b \\to +\\infty $，第一项 $ F(b)g(b) \\to 0 $（因 $ g(b) \\to 0 $），第二项因 $ |F(x)| \\leq C $ 且 $ \\int_a^{+\\infty} g^\\prime(x) \\d x=-g(a)$，故绝对收敛。\r一致版本：设 $ f(x, \\theta) $ 和 $ g(x, \\theta) $ 满足 $F(b,\\theta)=\\int_a^b f(x, \\theta) \\d x $ 对 $\\theta$ 一致有界，$ g(x, \\theta) $ 关于 $ x $ 单调且 $ g(x, \\theta) \\to 0 $ 对 $\\theta$ 一致收敛，则 $\\int_a^{+\\infty} f(x, \\theta)g(x, \\theta) \\d x $ 一致收敛。\r证明：$F(b,\\theta)g(b,\\theta)$ 是一致有界乘一致收敛，所以一致收敛；$\\int_a^bF(x,\\theta)g^\\prime(x,\\theta)\\d x$ 把 $F$ 提出来也是一致有界乘一致收敛。\r4. Abel 判别法\r定理：设 $ f(x) $ 和 $ g(x) $ 满足 $\\int_a^{+\\infty} f(x) \\d x $ 收敛，$ g(x) $ 单调有界，则 $\\int_a^{+\\infty} f(x)g(x) \\d x $ 收敛。\r证明：$\\int_a^{+\\infty}f(x)g(x)\\d x=g(+\\infty)\\int_a^{+\\infty}f(x)\\d x+\\int_a^{+\\infty}f(x)(g(x)-g(+\\infty))\\d x$，第一部分收敛，第二部分由 Dirichlet 判别法收敛。\r一致版本：设 $ f(x, \\theta) $ 和 $ g(x, \\theta) $ 满足 $\\int_a^{+\\infty} f(x, \\theta) \\d x $ 对 $\\theta$ 一致收敛，$ g(x, \\theta) $ 关于 $ x $ 单调且对 $\\theta$ 一致有界，则 $\\int_a^{+\\infty} f(x, \\theta)g(x, \\theta) \\d x $ 对 $\\theta$ 一致收敛。\r证明：$g(+\\infty,\\theta)\\int_a^{+\\infty}f(x,\\theta)\\d x$ 是一致有界乘一致收敛，后面是一样的。\r重积分 高维矩形 $I$ 上的 Lebesgue 准则：$f$ Riemann 可积 $\\Longleftrightarrow$ $f$ 有界且 Darboux 可积 $\\Longleftrightarrow$ $f$ 有界且间断点测度为零。\n写出高维情况下，零测度的定义。（15-12）\n证明：对 $I=[a,b]\\times[\\alpha,\\beta]$ 上的连续函数 $f$，（15-13） $$ \\iint_I f(x,y)\\d x\\d y=\\int_a^b\\int_\\alpha^\\beta f(x,y)\\d y\\d x=\\int_\\alpha^\\beta\\int_a^b f(x,y)\\d x\\d y $$\n提示\r将重积分写成\r$$\\lim\\sum_{i,j}f(\\xi_{i,j},\\eta_{i,j})\\Delta x_i\\Delta y_j$$\r的形式，然后利用 $\\sum$ 的交换律得到后两种积分。\r一般情况（Fubini 定理）：https://zhuanlan.zhihu.com/p/695338328、https://zhuanlan.zhihu.com/p/668687961。这里值得注意的点是，广义积分的情况要求绝对可积。\n证明：$\\p A$ 是闭的。（15-23）\n对于一般区域 $A$ 上的积分，是通过乘上示性函数，转化为矩形上的积分来定义的。如果有界 $f:A\\to\\R$ 的间断点为零测集，且 $\\p A$ 为零测集，则 $\\int_A f\\d x$ 有定义。（15-24）\n通过换元的方式，将以下积分变成 $[0,1]^3$上的积分：（15-34） $$ \\iiint_{x,y,z\\ge 0,\\|(x,y,z)\\|\\le 1}xyz\\d x\\d y\\d z $$\n理一下重积分换元的逻辑：假设有一个映射（微分同胚）$f:U\\to V$，那么一个小区域 $I$ 经过 $f$ 映射后，体积变为 $\\lvert\\det\\J f\\rvert$ 倍。这意味着，在 $V$ 中的区域的积分 $\\int_V w(\\b x)\\d v$，如果要换到 $U$ 中，就需要逐点乘上这个伸缩倍数，也就是 $\\int_U w(f(\\b t))\\lvert\\det\\J f(\\b t)\\rvert\\d v$。换句话说，这个换元的逻辑关系是逆过来的，或者说可以记忆为，重积分换元的标准形式是第二类换元法，其中 $f^\\prime(t)$ 变为了 $\\lvert\\det\\J\\rvert$。如果要用第一类换元法，就是把同胚逆过来，用第二类换元法。\n给出以下重积分的换元，使得区域变为矩形：（16-21） $$ \\iint_{(x^2-y^2,2xy)\\in[a,b]\\times[\\alpha,\\beta]}f(x,y)\\d x\\d y $$\n求 $\\iint_D(x^2+y^2+1)^{-2}\\d x\\d y$，其中 $D$ 为圆心在 $(1,1)$ 且经过原点的圆盘。（16-26）\n计算 $\\int_{[0,1]^m}\\min\\set{x_1,\\cdots,x_n}\\d x_1\\cdots\\d x_n$。\n曲线曲面积分 证明曲线积分与参数化方法无关。即 $\\gamma$ 的两种参数化方法 $\\b x(s)$、$\\b x(t)$，有（17-5） $$ \\int_\\gamma f(\\b x)\\d l=\\int_a^bf(\\b x(s))\\|\\b x^\\prime(s)\\|\\d s=\\int_\\alpha^\\beta f(\\b x(t))\\|\\b x^\\prime(t)\\|\\d t $$\n根据叉积公式写出二维曲面的面积公式。（17-8）证明与参数选择无关。（17-11）\n证明 $n$ 维空间中的 $k$ 维体的体积，可以由它 $k$ 条边的向量的度量矩阵开根算出。（17-12~17-15）\n提示\r考虑 Gram-Schmidt 正交化，归纳法。\r求 $n$ 维超曲面 $x^{n+1}=f(x^1,\\cdots,x^n)$ 的面积公式，利用 3。（17-19~17-20）\n利用上面的方法，严格说明三维旋转体的表面积公式 $\\int 2\\pi y\\sqrt{1+(y^\\prime)^2}\\d x$。（17-26~17-27）\n说明曲面维数和背景空间维数相同时，积分系数即为换元系数。（16-16）\n总结：第一类曲线/曲面积分： $$ \\int_Df(\\b x)\\d v=\\int_Df(\\b x)\\sqrt{\\det\\left(\\ip{\\frac{\\p\\b x}{\\p t_i},\\frac{\\p\\b x}{\\p t_j}}\\right)}\\d t_1\\cdots\\d t_k $$\n说明做功、环量、通量都可以写成以下形式：（18-7~18-9） $$ \\int_\\gamma\\b F\\cdot\\d\\b l=\\int_a^b\\b F(\\b x(t))\\cdot\\b x^\\prime(t)\\d t=\\int_a^b\\sum_i\\b F^i(\\b x(t))\\d\\b x^i(t) $$\n一阶微分形式的定义？一阶微分形式的积分的定义？（18-12）\n答案\r一阶微分形式 $\\omega$ 是一个从向量场到函数的映射。在区域（严格来说是微分流形）$R$ 上，$\\omega$ 将一个定义在 $R$ 上各点的向量函数（可以理解为每个点上的切向量）映射到定义在 $R$ 上各个点的实函数，这里对于单个点来说，向量到实数的映射是线性的。如果要取向量场 $\\b v$ 经过 $\\omega$ 后某一点 $\\b x$ 处的结果，写作 $\\omega(\\b v)(\\b x)$ 或 $\\omega(\\b x)\\b v$。\r$\\int_\\gamma\\omega$ 定义为 $\\int_a^b\\omega(\\b x(t))(\\b x^\\prime(t))\\d t$，其中 $\\b x(t)$ 是 $\\gamma$ 的参数化表示。\r值得注意的是，对于 $f:\\R^n\\to\\R$，$\\D f$ 也是个一阶微分形式，但 $\\D f(\\b x_0)$ 只是一个线性泛函。\r说明 $\\int_\\gamma\\omega$ 与（保方向）参数化表达选取无关。（18-13）\n保守场的定义？（18-18）无旋场的定义？（18-24）\n证明梯度场是保守场。（18-16） 证明保守场是梯度场。（18-19） 证明保守场是无旋场。（18-23） 说明什么时候无旋场不是保守场。（18-31） 求第二类曲线积分的方法是：首先先尝试凑全微分。剩下凑不了的部分，参数化之后暴力积。\n注意凑出全微分后还要保证区域单连通。\n求 $\\int_\\gamma(z\\d x+x\\d y+y\\d z)$，其中 $\\gamma$ 为 $\\set{x^2+y^2+z^2=R^2}\\cap\\set{x+y+z=0}$ 在 $xy$ 平面上的投影，逆时针。（18-28）\n证明 $\\int_\\gamma x\\d y=-\\int_\\gamma y\\d x=\\frac12\\int_\\gamma(x\\d y-y\\d x)$。（18-29）\n拉回的概念：对于 $\\Phi:A(\\subseteq\\R^m)\\to B(\\subseteq\\R^n)$，它的微分 $\\D\\Phi$（记为 $\\Phi_*$）在 $A$ 的每一个点上定义了一个 $\\R^m\\to\\R^n$ 的线性映射（或者也可以理解为将 $A$ 上的向量场映到 $B$ 上的向量场），就是切向量的线性映射。$\\Phi$ 的拉回 $\\Phi^*$ 定义了 $\\Omega^1(B)\\to\\Omega^1(A)$ 的线性映射，这个线性映射将 $B$ 上的一阶微分形式 $\\omega$ 映射成这样的一个 $\\R^m$ 上的微分形式：拿到一个向量场，将它先依据 $\\Phi_*$ 映到 $\\R^m$ 上，再应用 $\\omega$。直观地说，就是 $\\omega$ 对应 $B$ 上积分时的“权重函数”，$\\Phi^*(\\omega)$ 就是 $A$ 上积分时对应的权重。它首先将 $A$ 上切向量微元对应到 $B$ 上，再应用原来的权重。用数学语言来说就是，对于一个 $A$ 上的向量场 $\\b v$， $$ \\Phi^*(\\omega)(\\b v)(\\b x)=\\omega(\\Phi_*(\\b v))(\\b x) $$ （这里 $\\Phi_*$ 用的是括号里的定义，就是向量场之间的映射，注意笔记和课件的其他地方一般不会用这种方式看待微分，所以微分后面的括号里一般写的是个位置而不是向量场）\n拉回严格定义了第二类曲线积分的换元方式： $$ \\int_{\\Phi(\\gamma)}\\omega=\\int_\\gamma\\Phi^*(\\omega) $$ 证明： $$ \\begin{align*} \\int_\\gamma\\Phi^*(\\omega)\u0026amp;=\\int_a^b\\Phi^*(\\omega)(\\b x^\\prime)(\\b x(t))\\d t\\\\ \u0026amp;=\\int_a^b\\omega(\\Phi_*(\\b x^\\prime))(\\b x(t))\\d t\\\\ \u0026amp;=\\int_a^b\\sum_i F^i(\\Phi(\\b x(t)))(\\D\\Phi)(\\b x^\\prime)(\\b x(t))^i\\d t\\\\ \u0026amp;=\\int_a^b\\sum_i F^i(\\b y(t))\\b y^\\prime(t)^i\\d t\\\\ \u0026amp;=\\int_a^b\\omega(\\b y^\\prime)(\\b y(t))\\d t\\\\ \u0026amp;=\\int_{\\Phi(\\gamma)}\\omega \\end{align*} $$ 其中 $\\b y(t)=\\Phi(\\b x(t))$，而 $\\b y^\\prime(t)=\\D\\Phi(\\b x(t))\\cdot\\b x^\\prime(t)$，如果把 $\\D\\Phi$ 理解成向量场之间的映射，就是 $\\D\\Phi(\\b x^\\prime)(\\b x(t))$。\n对于 18-39~18-45 的例子，$\\Phi$ 是从 $(\\xi,\\eta,\\zeta)$ 到 $(x,y,z)$ 的映射，为了计算 $\\Phi^*(z\\d x+x\\d y+y\\d z)$，把 $\\xi,\\eta,\\zeta$ 代入展开即可。\n证明一个 $\\R^2\\to\\R^2$ 的线性函数（$\\R^2$ 上的 $\\R^2$ 向量场）可以拆成一个无旋场和一个无源场之和。（19-5）\n证明：对于一个矩形 $R$ 而言，$\\int_{\\p R}X\\d x+Y\\d y=\\iint_R(Y_x-X_y)\\d x\\d y$。（19-9）\n同理可以证明 $\\int_{\\p R}(-Y\\d x+X\\d y)=\\iint_R(X_x+Y_y)\\d x\\d y$。写出由这两个式子给出的旋度和散度的另一种表达式。\n二阶微分形式将两个向量场映到一个标量场。写出斜积的定义。（19-21）\n超曲面定义为维数比背景空间维数小 $1$ 的曲面。对于隐函数 $F(\\b x)=0$（$0$ 是 $F$ 的正则值），它定义了一个可定向的超曲面。法向量场为 $\\nabla F$ 单位化的结果。利用这个结果证明：\n可微函数的图像是一个可定向曲面。\n答案\r$y=f(\\b x)$ 可以写成 $y-f(\\b x)=0$，它的梯度向量为 $\\mat{-\\nabla f\\\\\\ 1}$。\r正则参数曲面是一个可定向曲面。回顾正则指的是单射且 $\\p\\b x/\\p\\b t$ 列满秩。\n答案\r构造函数 $L(\\b v)=\\dat{\\b v\u0026\\frac{\\p\\b x}{\\p\\b t}}$，我们声称 $\\nabla L$ 就是法向量。这是因为，如果代入某个 $\\frac{\\p\\b x}{\\p t_i}=\\b v$，$L(\\b v)$ 就等于 $0$ 了，在笛卡尔坐标系下，这就说明 $\\nabla L$ 与所有 $\\frac{\\p\\b x}{\\p t_i}$ 内积为 $0$，即垂直。$\\nabla L$ 是线性函数，从而是连续的。\r计算高维超曲面通量的方法：首先记 $\\b A=\\nabla L$，面积微元在数值上等于单位高度的体积，也就是 $$ L(\\b{\\hat A})=\\dat{\\frac{\\b A_1}{|\\b A|}\u0026amp;\\frac{\\p\\b x_1}{\\p t_1}\u0026amp;\\cdots\u0026amp;\\frac{\\p\\b x_1}{\\p t_m}\\\\ \\vdots\u0026amp;\\vdots\u0026amp;\\ddots\u0026amp;\\vdots\\\\ \\frac{\\b A_{m+1}}{|\\b A|}\u0026amp;\\frac{\\p\\b x_{m+1}}{\\p t_1}\u0026amp;\\cdots\u0026amp;\\frac{\\p\\b x_{m+1}}{\\p t_m}}=\\sum_{i=1}^{m+1}\\frac{\\b A_i^2}{|\\b A|}=|\\b A| $$\n$$ \\begin{align*} \\int_\\Omega\\b V\\cdot\\b n\\d S\u0026amp;=\\int_T\\b V\\cdot\\frac{\\b A}{|\\b A|}(|\\b A|\\d t_1\\cdots\\d t_m)\\\\ \u0026amp;=\\int_T\\b V\\cdot\\b A\\d t_1\\cdots\\d t_m\\\\ \u0026amp;=\\int_T\\dat{\\b V_1\u0026amp;\\frac{\\p\\b x_1}{\\p t_1}\u0026amp;\\cdots\u0026amp;\\frac{\\p\\b x_1}{\\p t_m}\\\\ \\vdots\u0026amp;\\vdots\u0026amp;\\ddots\u0026amp;\\vdots\\\\ \\b V_1\u0026amp;\\frac{\\p\\b x_{m+1}}{\\p t_1}\u0026amp;\\cdots\u0026amp;\\frac{\\p\\b x_{m+1}}{\\p t_m}}\\d t_1\\cdots\\d t_m \\end{align*} $$\n其中 $T$ 为参数的定义域。证明这个计算与参数化表达的选择无关。（20-17）\n三维中二阶微分形式的定义：\n对于一个二阶微分形式 $\\omega=X\\d y\\w\\d z+Y\\d z\\w\\d x+Z\\d x\\w\\d y$，对于定向曲面 $\\Sigma$ 上 $\\omega$ 的积分，这里通过参数化表达来定义。设参数化表达为 $(x,y,z)=(x(u,v),y(u,v),z(u,v))$，其中通过 $\\nabla\\det\\left(\\b v,\\frac{\\p(x,y,z)}{\\p(u,v)}\\right)$ 得到的法向量和 $\\Sigma$ 的定向一致（否则需要加负号），那么 $$ \\iint_\\Sigma\\omega=\\iint_D\\left(X\\det\\frac{\\p(y,z)}{\\p(u,v)}+Y\\det\\frac{\\p(z,x)}{\\p(u,v)}+Z\\det\\frac{\\p(x,y)}{\\p(u,v)}\\right)\\d u\\d v $$ 如果觉得难理解的话，可以以换元的角度来看。例如 $$ \\d y\\w\\d z(u,v)=\\det\\frac{\\p(y,z)}{\\p(u,v)} $$ 以及 $$ \\d y\\w\\d z=(y_u\\d u+y_v\\d v)\\w(z_u\\d u+z_v\\d v)=(y_uz_v-y_vz_u)\\d u\\w\\d v $$ 而在一致定向的情况下，$\\iint\\d u\\w\\d v=\\iint\\d u\\d v$，也就是说，我们将微分形式的积分转换成黎曼积分。\n二维曲面通量积分与二阶微分形式积分的关系：注意到 $$ \\iint_\\Sigma\\b V\\cdot\\b n\\d S=\\iint_D\\dat{\\b V_x\u0026amp;x_u\u0026amp;x_v\\\\ \\b V_y\u0026amp;y_u\u0026amp;y_v\\\\ \\b V_z\u0026amp;z_u\u0026amp;z_v}\\d u\\d v=\\iint_\\Sigma\\omega $$\n证明：任意微分形式 $\\omega$，$\\d(\\d\\omega)=0$。\n答案\r$$\r\\begin{align*}\r\\d\\omega\u0026=\\sum_{i_1,\\cdots,i_m}\\left(\\sum_{i=1}^n\\frac{\\p F_{i_1,\\cdots,i_m}}{\\p x_i}\\d x_i\\right)\\w\\d x_{i_1}\\w\\cdots\\w\\d x_{i_m}\\\\\\ \\d(\\d\\omega)\u0026=\\sum_{i_1,\\cdots,i_m}\\left(\\sum_{i=1}^n\\sum_{j=1}^n\\frac{\\p F_{i_1,\\cdots,i_m}}{\\p x_j\\p x_i}\\d x_j\\w\\d x_i\\right)\\w\\d x_{i_1}\\w\\cdots\\w\\d x_{i_m}\r\\end{align*}\r$$\r其中 $x_i$ 和 $x_j$ 可互换，正负抵消；$i=j$ 的时候 $\\d x_j\\w\\d x_i=0$。\r顺带一提，对于 $n-1$ 阶微分形式，它的外微分是 $\\tr\\frac{\\p\\b F}{\\p\\b x}x_1\\w\\cdots\\w x_n$。\n三维的 Gauss 公式证明大致思路：将体拆成一堆小块，每个小块侧面是悬崖，每个 $(x,y)$ 对应一个 $z$ 区间，不过俯视图不一定是矩形。然后分三个部分，分别会得到 $X_x$，$Y_y$ 和 $Z_z$。做的过程中会得到形似 $\\iint(Z(x,y,g(x,y))-Z(x,y,f(x,y)))\\d x\\d y$ 的，硬把里面一层写成积分即可。\n三维的 Stokes 公式证明思路：考虑把参数化曲面上的一个小正方形，换元变到参数自变量的 $[0,1]^2$，然后利用二维 Green 公式，再变回去。用微分形式的语言来说，就是 $$ \\iint_{\\p\\Sigma_k}\\omega=\\iint_{\\p[0,1]^2}\\Phi^*(\\omega)\\xlongequal{\\text{Green}}\\iint_{[0,1]^2}\\d\\Phi^*(\\omega)\\xlongequal{?}\\iint_{[0,1]^2}\\Phi^*(\\d\\omega)=\\iint_{\\Sigma_k}\\d\\omega $$ 证明 $\\d\\Phi^*=\\Phi^*\\d$ 可以直接展开 $\\Phi$ 和 $\\d$ 的定义，问题不大。（21-25）\n微分形式统一 Stokes 公式： $$ \\begin{array}{} \\Omega^0\u0026amp;{}\\xrightarrow{\\quad\\d\\quad}{}\u0026amp;\\Omega^1\u0026amp;{}\\xrightarrow{\\quad\\d\\quad}{}\u0026amp;\\Omega^2\u0026amp;{}\\xrightarrow{\\quad\\d\\quad}{}\u0026amp;\\Omega^3\\\\ f\u0026amp;\u0026amp;X\\d x+Y\\d y+Z\\d z\u0026amp;\u0026amp;X\\d y\\w\\d z+Y\\d z\\w\\d x+Z\\d x\\w\\d y\u0026amp;\u0026amp;f\\d x\\w\\d y\\w\\d z\\\\ f\u0026amp;{}\\xrightarrow{\\quad\\nabla\\quad}{}\u0026amp;\\b V\u0026amp;{}\\xrightarrow{\\quad\\nabla\\times\\quad}{}\u0026amp;\\b V\u0026amp;{}\\xrightarrow{\\quad\\nabla\\cdot\\quad}{}\u0026amp;f\\\\ \u0026amp;\\displaystyle f|_{\\p\\Gamma}=\\int_\\Gamma\\nabla f\\cdot\\d\\b x\u0026amp;\u0026amp;\\displaystyle\\oint_{\\p\\Sigma}\\b V\\cdot\\d\\b l=\\iint_\\Sigma(\\nabla\\times\\b V)\\cdot\\d\\b s\u0026amp;\u0026amp;\\displaystyle\\oiint_{\\p\\Omega}\\b V\\cdot\\d\\b s=\\iiint_\\Omega\\nabla\\cdot\\b V\\d v \\end{array} $$\n级数 注意以下涉及到绝对值的地方都可以换成范数。\n写出级数收敛的 Cauchy 准则。（22-18）推论：收敛的必要条件是 $|u_n|\\to 0$，注意这个对积分不一定成立。\n证明 $\\sum n^{-x}$ 收敛当且仅当 $x\u0026gt;1$。（22-21）\n写出积分判别法，并证明。（22-23）\n写出比较判别法，并证明。（22-32）\n幂级数的收敛是怎样刻画的？（22-33）\n提示\r${\u003c{}}r$ 收敛，$=r$ 不知道，$\u003er$ 发散。考虑使用比较判别法证明。\r$a_n\\le b_n\\le c_n$，若 $\\sum a_n$ 和 $\\sum c_n$ 都收敛，则 $\\sum b_n$ 收敛。进一步，若 $\\sum a_n$ 或 $\\sum c_n$ 绝对收敛，则全都绝对收敛。证明？（22-36）\n提示\r考虑 $b_n-a_n$、$c_n-a_n$，以及比较判别法、收敛的线性性。\r写出 D'Alembert 判别法，并证明。（22-37）\n写出 Cauchy 判别法，并证明。（22-38）\n第一种的优势是比值容易求，第二种的优势在于可以处理 $1/2,1/3,1/2^2,1/3^2,\\cdots$ 这种有震荡的情况。\n利用 Cauchy 判别法写出幂级数的收敛半径的表达式。（32-44）幂级数求导、积分后的幂级数收敛半径不变。\n写出 Raabe 判别法，并证明。（22-48）Raabe 判别法的思想是：已知 $\\sum n^{-x}$ 的收敛半径，注意到 $(n+1)^x/n^x=1+x/n+\\omicron(1/n)$，所以我们可以关注 $n^{-1}$ 项的系数。\n写出 Leibniz 判别法，并证明。（23-3）\n分析 $\\sum\\frac{(-1)^{n-1}}{n^\\alpha+(-1)^{n-1}}$ 在不同 $\\alpha$ 下的收敛情况。（23-7）\n写出 Dirichlet 与 Abel 判别法，并证明。（23-11~23-13）\n分析 $\\sum\\frac{z^n}{n^\\alpha}$ 的收敛情况。（23-14）\n证明条件收敛的实数级数不满足交换律，换句话说可以通过重排项得到任何收敛值（包括 $\\pm\\infty$）或震荡。（23-17~23-21）\n证明绝对收敛的级数满足交换律。（23-22~23-23）\n如果一个级数加括号之后收敛，且它单项 $\\to 0$，则它本身也不一定收敛。考虑 $1-1+\\frac12+\\frac12-\\frac12-\\frac12+\\frac13+\\frac13+\\frac13-\\frac13-\\frac13-\\frac13+\\cdots$。只有每个括号内的符号相同才能保证原级数收敛。\n注意条件收敛指的就是收敛不绝对收敛。\n绝对收敛和一致收敛是无关的。（ylj 26-55）\n对于函数项级数 $\\sum u_n(x)\\to S(x)$，证明如果在 $x\\to a$ 时 $S(x)\\to+\\infty$，那它在 $(a,b]$ 上不一致收敛。\n然而逆命题是不对的，给出一个反例，$S(x)$ 在 $[a,b]$ 上连续，然而在 $(a,b]$ 上不一致收敛。\ninsane counterexample: ylj 26-67\n如何说明函数项级数在某个区间上不一致收敛？（24-3）\n函数项级数 $\\sum u_n(x)\\overset I\\rightrightarrows S(x)$，证明 $S(x)$ 保持有界性与连续性；若每项都可积，则 $S(x)$ 可积。（24-14~24-15）\n证明：若导数的级数一致收敛且原级数单点收敛，则原函数一致收敛且 $S(x)$ 可导。（24-16~24-17）\n如何说明每个 Taylor 级数都对应多个 $\\mathscr{C}^\\infty$ 函数？\n提示\r考虑函数 $f(x)=\\begin{cases}\\e^{-1/x^2},\u0026x\\ne 0\\\\\\ 0,\u0026x=0\\end{cases}$\r说明一个幂级数的封闭形式是某个函数的方法：构造微分方程，利用初值问题解的唯一性。\n傅里叶级数 $\\sum_n\\frac{\\sin nx}n$ 这类级数的求法：首先由于 $$ \\sum_{n\\le N}\\sin nx=\\frac{1}{\\sin\\frac x2}\\sum_{n\\le N}\\sin nx\\sin\\frac x2=\\frac{1}{2\\sin\\frac x2}\\sum_{n\\le N}\\left(\\cos\\left(n-\\frac12\\right)x-\\cos\\left(n+\\frac12\\right)x\\right)=\\frac{\\cos\\frac x2-\\cos(N+\\frac 12)x}{2\\sin\\frac x2}=\\frac{\\sin\\frac{(N+1)x}2\\sin\\frac{Nx}2}{\\sin\\frac x2} $$ 有界，故由 Dirichlet，它收敛，且在 $x$ 的取值范围不包含（接近）$2k\\pi$ 时一致收敛。其次 $$ \\sum_{n\\le N}\\frac{\\sin nx}{n}=\\sum_{n\\le N}\\int_\\pi^x\\cos nt\\d t=\\int_\\pi^x\\sum_{n\\le N}\\cos nt\\d t=\\int_\\pi^x\\frac{\\sin(N+\\frac12)t-\\sin\\frac t2}{2\\sin\\frac t2}\\d t\\to\\frac{\\pi-x}{2} $$ 其中 $\\int\\sin(N+\\frac 12)t\\d t$ 这个东西可以通过一次分部积分让分母出来一个 $2N+1$，所以 $\\to 0$。\n对于 $x=2k\\pi$ 显然和为 $0$。\n上面那个 $\\to 0$ 有个一般的定理，就是 Riemann-Lebesgue 引理： $$ \\lim_{n\\to\\infty}\\int_a^bf(x)g(nx)\\d x=\\frac1T\\left(\\int_a^bf(x)\\d x\\right)\\left(\\int_0^Tg(x)\\d x\\right) $$\n写出 $\\mathscr{L}^p(I)$ 函数的定义。（26-3）\n傅里叶级数的定义： $$ a_n=\\frac1\\pi\\int_{-\\pi}^{+\\pi}f(x)\\cos nx\\d x,b_n=\\frac1\\pi\\int_{-\\pi}^{+\\pi}f(x)\\sin nx\\d x $$\n$$ f(x)\\textcolor{red}\\sim\\frac{a_0}2+\\sum_{n=1}^{\\infty}(a_n\\cos nx+b_n\\sin nx) $$\n定义内积：$\\ip{f,g}=\\int_{-\\pi}^{+\\pi}f(x)g(x)\\d x$。\nBessel 不等式：根据正交性—勾股定理，已知 $\\sum\\frac{(\\b v\\cdot\\b e_i)^2}{\\b e_i\\cdot\\b e_i}\\le\\|\\b v\\|^2$。对于傅里叶级数的情况，即为（取极限）： $$ \\frac{a_0^2}{2}+\\sum_n(a_n^2+b_n^2)\\le\\frac1\\pi\\int_{-\\pi}^{+\\pi}f(x)^2\\d x $$ Parseval 等式即为上式取等。Parseval 等式与内积形式（两个不同函数）等价。\n对于 $2\\pi$ 周期函数 $f$，Parseval 等式成立等价于 $f$ 的傅里叶级数均方收敛： $$ \\lim_{n\\to\\infty}\\left\\lVert S_n-f\\right\\rVert_2\u0026lt;\\infty $$ 而均方收敛当且仅当 $f\\in\\mathscr{L}^2$。\nRiemann 可积函数一定满足 Parseval 等式，从而均方收敛。证明思路：\n首先证明方波 $f(x)=[x\\bmod 2\\pi\\le L]$ 满足：$a_0=\\frac{L}{\\pi}$，$a_n=\\frac{\\sin nL}{n\\pi}$，$b_n=\\frac{1-\\cos nL}{n\\pi}$。于是 $$ \\frac{a_0^2}{2}+\\sum_n(a_n^2+b_n^2)=\\frac{L^2}{2\\pi^2}+\\sum_n\\frac{2-2\\cos nL}{n^2\\pi^2}\\qquad\\cdots(1) $$ 这里需要计算一个关键的式子： $$ \\sum_n\\frac{\\cos nx}{n^2}=-\\sum_n\\left(\\frac{1}{n^2}+\\int_0^x\\frac{\\sin nt}n\\d t\\right)=\\sum_n\\frac1{n^2}-\\int_0^x\\frac{\\pi-t}2\\d t=\\sum_n\\frac1{n^2}-\\frac{\\pi x}{2}+\\frac{x^2}4 $$ 神秘处理：两边同时关于 $x$ 积分： $$ 0=\\sum_n\\frac1{n^2}\\int_0^{2\\pi}\\cos nx\\d x=2\\pi\\sum_n\\frac{1}{n^2}-\\frac{\\pi^3}3 $$ 故 $\\zeta(2)=\\pi^2/6$， $$ \\sum_n\\frac{\\cos nx}{n^2}=\\frac14x^2-\\frac\\pi2x+\\frac{\\pi^2}6 $$ 代回 $(1)$ 得 $a_0^2/2+\\sum_n(a_n^2+b_n^2)=L/\\pi$，这恰好等于 $\\int_0^{2\\pi}f(x)^2\\d x$。\n满足 Parseval 等式的，正交的两个函数之和也满足。这个通过展开 $f+g$ 和 $f-g$ 积分，然后代回 Bessel 不等式，可得到交叉乘积项 $=0$。\n分段常值函数满足 Parseval 不等式。\n使用分段常值函数逼近 $f$。通过达布积分的方式得到 $f$ 的一个下界分段函数 $g$。于是 $$ \\|f-S_n(f)\\|_2\\le\\|f-S_n(g)\\|_2\\le\\|f-g\\|_2+\\|g-S_n(g)\\|_2 $$ 第一个不等号是最小二乘性质。最后两个距离都可以任意小。\n上述定理说明了 $\\mathscr{L}^2$ 函数和 $\\ell^2$ 函数通过傅里叶级数构成一个等距同构（这里 $\\mathscr{L}^2$ 中两个函数相等当且仅当差的模为 $0$），求积分和求级数可以互相转换。\n证明 $f$ 连续且一致收敛，则傅里叶级数收敛到 $f$。（27-22~27-24）\n提示\r用 $S_n$ 联系 $f$ 和极限 $S$。一方面用均方收敛，一方面用一致收敛。过程中可能要用 Cauchy 不等式在平方和绝对值积分之间转换。最后得到 $\\int|f-S|=0$，再用连续性。\r证明 $\\sum_n n^p(|a_n|+|b_n|)$ 收敛则傅里叶级数是 $\\mathscr{C}^p$ 的。（27-37）\n提示\r归纳。利用导数、极限与函数项级数的交换条件。\r分段连续的情况下（不要求傅里叶级数收敛）， $$ \\int_\\alpha^\\beta f(x)\\d x=\\frac{a_0}2(\\beta-\\alpha)+\\sum_n\\left(a_n\\frac{\\sin n\\alpha-\\sin n\\beta}{n}+b_n\\frac{\\cos n\\beta-\\cos n\\alpha}{n}\\right) $$\n重要定理汇总 判定条件 Cauchy 比较 Dirichlet Abel 广义积分收敛 1 2 3 4 广义含参积分一致收敛 5 6 7 8 数项级数收敛 9 10 11 12 函数项级数一致收敛 13 14 15 16 $\\int_a^\\omega f(x)\\d x$ 收敛当且仅当 $\\forall\\eps\u0026gt;0$，$\\exists b\u0026lt;\\omega$，$\\forall b_2\\ge b_1\u0026gt;b$，$\\left\\lvert\\int_{b_1}^{b_2}f(x)\\d x\\right\\rvert\u0026lt;\\eps$。 若 $\\int_a^\\omega g(x)\\d x$ 收敛且 $\\exists b\u0026lt;\\omega$，$x\\in(b,\\omega)$ 时 $|f(x)|\\le g(x)$，则 $\\int_a^\\omega f(x)\\d x$ 收敛。 若 $\\int_a^bf(x)\\d x$（关于 $b$）有界且 $g(x)$ 单调 $\\to 0$，则 $\\int_a^\\omega f(x)g(x)\\d x$ 收敛。 若 $\\int_a^\\omega f(x)\\d x$ 收敛且 $g(x)$ 单调有界，则 $\\int_a^\\omega f(x)g(x)\\d x$ 收敛。 $\\int_a^\\omega f(x,y) \\d x $ 在 $I$ 上一致收敛当且仅当 $\\forall \\eps\u0026gt; 0$，$\\exists b\u0026lt;\\omega$，$\\forall y\\in I$，$\\forall b_2\\ge b_1 \u0026gt; b$，$\\left| \\int_{b_1}^{b_2} f(x,y) \\d x \\right| \u0026lt; \\eps$。 若 $\\int_a^\\omega g(x,y)\\d x$ 一致收敛且 $\\exists b\u0026lt;\\omega$，$x\\in(b,\\omega)$ 时 $|f(x,y)|\\le g(x,y)$，则 $\\int_a^\\omega f(x,y)\\d x$ 一致收敛。 若 $\\int_a^bf(x,y)\\d x$ 对 $b$ 和 $y$ 一致有界，$g(x,y)$ 关于 $x$ 单调且 $x\\to\\omega$ 时一致 $\\to 0$，则 $\\int_a^\\omega f(x,y)g(x,y)\\d x$ 一致收敛。 若 $\\int_a^\\omega f(x,y)\\d x$ 一致收敛，$g(x,y)$ 关于 $x$ 单调且对 $x$ 和 $y$ 一致有界，则 $\\int_a^\\omega f(x,y)g(x,y)\\d x$ 一致收敛。 $\\sum_na_n$ 收敛当且仅当 $\\forall\\eps\u0026gt;0$，$\\exists N$，$\\forall N_2\\ge N_1\u0026gt;N$，$\\left\\lVert\\sum_{n=N_1}^{N_2}a_n\\right\\rVert\u0026lt;\\eps$。 若正项级数 $\\sum_nb_n$ 收敛且 $\\|a_n\\|=\\Omicron(b_n)$，则 $\\sum_na_n$ 绝对收敛。 若 $\\sum_na_n$ 部分和有界，$b_n$ 单调且 $\\to 0$，则 $\\sum_na_nb_n$ 收敛。 若 $\\sum_na_n$ 收敛，$b_n$ 单调有界，则 $\\sum_na_nb_n$ 收敛。 $\\sum_nf_n(x)$ 在 $I$ 上一致收敛当且仅当 $\\forall\\eps\u0026gt;0$，$\\exists N$，$\\forall x\\in I$，$\\forall N_2\\ge N_1\u0026gt;N$，$\\left\\lvert\\sum_{n=N_1}^{N_2}f_n(x)\\right\\rvert\u0026lt;\\eps$。 若恒正的函数项级数 $\\sum_ng_n(x)$ 一致收敛且 $\\forall x\\in I$，$|f_n(x)|=\\Omicron(g_n(x))$，则 $\\sum_nf_n(x)$ 一致收敛。 若 $\\sum_nf_n(x)$ 部分和一致有界，$g_n(x)$ 关于 $n$ 单调且一致 $\\to 0$，则 $\\sum_nf_n(x)g_n(x)$ 一致收敛。 若 $\\sum_nf_n(x)$ 一致收敛，$g_n(x)$ 关于 $n$ 单调且一致有界，则 $\\sum_nf_n(x)g_n(x)$ 一致收敛。 正项级数. 若部分和有界则收敛。\n积分判别法. 若 $a_n$ 能扩展为减函数 $f:[1,+\\infty)\\to\\R$，则 $\\sum_na_n=\\sum_nf(n)$ 收敛 $\\Longleftrightarrow$ $\\int_1^{+\\infty}f(x)\\d x$ 收敛。\n“夹逼”判别法. 若 $a_n\\le b_n\\le c_n$ 且 $\\sum_na_n$ 与 $\\sum_nc_n$ 都收敛，则 $\\sum_nb_n$ 收敛。若 $\\sum_na_n$ 或 $\\sum_nc_n$ 绝对收敛，则另外两个也绝对收敛。\nD'Alembert. 若 $\\overline\\lim_{n\\to\\infty}\\left\\lvert\\frac{a_{n+1}}{a_n}\\right\\rvert\u0026lt;1$ 则 $\\sum_na_n$ 绝对收敛，若 $\\underline\\lim_{n\\to\\infty}\\left\\lvert\\frac{a_{n+1}}{a_n}\\right\\rvert\u0026gt;1$，则 $\\sum_na_n$ 发散。\nCauchy. 若 $\\overline\\lim_{n\\to\\infty}\\sqrt[n]{|a_n|}\u0026lt;1$ 则 $\\sum_na_n$ 绝对收敛，若 $\\overline\\lim_{n\\to\\infty}\\sqrt[n]{|a_n|}\u0026gt;1$，则 $\\sum_na_n$ 发散。\n幂级数. $\\frac1R=\\overline\\lim_{n\\to\\infty}\\sqrt[n]{|a_n|}$。\nRaabe. 对于正项级数，若 $\\underline\\lim_{n\\to\\infty}n\\left(\\frac{a_n}{a_{n+1}}-1\\right)\u0026gt;1$ 则 $\\sum_na_n$ 收敛，若 $\\overline\\lim_{n\\to\\infty}n\\left(\\frac{a_n}{a_{n+1}}-1\\right)\u0026lt;1$，则 $\\sum_na_n$ 发散。\nLeibniz. 对于单调不增的 $a_n\\ge 0$，$\\sum_n(-1)^na_n$ 收敛仅要求 $a_n\\to 0$。\nHardy. 若 $\\sum_nf_n(x)$ 部分和一致有界，$\\sum_n|g_{n+1}(x)-g_n(x)|$ 一致收敛且 $g_n(x)$ 一致 $\\to 0$，则 $\\sum_nf_n(x)g_n(x)$ 一致收敛。\n换序条件 极限 求导 积分 广义积分 级数 极限 1 求导 2 3 积分 4 5 6 广义积分 7 8 9 10 级数 11 12 13 14 15 若 $\\lim_{y\\to y_0}f(x,y)$ 在 $U(x_0)$ 内一致收敛，$\\lim_{x\\to x_0}f(x,y)$ 在 $U(y_0)$ 内收敛，则 $\\lim_{x\\to x_0}\\lim_{y\\to y_0}f(x,y)$ 与 $\\lim_{y\\to y_0}\\lim_{x\\to x_0}f(x,y)$ 存在且相等。 若 $\\frac{\\p f}{\\p y}(x,y_0)$ 在 $U(x_0)$ 内存在且求导的极限一致收敛，$\\lim_{x\\to x_0}f(x,y)$ 在 $U(y_0)$ 内收敛，则 $\\frac{\\p}{\\p y}\\left(\\lim_{x\\to x_0}f(x,y)\\right)\\big|_{y=y_0}$ 与 $\\lim_{x\\to x_0}\\frac{\\p f}{\\p y}(x,y_0)$ 存在且相等。 若 $\\frac{\\p f}{\\p x\\p y}$ 在 $U(x_0,y_0)$ 内存在且连续，$\\frac{\\p f}{\\p y\\p x}(x_0,y_0)$ 存在，则 $\\frac{\\p f}{\\p x\\p y}(x_0,y_0)=\\frac{\\p f}{\\p y\\p x}(x_0,y_0)$。（加强：https://en.wikipedia.org/wiki/Symmetry_of_second_derivatives#Sufficiency_of_twice-differentiability） 若 $f$ 在 $[a,b]\\times U(y_0)$ 内连续，则 $\\lim_{y\\to y_0}\\int_a^bf(x,y)\\d x=\\int_a^bf(y_0)\\d x$。 若 $\\frac{\\p f}{\\p y}$ 在 $[a,b]\\times U(y_0)$ 内连续，则 $\\frac{\\p}{\\p y}\\left(\\int_a^bf(x,y)\\d x\\right)\\big|_{y=y_0}=\\int_a^b\\frac{\\p f}{\\p y}(x,y_0)\\d x$。 若 $f$ 在 $[a,b]\\times[c,d]$ 内连续，则 $\\int_a^b\\int_c^df(x,y)\\d y\\d x=\\int_c^d\\int_a^bf(x,y)\\d x\\d y$。 若 $f$ 在 $[a,\\omega)\\times U(y_0)$ 内连续，且 $\\int_a^\\omega f(x,y)\\d x$ 一致收敛，则 $\\lim_{y\\to y_0}\\int_a^\\omega f(x,y)\\d x =\\int_a^\\omega f(x,y_0)\\d x$。 若 $\\frac{\\p f}{\\p y}$ 在 $[a,\\omega)\\times U(y_0)$ 内连续，且 $\\int_a^\\omega\\frac{\\p f}{\\p y}(x,y)\\d x$ 一致收敛，且 $\\int_a^\\omega f(x,y_0)\\d x$ 收敛，则 $\\int_a^\\omega f(x,y)\\d x$ 在闭区间上一致收敛，且 $\\frac{\\p}{\\p y}\\left(\\int_a^\\omega f(x,y)\\d x\\right)=\\int_a^\\omega\\frac{\\p f}{\\p y}(x,y)\\d x$。 若 $f$ 在 $[a,\\omega)\\times[c,d]$ 内连续，且 $\\int_a^\\omega f(x,y)\\d x$ 一致收敛，则 $\\int_a^\\omega\\int_c^df(x,y)\\d y\\d x=\\int_c^d\\int_a^\\omega f(x,y)\\d x\\d y$。 若 $f$ 在 $[a,\\omega)\\times[c,\\psi)$ 内连续，且 $\\int_a^\\omega f(x,y)\\d x$ 一致收敛，$\\int_c^\\psi f(x,y)\\d y$ 一致收敛，$\\int_a^\\omega\\int_c^\\psi |f(x,y)|\\d y\\d x$ 和 $\\int_c^\\psi\\int_a^\\omega |f(x,y)|\\d x\\d y$ 至少一个收敛，则 $\\int_a^\\omega\\int_c^\\psi f(x,y)\\d y\\d x$ 与 $\\int_c^\\psi\\int_a^\\omega f(x,y)\\d x\\d y$ 存在且相等。 若 $\\sum_nf_n(x)$ 在 $U(x_0)$ 上一致收敛，且 $\\lim_{x\\to x_0}f_n(x)$ 存在，则 $\\sum_n\\lim_{x\\to x_0}f_n(x)$ 与 $\\lim_{x\\to x_0}\\sum_nf_n(x)$ 存在且相等。 若 $\\sum_nf_n(x)$ 满足在 $U(x_0)$ 上 $f^\\prime_n(x)$ 存在且连续，且 $\\sum_nf^\\prime_n(x)$ 一致收敛，且 $\\sum_nf(x_0)$ 收敛，则 $\\sum_nf_n(x)$ 在闭区间上一致收敛，且 $\\left(\\sum_nf_n(x)\\right)^\\prime=\\sum_nf^\\prime_n(x)$。 若 $\\sum_nf_n(x)$ 在 $[a,b]$ 上一致收敛，且 $\\int_a^bf_n(x)\\d x$ 可积，则 $\\sum_n\\int_a^bf_n(x)\\d x$ 与 $\\int_a^b\\sum_nf_n(x)\\d x$ 存在且相等。 若在 $[a,\\omega)$ 上 $\\sum_nf_n(x)=f(x)$，且存在可积函数 $F(x)$ 使 $\\forall N$，$\\left\\lvert\\sum_{n=1}^Nf_n(x)\\right\\rvert\\le F(x)$，则 $\\sum_n\\int_a^\\omega f_n(x)\\d x$ 与 $\\int_a^\\omega\\sum_nf_n(x)\\d x$ 存在且相等。（控制收敛定理） 若 $\\sum_{m,n}a_{m,n}$ 能通过安排顺序变为绝对收敛的级数，则 $\\sum_{m,n}a_{m,n}$ 绝对收敛，且等于 $\\sum_m\\sum_na_{m,n}=\\sum_n\\sum_ma_{m,n}$。 傅里叶级数的收敛：\n一致收敛 $+$ 连续 $\\implies$ 逐点收敛到 $f$。 参数级数绝对收敛 $\\implies$ 一致收敛 $+$ 连续。如果 $f$ 也连续则逐点收敛到 $f$（注意 $f$ 可能有可去间断点）。 参数单调 $\\to 0$ $\\implies$ 内闭一致收敛 $+$ 开区间连续。 连续 $+$ 分段 $\\mathscr{C}^1$ $\\implies$ 一致逐点收敛到 $f$。 分段 $\\mathscr{C}^1$ $+$ 只有第一类间断点 $\\implies$ 逐点收敛到两侧极限的平均值。 有界 $+$ 分段单调连续 $\\implies$ 逐点收敛到两侧极限的平均值。 $\\mathscr{L}^1$ $+$ 各点左右极限存在 $+$ $\\int_{0^+}|(f(x-t)-f(x-)+f(x+t)-f(x+))/t|\\d t\u0026lt;\\infty$ $\\implies$ 逐点收敛到两侧极限的平均值。 （存疑）分段可微 $\\implies$ 逐点收敛到两侧极限的平均值。 $\\mathscr{L}^{p\u0026gt;1}$ $\\implies$ 几乎处处收敛。 $\\sum_n n^p(|a_n|+|b_n|)$ 收敛 $\\implies$ $S(n)\\in\\mathscr{C}^p$。 ","date":"2025-06-16T00:00:00Z","image":"https://littlereuben.github.io/study/course-calculus-2-1/cover.png","permalink":"https://littlereuben.github.io/study/course-calculus-2-1/","title":"微积分 A(2) 复习"},{"content":"这是一篇学习笔记。\r$\\gdef\\P{\\mathsf{Pr}}\\gdef\\E{\\mathsf{E}}\\gdef\\e{\\mathrm{e}}\\gdef\\eq#1{\\begin{align*}#1\\end{align*}}\\gdef\\V{\\mathsf{Var}}\\gdef\\acc{\\operatorname{acc}}\\gdef\\eps{\\varepsilon}\\gdef\\Ext{\\mathsf{Ext}}\\gdef\\Com{\\mathsf{Com}}\\gdef\\Enc{\\mathsf{Enc}}\\gdef\\Dec{\\mathsf{Dec}}\\gdef\\Err{\\mathsf{Err}}\\gdef\\Ring{\\mathsf{Ring}}\\gdef\\d{\\mathrm{d}}\\gdef\\p{\\partial}\\gdef\\i{\\mathrm{i}}\\gdef\\res{\\operatorname{Res}}\\gdef\\b#1{\\boldsymbol{#1}}\\gdef\\Nd{\\mathcal{N}}\\gdef\\mat#1{\\begin{bmatrix}#1\\end{bmatrix}}\\gdef\\ip#1{\\left\\langle #1\\right\\rangle}\\gdef\\span#1{\\operatorname{span}\\Set{#1}}\\gdef\\r{\\operatorname{rank}}\\gdef\\diag{\\operatorname{diag}}$\n一些书：\nDiscrete Mathematics by Lovász, Pelikán, and Vesztergombi All of Statistics A Concise Course in Statistical Inference by Larry Wasserman Foundations of Data Science by Avrim Blum, John Hopcroft, and Ravindran Kannan 这边没记 Matrix Tree Theorem 和 Pfaffian 相关的，有空可能会补 Pfaffian。\n计应数 概率论 Theorem (全概率公式)\r$$\r\\boxed{\\eq{\r\u0026\\P\\left[\\bigcap_iA_i\\right]=\\prod_i\\P\\left[A_i\\Big|\\bigcap_{j{\u003c}i}A_j\\right]\\\\\r\u0026\\P[A]=\\sum_i\\P[A|B_i]\\P[B_i]\r}}\r$$\r如果后件概率为 $0$，那么条件概率为 $0$！！！\rProblem (Monty Hall Problem)\rThere are $n$ closed doors. Behind one (randomly chosen) door is a beautiful sports car, while the other $n-1$ doors each has a donkey behind it. Now the guest choose one door, Monty opens $n-2$ doors which have donkeys behind them. Should the guest switch the choice or not?\rSolution\r略。\rProblem (Birthday Paradox)\r$n$ random integers $x_{1\\sim n}$ chosen uniformly from $1$ to $m$. Estimate $q(n)=\\P[\\forall i\\ne j,x_i\\ne x_j]$.\rSolution\r$q(n)=\\P[\\text{all distinct}]\\approx\\exp(-\\binom n2/365)=d(n)$，$|d(n)-q(n)|\\ll q(n)-q(n-1)$, specifically:\r$$\r\\exp\\left(\\frac{n(n-1)(2n-1)}{12m^2}\\right)\\le\\frac{\\exp\\left(-\\frac{n(n-1)}{2m}\\right)}{\\prod_{i{\u003c}n}\\left(1-\\frac im\\right)}\\le\\exp\\left(\\frac{n(n-1)(2n-1)}{6m^2}\\right)\r$$\r(Prove by $\\e^{x^2/2}\\le\\e^x/(1+x)\\le\\e^{x^2}$.) $d(n)$ 必然是把无重率估大了。\rProblem (Online Auction Problem)\rGiven a stream of $n$ distinct random values $x_{1\\sim n}$, you have to make decision (choose once) in real-time. You want to maximize the probability of accepting the greatest value.\rSolution\r基本策略未证明。考虑枚举最大值所在位置，在 $j$ 的话，总贡献概率为 $\\frac k{n(j-1)}$。于是总共就是 $\\frac kn\\left(\\frac1k+\\cdots+\\frac1{n-1}\\right)\\approx\\frac kn\\ln\\frac nk$，取 $k=n/\\e$。\rProblem (Ramsey Number)\r$R(k)=$ minimum $N$ such that any graph with $N$ vertices has either a $k$ clique or a $k$ independent set.\rSolution\r$R(3)=6$，五元环，$n=6$ 取一点，如果 $d\\ge 3$，那么取三个邻点，无论有无边都找到；$d\u003c3$ 就找三个不邻点。\r$R(k)\\ge\\lfloor 2^{k/2}\\rfloor$: 概率方法，证随机图有 $k$ 团/独立集的概率 $\u003c1$，用 union bound：\r$$\r2\\binom{\\lfloor 2^{k/2}\\rfloor}{k}2^{-\\binom k2}\\le\\frac{\\lfloor 2^{k/2}\\rfloor^k}{k!2^{\\binom k2-1}}\\le\\frac{2^{k^2/2-k(k-1)/2+1}}{k!}=\\frac{2^{k/2+1}}{k!}\u003c1\r$$\r$R(k)\\le\\binom{2k-2}{k-1}\u003c4^k$: 相邻两个组合数的比值为 $4-2/k$；$R(r,s)\\le R(r,s-1)+R(r-1,s)\\le\\binom{r+s-2}{r-1}$。\rProblem\r随机 $n$ 排列中 $1$ 所在的环长？环个数的期望？\rSolution\r$E_i$ 表示 $|C_1|\u003ei$。$\\P[E_i\\mid E_{i-1}]=\\frac{n-i}{n-i+1}$，用 chain rule。Bijection：$S_n\\text{ with }|C_1|=i\\longleftrightarrow S_{n-1}$，$\\forall\\pi\\in S_n$，取出 $1$ 所在的环先列出来，其余再列出来。\r$\\E(\\text{\\# of cycles})=\\E(\\sum 1/L_i)=n\\E(L_i^{-1})=H_n$。Also $(x^{\\overline{n}})^\\prime|_{x=1}$。\rProblem\rGiven a random graph ($|V|=n$, every edge $1/2$), find a great clique.\rSolution (Greedy Clique Algorithm)\r直接逐一贪心，能选就选。\r$\\P[|A(G)|\u003e\\log_2n+\\log_2\\log_2n]=\\omicron(1)$。思路 1：枚举前 $k$ 个是哪几个选上，概率是定的。思路 2：\r$$\r\\begin{align*}\r\\P[|A(G)|\u003ek]\u0026=\\sum\\P[k+1\\text{-th is chosen after }i\\mid k\\text{-th is chosen at }i]\\\\\r\u0026\\le\\sum\\frac{n}{2^k}\\P[k\\text{-th is chosen at }i]\\\\\r\u0026\\le\\frac{n}{2^k}\\cdot 1\\\\\r\u0026=\\Omicron((\\log n)^{-1})\r\\end{align*}\r$$\r$\\P[|A(G)|\u003c\\log_2n-\\log_2\\log_2n]=\\omicron(1)$。考虑相邻两个被选中直接的 gap（期望为 $2^i$），然后希望前 $k$ 个 gap 加起来 $\\le n$ 这种。\r第 $i$ 个和第 $i+1$ 个之间，方差为 $p^{-2}-p^{-1}=4^i-2^i$。因此满 $k$ 个的 $\\E=2^k-1$，$\\V=(4^k-1)/3-2^k+1$。$n$ 个不够的概率：\r$$\r\\eq{\r\\P[|A(G)|{{}\u003c{}}k]\u0026=\\P[v_k\u003en]\\\\\r\u0026=\\P[v_k-\\E[v_k]\u003en-\\E[v_k]]\\\\\r\u0026\\le\\P[v_k-\\E[v_k]\u003en/2]\\\\\r\u0026\u003c\\V(v_k)/(n/2)^2\u0026\\rm(Chebyshev)\\\\\r\u0026=\\Omicron((\\log n)^{-2})\r}\r$$\rProblem (Finding Pet)\r一个随机未知 $n$ 排列 $p$，两个人 $i$，$j$ 要均找到各自 $p_i^{-1}$、$p_j^{-1}$，各自只能查看 $n/2$ 个值且不能交流。\rSolution\r单个人：$1/2$；两个人策略：$i\\to p_i\\to\\cdots$，$\\P[i\\text{ succeed}]=\\P[|C_i|\\le n/2]$。\r① $i$ 和 $j$ 同环：\r$$\r\\begin{align*}\r\\P[i,j\\text{ succeed}]\u0026=\\P[C_i=C_j\\land |C_i|\\le n/2]\\\\\r\u0026=\\sum_{l\\le n/2}\\P[|C_i|=l]\\cdot\\P[C_j=C_i\\mid|C_i|=l]\\\\\r\u0026=\\sum_{l\\le n/2}\\frac1n\\cdot\\frac{l-1}{n-1}\\\\\r\u0026=\\frac{(n/2)(n/2-1)}{2n(n-1)}\\\\\r\u0026=\\frac{n-2}{8(n-1)}\r\\end{align*}\r$$\r② $i$ 和 $j$ 异环：\r$$\r\\begin{align*}\r\\P[i,j\\text{ succeed}]\u0026=\\P[C_i\\ne C_j\\land |C_i|\\le n/2\\land |C_j|\\le n/2]\\\\\r\u0026=\\sum_{l\\le n/2}\\frac1n\\cdot\\P[C_j\\ne C_i\\land|C_j|\\le n/2\\mid|C_i|=l]\\\\\r\u0026=\\sum_{l\\le n/2}\\frac1n\\cdot\\P[C_j\\ne C_i\\mid|C_i|=l]\\cdot\\P[|C_j|\\le n/2\\mid |C_i|=l\\land C_j\\ne C_i]\\\\\r\u0026=\\sum_{l\\le n/2}\\frac1n\\cdot\\frac{n-l}{n-1}\\cdot\\frac{n/2}{n-l}\\\\\r\u0026=\\frac{n}{4(n-1)}\r\\end{align*}\r$$\r共 $\\boxed{(3n-2)/(8n-8)}$。\r所有人：绝对众数的性质，$1-H_n+H_{n/2}\\sim1-\\ln2$。\r最优性：考虑开门之后不再关，这时成功概率与策略无关，等于原问题最优策略的成功率。\rProblem\rFind the variance of the geometric distribution.\rSolution\r$\\V(X)=(1-p)/p^2$, by $\\sum(1-p)^{i-1}pi^2$ or $p^\\prime(1)-p^{\\prime\\prime}(1)-p^\\prime(1)^2$. By recurrence:\r$$\r\\eq{\r\u0026\\E(X^2)=\\sum_{i\\ge 1}p_ii^2=p+\\sum_{i\\ge 2}p_ii^2=p+(1-p)\\sum_{i\\ge 1}p_i(i+1)^2=p+(1-p)[\\V(X)+2\\E(X)+1]\\\\\r\\Longrightarrow{}\u0026p\\E(X^2)=p+2\\frac{1-p}p+1-p\\Longrightarrow\\E(X^2)=\\frac{2-p}{p^2}\\Longrightarrow\\V(X)=\\boxed{\\frac{1-p}{p^2}}\r}\r$$\rTheorem (Markov's Inequality)\rNonnegative $X$, $\\boxed{\\P[X\u003ea\\E(X)]\u003c1/a}$, or $\\boxed{\\P[X\u003ea]\u003c\\E(X)/a}$.\rTheorem (Chebyshev's Inequality)\rAllow negative! $X\\mapsto(X-\\E(x))^2$, $\\P[(X-\\E(X))^2\u003ea\\V(X)]\u003c1/a$ $\\Longrightarrow$ $\\boxed{\\P[|X-\\E(X)|\u003e\\sqrt a\\sigma(X)]\u003c1/a}$, or $\\boxed{\\P[|X-\\E(X)|\u003ea\\sigma(X)]\u003c1/a^2}$, or $\\boxed{\\P[|X-\\E(X)|\u003ea]\u003c\\V(X)/a^2}$. Not always better than Markov. 几何解释：考虑用直线（Markov）或二次函数曲线（Chebyshev）去 bound X，保证各处都大于等于（在 $x=a$/$x=\\mu$ 处等）。Chebyshev 保证在 $\\mu$ 附近比较逼进，离 $\\mu$ 远的地方可能比 Markov 差。\rTheorem (Chernoff Bound)\r$$\r\\boxed{\\text{Condition}:X=\\sum_{i=1}^nX_i,\\text{independent }X_i\\in\\set{0,1}}\r$$\rConsider $g(x)=\\e^{tx}/\\e^{ta}$，then $\\P[X\\ge a]\\le\\E[g(X)]=\\E(\\e^{tX})/\\e^{ta}$. Now consider $X=\\sum X_i$, where $X_i\\in\\set{0,1}$ and $\\set{X_i}$ are independent. $\\mu=\\E(X)=\\sum\\P[X_i=1]$. Let $\\P[X_i=1]=b_i$.\r$$\r\\eq{\r\\E(\\e^{tX})=\\E(\\e^{t\\sum X_i})=\\E(\\prod\\e^{tX_i})=\\prod\\E(\\e^{tX_i})=\\prod(1-b_i+\\e^{t}b_i)\\le\\prod\\e^{(\\e^t-1)b_i}=\\e^{(\\e^t-1)\\sum b_i}=\\e^{(\\e^t-1)\\mu}\r}\r$$\rNow, $a=(1+\\delta)\\mu$, $\\min\\e^{(\\e^t-1)\\mu-t(1+\\delta)\\mu}$, take derivative, $t=\\ln(1+\\delta)$, we get\r$$\r\\min=\\left(\\frac{\\e^\\delta}{(1+\\delta)^{1+\\delta}}\\right)^\\mu\r$$\r$$ \\left(\\frac{\\e^\\delta}{(1+\\delta)^{1+\\delta}}\\right)^\\mu\\longrightarrow \\e^{-\\frac{\\delta^2}{2+\\delta}\\mu}:\\text{take log then use }\\ln(1+x)\\ge \\frac{2x}{2+x} $$\nRemark. For $\\P[X\\ge a]=\\E(\\e^{tX})/\\e^{ta}$, we can simple use Markov: $\\P[X\\ge a]=\\P[tX\\ge ta]=\\P[\\e^{tX}\\ge\\e^{ta}]=\\cdots$.\nFor $\\P[X\\le a]$, $a=(1-\\delta)\\eps$, the best $t$ will be negative. $$ \\left(\\frac{\\e^{-\\delta}}{(1-\\delta)^{1-\\delta}}\\right)^\\mu\\longrightarrow \\e^{-\\frac{\\delta^2}2\\mu}:(1-x)\\ln(1-x)\\ge-x+\\frac{x^2}2\\text{ for }x\\in(0,1) $$\nOverall: $$ \\boxed{ \\left\\{\\eq{\u0026amp;\\P[X\\ge(1+\\delta)\\mu]\\le\\left(\\frac{\\e^\\delta}{(1+\\delta)^{1+\\delta}}\\right)^\\mu\\le\\e^{-\\frac{\\delta^2}{2+\\delta}\\mu}\u0026amp;(\\delta\\ge 0)\\\\ \u0026amp;\\P[X\\le(1-\\delta)\\mu]\\le\\left(\\frac{\\e^{-\\delta}}{(1-\\delta)^{1-\\delta}}\\right)^\\mu\\le\\e^{-\\frac{\\delta^2}2\\mu}\u0026amp;(0\\le\\delta\u0026lt;1)}\\right\\}\\longrightarrow\\P[|X-\\mu|\\ge\\delta\\mu]\\le2\\e^{-\\frac{\\delta^2}3\\mu} } $$\n$$ \\boxed{\\P[X\\ge c]\\le 2^{-c}\\text{ if } c\\ge 7\\mu} $$\n$$ \\boxed{\\P[|\\overline{X}-\\E(\\overline{X})|\\ge\\eps]\\le2\\e^{-\\frac{\\eps^2}{2+\\eps}n}} $$\nTheorem (Hoeffding)\r$Z=\\sum Z_i$, $Z_i\\in[a,b]$ independent\r$$\r\\boxed{\\P[\\overline{Z}-\\E(\\overline{Z})\\ge t],\\P[\\overline{Z}-\\E(\\overline{Z})\\le-t]\\le\\e^{-\\frac{2nt^2}{(b-a)^2}}}\r$$\rProve by considering $\\E[\\e^{tZ}]$, from convexity of $\\e^x$, we have\r$$\r\\E[\\e^{tZ}]\\le\\e^{\\frac{t^2(b-a^2)}8}\r$$\rFor the original $\\P[\\overline{Z}-\\E(\\overline{Z})\\ge t]$, first convert to $\\e^{t\\cdot}$ form, then use Hoeffding lemma, then minimize it by derivative.\rProblem (Machine Learning Problem)\rThere are several hypothesis $h_1\\sim h_k$, find the minimal $n$ that given $n$ samples $X\\sim D(X)$, we can find $h_j$ with $\\acc(h_j)\\ge{\\acc^*}-\\eps$ with probability $1-\\delta$. Solution\rThe worst case: except the best $h_j$, others all have $\\acc\u003c{\\acc^*}-\\eps$. So we must use the samples to approximate each $\\acc(h_j)$ with deviation $\u003c\\eps/2$.\r$$\r\\P\\left[\\bigwedge_i\\left\\lvert\\widetilde{\\acc}(h_i)-\\acc(h_i)\\right\\rvert\u003c\\frac\\varepsilon2\\right]\\le\rk\\P\\left[\\left\\lvert\\widetilde{\\acc}(h_i)-\\acc(h_i)\\right\\rvert\u003c\\frac\\varepsilon2\\right]\\le 2k\\exp\\left(-\\frac{\\varepsilon^2}{8+2\\varepsilon}n\\right)\\le\\delta\r$$\rThe result is\r$$\rn=\\Omicron\\left(\\frac1{\\varepsilon^2}\\log\\frac k\\delta\\right)\r$$\rIf $\\acc^*=1$, we only care about whether there exists some $h_i$ with $\\acc\u003c1-\\eps$ correctly answering all the samples. The bound can be improved to\r$$\rn=\\Omicron\\left(\\frac1{\\varepsilon}\\log\\frac k\\delta\\right)\r$$\rProblem (Largest Clique Problem)\rBound the size of the largest clique $w(G)$ of a $n$-vertices random graph.\rSolution\r$\\P[(2-\\eps)\\log_2n\\le w(G)\\le (2+\\eps)\\log_2n]=1-\\omicron(1)$. For the first $\\le$:\rLet $X=\\sum[\\text{is a clique}]$ over all subset of $V$, of size $(2-\\eps)\\log_2n$. $\\P[X\\le0]=\\P[X\\le\\E(X)/2]\\le\\P[|X-\\E(X)|\\ge\\E(X)/2]\\le4\\V(X)/\\E(X)^2$. We wanna prove $\\V(X)$ grows slower than $\\E(X)^2$. First we need $\\E(X)\\to\\infty$. $\\E(X)=\\binom nm2^{-\\binom m2}$, it $\\to+\\infty$ exactly when $\\eps\u0026gt;0$. Then we need to expand $\\V(X)$. $\\V(X)=\\E(X^2)-\\E(X)^2$. Divide $X^2$ into three types: $\\cap\\le 1$, $\\cap=m$, $1\u0026lt;\\cap\u0026lt;m$. The first type can be cancelled out by $\\E(X)^2$, the second type is simply $\\E(X)$. The last type $\\le\\frac{m^5}{n-m+1}\\E(X)^2=\\omicron(\\E(X)^2)$. Done. Problem (Network Routing Problem)\rThere's an $n$-hypercube network, packet on vertex $i$ need to go to $\\sigma(i)$. An edge takes $1$ unit time, and can transfer a single packet at one time. Find a routing scheme to transfer all the packets within a short time.\rSolution\rBSA (Bit-Fixing Algorithm): 每次选 $i\\mathop{\\mathrm{xor}}\\sigma(i)$ 的最高位走。\rSimple BSA counterexample: $\\sigma(\\overline{u0v})=\\overline{v1u}$, then all of these must pass through $(\\overline{v0v}, \\overline{v1v})$.\rRandomized: choose random $v_i$ for each $i$. $i\\to v_i\\to\\sigma(i)$. $\\exists i,T_{i\\to v_i}\u003e6n$ 的概率为 $\\Omicron(2^{-3n})$. 考虑 $\\P[T_{i\\to u}\u003e6n]$, 最后乘 $2^n$ 即可. 已知 $T_{i\\to u}\\le d(i,u)+|S|\\le n+|S|$, $S$ 为路径与 $i\\to u$ 有交的 $j\\to v_j$. 我们有 $|S|\\le n/2$ 因为每条边有其他路径经过的概率为 $1/2$. 于是由 Chernoff bound, $\\P[|S|\u003e5n]=\\Omicron(2^{-4n})$. $v_i\\to\\sigma(i)$ 是对称的.\r信息论 Property (Inequality about Binomial Coefficient)\r$$\r\\boxed{\\frac{2^{nH(q)}}{n+1}\\le\\binom{n}{nq}\\le 2^{nH(q)}}\r$$\rwhere $nq\\in[0,n]\\cap\\Z$, $H(q)=-q\\log_2q-(1-q)\\log_2(1-q)$. Can be proven by $1=(q+1-q)^n=\\sum\\binom niq^i(1-q)^{n-i}$, 后一个只取 $\\binom{n}{nq}$ 一项，前一个证明 $\\binom{n}{nq}q^{nq}(1-q)^{n(1-q)}$ 是最大的，别的都放成它。\r$$\r2^{H(q)}=\\frac1{q^q(1-q)^{1-q}}\r$$\rProblem (Extraction)\r将随机变量映到 01 串，某一长度的 01 串如果可能的话，所有 $2^l$ 种必须等概率。\rSolution\r对于各位均以 $p$ 概率独立随机的 01 串：\r$\\forall n$, $\\forall\\Ext$, $\\E(|\\Ext|)\\le nH(p)$ $\\forall\\delta\u0026gt;0$, $\\forall n\u0026gt;N$, $\\exists\\Ext$, $\\E(|\\Ext|)\\ge(1-\\delta)nH(p)$. 1 证：考虑到如果一个串它以某个概率 $q$ 出现，那一个 deterministic 的 $\\Ext$ 就必须把它映到长度不超过 $\\log_2 q^{-1}$ 的串。 2 证：考虑发掘 $p\\ne 1/2$ 的不均匀性中的均匀性——同 $\\#1$ 的串都是等概率的。对于等概率的 $m$ 种情况，可以用二进制拆分，使得 $\\E(|\\Ext|)\\ge\\lfloor\\log_2m\\rfloor-1$。所有可能的 $\\#1$ 求和后，只关注 $np$ 附近的一部分，因为 $\\E(|\\Ext|)$ 容易放缩而且 $\\P$ 可以用 Chernoff。具体放缩用上面那个式子的左侧。\nProblem (Compression)\r构造把不均匀的随机变量的（期望）长度压缩的单射。\rSolution\r对于各位均以 $p$ 概率独立随机的 01 串：\r$\\forall\\delta\u0026gt;0$, $\\forall n\u0026gt;N$, $\\forall\\Com$, $\\E(|\\Com|)\\ge(1-\\delta)nH(p)$. $\\forall\\delta\u0026gt;0$, $\\forall n\u0026gt;N$, $\\exists\\Com$, $\\E(|\\Com|)\\le(1+\\delta)nH(p)$. 1 证：证明最优方案中，出现概率小的对应的压缩长度一定越长，然后考虑 $\\lfloor(p+\\varepsilon)n\\rfloor$ 个 1 的序列有几种。 2 证：$U_\\eps(p)$ 个 $1$ 的用等概率编码，其余的用原编码，用 Chernoff bound。\nProblem (Channel with Noise)\r一个有 $p$ 的错误率的信道，每 $n$ 位能传输多少有效信息？\rSolution (Shannon's Theorem)\r$\\forall \\delta,\\eps\u0026gt;0$, $\\forall n\u0026gt;N$, $\\forall k\\le n(1-H(p)-\\delta)$, $\\exists(k,n)\\Enc$ with every input $\\Err\\le\\eps$. $\\forall \\delta,\\eps\u0026gt;0$, $\\forall n\u0026gt;N$, $\\forall k\\ge n(1-H(p)+\\delta)$, $\\nexists(k,n)\\Enc$ with random input $\\Err\\le\\eps$. $1-H(p)$ is called channel capacity.\n1 证：需要在 $\\set{0,1}^n$ 中找到大小为 $2^k$ 的子集，使得它们各自偏移其中约 $p$ 的部分之后，形成的一堆“环”的交不大。核心困难是，以高概率找到对大部分输入均高概率成功的，和证明存在对所有输入均高概率成功，此两者之间的 gap。对于第一个“高概率”，用 probabilistic method 证；对“大部分”，用冗余筛选证。\n考虑所有 $2^{k+1}$ 大小的子集，随机选一个情况失败的概率。 $$ \\eq{ \\P_{C,i}[\\text{Fail}]\u0026amp;\\le\\P_{C,i}[\\tilde{c}_i\\notin\\Ring_\\gamma(c_i)]+\\P_{C,i}[\\tilde{c}_i\\in\\Ring_\\gamma(c_{j\\ne i})]\\\\ \u0026amp;\\le\\eps_1+2^{k+1}\\frac{|\\Ring_\\gamma|}{2^n} } $$ $\\Ring_\\gamma$ 是错 $pn$ 个附近的邻域。$\\eps_1$ 可由 Chernoff bound 得到，性质：$|\\Ring|\\le2^{(H(p)+\\delta^\\prime)n}(\\delta^\\prime\\to 0\\text{ as }n\\to\\infty)$. 后一项就是 $$ 2^{k+1+(H(p)+\\delta^\\prime)n-n}=2^{1+(\\delta^\\prime-\\delta)n}\\to 0 $$ 因为 $\\delta$ 是定的，而 $\\delta^\\prime$ 可以任意小。从而 $\\Pr_{C,i}[\\text{Fail}]$ 可以任意小，因此存在一个 $C$ 使 $\\P_i[\\text{Fail}]$ 足够小，取 $2^{k+1}$ 个 $i$ 中前一半优的，由类似于 Markov 的论证，它们的失败率都 $\u0026lt;2\\P_i[\\text{Fail}]$ 从而成功。\n2 证：如果存在，设解码为 $i$ 的集合为 $S_i$。 $$ \\eq{ \\P[\\text{Success}]\u0026amp;=\\frac{1}{2^k}\\sum_i\\sum_{s\\in S_i}\\P[\\tilde c_i=s]\\\\ \u0026amp;=\\frac{1}{2^k}\\sum_i\\left(\\sum_{s\\in S_i\\cap\\Ring_\\gamma(c_i)}\\P[\\tilde c_i=s]+\\sum_{s\\in S_i\\setminus\\Ring_\\gamma(c_i)}\\P[\\tilde c_i=s]\\right)\\\\ \u0026amp;\\le\\frac{1}{2^k}\\sum_i|S_i|p^{(p-\\eps)n}(1-p)^{(1-p+\\eps)n}+\\eps_1\u0026amp;(\\text{WLOG }p\u0026lt;\\frac12)\\\\ \u0026amp;\\le \\eps_1+\\eps_2 } $$\n概率密度 Problem\rWe need to sample from some weird probability distribution.\rSolution (Importance Sampling)\rConsider $\\E_{x\\sim p}(f(x))$ where sampling from $p$ is difficult. For a sampleable distribution $q$, $$\rI=\\E_{x\\sim p}(f(x))=\\E_{x\\sim q}\\left(f(x)\\frac{p(x)}{q(x)}\\right)\r$$\rLet\r$$\r\\hat I_n=\\frac1n\\sum_{i=1}^nf(x_i)\\frac{p(x_i)}{q(x_i)}\r$$\r$$ \\P[|\\hat I_n-I|\\ge\\eps]\\le\\frac{\\V(\\hat I_n)}{\\eps^2}=\\frac1{\\eps^2n}\\left(\\int f(x)^2\\frac{p(x_i)^2}{q(x_i)}\\d x-I^2\\right) $$\nmay diverge. The optimal $q$ is $$ q^*(x)=\\frac{f(x)p(x)}{\\int f(x)p(x)\\d x} $$ which is unachievable.\nSolution (Rejection Sampling)\rAccept rate = $\\sup f(x)/g(x)$. 思想就是在概率分布图象内部随便取一个点，其横坐标就符合该分布。\r复分析 https://www.bilibili.com/video/BV15F41137Nn/\n解析函数的定义 保角性质（通过棣莫弗定理） C-R 条件的等价性 偏导的几种形式（$f^\\prime$、$\\frac{\\p f}{\\p x}$、$\\frac{\\p f}{\\p y}$、$u^\\prime$、$\\frac{\\p u}{\\p x}$、$\\frac{\\p u}{\\p y}$、$v^\\prime$、$\\frac{\\p v}{\\p x}$、$\\frac{\\p v}{\\p y}$、$\\frac{\\p f}{\\p z}$、$\\frac{\\p f}{\\p\\bar z}$）及解析的偏导表示 调和函数与解析函数的关系（在单连通集上唯一确定） 调和多项式的基（考虑齐次→维数→极坐标） 复变函数的积分 积分合法的条件及积分的参数化 同伦的定义 积分的展开及柯西积分定理（用 Green 公式） 通过切开连接的方法将围道推向无穷远，从而求一些积分的方法 柯西积分公式（通过展开到一阶项）推论： 一点由其围道 $\\sup$ bound 高阶导数公式 Liouville 定理 Taylor 展开及级数收敛性质 Cauchy\u0026rsquo;s Residue Theorem: $$ \\oint_\\gamma f(z)\\d z=2\\pi\\i\\sum_k\\res(f,z_k) $$ If $$ f(z)=\\sum_{j=-\\infty}^{+\\infty}c_{j}(z-z_k)^{j} $$ then $\\res(f(z),z_k)=c_{-1}$. So for simple pole: $$ \\res(f(z),z_k)=\\lim_{z\\to z_k}(z-z_k)f(z) $$ (usually calculated by l'H)\nFor pole of order $m$: $$ \\res(f(z),z_k)=\\frac1{(m-1)!}\\lim_{z\\to z_k}\\frac{\\d^{m-1}}{\\d z^{m-1}}\\left[(z-z_k)^mf(z)\\right] $$ For infinity, if $$ f(z)=\\sum_{j=-\\infty}^{+\\infty}c_jz^j $$ then $\\res(f(z),\\infty)=-c_{-1}$. If the pole is of order $m$ ($\\max\\set{j\\mid c_j\\ne 0}=m$), then $$ \\res(f(z),\\infty)=\\frac{(-1)^m}{(m+1)!}\\lim_{z\\to\\infty}\\left(z^{m+1}\\frac{\\d^{m+1}}{\\d z^{m+1}}f(z)\\right) $$ also, $$ \\res(f(z),\\infty)=-\\res\\left(\\frac{1}{z^2}f\\left(\\frac1z\\right),0\\right) $$ So another form of Residue Theorem: $$ \\oint_{\\gamma^-}f(z)\\d z=2\\pi\\i\\res(f(z),\\infty)\\quad(\\text{for contour enclosing all the singularities}) $$\n$$ \\sum\\res(f(z),z_k)+\\res(f(z),\\infty)=0 $$\nEstimate the asymptotics of coefficients of a GF: $$ f(z)=\\text{some closed form}=\\sum a_iz^i $$\n$$ a_i=\\res\\left(\\frac{f(z)}{z^{i+1}},0\\right) $$\nAlso: $$ \\oint_{\\gamma}\\frac{f(z)}{z^{i+1}}\\d z=a_i+\\sum_k\\res\\left(\\frac{f(z)}{z^{i+1}},z_k\\right) $$ For most of the functions, we can choose a family of contours, to make $$ f(z)=\\Omicron(1)\\Longrightarrow\\oint_\\gamma\\frac{f(z)}{z^{i+1}}\\d z\\to 0 $$ so that we can get $a_i$ from those residues. For rational functions, the asymptotic behavior is governed by the nearest singularity to $0$.\n智应数 高维几何 Problem (Volume of a ball)\rCalculate the volume and surface area of a $d$-dimensional unit ball.\rSolution\r$$\rV_d=\\int_{|\\b x|\\le 1}\\d x=\\int_0^1\\int\\d\\Omega\\cdot r^{d-1}\\d r=\\frac{A_d}{d}\r$$\rHere, $$\r\\d x_1\\cdots\\d x_d=\\left\\lvert\\frac{\\p(x_1,\\cdots,x_d)}{\\p(r,\\theta_1,\\cdots,\\theta_{d-1})}\\right\\rvert\\d r\\d\\theta_1\\cdots\\d\\theta_{d-1}=\\left(r^{d-1}\\d r\\right)\\underline{\\left(\\sin^{d-2}\\theta_1\\cdots\\sin\\theta_{d-2}\\d\\theta_1\\cdots\\d\\theta_{d-1}\\right)}_{\\d\\Omega}\r$$\rHow to get $V_d$ and $A_d$? A strange way is consider normal distribution:\r$$\r\\int_{\\b x}\\e^{-|\\b x|^2}\\d x=\\left(\\int_{-\\infty}^{+\\infty}\\e^{-x^2}\\d x\\right)^d=\\pi^{d/2}\r$$\rAlso:\r$$\r\\int_{\\b x}\\e^{-|\\b x|^2}\\d x=\\int_0^{+\\infty}\\int\\e^{-r^2}\\d\\Omega\\cdot r^{d-1}\\d r=A_d\\int_0^{+\\infty}\\e^{-r^2}r^{d-1}\\d r\\xlongequal{t=r^2}\\frac{A_d}2\\int_0^{+\\infty}\\e^{-t}t^{d/2-1}\\d t=\\frac{A_d}{2}\\Gamma\\left(\\frac d2\\right)\r$$\r$$ \\frac{A_d}2\\Gamma\\left(\\frac d2\\right)=\\pi^{d/2}\\Longrightarrow\\boxed{A_d=\\frac{2\\pi^{d/2}}{\\Gamma(d/2)}}\\Longrightarrow\\boxed{V_d=\\frac{2\\pi^{d/2}}{d\\Gamma(d/2)}} $$\nHere a useful formula is $$ \\boxed{\\int_{0}^{+\\infty}\\e^{-x^2}x^n\\d x=\\frac12\\Gamma\\left(\\frac{n+1}2\\right)=\\left\\{\\begin{aligned}\u0026amp;\\frac{(2n-1)!!}{2^{n+1}}\\sqrt{\\pi},\u0026amp;2\\mid n\\\\ \u0026amp;\\frac{n!}{2},\u0026amp;2\\nmid n\\end{aligned}\\right.} $$\nProperty (Volume Near the Shell)\r$$\r1-(1-\\eps)^d\\le 1-\\e^{-\\eps d}\r$$\rProperty (Volume Near the Equator)\r$$\r1-\\text{ratio}=\\frac{V\\text{ above }\\frac{c}{\\sqrt{d-1}}}{V_d/2}\r$$\r$$ \\begin{align*} V\\text{ above }\\frac{c}{\\sqrt{d-1}}\u0026amp;=\\int_{c/\\sqrt{d-1}}^1\\sqrt{1-r^2}^{d-1}V_{d-1}\\d r\\\\ \u0026amp;\\le V_{d-1}\\int_{c/\\sqrt{d-1}}^1\\e^{-\\frac{d-1}2r^2}\\d r\\\\ \u0026amp;\\le V_{d-1}\\int_{c/\\sqrt{d-1}}^{+\\infty}\\e^{-\\frac{d-1}2r^2}\\d r\\\\ \u0026amp;\\le V_{d-1}\\int_{c/\\sqrt{d-1}}^{+\\infty}\\e^{-\\frac{d-1}2r^2}\\cdot\\frac{r}{c/\\sqrt{d-1}}\\d r\\\\ \u0026amp;=\\frac{V_{d-1}\\sqrt{d-1}}{2c}\\int_{c/\\sqrt{d-1}}^{+\\infty}\\e^{-\\frac{d-1}2r^2}\\d(r^2)\\\\ \u0026amp;=\\frac{V_{d-1}\\sqrt{d-1}}{2c}\\cdot\\frac{2}{d-1}\\e^{-\\frac{d-1}2\\cdot\\frac{c^2}{d-1}}\\\\ \u0026amp;=\\frac{V_{d-1}}{c\\sqrt{d-1}}\\e^{-c^2/2} \\end{align*} $$\n(Main idea: 凑 $V_{d-1}$ and $\\e^{-x^2}\\to x\\e^{-x^2}$) $$ \\begin{align*} \\frac{V_d}2\u0026amp;=\\int_0^1\\sqrt{1-r^2}^{d-1}V_{d-1}\\d r\\\\ \u0026amp;=V_{d-1}\\int_0^1(1-r^2)^{(d-1)/2}\\d r\\\\ \u0026amp;\\ge V_{d-1}\\int_0^{1/\\sqrt{d-1}}\\left(1-\\frac{d-1}2r^2\\right)\\d r\u0026amp;\\left(\\text{need }\\frac{d-1}2\\ge 1\\text{ !!!}\\right)\\\\ \u0026amp;\\ge V_{d-1}\\frac{1}{\\sqrt{d-1}}\\left(1-\\frac{d-1}2\\left(\\frac1{\\sqrt{d-1}}\\right)^2\\right)\\\\ \u0026amp;=\\frac{V_{d-1}}{2\\sqrt{d-1}} \\end{align*} $$ (Main idea: 取一个圆柱)\nSo, $$ 1-\\text{ratio}\\le\\boxed{\\frac c2\\e^{c^2/2}}\\qquad\\color{red}\\text{when }d\\ge 3,c\\ge 1 $$\nProperty (Random Vectors in the Ball)\rWith $\\P=1-\\Omicron(n^{-1})$:\rall $|\\b x_i|\\ge 1-\\frac{2\\ln n}d$. Directly union bound. all pairs $|\\b x_i\\cdot\\b x_j|\\le\\frac{\\sqrt{6\\ln n}}{\\sqrt{d-1}}$. 把 $\\b x_i$ 视作 equator 的法向量，$\\b x_j$ 大概率在 equator 的圆盘附近，再 union bound. Definition (Normal Distribution)\rPDE of $\\Nd(\\mu,\\sigma^2)$:\r$$\rf(x)=\\frac{1}{\\sqrt{2\\pi}\\sigma}\\e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\r$$\rwhen $\\sigma=1$, it is called standard.\nPDE of $\\Nd(\\b{\\mu}, \\b{\\Sigma})$: $$ f(\\b{x}) = \\frac{1}{(2\\pi)^{d/2} |\\b{\\Sigma}|^{1/2}} \\exp\\left( -\\frac{1}{2} (\\b{x} - \\b{\\mu})^\\top \\b{\\Sigma}^{-1} (\\b{x} - \\b{\\mu}) \\right) $$ when $\\b\\Sigma=kI$, it is called spherical.\nTheorem (3 Different Tail Bounds)\rHoeffding. i.i.d. $X_i\\sim\\mathcal{U}(-a,+a)$, $$ \\boxed{\\P\\left[\\left\\lvert S_n - \\E(S_n)\\right\\rvert\\geq t \\right] \\leq2\\exp\\left( -\\frac{t^2}{2na^2} \\right)} $$\nsub-Gaussian. i.i.d. $X_i$ s.t. $\\forall \\lambda$, $\\E\\left[\\e^{\\lambda(X_i-\\E(X_i))}\\right]\\le\\e^{\\lambda^2\\sigma^2/2}$, $$ \\boxed{\\P\\left[\\left\\lvert S_n - \\E(S_n)\\right\\rvert\\geq t \\right] \\leq 2\\exp\\left( -\\frac{t^2}{2n\\sigma^2} \\right)} $$\nsub-Exponential. i.i.d. $X_i$ s.t. $\\forall|\\lambda|\u0026lt;\\alpha^{-1}$, $\\E\\left[\\e^{\\lambda(X_i-\\E(X_i))}\\right]\\le\\e^{\\lambda^2\\nu^2/2}$, $$ \\boxed{\\P\\left[\\left\\lvert S_n - \\E(S_n)\\right\\rvert\\geq t \\right] \\leq 2\\exp\\left(-\\min\\Set{\\frac{t^2}{2n\\nu^2},\\frac{t}{2\\alpha}}\\right)} $$\nsub-Gaussian is $(\\sigma,0)$ sub-exp.\nTheorem (Gaussian Annulus Theorem)\r$$\r\\boxed{\\underset{x\\sim\\mathcal{N}(\\b 0,I)}\\P\\left[\\left\\lvert|\\b x|-\\sqrt d\\right\\rvert\\le\\beta\\right]\\ge 1-3\\e^{-c\\beta^2}\\text{ for any }\\beta\\le\\sqrt{d}\\text{ and some constant }c}\r$$\rFirst,\r$$\r\\P\\left[\\left\\lvert|\\b x|-\\sqrt{d}\\right\\rvert\\ge\\beta\\right]=\\P\\left[\\left\\lvert|\\b x|^2-d\\right\\rvert\\ge\\beta\\left(|\\b x|+\\sqrt{d}\\right)\\right]\\le\\P\\left[\\left\\lvert|\\b x|^2-d\\right\\rvert\\ge\\beta\\sqrt{d}\\right]\r$$\r证 1. use sub-exp tail bound.\r易证 $\\E(|\\b x|^2)=d$. 这玩意叫卡方分布（$k$ 个标准正态的平方和记作 $\\chi_k^2$）。\n证明 $\\chi_1^2$ 是 sub-exp with $(\\nu,\\alpha)=(2,4)$:\nMGF $\\E[\\e^{\\lambda (Z-1)}]=\\frac{\\e^{-\\lambda}}{\\sqrt{1 - 2\\lambda}}$. 取 $\\ln$，为 $-\\lambda-\\frac12\\ln(1-2\\lambda)=-\\lambda-\\frac12\\left(-2\\lambda-2\\lambda^2-\\frac83(\\theta\\lambda)^3\\right)=\\lambda^2+\\frac43\\theta^3\\lambda^3\\le\\lambda^2+\\frac13\\theta^3\\lambda^2\\le 2\\lambda^2$. $$ \\P\\left[\\left\\lvert|\\b x|^2-d\\right\\rvert\\ge\\beta\\sqrt{d}\\right]\\le 2\\exp\\left(-\\min\\Set{\\frac{(\\beta\\sqrt d)^2}{8d},\\frac{\\beta\\sqrt d}{8}}\\right)=2\\e^{-\\beta^2/8} $$\n证 2. Master tail bound theorem: i.i.d. $X_i$ s.t. $\\E=0$ and $\\V\\le\\sigma^2$. $0\\le a\\le \\sqrt2n\\sigma^2$, $|\\E(X_i^s)|\\le \\sigma^2s!$ for $s=3\\sim\\lfloor a^2/4n\\sigma^2\\rfloor$, $$ \\boxed{\\P[|S_n|\\ge a]\\le 3\\exp\\left(-\\frac{a^2}{12n\\sigma^2}\\right)} $$ We have $\\left\\lvert|\\b x^2|-d\\right\\rvert=\\left\\lvert\\sum_{i=1}^d(\\b x_i^2-1)\\right\\rvert$, let $X_i=\\frac{\\b x_i^2-1}2$. $$ \\begin{align*} |\\E(X_i^s)|\u0026amp;\\le\\E(|X_i|^s)\\\\ \u0026amp;\\le 2^{-s}\\E(1+\\b x_i^{2s})\\\\ \u0026amp;=2^{-s}(1+(2s-1)!!)\\\\ \u0026amp;\\le s! \\end{align*} $$ So, we can let $\\sigma=2$, $a=\\beta\\sqrt d/2$, $|\\E(X_i^s)|\\le \\sigma^2s!$ is easily satisfied, thus $$ \\P\\left[\\left||\\b x|^2-d\\right|\\ge\\beta\\sqrt d\\right]=\\P\\left[\\left|\\sum_{i=1}^dX_i\\right|\\ge a\\right]\\le 3\\e^{-\\frac{\\beta^2}{96}} $$ 证 3. Chernoff bound: $$ \\P[X\\ge a]\\le\\inf_{t\\ge0}\\frac{\\E(\\e^{tX})}{\\e^{ta}} $$ Here $\\E(\\e^{tX})=M_X(t)$ is the MGF of $X$. Consider $Y=|\\b x|^2$. $$ \\begin{align*} M_Y(t)\u0026amp;=\\E\\left(\\e^{tY}\\right)\\\\ \u0026amp;=\\E\\left(\\e^{t\\sum_{i=1}^d\\b x_i^2}\\right)\\\\ \u0026amp;=\\E\\left(\\prod_{i=1}^d\\e^{t\\b x_i^2}\\right)\\\\ \u0026amp;=\\left(\\E\\left(\\e^{t\\b x_1^2}\\right)\\right)^d\\\\ \u0026amp;=\\left(\\int_{-\\infty}^{+\\infty}\\frac{1}{\\sqrt{2\\pi}}\\e^{-x^2/2}\\e^{tx^2}\\d x\\right)^d\\\\ \u0026amp;=\\left(\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{+\\infty}\\e^{-(1/2-t)x^2}\\d x\\right)^d\\\\ \u0026amp;=\\left(\\frac{1}{\\sqrt{2\\pi}}\\sqrt{\\frac{\\pi}{1/2-t}}\\right)^d\\\\ \u0026amp;=\\left(1-2t\\right)^{-d/2} \\end{align*} $$\n$$ \\begin{align*} \\P\\left[|\\b x|^2\\ge d(1+\\eps)^2\\right]\u0026amp;\\le\\frac{(1-2t)^{-d/2}}{\\e^{td(1+\\eps)^2}}\\\\ \u0026amp;=\\exp\\left(-\\frac d2\\ln(1-2t)-d(1+\\eps)^2t\\right)\\\\ \u0026amp;=\\exp\\left(d\\ln(1+\\eps)-d\\eps\\left(1+\\frac\\eps2\\right)\\right)\u0026amp;\\left(t=\\frac12\\left(1-\\frac1{(1+\\eps)^2}\\right)\\right)\\\\ \u0026amp;\\le\\exp\\left(d\\eps-d\\eps\\left(1+\\frac\\eps2\\right)\\right)\\\\ \u0026amp;=\\e^{-d\\eps^2/2} \\end{align*} $$\nTake $Z=-Y$, we can similarly prove $\\P\\left[|\\b x|^2\\le d(1-\\eps)^2\\right]\\le\\e^{-d\\eps^2/2}$. $$ \\P\\left[\\left\\lvert|\\b x|-\\sqrt d\\right\\rvert\\ge\\beta\\right]=\\P\\left[|\\b x|^2\\ge d\\left(1+\\frac{\\beta}{\\sqrt d}\\right)^2\\right]+\\P\\left[|\\b x|^2\\le d\\left(1-\\frac{\\beta}{\\sqrt d}\\right)^2\\right]\\le2\\e^{-\\beta^2/2}\\quad(\\eps=\\beta/\\sqrt d) $$\nProperty (MGF of $\\Nd(\\mu,\\sigma^2)$)\r$$\r\\begin{align*}\rM_X(t)\u0026=\\E\\left[\\e^{t X}\\right]\\\\\\\r\u0026=\\frac{1}{\\sqrt{2\\pi}\\sigma}\\int_{-\\infty}^{+\\infty}\\e^{t(x+\\mu)}\\e^{-x^2/2\\sigma^2}\\d x\\\\\\\r\u0026=\\frac{\\e^{\\mu t+\\sigma^2t^2/2}}{\\sqrt{2\\pi}\\sigma}\\int_{-\\infty}^{+\\infty}\\e^{-(x/\\sigma+\\sigma t)^2/2}\\d x\\\\\\\r\u0026=\\e^{\\mu t+\\sigma^2t^2/2}\r\\end{align*}\r$$\rProperty (Tail Bound of $\\Nd(\\mu,\\sigma^2)$)\r$$\r\\begin{align*}\r\u0026\\P[X-\\mu\\ge t]\\le\\inf_\\lambda\\frac{\\E\\left[\\e^{\\lambda X}\\right]}{\\e^{\\lambda(t+\\mu)}}=\\e^{-t^2/2\\sigma^2}\\\\\\\r\u0026\\boxed{\\P[|X-\\mu|\\ge t]\\le 2\\e^{-t^2/2\\sigma^2}}\r\\end{align*}\r$$\rTheorem (Random Projection Theorem)\rFor $\\b v\\in\\R^d$, i.i.d. $\\b u_i\\sim\\Nd(\\b 0,I_d)$, $f(\\b v):\\b v\\mapsto\\mat{\\b u_1\\cdot\\b v\u0026\\cdots\u0026\\b u_k\\cdot\\b v}$.\r$$\r\\boxed{\\P\\left[\\left\\lvert|f(\\b v)|-\\sqrt k|\\b v|\\right\\rvert\\ge\\eps\\sqrt k|\\b v|\\right]\\le 3\\e^{-ck\\eps^2}\\text{ for some constant }c\\text{ and any }\\eps\\in(0,1)}\r$$\rProof. i.i.d. $\\b u_i\\cdot\\b{\\hat v}\\sim\\Nd(0,1)$, then use GAT with $\\beta=\\sqrt k\\eps$. 注意这里关键的一点是，i.i.d. 的随机变量的相同线性组合也是 i.i.d. 的。\rTheorem (Johnson-Lindenstrauss Lemma)\r$c$ and $\\eps$ as above. For any $n$ points in $\\R^d$, let $k\\ge\\frac{3}{c\\eps^2}\\ln n$, $f:\\R^d\\to\\R^k$ as above.\r$$\r\\boxed{\\P\\left[\\forall i,j,(1-\\eps)\\sqrt k|\\b v_i-\\b v_j|\\le |f(\\b v_i)-f(\\b v_j)|\\le (1+\\eps)\\sqrt k|\\b v_i-\\b v_j|\\right]\\ge 1-\\frac{3}{2n}}\r$$\rProof. $f(\\b v_i)-f(\\b v_j)=f(\\b v_i-\\b v_j)$, then use RPT above. $3\\e^{-ck\\eps^2}\\le 3n^{-3}$ then union bound, times $\\binom n2$.\nTheorem (JL Lemma Inner Product Version)\rUnder the same setting, plus $|\\b v_i|\\le 1$, we have with high Pr:\r$$\r\\boxed{\\forall i,j,\\left\\lvert\\frac{\\ip{f(\\b v_i),f(\\b v_j)}}k-\\ip{\\b v_i,\\b v_j}\\right\\rvert\\le 2\\eps+\\frac{\\eps^2}4}\r$$\rProof. Consider\r$$\r\\ip{f(\\b v_i),f(\\b v_j)}=\\frac14\\left(|f(\\b v_i)+f(\\b v_j)|^2-|f(\\b v_i)-f(\\b v_j)|^2\\right)\r$$\rOther versions: https://kexue.fm/archives/8679/comment-page-1\rProblem (Separating Two Gaussians or Sphericals)\rThere are points sampled from two Gaussians/Sphericals (only the centers differ), $n$ points each. Identify (cluster) them.\rSolution\r求出每对点之间的距离。在足够大的概率下，同一个分布内的点对距离和不同分布的点对距离有个可辨别的 gap：\r用球壳/GAT bound 模长； 用“体积集中在赤道”bound 点积； 同一个分布的两个向量差平方 $\\le$ $2$ 倍模长$^2$ $+$ $2$ 倍点积； 不同个分布的两个向量差平方 $\\ge$ $2$ 倍模长$^2$ $+$ $\\delta^2$ $-$ $2$ 倍点积 $-$ $4\\delta$ 倍点积； 只要 $\\delta=\\Omega(\\log d/d^{1/4})$ 就能分离。 线代 Definition (Best-Fit Space)\r$\\b a_{1\\sim n}\\in\\R^d$, $A=\\mat{\\b a_1\u0026\\cdots\u0026\\b a_n}^\\top$. The best-fit $k$-dim space $V_k$ is a space that minimizes $\\sum\\operatorname{dis}(\\b a_i,V_k)^2$ $\\Longleftrightarrow$ maximizing $\\sum_i\\sum_{j\\le k}(\\b a_i\\cdot\\b v_j)^2=\\sum|A\\b v_j|^2$, here $\\set{\\b v_j}$ is an orthonormal basis for $V_k$.\rSolution (The Greedy Algorithm)\r定义 the $k$-th singular vector:\r$$\r\\boxed{\\b v_k=\\operatorname*{argmax}_{|\\b v|=1,\\b v\\perp\\b v_{1\\sim k-1}}|A\\b v_k|}\r$$\rand the $k$-th singular value: $\\sigma_k=|A\\b v_k|$. $\\span{\\b v_1,\\cdots,\\b v_k}$ is the best-fit $k$-dim space.\rProof. 归纳。考虑 $W_k\\ne V_k$，取 $\\b w_k\\in W_k\\cap V_{k-1}^\\perp$，将它扩展成 $W_k$ 的一组基 $\\set{\\b w_1,\\cdots,\\b w_k}$。由归纳假设， $$ \\sum_{i=1}^k|A\\b w_i|^2\\le\\sum_{i=1}^{k-1}|A\\b v_i|^2+|A\\b w_k|^2 $$ 由 $\\b v_k$ 定义 $|A\\b w_k|\\le|A\\b v_k|$。\nProperty\r$$\r\\boxed{\\sum\\sigma_i^2=\\sum|A\\b v_i|^2=\\sum\\sum(\\b a_i\\cdot\\b v_j)^2=\\sum|\\b a_i|^2=\\sum\\sum a_{i,j}^2=\\|A\\|_F^2}\r$$\rProperty\r定义 left singular vectors $\\b u_k=\\sigma_k^{-1}A\\b v_k$, we have: $\\boxed{\\b u_i\\perp\\b u_j}$.\rProof. 反证，找到最小的 $\\b u_i\\not\\perp\\b u_j$（$i\u0026lt;j$），不妨设 $\\b u_i\\cdot\\b u_j=\\delta\u0026gt;0$。 $$ A\\frac{\\b v_i+\\eps\\b v_j}{|\\b v_i+\\eps\\b v_j|}=\\frac{\\sigma_i\\b u_i+\\eps\\sigma_j\\b u_j}{\\sqrt{1+\\eps^2}}\\Longrightarrow \\b u_i\\left(A\\frac{\\b v_i+\\eps\\b v_j}{|\\b v_i+\\eps\\b v_j|}\\right)=\\frac{\\sigma_i+\\eps\\sigma_j\\delta}{\\sqrt{1+\\eps^2}}=\\sigma_i+\\sigma_j\\delta\\eps+\\omicron(\\eps^2) $$ 这与 $\\b v_i$ 定义（$\\max.|A\\b v_i|$）矛盾。\nTheorem (Singular Value Decomposition)\r$$\r\\boxed{A_{n\\times m}=\\sum\\sigma_i\\b u_i\\b v_i^\\top=\\mat{\\b u_1\u0026\\cdots\u0026\\b u_r}\\mat{\\sigma_1\u0026\\cdots\u00260\\\\\\vdots\u0026\\ddots\u0026\\vdots\\\\0\u0026\\cdots\u0026\\sigma_r}\\mat{\\b v_1^\\top\\\\\\vdots\\\\\\b v_r^\\top}=U_{n\\times r}\\Sigma_{r\\times r}V^\\top_{r\\times m}}\r$$\rProof.\r$$\r\\sum\\sigma_i\\b u_i\\b v_i^\\top=\\sum A\\b v_i\\b v_i^\\top=A\\mat{\\b v_1\u0026\\cdots\u0026\\b v_n}\\mat{\\b v_1^\\top\\\\\\vdots\\\\\\b v_n^\\top}\r$$\rand by definition,\r$$\r\\mat{\\b v_1^\\top\\\\\\vdots\\\\\\b v_n^\\top}\\mat{\\b v_1\u0026\\cdots\u0026\\b v_n}=I\\Longrightarrow \\mat{\\b v_1\u0026\\cdots\u0026\\b v_n}\\mat{\\b v_1^\\top\\\\\\vdots\\\\\\b v_n^\\top}=I\r$$\ror we can prove by $\\forall\\b x(A\\b x=B\\b x)\\Longrightarrow A=B$.\rLet $A_k=\\sum_{i\\le k}\\sigma_i\\b u_i\\b v_i^\\top$.\nNote. 当 $A$ 是实对称矩阵时，$\\set{\\sigma_i}=\\set{\\lvert\\lambda_i\\rvert}$，如果 $\\lambda_i$ 是负的，则 $U$ 和 $V$ 的对应列符号相反。$A$ 有重复特征值时 $U$ 和 $V$ 不唯一。求 SVD 的手工方法是 $A^\\top A=V\\Sigma^2 V^\\top$，对它做正交对角化。对称正定矩阵的特征值分解保证 $U=V$，但半正定不保证 $U=V$。\nProperty\rThe rows of $A_k$ are the projections of the rows of $A$ onto the subspace $V_k$ spanned by the first $k$ singular vectors of $A$.\rProof. $$ \\sum_{i\\le k}A\\b v_i\\b v_i^\\top=\\sum_{i\\le k}\\sigma_i\\b u_i\\b v_i^\\top=A_k $$\nDefinition (Operator $p$-norm)\r$$\r\\boxed{\\|A\\|_p=\\max_{\\|\\b x\\|_p=1}\\|A\\b x\\|_p}\r$$\r$\\|A\\|_1$ 是 $A$ 的各列 $1$-范数的 $\\max$。 $\\|A\\|_2$（谱范数）是 $A$ 的奇异值 $\\max$ (so $\\lVert A-A_k\\rVert_2=\\sigma_{k+1}$)。 $\\|A\\|_\\infty$ 是 $A$ 的各行 $1$-范数的 $\\max$。 Theorem (Best Rank-$k$ Approximation)\r$$\r\\boxed{\\|A-A_k\\|_F=\\min_{\\r(B)\\le k}\\|A-B\\|_F,\\|A-A_k\\|_2=\\min_{\\r(B)\\le k}\\|A-B\\|_2}\r$$\rProof. $\\min$ 差的 Frobenius 范数可以理解成 $A$ 的各行到 $\\operatorname{R}(B)$ 的距离，于是从 best-fit space 的角度即可说明。 对于 $2$ 范数，找单位向量 $\\b z\\in\\operatorname{N}(B)\\cap\\span{\\b v_1,\\cdots,\\b v_{k+1}}$，设 $\\b z=\\sum c_i\\b v_i$，\r$$\r\\|A-B\\|_2\\ge|(A-B)\\b z|=|A\\b z|=\\left\\lvert\\sum Ac_i\\b v_i\\right\\rvert=\\left\\lvert\\sum c_i\\sigma_i\\b u_i\\right\\rvert=\\sqrt{\\sum c_i^2\\sigma_i^2}\\ge\\sigma_{k+1}\\sqrt{\\sum c_i}=\\sigma_{k+1}|\\b z|=\\sigma_{k+1}\r$$\rDefinition (Schatten $p$-norm)\r$$\r\\boxed{\\|A\\|_{S_p}=\\left\\lVert\\mat{\\sigma_1\u0026\\cdots\u0026\\sigma_r}\\right\\rVert_p}\r$$\r$\\|A\\|_{S_1}$ 是核范数。 $\\|A\\|_{S_2}=\\|A\\|_F$。 $\\|A\\|_{S_\\infty}=\\|A\\|_2$。 注意：\n奇异值 \u0026amp; 向量有两种定义方式：$\\set{A\\b v_i=\\sigma_i\\b u_i}$（$\\set{\\b v_i}$、$\\set{\\b u_i}$ 分别单位正交，$\\sigma_i\\ge 0$），以及 $\\max_{|\\b v|=1}|A\\b v|$ 这类。类似地，特征值 \u0026amp; 向量也有两种定义，第二种是 $\\max_{|\\b v|=1}\\set{\\b v^\\top A\\b v}$。\n当特征值互异时，正交对角化唯一 up to 特征向量乘 $\\pm 1$；奇异值互异时，SVD 也是一样。\n方阵的左右特征值必然相同，左右特征向量一般不同。\n对于正规矩阵（$AA^\\dagger=A^\\dagger A$），$\\sigma_i=|\\lambda_i|$，否则反例：$A=E^{1,2}$。\n$A$ 的所有单位特征向量和所有奇异向量完全相同（与此同时左右奇异向量相同）$\\Longleftrightarrow$ $A$ 对称半正定。对称反例：$\\mat{0\u0026amp;1\\\\1\u0026amp;0}$。\n证明核心步骤：对于 $A=B^\\top B$，设 $B=U\\Sigma V^\\top$，这里只证明最大右奇异向量 $=$ 最大单位特征向量：\n$\\color{white}\\Longleftrightarrow$ $\\b v$ 是 $A$ 的右奇异向量\n$\\Longleftrightarrow$ $\\b v$ 最大化了 $|A\\b v|$（定义）\n$\\Longleftrightarrow$ $\\b v$ 最大化了 $\\b v^\\top A^\\top A\\b v=\\b v^\\top V\\Sigma^4V^\\top\\b v=(V^\\top\\b v)^\\top\\Sigma^4(V^\\top\\b v)$\n$\\Longleftrightarrow$ $\\b v$ 最大化了 $(V^\\top\\b v)^\\top\\Sigma^2(V^\\top\\b v)=\\b v^\\top B^\\top B\\b v$（这一步是因为 $V^\\top\\b v$ 是单位向量，对于单位向量 $\\b u$ 而言，最大化 $\\sum\\sigma_i^4\\b u_i^2$ 和最大化 $\\sum\\sigma_i^2\\b u_i^2$ 是等价的，都必须只有 $\\sigma$ 最大的那些部分对应的 $\\b u$ 的分量不是 $0$）\n$\\Longleftrightarrow$ $\\b v$ 最大化了 $|B\\b v|$\n$\\Longleftrightarrow$ $\\b v$ 是 $B$ 的右奇异向量（定义）\n$\\Longleftrightarrow$ $\\b v$ 是 $B^\\top B=A$ 的特征向量（奇异向量的求法）\nSVD 的工业应用 Solution (The Power Method)\rSample a unit vector $\\b x$. Calculate $(A^\\top A)^k\\b x$, $k=\\Omega(-\\eps^{-1}\\log\\eps)$. Every time normalize the resulting vector. The resulting vector $\\b v$ is very likely to be a eigenvector corresponding to the greatest eigenvalue of $A$. $A\\xleftarrow{-}A\\b v\\b v^\\top$, goto 1. Intuition: let $\\b x=\\sum c_i\\b v_i$, $$ A^\\top A=\\left(\\sum\\sigma_i\\b v_i\\b u_i^\\top\\right)\\left(\\sum\\sigma_i\\b u_i\\b v_i^\\top\\right)=\\sum\\sigma_i^2\\b v_i\\b v_i^\\top\\Longrightarrow\\left(A^\\top A\\right)^k=\\sum\\sigma_i^{2k}\\b v_i\\b v_i^\\top\\Longrightarrow\\left(A^\\top A\\right)^k\\b x=\\sum\\sigma_i^{2k}c_i\\b v_i $$ We can also do the first $k$ eigenvectors in parallel, just do Gram-Schmidt orthogonalization every time.\nTheorem (Correctness of the Power Method)\rUnit vector $\\b x$ satisfies $|\\b x^\\top\\b v_1|\\ge\\delta$. Let $V$ be the subspace spanned by 特征值 $\u003e(1-\\eps)\\sigma_1$ 的 $\\b v$ 们. For\r$$\r\\boxed{k=\\frac{-\\ln(\\eps\\delta)}{2\\eps}}\r$$\rthe result $\\b w=\\left(A^\\top A\\right)^k\\b x$ satisfies that\r$$\r\\boxed{\\left\\lvert\\b{\\hat w}_{V^\\perp}\\right\\rvert\\le\\eps}\r$$\rProof. 单位化后垂直分量的长度，就是 $\\b w$ 垂直分量部分占总模长的比例：\r$$\r\\left\\lvert\\b w\\right\\rvert=\\left\\lvert\\sum\\sigma_i^{2k}c_i\\b v_i\\right\\rvert\\ge\\sigma_1^{2k}c_1=\\sigma_1^{2k}\\delta\r$$\r$$ \\left\\lvert\\b w_\\perp\\right\\rvert=\\left\\lvert\\sum_{\\sigma_i\\le(1-\\eps)\\sigma_1}\\sigma_i^{2k}c_i\\b v_i\\right\\rvert\\le(1-\\eps)^{2k}\\sigma_1^{2k}\\sqrt{\\sum_{\\sigma_i\\le(1-\\eps)\\sigma_1}c_i^2}\\le(1-\\eps)^{2k}\\sigma_1^{2k} $$\n$$ \\text{ratio}\\le\\frac{(1-\\eps)^{2k}}\\delta\\le\\frac{\\e^{-2k\\eps}}\\delta=\\eps $$\nSolution (How to Sample $\\b x$)\r直接均匀随机。书里的结论很傻逼：\r$$\r\\P\\left[\\left\\lvert\\b x^\\top\\b v_1\\right\\rvert\\le\\frac{1}{20\\sqrt d}\\right]\\le\\frac1{10}+3\\e^{-d/96}\r$$\r它是通过单位化 $\\b y\\sim\\Nd(\\b 0,I_d)$ 随机的，然后没单位化的时候，$\\b y^\\top\\b v_1\\sim \\Nd(\\b 0,I_d)$，因此\r$$\r\\P\\left[\\left\\lvert\\b x^\\top\\b v_1\\right\\rvert\\le\\frac{1}{20\\sqrt d}\\right]\\le\\P\\left[\\left\\lvert\\b y^\\top\\b v_1\\right\\rvert\\le\\frac{1}{10}\\right]+\\P\\left[\\left\\lvert\\b y\\right\\rvert\\ge 2\\sqrt d\\right]\r$$\r这里我们有一个更智慧的分析，注意到 $\\b x^\\top\\b v_1$ 和球面第一维分布的坐标相同。这货的 PDF 是\r$$\r\\boxed{f(t)=\\frac{(1-t^2)^{(d-3)/2}}{\\Beta((d-1)/2,1/2)}=\\frac{\\Gamma(d/2)}{\\sqrt{\\pi}\\Gamma((d-1)/2)}(1-t^2)^{(d-3)/2}}\r$$\r(note that for $d=3$, $f$ is uniform distribution)\r稍微 bound 一下，根据不等式 $$ \\frac{\\Gamma(x+1/2)}{\\Gamma(x)}\u0026lt;\\sqrt x $$ 我们得到 $$ \\boxed{\\P[x_1\\le\\eps]\u0026lt;\\sqrt{\\frac{2(d-1)}\\pi}\\eps} $$ 这样就可以放心大胆地只随机单次 $\\b x$ 了。\nProblem (Principal Component Analysis)\r$n$ sample size, $d$ data dim, $A\\in\\R^{n\\times d}$. We want to compress $A$ to $\\hat A\\in\\R^{n\\times r}$.\rSolution\r由于 $A$ 的每行是一个样本，它与 $\\b v_{1\\sim r}$ 点积就可以得到在前 $r$ 个特征方向上的投影，这是“最优的”秩 $r$ 近似：\r$$\rAV_r=\\mat{\\sigma_1\\b u_1\u0026\\cdots\u0026\\sigma_r\\b u_r}\r$$\r这就同时说明一个事情：右奇异向量给出数据的方向，左奇异向量给出各数据投影到 fit plane 上某一维后的坐标。从另一个角度看 $U_r^\\top A$ 给出的就是数据的前 $r$ 个“特征方向”，在 $A$ 每行都是一组人脸数据（二维像素排开）时，$U_r^\\top A$ 就是前 $r$ 个“特征脸”。\r将一个数据投影到前 $r$ 个特征脸上：\r$$\r\\b x\\sum_{i=1}^r\\b v_i\\b v_i^\\top\r$$\rProblem (Page Ranking)\rA directed graph representing the hyperlinks between $n$ websites. We want to calculate: hub weights $\\b u$ and authority weights $\\b v$. Definition:\r$$\r\\begin{align*}\r\\b v_i\u0026\\propto\\sum_j[j\\to i]\\b u_j\\Longrightarrow\\b v\\propto A^\\top\\b u\\\\\r\\b u_i\u0026\\propto\\sum_j[i\\to j]\\b v_j\\Longrightarrow\\b u\\propto A\\b v\r\\end{align*}\r$$\rSolution\rSet $|\\b u|=|\\b v|=1$, we can iteratively update $\\b u$ and $\\b v$... Wait, $\\b u$ and $\\b v$ are just the first left and right singular vectors!\rProblem (Clustering Problem)\rA undirected graph $G$ with $n$ vertices separated into two $n/2$ groups. We only know the graph and\r$$\r\\P[(i,j)\\in E]=\\begin{cases}p,\u0026i\\text{ and }j\\text{ are in the same group}\\\\q,\u0026i\\text{ and }j\\text{ are in different groups}\\end{cases}\r$$\rGoal: detect the division.\rSolution\rMotivation: let $t_i=(-1)^{[i\\text{ is in the second group}]}$, we have\r$$\rP:=\\E[A]=\\Set{\\frac{p+q}2+\\frac{p-q}2t_it_j}=\\frac{p+q}2\\b 1\\b 1^\\top+\\frac{p-q}2\\b t\\b t^\\top\r$$\rThus $\\r(A)=2$ and the second eigenvector encodes the division. So we guess taking the second eigenvector of random $A$ is also viable. To verify the guess, we need to answer these two questions:\rHow large is the noise? How does the noise changes the singular vectors? Bernstein inequality: independent zero-mean $X_i$ s.t. $|X_i|\\le R$, $$ \\boxed{\\P\\left[|S_n|\\ge t\\right]\\le 2\\exp\\left(-\\frac{t^2/2}{\\sum\\E(X_i^2)+Rt/3}\\right)} $$ Bernstein inequality, self-adjoint matrix form: independent zero-mean self-adjoint $d\\times d$ matrix $X_i$ s.t. $|X_i|_2\\le R$, $$ \\boxed{\\P\\left[|S_n|_2\\ge t\\right]\\le 2d\\exp\\left(-\\frac{t^2/2}{\\left|\\sum\\E(X_i^2)\\right|_2+Rt/3}\\right)} $$ （这种东西说的是，$t$ 小的时候像 sub-Gaussian tail，$\\e^{-\\Theta(t^2)}$；$t$ 大的时候像 sub-exp tail，$\\e^{-\\Theta(t)}$）\nNow, $$ A-P=\\sum_{i\\sim j}X_{i,j}(E^{i,j}+E^{j,i})+\\sum_iX_iE^{i,i}+\\sum_{i\\nsim j}Y_{i,j}(E^{i,j}+E^{j,i}) $$ Here $X\\sim\\begin{cases}1-p,\u0026amp;\\text{w.p. }p\\\\ -p,\u0026amp;\\text{w.p. }1-p\\end{cases}$, $Y\\sim\\begin{cases}1-q,\u0026amp;\\text{w.p. }q\\\\ -q,\u0026amp;\\text{w.p. }1-q\\end{cases}$, so $$ \\sum\\E(Z_i^2)=\\left(\\frac n2p(1-p)+\\frac n2q(1-q)\\right)I_n $$ also all $|Z|_2\\le 1$, so $$ \\P\\left[|A-P|_2\\ge t\\right]\\le 2n\\exp\\left(-\\frac{t^2/2}{n\\max\\set{p,q}+t/3}\\right) $$ take $t=2\\sqrt{n\\max\\set{p,q}\\log n}$, $$ \\P\\left[|A-P|_2\\ge 2\\sqrt{n\\max\\set{p,q}\\log n}\\right]=\\Omicron(n^{-1}) $$ which is small compared to $|P|_2=n(p+q)/2$.\nDavis-Kahan theorem: symmetric matrices $M$, $\\tilde M=M+E$, let the eigenvalues be $\\lambda_1\\ge\\cdots\\ge\\lambda_n$ and $\\tilde\\lambda_1\\ge\\cdots\\ge\\tilde\\lambda_n$, for $S\\subseteq\\set{1,\\cdots,n}$, define the eigen-gap as $$ \\gamma=\\min_{i\\in S,j\\notin S}\\set{|\\lambda_i-\\lambda_j|} $$ Let $V$, $\\tilde V$ be the subspace generated by the eigenvectors of $M$, $\\tilde M$ corresponding to $\\lambda_S$, $\\tilde\\lambda_S$ respectively, then $$ \\boxed{\\left\\lVert\\sin\\Theta(V,\\tilde V)\\right\\rVert_2\\le\\frac{\\|E\\|_2}{\\gamma}} $$ where $\\Theta(V,\\tilde V)$ is defined as $$ \\Theta(V,\\tilde V)=\\diag\\left(\\theta_1,\\cdots\\theta_n\\right),\\cos\\theta_1=\\max_{\\b v\\in V,\\b{\\tilde v}\\in\\tilde V,|\\b v|=|\\b{\\tilde v}|=1}\\ip{\\b v,\\b{\\tilde v}},\\theta_{2\\sim n}\\text{ is defined similarly to singular values} $$ or, take orthonormal basis matrix $Q$, $\\tilde Q$ of $V$, $\\tilde V$, we have $$ \\cos\\theta_i=\\sigma_i\\text{ of }Q^\\top\\tilde Q $$ 这个事情套到 clustering 问题就相当于在说什么呢？由于 $|S|=1$ 时相当于考虑对应的单个特征向量之夹角，所以取 $S=\\set{2}$，我们就知道，$A$ 的第二个特征向量和 $\\b t/\\sqrt n$ 差不太多。具体来说， $$ \\gamma=\\min\\Set{qn,\\frac{p-q}2n} $$ 所以 $$ \\P\\left[\\left\\lvert\\sin\\angle(\\b t,\\b v_2\\text{ of }A)\\right\\rvert\\le\\frac{2\\sqrt{\\max\\set{p,q}\\log n}}{\\min\\set{q,(p-q)/2}\\sqrt n}\\right]=1-\\Omicron(n^{-1}) $$ 考虑 $p\\ge q\\ge p-q$. 记 $\\b{\\hat t}:=\\b v_2\\text{ of }A$, $\\eta$ 为“符号校正”参数, 下文 $\\b t$, $\\b{\\hat t}$ 都认为已经单位化: $$ \\eta=\\operatorname*{argmax}_{\\eta\\in\\set{\\pm 1}}\\langle{\\eta\\b{\\hat t},\\b t}\\rangle $$ 错误个数 $$ \\text{err}\\le n\\sum(\\eta\\b{\\hat t}_i-\\b t_i)^2=n|\\eta\\b{\\hat t}-\\b t|^2_2=2n(1-\\langle\\b{\\hat t},\\b t\\rangle)\\le2n(1-\\langle\\b{\\hat t},\\b t\\rangle^2)=2n\\sin^2\\angle(\\b{\\hat t},\\b t)\\le\\frac{32p\\log n}{p-q} $$ with high Pr.\n多个 cluster 的 clustering 方法跟这里讲的很不一样，参见 https://people.csail.mit.edu/dsontag/courses/ml14/notes/Luxburg07_tutorial_spectral_clustering.pdf。\n马尔可夫链 Definitions (Random Process)\rFirst-return time: $T_{i,j}=\\inf\\set{n\\ge 1\\mid X_n=i}\\text{ when }X_0=j$ Return probability: $f_{i,j}=\\P[T_{i,j}\u0026lt;\\infty]$ # of visits: $N_{i,j}=\\sum_{n\\ge 0}[X_n=i]$ $i$ is recurrent iff $f_i=1$ 当 $i=j$ 时以上下标都只记一个 $i$。 Property: $\\E_i[N_i]=1/(1-f_i)$, so $i$ is recurrent iff $\\E_i[N_i]=\\infty$. Theorem (Returning of $n$-dimensional Random Walk)\r$1\\text{-D}$ case: $$ \\P[X_{2n}=0]=4^{-n}\\binom{2n}n=\\frac{1}{\\sqrt{\\pi n}}\\left(1+\\Omicron(n^{-1})\\right)\\Longrightarrow\\E[N_0]=\\sum_{n}\\P[X_{2n}=0]\\sim\\sum_nn^{-1/2}=\\infty $$ so $f_0=1$.\n$2\\text{-D}$ case (考虑组合恒等式或转 $45^\\circ$): $$ \\P[X_{2n}=(0,0)]=16^{-n}\\binom{2n}{n}^2=\\frac{1}{\\pi n}\\left(1+\\Omicron(n^{-1})\\right)\\Longrightarrow\\E[N_{(0,0)}]=\\infty $$ so $f_{(0,0)}=1$.\nFor any $(x,y)$, it is also reached almost surely, because $\\P[(0,0)\\to(x,y)]\\ne 0\\Longrightarrow\\E[N_{(0,0),(x,y)}]=\\infty\\Longrightarrow f_{(0,0),(x,y)}=1$.\n$\\ge 3\\text{-D}$ case: approximately $\\E[N_{(0,0,0)}]\\sim\\sum_nn^{-3/2}\u0026lt;\\infty$, so we expect that it is not recurrent. Accurately, consider $$ \\P[X_{2n}=\\b 0]=[x_1^0\\cdots x_k^0]\\left(\\frac{x_1+x_1^{-1}+\\cdots+x_k+x_k^{-1}}{2k}\\right)^{2n} $$ to get something like $[x^0]P(x)$, we can consider $\\frac{1}{2\\pi}\\int_0^{2\\pi}P(\\e^{\\i\\theta})\\d\\theta$. So $$ \\P[X_{2n}=\\b 0]=\\frac{1}{(2\\pi)^k}\\int_{[0,2\\pi]^k}\\left(\\frac{\\sum_{i=1}^k\\cos x_k}{k}\\right)^{2n}\\d x $$ Notice that $2n+1$ does not contribute to the result, so we can also have $$ \\E[N_{\\b 0}]=\\frac{k}{(2\\pi)^k}\\int_{[0,2\\pi]}\\left(k-\\sum_{i=1}^k\\cos x_k\\right)^{-1} $$ For $k=3$, it's called Watson integral, and the result is $\\approx 1.516$, leading to $f_{(0,0,0)}\\approx 0.34$.\nDefinitions (Markov Chain)\rWe have a state space $\\mathcal{S}=\\set{1,\\cdots,m}$, a distribution over states $\\b p(t)=(p_1(t),\\cdots,p_m(t))\\in[0,1]^m$, $\\sum p_i(t)=1$, and a transition matrix $P=\\set{P_{i,j}}_{m\\times m}$, each row summing to $1$. Markovian: $\\P[X_{t+1}=i_{t+1}\\mid X_t,\\cdots,X_0]=\\P[X_{t+1}=i_{t+1}\\mid X_t]=P_{X_t,i_{t+1}}$. So:\r$$\r\\boxed{\\b p(t)P=\\b p(t+1)}\r$$\rConnected/irreducible Markov chain: $\\forall i,j,\\exists n,P^n_{i,j}\\ne 0$, or $P$ 非零的位置对应的图强连通.\rNote. 对于不可约的 Markov chain，它要么收敛到唯一的状态（无论初始如何），要么在某些状态之间震荡（依赖初始状态），最简单的考虑方法是考虑对角化（实际上不一定能对角化，https://math.stackexchange.com/q/332659），我们有个结论（Perron-Frobenius 定理）是：不可约的情况下，$|\\lambda|\\le 1$ 且所有 $|\\lambda|=1$ 的根都是单根。于是可以想象，$\\Lambda^n$ 在 $1$ 处不动，在其他 $\\e^{2k\\pi\\i/d}$ 处震荡，其余 $\\to 0$。\n实际上上述说法可以感性理解。首先 $I/m$ 一定是个特征向量，然后后面的 fundamental theorem 说明对应 $\\lambda=1$ 的特征空间维数为 $1$。如果 $|\\lambda|=1$ 的部分代数重数 $\u0026gt;$ 几何重数，会造成 Jordan 块 $n$ 次方指数增长，就爆了。另外，除了 $\\lambda=1$ 对应的特征向量之外，别的特征向量各个分量的和必为 $0$，可以考虑 $\\b vP=\\lambda\\b v$ 然后把两边分量都加起来会得到 $s=\\lambda s$。\n总而言之，结论就是：如果 chain 是非周期性的，那么 $\\b p(t)\\to \\b\\pi$；否则就不行。严格证明首先用 P-F 定理，设出 Jordan 分解，就可以得到 $P^n\\to\\b 1\\b\\pi$。还有一种证明方法是 coupling。\nProperty\r$$\\r(\\mat{P-I\u0026\\b 1})=m.$$\rProof. We need to how that $\\operatorname{Nul}\\mat{P-I\u0026\\b 1}=\\span{\\mat{1\u0026\\cdots\u00261\u00260}^\\top}$. If there\\'s another vector $\\mat{\\b x\u0026\\alpha}^\\top$, then\r$$\r\\forall i,\\b x_i=\\sum_{j}P_{i,j}\\b x_j+\\alpha\r$$\rand $\\sum\\b x_i=0$ (so that $\\mat{\\b x\u0026\\alpha}\\perp\\mat{1\u0026\\cdots\u00261\u00260}$), thus $\\b x_i$ are not all the same. By irreducibility, 存在一个 $\\b x_i\\ge$ 它所有出边且有 $\u003e$ 的, so $\\alpha\u003e0$; also 存在一个 $\\b x_i\\le$ 它所有出边且有 $\u003c$ 的, so $\\alpha\u003c0$. Contradiction.\rTheorem (Fundamental Theorem of Markov Chains)\r$\\exists$ unique distribution $\\b\\pi$ s.t. $\\b\\pi P=\\b\\pi$. $\\b\\pi=\\lim_{t\\to\\infty}\\b a(t)$, here $\\b a(t)=$ average of $\\b p(0)\\sim\\b p(t-1)$. Proof. Let $\\b b(t)=\\b a(t)P-\\b a(t)$. On one hand,\r$$\r\\b b(t)=\\frac1t\\left(\\sum_{i=0}^{t-1}\\b a(i)P-\\sum_{i=0}^{t-1}\\b a(i)\\right)=\\frac1t\\left(\\sum_{i=1}^{t}\\b a(i)-\\sum_{i=0}^{t-1}\\b a(i)\\right)=\\frac1t(\\b a(t)-\\b a(0))\\Longrightarrow|\\b b(t)|\\le\\frac{2}{t}\r$$\rOn the other hand, let $B=\\mat{P-I\u0026\\b 1}$, and $\\b x_1$ denote $\\b x$ removing the first column, taking limit on both side,\r$$\r\\b a(t)B_1=\\mat{(\\b a(t)P-\\b a(t))_1\u00261}=\\mat{\\b b(t)_1\u00261}\\Longrightarrow\\lim_{t\\to\\infty}\\b a(t)B_1=\\mat{0\u0026\\cdots\u00260\u00261}\\Longrightarrow\\lim_{t\\to\\infty}\\b a(t)=B_1^{-1}\\mat{0\u0026\\cdots\u00260\u00261}\r$$\rUniqueness is from $\\r(P-I)=m-1$.\rCorollary (Reversible Markov Chain)\rFor SCC, if $\\b\\pi$ satisfies $\\b\\pi_xp_{x,y}=\\b\\pi_yp_{y,x}$ for every edge and $\\sum_i\\b\\pi_i=0$, then $\\b\\pi$ is the stationary distribution.\r注意这里加强了条件，所以这样的向量不总是存在。如果稳态分布满足该条件，则称它为 reversible. $P$ 对称一定是 reversible 的。\r马尔可夫链蒙特卡洛方法 Problem (Sampling)\r我们假设有一个难求的概率分布 $\\b\\pi\\in\\R^{n^d}$，存在一个倍数 $Z$ 使得 $Z\\b\\pi$ 的每一位都好求，也就是各情况概率的比例好求。但是要把它 normalize 需要求和得到 $Z$，而维数是指数级，所以没法算，也没法从中采样。MCMC 可以用来 sample。我们让难求的概率分布为 $\\b\\pi$，设计一个 Markov chain 使得它的稳态分布为 $\\b\\pi$。这样，如果我们想要求 $\\E_{x\\sim\\b\\pi}(f(x))$，就可以通过 $\\b a(t)$ 来求：\r$$\r\\E_{x\\sim\\b\\pi}(f(x))=\\lim_{t\\to\\infty}\\sum_{x}f(x)\\b a(t)_x\r$$\r最好这个马尔可夫链是 reversible 的，这样证明起来方便。设计马尔可夫链的过程是基于一张无向图 $G$。\rSolution (Metropolis-Hastings)\rFor desired distribution $\\pi$ (with no zero entry) and any given $G$, define $P$: $\\boxed{P_{i,j}=\\min(1,\\pi_j/\\pi_i)/r}$, $P_{i,i}=1-\\sum_{j}P_{i,j}$. Here $r=\\max\\deg$. By the corollary:\r$$\r\\pi_xp_{x,y}=\\min(\\pi_i,\\pi_j)=\\pi_yp_{y,x}\r$$\rso $\\pi P=\\pi$. Now 我们就是要根据 $P$ 随机游走，由于 $\\pi$ 的两个位置的比是容易求的，所以相对容易些。然而，$\\deg$ 是指数级的时候，仍然太慢了，所以还得优化。这个 M-H 还有一个更加一般的算法：我们可以将上述算法理解成以 $1/r$ 走到相邻点，再根据两点的概率关系，以某一概率“撤回”。那么 $1/r$ 其实可以改成一个更一般的“提议分布”$T$，然后让\r$$\rP_{i,j}=T_{i,j}\\cdot\\min\\left(1,\\frac{T_{j,i}\\pi_j}{T_{i,j}\\pi_i}\\right)\r$$\r从这种意义上来说，下面的 Gibbs 采样是 M-H 的一种特殊情况。\rSolution (Gibbs Sampling)\r样本空间可以视作一个 $n^d$ 的空间，考虑设计超立方体图 $G$，只有差一维坐标的样本之间有边，最后仍能达到稳态分布，牺牲收敛速度。For $\\b x$, $\\b y$ that differ in exactly one coordinate $i$,\r$$\r\\boxed{P_{\\b x,\\b y}=\\frac{\\P[\\b y_i\\mid\\b x_1,\\cdots\\b x_{i-1},\\b x_{i+1},\\cdots,\\b x_n]}d}\r$$\r$$ P_{\\b x,\\b x}=1-\\sum_{\\b y}P_{\\b x,\\b y} $$\n验证： $$ \\pi_{\\b x}P_{\\b x,\\b y}=\\frac1d\\frac{\\pi_{\\b x}\\pi_{\\b y}}{\\P[\\b x_1,\\cdots,\\b x_{i-1},\\forall,\\b x_{i+1},\\cdots,\\b x_n]}=\\pi_{\\b y}P_{\\b y,\\b x} $$\nProblem (Vertex Cover Problem)\rFor a subset presented by a 示性函数 $\\sigma$, define the energy function\r$$\rH(\\sigma)=\\begin{cases}\\text{\\# of 1s in }\\sigma,\u0026\\sigma\\text{ is valid}\\\\+\\infty,\u0026\\sigma\\text{ is invalid}\\end{cases}\r$$\rand Gibbs measure $\\pi_\\beta(\\sigma)=\\e^{-\\beta H(\\sigma)}/Z_\\beta$, $Z_\\beta$ is taken in order to make $\\sum_\\sigma\\pi_\\beta(\\sigma)=1$. If we run the above algorithm on $\\pi_\\beta$, we will get a great $\\sigma$, and if $\\beta\\to+\\infty$, $\\sigma$ will $\\to$ the best solution. But VC is NPC, so we can imagine that the mixing time must be exponential.\rProperty (L1 Norm)\r$$\r\\|\\b p-\\b q\\|_1=2\\sum(p_i-q_i)^+=2\\sum(q_i-p_i)^+\r$$\rDefinition (Total Variation Distance)\r$$\\|\\b p-\\b q\\|_{\\rm TV}=\\frac12\\|\\b p-\\b q\\|_1$$\r接下来讨论的都是无向图，即 $w_{x,y}=w_{y,x}$，记 $w_x=\\sum w_{x,y}$，马尔可夫链 $p_{x,y}=w_{x,y}/w_x$，这时稳态分布 $\\pi_x=w_x/\\sum w_y$。\nDefinition (Mixing Time)\r$$\r\\tau(\\eps)=\\sup_{\\b p(0)}\\min_t\\Set{t\\mid\\lVert\\b a(t)-\\b\\pi\\rVert_1\\le\\eps}\r$$\rRemark. 这里可能会担心：如果时刻 $t$ 之后又超过 $\\eps$ 了呢？接下来我们会看到，差距是指数缩小的，所以定义成 $\\sup_{\\b p(0)}\\max_t\\Set{t+1\\mid\\forall\\lVert \\b a(t)-\\b\\pi\\rVert_1\u003e\\eps}$，得到的结果和上面的定义就差常数倍（upd: 实际上可以用 coupling 证明，（对于非周期性的）$\\|\\b p(t)-\\b\\pi\\|_1$ 单调不增）。另外可能在其他地方定义的直接是 $\\|\\b p(t)-\\b\\pi\\|_1\\le\\eps$（对于非周期性的马尔可夫链），同样可以证明它们只差一个常数。\rTheorem (Bound the Mixing Time through Conductance)\rIntuition: 找到图的一个割，使得两部分之间以低概率互通。Conductance:\r$$\r\\boxed{\\Phi(S)=\\frac{\\sum_{x\\in S,y\\notin S}\\pi_xp_{x,y}}{\\min\\left(\\pi(S),\\pi(\\overline S)\\right)},\\Phi=\\min_{\\varnothing\\subset S\\subset V}\\Phi(S)}\r$$\r$$\r\\boxed{\\Theta\\left(\\frac{1}{\\Phi}\\right)\\le\\tau(\\eps)\\le\\Theta\\left(\\frac{-\\ln\\min\\pi}{\\Phi^2\\eps^3}\\right)}\r$$\rProof. WLOG assume $\\pi(S)\\le1/2$, then we can write $\\Phi(S)$ as\r$$\r\\Phi(S)=\\sum_{x\\in S}\\frac{\\pi_x}{\\pi(S)}\\sum_{y\\notin S}p_{x,y}\r$$\rFor the lower bound, consider starting in $S$, and each time with $\\P=\\sum_{x\\in S,y\\notin S}p_{x,y}\\quad(*)$ we get to $\\overline{S}$ so by union bound, $\\P[\\text{from }S\\text{ to }\\overline{S}\\text{ in }t]\\le t\\cdot(*)$, and under the condition that $X_0\\in S$ (we can do this since $\\b p(0)$ is arbitrary), $\\P[\\text{stays in }S\\text{ in }t\\text{ steps}\\mid X_0\\in S]=\\Phi(S)$. thus $\\|\\b a(t)-\\b\\pi\\|_1\\ge1-t\\Phi(S)-\\pi(S)\\ge1/2-t\\Phi(S)$. For $\\eps=1/4$, $t$ need to be $\\ge 1/4\\Phi(S)$.\rFor the upper bound:\nLet $\\tau=-C(\\ln\\min\\pi)/\\Phi^2\\eps^3$. Denote $a_i=\\b a(t)_i$, $v_i=a_i/\\pi_i$ (multiplicative error) and sort $v_i$s in decreasing order.\nNow $\\|\\b a(t)-\\b\\pi\\|_1=2\\sum_{i\\le i_0}(v_i-1)\\pi_i=2\\sum_{i\u0026gt;i_0}(1-v_i)\\pi_i$, where $i_0$ is the split point between $\\pi_i\u0026gt;1$ and $\u0026lt;1$.\n$\u0026gt;i_0$ 的再大也大不过 $2\\sum_{i\u0026gt;i_0}\\pi_i$，如果它 $\\le\\eps/2$ 就完事了。\n否则将 $\\le i_0$ 的部分划分连续段 $G_1\\sim G_?$。令 $\\gamma=\\sum\\pi$（前缀和），$G_1=[1]$，每次从上次的末尾加一（记为 $k$）往后找到最后一个 $$ \\sum_{j=k+1}^l\\pi_j\\le\\frac{\\eps\\Phi\\gamma_{k}}4 $$ 的 $l$，$G_{\\text{next}}=[k\\sim l]$。\n已知 $\\gamma_{l+1}-\\gamma_{k}\u0026gt;\\eps\\Phi\\gamma_{k}/4\\Longrightarrow \\gamma_{l+1}\u0026gt;(1+\\eps\\Phi/4)\\gamma_{k}$，至少每次跳跃都乘了这个倍数，所以至多跳 $\\log_{1+\\eps\\Phi/4}\\pi_1\\le-4\\ln\\pi_1/\\eps\\Phi$ 次。\n现在我们只需 bound 每次的贡献即可。此处先得修改一下求和的顺序。令 $u_i$ 为 $G_i$ 开头的 $v$。 $$ \\sum_{i\\le i_0}(v_i-1)\\pi_i\\le\\sum_i(u_i-1)\\sum_{j\\in G_i}\\pi_j=\\sum_i\\pi(G_1\\sim G_i)\\cdot(u_i-u_{i+1}) $$ 其中 $u_{r+1}=1$。我们将证明求和中的每一项都 $\\le 8/\\eps\\Phi\\tau$。\n对于 $G_r=[k\\sim l]$：\nBy the proof of fundamental theorem of Markov chain, $$ \\begin{align*} \\frac2\\tau\u0026amp;\\ge\\left\\lVert\\b a-\\b aP\\right\\rVert_1\\\\ \u0026amp;\\ge\\sum_{i=1}^k(\\b a-\\b aP)_i\\\\ \u0026amp;=\\sum_{i\\le k}\\sum_{j\u0026gt;k}(p_{i,j}a_i-p_{j,i}a_j)\u0026amp;(\\text{imagine as flow})\\\\ \u0026amp;=\\sum_{i\\le k}\\sum_{j\u0026gt;k}(p_{i,j}\\pi_iv_i-p_{j,i}\\pi_jv_j)\\\\ \u0026amp;=\\sum_{i\\le k}\\sum_{j\u0026gt;k}p_{j,i}\\pi_j(v_i-v_j)\\\\ \u0026amp;\\ge\\sum_{i\\le k}\\sum_{j\u0026gt;l}p_{j,i}\\pi_j(v_i-v_j)\\\\ \u0026amp;\\ge(v_k-v_{l+1})\\sum_{i\\le k}\\sum_{j\u0026gt;l}p_{j,i}\\pi_j\\\\ \u0026amp;=(u_r-u_{r+1})\\sum_{i\\le k}\\sum_{j\u0026gt;l}p_{j,i}\\pi_j \\end{align*} $$\nDealing with the stupid $\\sum\\sum$: $$ \\begin{align*} \\sum_{i\\le k}\\sum_{j\u0026gt;l}p_{j,i}\\pi_j\u0026amp;=\\sum_{i\\le k}\\sum_{j\u0026gt;k}p_{j,i}\\pi_j-\\sum_{i\\le k}\\sum_{k\u0026lt;j\\le l}p_{j,i}\\pi_j\\\\ \u0026amp;\\ge\\sum_{i\\le k}\\sum_{j\u0026gt;k}p_{j,i}\\pi_j-\\sum_{j=k+1}^l\\pi_j\\\\ \u0026amp;\\ge\\Phi\\cdot\\min(\\pi(1\\sim k),\\pi(k+1\\sim n))-\\frac{\\eps\\Phi\\gamma_k}4\\\\ \u0026amp;\\ge\\Phi\\cdot\\min(\\gamma_k,\\pi(i_0+1\\sim n))-\\frac{\\eps\\Phi\\gamma_k}4\\\\ \u0026amp;\\ge\\Phi\\cdot\\gamma_k\\cdot\\pi(i_0+1\\sim n)-\\frac{\\eps\\Phi\\gamma_k}4\\\\ \u0026amp;\\ge\\frac{\\eps\\Phi\\gamma_k}4\u0026amp;\\left(\\text{by }\\sum_{i\\ge i_0}\\pi_i\u0026gt;\\frac\\eps4\\right) \\end{align*} $$\nDividing: $$ u_r-u_{r+1}\\le\\frac{8}{\\eps\\Phi\\gamma_k\\tau} $$\n$$ \\sum_i\\pi(G_1\\sim G_i)\\cdot(u_i-u_{i+1})\\le-\\frac{4\\ln\\pi_1}{\\eps\\Phi}\\cdot\\frac{8}{\\eps\\Phi\\gamma_k\\tau}\\le\\frac{32\\eps}{C} $$\nYippee!\nBTW this proof is as stupid as shit.\nTheorem (Bound the Mixing Time through Eigengap)\rFor irreducible, aperiodic, reversible Markov chain, let $\\lambda_2$ be the second largest eigenvalue norm of the transition matrix, for mixing time of $\\b p(t)$:\r$$\r\\boxed{\\left(\\frac{1}{1-\\lambda_2}-1\\right)\\ln\\frac1\\eps\\le\\tau(\\eps)\\le\\frac{1}{1-\\lambda_2}\\ln\\frac{1}{\\eps\\pi_{\\min}}}\r$$\rRemark. 如果 $P$ 是对称的，直接设出谱分解，然后 $1$ 范数和 $2$ 范数之间来回放缩即可，证明较简单（期末考了！）。\rProof. WLOG assume $\\lambda_2=$ actual $\\lambda_2$. Let $D=\\diag(\\pi)$. Although $P$ is not symmetric, $A=D^{1/2}PD^{-1/2}$ is symmetric by reversibility. So we have spectral decomposition $$ A=\\sum\\lambda_i\\b v_i\\b v_i^\\top\\Longrightarrow P^t=D^{-1/2}\\sum\\lambda_i^t\\b v_i\\b v_i^\\top D^{1/2} $$ For some (row vector) $\\b p_0$, $$ \\b p_0P^t-\\b\\pi=\\b p_0D^{-1/2}\\sum\\lambda_i^t\\b v_i\\b v_i^\\top D^{1/2}-\\b 1^\\top D $$ For $i=1$, $\\lambda_1=1$, $\\b v_1=D^{1/2}\\b 1$, so $$ \\b p_0D^{-1/2}\\b v_1\\b v_1^\\top D^{1/2}=\\b p_0\\b 1\\b 1^\\top D=\\b 1^\\top D $$ so $$ \\b p_0P^t-\\b\\pi=\\b p_0D^{-1/2}\\sum_{i\\ge 2}\\lambda_i^t\\b v_i\\b v_i^\\top D^{1/2} $$ 我们可以把 $|\\b p_0P^t-\\b\\pi|_1$ 想象成一个高维凸多面体上离一个点的距离，最远的一定是顶点，因此只考虑 $\\b p_0=\\b e_x^\\top$。 $$ \\begin{align*} \\left\\lvert\\left(\\b e_x^\\top D^{-1/2}\\sum_{i\\ge 2}\\lambda_i^t\\b v_i\\b v_i^\\top D^{1/2}\\right)_y\\right\\rvert\u0026amp;=\\left|\\b e_x^\\top D^{-1/2}\\sum_{i\\ge 2}\\lambda_i^t\\b v_i\\b v_i^\\top D^{1/2}\\b e_y\\right|\\\\ \u0026amp;\\le\\sqrt{\\frac{\\pi_y}{\\pi_x}}\\sum_{i\\ge 2}|\\lambda_i|^t|v_{i,x}||v_{i,y}|\\\\ \u0026amp;\\le\\sqrt{\\frac{\\pi_y}{\\pi_x}}\\lambda_2^t\\sum_{i\\ge 2}|v_{i,x}||v_{i,y}|\\\\ \u0026amp;\\le\\sqrt{\\frac{\\pi_y}{\\pi_x}}\\lambda_2^t\\sqrt{\\left(\\sum_{i\\ge 2}v_{i,x}^2\\right)\\left(\\sum_{i\\ge 2}v_{i,y}^2\\right)}\\\\ \u0026amp;\\le\\sqrt{\\frac{\\pi_y}{\\pi_x}}\\lambda_2^t \\end{align*} $$ 这里最后一个不等式是因为 $\\set{\\b v_i}$ 是一组单位正交基。现在 $$ \\|\\b p_0P^t-\\b\\pi\\|_1\\le\\frac{\\lambda_2^t}{\\sqrt{\\pi_x}}\\sum\\sqrt{\\pi_y}\\le\\frac{\\lambda_2^t}{\\sqrt{\\pi_x}}\\sqrt{n} $$ 因此 $$ \\max\\lVert\\b p_0P^t-\\b\\pi\\rVert_1\\le\\lambda_2^t\\cdot\\sqrt n\\cdot\\max\\frac{1}{\\sqrt{\\pi_x}}\\le\\frac{\\lambda_2^t}{\\pi_{\\min}} $$ 所以可以要求 $t\\ge\\log_{\\lambda_2}(\\eps\\pi_{\\min})=\\ln(\\eps\\pi_{\\min})/\\ln\\lambda_2$，这里 $$ \\ln\\lambda_2=\\ln(1-(1-\\lambda_2))\\le-\\frac{1}{1-\\lambda_2} $$\n下界（不要问我为什么突然开始右乘，我也不知道）：考虑 $P$ 的 $\\lambda_2$ 对应的右特征向量 $\\b v_2$（用于硬凑 $\\|\\b p_0P^t-\\b\\pi\\|_1$ 形式） $$ \\lambda_2^t|(\\b v_2)_x|=|(P^t\\b v_2)_x|=\\left|\\sum_yP_{x,y}^t(\\b v_2)_y\\right|=\\left|\\sum_y(P_{x,y}^t-\\pi_y)(\\b v_2)_y\\right|\\le\\|\\b v_2\\|_1\\sum_y|P_{x,y}^t-\\pi_y| $$ 其中 $\\b\\pi\\cdot\\b v_2=0$ 是因为 $P\\b v_2=\\lambda_2\\b v_2$，而 $\\b\\pi^\\top\\lambda_2\\b v_2=\\b\\pi^\\top P\\b v_2=\\b\\pi^\\top\\b v_2$。现在注意到 $$ \\lVert\\b e_xP^t-\\b\\pi\\rVert_1=\\sum_y|P_{x,y}^t-\\pi_y| $$ 取 $x=\\operatorname{argmax}|(\\b v_2)_x|$，得到 $$ \\eps\\ge\\lambda_2^{\\tau(\\eps)}\\Longrightarrow\\tau(\\eps)\\ge\\log_{\\lambda_2}\\eps=\\frac{\\ln(1/\\eps)}{\\ln(1/\\lambda_2)}\\ge\\frac{\\ln(1/\\eps)}{1/\\lambda_2-1}=\\left(\\frac{1}{1-\\lambda_2}-1\\right)\\ln\\frac1\\eps $$\nTheorem (Cheeger Inequality)\r$$\r\\frac{\\Phi^2}2\\le1-\\lambda_2\\le2\\Phi\r$$\rCorollary\r$$\r\\left(1-\\frac{1}{2\\Phi}\\right)\\ln\\frac{1}{\\eps}\\le\\tau(\\eps)\\le\\frac{2}{\\Phi^2}\\ln{\\frac{1}{\\pi_{\\min}\\eps}}\r$$\rclique: $\\Phi=\\frac12$. 无向连通图: $\\Phi\\ge\\frac1m$, $\\pi_{\\min}\\ge\\frac1{2m}$. two clique connected by one edge: $\\Phi=\\frac{1}{n^2-n+1}$, $1-\\gamma_2=\\Theta(n^{-2})$. one clique + one vertex with one edge: $\\tau=\\Omicron(\\log(n\\eps^{-1}))$. 1D path/cycle: $\\Phi=\\frac1n$, $1-\\gamma_2=1-\\cos\\frac{2\\pi}{n}=\\Theta(\\frac1{n^2})$. 2D $n\\times n$ grid: $\\Phi=\\Theta(\\frac1n)$. dD $n^d$ grid: $\\Phi=\\Theta(\\frac{1}{nd})$ ($S$ takes $x_1\\in[1,n/2]$, $x_2\\sim x_d\\in[1,n]$). ","date":"2025-06-15T00:00:00Z","permalink":"https://littlereuben.github.io/study/course-math4csai/","title":"计算机与人工智能应用数学笔记"},{"content":"这是一篇学习笔记。\r[PDF file] ","date":"2025-05-31T00:00:00Z","permalink":"https://littlereuben.github.io/study/course-calculus-2-2/","title":"微积分 A(2) 期末复习会—知识点梳理"},{"content":"$\\gdef\\b#1{\\boldsymbol{#1}}\\gdef\\d{\\mathrm{d}}$\n这是一篇学习笔记。\r这篇笔记是学普物二时为了理解磁场和电场本质一致的关系时写的，侧重于理解狭相的推导过程。好像这学期普物一也会用，大家可以参考。\n这篇文章里没包含的内容：\n用闵氏空间语言讲相对论，包括时空间隔的几何意义、四维矢量，以及一些高级的上下标表示法。 钟慢、尺缩、质量的三个实验详细推导。 双生子佯谬。 四维加速度的推导（其实应该算是四维力的前置，但是后续只有力变换用得着，我就没推）。 公理 1：在任意惯性系内，所有物理规律都是相同的。\n这里“惯性系”根本没定义，我们可以理解成，是这几条公理定义了惯性系，或者说惯性系要满足这几条公理。\n公理 2：在任意惯性系内，光速均 $=c$。\n公理 *：如果从惯性系 $A$ 来看，惯性系 $B$ 相对于 $A$ 以 $\\b v$ 的速度运动，那么从惯性系 $B$ 来看，惯性系 $A$ 相对于 $B$ 以 $-\\b v$ 的速度运动。\n这条公理本来是可以由前两条公理推导出来，但是太复杂了（详见这里），所以就默认它也算公理了。\n惯性系的描述：一个惯性系中，事件可以用三维空间加一维时间 $(x,y,z,t)$ 描述。同一个惯性（参考）系可以有很多惯性坐标系，但这些坐标系直接只是平移（含时间）和旋转（不含时间）关系，所以这个不是重点。注意，对坐标进行拉伸或压缩后，得到的并不是合法的惯性坐标系。\n惯性系中的观测：可以认为，当一个事件发生时，这个惯性系可以立即得到其坐标，而并非一个站在原点处的人通过眼睛观测这个事件。书中具体实现这个事情，是通过在三维空间的每一点放一个钟，然后对时。 $$ \\boxed{\\gamma=\\frac{1}{\\sqrt{1-\\frac{v^2}{c^2}}}} $$ 钟慢效应：当一个钟在运动时（不一定是惯性地），它本身有一个固有时 $\\tau$。这个固有时与观测它的参考系无关。\n通过对车上法向测距的几何分析（自己看书）（注意需要假设与速度垂直方向空间不伸缩）可得 $\\Delta t=\\gamma\\Delta\\tau$。\n注意这个式子的含义不是“在系 $A^\\prime$ 中经过了 $\\Delta\\tau$ 时间，对应在系 $A$ 中经过了 $\\gamma\\Delta\\tau$ 时间”，这个对应是非良定义的。它的严格表述是，“在 $A^\\prime$ 中同一点处发生的间隔 $\\Delta\\tau$ 的事件，从 $A$ 中来看是间隔 $\\gamma\\Delta\\tau$ 的事件”。\n尺缩效应：类似地，如果两点相对于钟静止，那么两点之间的距离就是固有长度 $l_0$。\n通过对车上径向测距的几何分析（注意需要依赖钟慢效应的推导）可得（与速度方向相同的杆）$l=l_0/\\gamma$。\n更一般的尺缩效应会在下面解释。\n同时相对性：一个系对时的过程中出现两处同时收到光信号，从另一个系看来是不同时的。注意这是一个定性的规律，因为从另一个系来看的长度还需分析。\n洛伦兹变换推导：\n这里我们默认两个参考系的 $(0,0)$ 重合。\n一维洛伦兹变换的推导（依赖于钟慢、尺缩）：\n我们首先不加证明地说，变换存在，且是线性的。\n钟慢效应说，在参考系 $A^\\prime$ 中发生的事 $(0,0)-(0,t)$，可以对应到 $A$ 中发生的事 $(0,0)-(v\\gamma t,t)$；\n尺缩效应需要改一下才能用，书里说的是，长度的测量是通过“激光测距仪”实现的，这个不好搞。考虑这样：$A^\\prime$ 中有一根 $-l\\sim 0$ 的棍子，它的两端经过 $A$ 中的原点作为两个事件。$A^\\prime$ 中是 $(0,0)-(-l,l/v)$，$A$ 中则由于两次测的点相同，故反用钟慢效应，是 $(0,0)-(0,l/\\gamma v)$。\n于是我们有方程： $$ \\left\\{\\begin{align*} \\begin{bmatrix}0\\\\ t\\end{bmatrix}\u0026amp;=\\begin{bmatrix}a_{11}\u0026amp;a_{12}\\\\ a_{21}\u0026amp;a_{22}\\end{bmatrix}\\begin{bmatrix}v\\gamma t\\\\ t\\end{bmatrix}\\\\ \\begin{bmatrix}-l\\\\ \\frac lv\\end{bmatrix}\u0026amp;=\\begin{bmatrix}a_{11}\u0026amp;a_{12}\\\\ a_{21}\u0026amp;a_{22}\\end{bmatrix}\\begin{bmatrix}0\\\\ \\frac{l}{\\gamma v}\\end{bmatrix} \\end{align*}\\right. $$ 解得 $$ \\Lambda=\\begin{bmatrix}\\gamma\u0026amp;-\\gamma v\\\\ -\\frac{\\gamma v}{c^2}\u0026amp;\\gamma\\end{bmatrix} $$\n一维洛伦兹变换的推导（依赖于时空间隔不变性）（《电动力学》（郭硕鸿））：\n光速不变的说法强于 $\\sqrt{x^2+y^2+z^2}=ct\\Leftrightarrow \\sqrt{{x^\\prime}^2+{y^\\prime}^2+{z^\\prime}^2}=ct^\\prime$。我们可以说时空间隔是不变量 $$ x^2+y^2+z^2-c^2t^2={x^\\prime}^2+{y^\\prime}^2+{z^\\prime}^2-c^2{t^\\prime}^2 $$ 于是 $$ (a_{11}x+a_{12}t)^2-c^2(a_{21}x+a_{22}t)^2=x^2-c^2t^2 $$ 给出了三个方程（比对 $x^2$、$xt$、$t^2$ 的系数）。另外，考虑到 $v$，我们知道 $A$ 中的 $(vt,t)$ 对应着 $A^\\prime$ 中的 $(0,?)$。于是 $$ \\left\\{ \\begin{align*} a_{11}^2-a_{21}^2\u0026amp;=1\\\\ a_{11}a_{12}-c^2a_{21}a_{22}\u0026amp;=0\\\\ a_{12}^2-c^2a_{22}^2\u0026amp;=-c^2\\\\ a_{11}v+a_{12}\u0026amp;=0 \\end{align*} \\right. $$ 其中 $a_{11},a_{22}\u0026gt;0$。解得同样的结果。\n注：为什么我们必须要么构造实际场景，要么用有额外公理之感的时空间隔不变性，才能证明洛伦兹比变换呢？因为公理 2 要是用严格的语言描述，必须引入闵氏空间，就很麻烦了。 三维洛伦兹变换的推导（https://zhuanlan.zhihu.com/p/266509750）：我们固然可以用基变换矩阵，但是另两维其实没必要分开。\n空间的拉伸，只需将 $\\b x=(x,y,z)$ 分解为与速度方向共线与垂直的两部分即可（至于垂直为啥不变，我也不知道）。即： $$ \\left\\{\\begin{align*} \\b x_{\\parallel}\u0026amp;=\\frac{\\b x\\cdot\\b v}{v^2}\\b v\\\\ \\b x_{\\perp}\u0026amp;=\\b x-\\b x_{\\parallel}\\\\ \\begin{bmatrix}|\\b x_{\\parallel}^\\prime|\\\\ \\b x_{\\perp}^\\prime\\\\ t^\\prime\\end{bmatrix}\u0026amp;=\\begin{bmatrix}\\gamma\u0026amp;0\u0026amp;-\\gamma v\\\\ 0\u0026amp;1\u0026amp;0\\\\ -\\frac{\\gamma v}{c^2}\u0026amp;0\u0026amp;\\gamma\\end{bmatrix}\\begin{bmatrix}|\\b x_{\\parallel}|\\\\ \\b x_{\\perp}\\\\ t\\end{bmatrix} \\end{align*}\\right. $$ 于是 $$ \\begin{align*} \u0026amp;\\b x^\\prime=\\b x_\\parallel^\\prime+\\b x_\\perp=\\gamma\\b x_\\parallel-\\gamma\\b vt+\\b x-\\b x_\\parallel\\\\ \u0026amp;t^\\prime=-\\frac{\\gamma v}{c^2}|\\b x_\\parallel|+\\gamma t=-\\frac{\\gamma}{c^2}|\\b x\\cdot\\b v|+\\gamma t \\end{align*} $$\n主要要展开的就是（这里 $v$ 再加粗就太阴间了……） $$ \\b x_\\parallel=\\frac{xv_x+yv_y+zv_z}{v^2}\\begin{bmatrix}v_x\\\\ v_y\\\\ v_z\\end{bmatrix} $$ 于是 $$ \\b x^\\prime=\\begin{bmatrix} \\gamma tv_x+x+(\\gamma-1)\\frac{v_x^2}{v^2}x+(\\gamma-1)\\frac{v_xv_y}{v^2}y+(\\gamma-1)\\frac{v_xv_z}{v^2}z\\\\ \\gamma tv_y+(\\gamma-1)\\frac{v_yv_x}{v^2}x+y+(\\gamma-1)\\frac{v_y^2}{v^2}y+(\\gamma-1)\\frac{v_yv_z}{v^2}z\\\\ \\gamma tv_z+(\\gamma-1)\\frac{v_zv_x}{v^2}x+(\\gamma-1)\\frac{v_zv_y}{v^2}y+z+(\\gamma-1)\\frac{v_z^2}{v^2}z\\\\ \\end{bmatrix} $$ 即 $$ \\begin{bmatrix}x^\\prime\\\\ y^\\prime\\\\ z^\\prime\\\\ t^\\prime\\end{bmatrix}= \\begin{bmatrix} 1+(\\gamma-1)\\frac{v_x^2}{v^2}\u0026amp;(\\gamma-1)\\frac{v_xv_y}{v^2}\u0026amp;(\\gamma-1)\\frac{v_xv_z}{v^2}\u0026amp;\\gamma v_x\\\\ (\\gamma-1)\\frac{v_yv_x}{v^2}\u0026amp;1+(\\gamma-1)\\frac{v_y^2}{v^2}\u0026amp;(\\gamma-1)\\frac{v_yv_z}{v^2}\u0026amp;\\gamma v_y\\\\ (\\gamma-1)\\frac{v_zv_x}{v^2}\u0026amp;(\\gamma-1)\\frac{v_zv_y}{v^2}\u0026amp;1+(\\gamma-1)\\frac{v_z^2}{v^2}\u0026amp;\\gamma v_z\\\\ -\\gamma\\frac{v_x}{c^2}\u0026amp;-\\gamma\\frac{v_y}{c^2}\u0026amp;-\\gamma\\frac{v_z}{c^2}\u0026amp;\\gamma \\end{bmatrix} \\begin{bmatrix}x\\\\ y\\\\ z\\\\ t\\end{bmatrix} $$\n用洛伦兹变换解释尺缩效应：值得注意的是，上面说的“尺缩效应”是一般情况的特例。简单分析是无法得到一般情况的。有洛伦兹变换之后就可以分析了。\n尺缩效应的表述是“在系 $A^\\prime$ 中沿运动方向的长为 $l_0$ 的静止的杆，对应在系 $A$ 中长为 $l_0/\\gamma$”。必须定义的是，如何在一个参考系中测量一个运动的杆：如果在系 $A$ 中有两个事件 $(x_0,t)$ 和 $(x_1,t)$（这里简化就用一维空间了），第一个事件是该地该时观测到杆的一头在该地，第二个事件是（另一）该地（同一）该时观测到杆的另一头在该地，那么 $|x_1-x_0|$ 就是观测到的长度。\n那么严格的推导是 $l_0=x_1^\\prime-x_0^\\prime=\\Lambda_{11}x_1+\\Lambda_{12}t-\\Lambda_{11}x_0-\\Lambda_{12}t=\\gamma(x_1-x_0)=\\gamma l$。\n现在我们可以明确，所谓“$A^\\prime$ 比 $A$ 慢/短，反过来 $A$ 又比 $A^\\prime$ 慢/短”，只是没有搞清钟慢和尺缩的严格表述犯的错，这两个效应不能正反连续两次应用（不是“对合”的）。\n速度变换：速度显然可以定义为，如果质点在两处分别出现的事件为 $(x_0,t_0)$ 和 $(x_0+\\d x,t_0+\\d t)$，那么 $v=\\frac{\\d x}{\\d t}$。如果系 $A$ 中有个质点以 $v$ 的速度移动，而系 $A$ 相对于 $A^\\prime$ 以 $v_0$ 的速度移动，那么从 $A^\\prime$ 看来， $$ v^\\prime=\\frac{\\d x^\\prime}{\\d t^\\prime}=\\frac{\\Lambda_{11}\\d x+\\Lambda_{12}\\d t}{\\Lambda_{21}\\d x+\\Lambda_{22}\\d t}=\\frac{\\gamma_0\\d x+\\gamma_0v_0\\d t}{\\frac{\\gamma_0v_0}{c^2}\\d x+\\gamma_0\\d t}=\\frac{v+v_0}{\\frac{v_0v}{c^2}+1} $$ 从这里开始，$\\gamma_0$ 表示 $v_0$ 对应的洛伦兹因子，$\\gamma$ 表示 $v$ 对应的。如果是垂直方向的速度，则 $$ v_y^\\prime=\\frac{\\d y}{\\d t^\\prime}=\\frac{\\d y}{\\frac{\\gamma_0v_0}{c^2}\\d x+\\gamma_0\\d t}=\\frac{v_y}{\\gamma_0\\left(\\frac{v_0v_x}{c^2}+1\\right)} $$ 例：两个相对地球反向分别以 $0.5c$ 的速度运动的飞船，从一架飞船上看另一架，相对速度为 $$ \\frac{0.5c+0.5c}{0.25+1}=0.8c $$ 动量定义：对于一个参考系中一个运动的质点，其动量 $\\b p$ 为一个与它运动方向同向的向量。不同系中动量由于速度不同可能不同，但必须只依赖于 $v$ 和质点本身的性质（而不依赖于参考系），必须满足动量守恒。\n质量定义：对于 $\\b v\\ne 0$ 的质点，动质量 $m_v$ 定义为使得 $\\b p=m_v\\b v$ 的标量，特殊地定义静质量 $m_0$，经过后续推导可知 $m_v$ 在 $v=0$ 处右连续。质量必须满足质量守恒。\n质量变换：考虑 $A$ 中静质量相同的两个质点，一动一静发生完全非弹性碰撞。考虑与碰撞后状态相对静止的另一个系 $A^\\prime$。在两个系中分别列出动量守恒与质量守恒方程，可以解得 $$ m_v=\\gamma m_0 $$ 同理可以得出动量变换，它有个更优美的形式，所以我们放到能量之后讲。\n力的定义：和速度类似，$\\b F=\\frac{\\d\\b p}{\\d t}$。\n功与能量：功的定义和经典力学一样： $$ \\begin{align*} \\d W\u0026amp;=\\b F\\cdot\\d\\b x\\\\ \u0026amp;=\\frac{\\d\\b p\\cdot\\d\\b x}{\\d t}\\\\ \u0026amp;=\\b v\\cdot\\d\\b p\\\\ \u0026amp;=\\b v\\cdot\\d(\\gamma m_0\\b v)\\\\ \u0026amp;=m_0(v^2\\d\\gamma+\\gamma\\b v\\cdot\\d\\b v)\\\\ \u0026amp;=m_0v(v\\d\\gamma+\\gamma\\d v)\\\\ \u0026amp;=m_0\\gamma^3v\\d v\\\\ \u0026amp;=m_0c^2\\d\\gamma \\end{align*} $$ （最后两行就是在凑积分）也就是说，定义能量变化量为做功的话， $$ \\Delta E=W=\\Delta\\gamma m_0c^2=\\Delta m_vc^2 $$ 也是只跟初末状态有关。$m_0c^2$ 被称为静能，$(\\gamma-1)m_0c^2$ 被称为动能，$m_vc^2=\\gamma m_0c^2$ 被称为总能。\n动质量、动量、总能都是守恒量，但参考系不同会不同；静质量不是守恒量，但与参考系无关。考虑一个质量转换成能量的例子：原来一个静止的物体爆炸，碎片向各处飞去。动质量守恒说明，原静质量等于现动质量之和，从而大于现静质量之和。少的质量充当动能。\n最后，我们可以推出能量与动量的关系： $$ E^2=\\gamma^2m_0^2c^4=\\frac{1-\\frac{v^2}{c^2}+\\frac{v^2}{c^2}}{1-\\frac{v^2}{c^2}}m_0^2c^4=m_0^2c^4+\\gamma^2m_0^2v^2c^2=E_0^2+p^2c^2 $$ 四维速度与四维动量：我们希望用洛伦兹变换矩阵直接表示速度、动量变换。考虑速度，其一大问题在于，它在变换后是两个变换量之比 $\\frac{\\d\\b x^\\prime}{\\d t^\\prime}$，这个没法方便地写成线性变换的形式。很容易想到，我们希望让分母变成一个不需变换的东西。所以考虑定义一种初看起来有些不伦不类的速度：对于在系 $A$ 中运动的一个质点，它本身有一个固有时 $\\tau$。若它在 $\\d\\tau$ 的时间内，从 $A$ 观测走了 $\\d\\b x$，定义 $\\b u=\\frac{\\d\\b x}{\\d\\tau}$。\n由于 $\\tau$ 与选取的参考系无关，现在我们就有（可根据实际情况选取一维空间或三维空间的 $\\Lambda$） $$ \\begin{bmatrix}\\frac{\\d\\b x^\\prime}{\\d \\tau}\\\\ \\frac{\\d t^\\prime}{\\d\\tau}\\end{bmatrix}=\\Lambda\\begin{bmatrix}\\frac{\\d\\b x}{\\d\\tau}\\\\ \\frac{\\d t}{\\d\\tau}\\end{bmatrix} $$ 而 $\\frac{\\d}{\\d\\tau}=\\frac{\\d}{\\d t}\\frac{\\d t}{\\d\\tau}=\\gamma\\frac{\\d}{\\d t}$，从而 $$ \\begin{bmatrix}\\gamma^\\prime\\b v^\\prime\\\\ \\gamma^\\prime\\end{bmatrix}=\\Lambda\\begin{bmatrix}\\gamma\\b v\\\\ \\gamma\\end{bmatrix} $$ 同样可以在 $\\Lambda$ 中代入 $-v_0$，求出 $v_x^\\prime$ 与 $v_x$ 的关系，与上面那种推导校验。\n动量变换反而容易了！因为 $\\b p=\\gamma m_0\\b v$，直接就有 $$ \\begin{bmatrix}\\b p^\\prime\\\\ m_{v^\\prime}\\end{bmatrix}=\\Lambda\\begin{bmatrix}\\b p\\\\ m_v\\end{bmatrix} $$ 四维力：动量非常自然地把 $\\d\\tau$ “吸收”进了 $\\gamma$，于是我们又可以通过 $/\\d\\tau$ 定义一个怪怪的力了！（大雾） $$ \\begin{bmatrix}\\frac{\\d\\b p^\\prime}{\\d\\tau}\\\\ \\frac{\\d m_{v^\\prime}}{\\d\\tau}\\end{bmatrix}=\\Lambda\\begin{bmatrix}\\frac{\\d\\b p}{\\d\\tau}\\\\ \\frac{\\d m_v}{\\d\\tau}\\end{bmatrix} $$ 上面就是 $\\gamma\\b F$，但是下面这个呢？实际算问题的时候鬼知道 $\\frac{\\d m_v}{\\d\\tau}$ 是多少啊…… $$ \\frac{\\d m_v}{\\d\\tau}=m_0\\frac{\\d\\gamma}{\\d\\tau}=\\frac{\\b F\\cdot\\d\\b x}{c^2\\d\\tau}=\\frac{\\b F\\cdot\\b u}{c^2}=\\gamma\\frac{\\b F\\cdot\\b v}{c^2} $$ 第二个等号参见功与能量那边的推导。于是（网上有些文章是把 $/\\d t$ 的速度记成 $\\b u$，不要搞混了） $$ \\begin{bmatrix}\\gamma^\\prime\\b F^\\prime\\\\ \\gamma^\\prime\\frac{\\b F^\\prime\\cdot\\b v^\\prime}{c^2}\\end{bmatrix}=\\Lambda\\begin{bmatrix}\\gamma\\b F\\\\ \\gamma\\frac{\\b F\\cdot\\b v}{c^2}\\end{bmatrix} $$ 于是我们发现，力的变换不仅与时空有关系，还与质点当前的速度有关系。\n四维加速度见 https://zhuanlan.zhihu.com/p/114045707。另一个比较靠谱的推导 https://dsl.nju.edu.cn/litao/teach/Ch6.pdf。\n参考书：《从零学相对论》（梁灿彬、曹周键），《新概念物理学教程 力学》（赵凯华、罗蔚茵）。\n","date":"2025-02-23T00:00:00Z","permalink":"https://littlereuben.github.io/study/special-relativity/","title":"狭义相对论笔记"},{"content":"这是一篇记事。\r想分享自己经历的一个一波三折的故事，感觉里面蕴含着很多处事和学习的道理，希望能作为大家的前车之鉴。\nPrerequisite：微积分是作业 $20$、期中 $30$、期末 $50$，A- 要求总评 $\\ge 90$，B+ 要求总评 $\\ge 85$。期中期末都是 1~10 填空 $3$ 分/题，11~17 大题平均 $10$ 分/题。\n开学，我报了 wxf 的微积分。因为自己之前已经学过 A(1) 的大部分内容，所以听了第一节课之后就没去了。wxf 的课有录屏，我就开倍速看录屏跟着进度，2.5h 的课我一般 1.5h 就能听完，节约了时间。 期中之前，回顾了一下，发现，诶，知识点细节还挺多，最好还是梳理梳理，所以依据课件和录屏列了一下知识点的提纲，还讲了个复习会。 期中考了 $98$，似乎是全校前 12，感觉还不错。考完后分批查卷，第一批是 $\\le 63$ 和 $\\ge 95$ 的，那天晚上我自己有点安排（学点东西不想被打断），就没去查；第二天，第二批是 $\\le 70$ 和 $\\ge 90$ 的，我有点空，就去了，结果到查卷的会议室发现已经坐了 20 个人这样，完全排不上。所以没能知道期中自己错哪了。 期中之后开始有考勤，说是捞 F 的，所以我就没管，心想期末考得好些就行了。 下半学期比较难，而且之前没学过微分方程，我就每次看完录屏后记点笔记。期末前大概有三整天复习时间，但因为我把算设的大作业拖到 ddl 前，搞完就剩下一整天了，我那天回顾了一下笔记和错题，做了一套完整真题，和三套真题的压轴题。 期末考当天状态不太好，可能是因为考试是 9~11 点，但平时我一般 9 点才起。填空做了 ~45min，做完第 15 题剩下 30min。当时大脑还是能思考的，就是想东西很乱没啥条理，16 题微分方程，想了各种思路都不会，17 题也不会，最后这两题基本空着了。出来发现 16 题漏想了一种最简单的思路（两边同时求导）。估分至多 $83$。 出成绩发现是 B，我想怎么挂分都没法挂到 $\\le 70$ 啊，有没有可能因为没去签到被调分了。就想去复议。 新学期第一周周二上午向 wxf 发邮件问能不能去查卷，想好了过两天去他办公室见到他，怎么说比较能体现自己认错的态度。下午五点打开邮箱（没有新邮件提醒功能）发现 wxf 上午就秒回了，让我下午过去。我赶紧过去发现他已经下班了，我想如果他是比较严肃的老师，就已经留给他不好的印象了。 周三，第一次微积分课下我当面找 wxf 问他接下来还有什么时候有机会，他说今天下午。下午去找他，发现他在和另一个老师谈话，我就在外面等了 30min 这样。进去发现其实是很平易近人的老师，没说啥，直接打开评卷网页让我自己看。$68$，发现填空 8 旁边有个半对半错的符号，我指出来，似乎是因为没有分母有理化被判错了，wxf 说这里可以加回 $3$ 分。另外 15 题答案错了 $-2$，16、17 没问题 $-17$。惊讶地发现 14 题答题卡上是空的，我当时应该是在草稿纸上算过了，没写到答题卡上去，这个 $-10$。wxf 说回头帮我查一下 $+3$ 后的总评，如果能改等第会联系我。我自己回去算了一下总评是 $84.9$。 周四周五 wxf 没联系我，我想他可能比较忙就没催。周六我发邮件问了下，周日 wxf 回我说可以改到 B+，一早看到我就兴奋了，看来不是因为考勤。去打印复议表。结果看到官方复议通知上写复议截止周五下午 5 点。这个通知之前我就看过，但没仔细注意日期。 很担心。但不管了，赶紧填完表去办公室，门锁着，我想因为周末嘛，得等明天了，越晚希望越渺茫了。去图书馆路上就发了封邮件问他什么时候能给他复议表。刚落座就看到他回邮件说他在（刚到）办公室，微信大群里也 @ 我。我赶紧又过去。他说超过截止日期没关系，会弄好的。总算松了口气。 回去半路上他在大群里 @ 我让我再回去，上去后给我看评卷网页，说仔细看了下小分，发现其实是填空 3 错了（那个半对半错是针对整个 10 道填空的，填空 8 仲裁时就是算对的），这是真的错了，没得改了。 微积分 A(2) 拿了 A+。 ","date":"2025-02-23T00:00:00Z","image":"https://littlereuben.github.io/life/course-calculus-story/cover.jpg","permalink":"https://littlereuben.github.io/life/course-calculus-story/","title":"一个微积分的故事"},{"content":"这是一篇记事。\r前言 我是一名孤独的 OIer。\nOI 对我来说，是数年如一日，两点一线的封闭训练，是光阴飞逝，稿纸如流水的独自思索。不同于其他 OIer，我的训练几乎是与外界隔绝的，不仅是空间上的隔绝，更是信息上的隔绝。我的教练并不精通编程。我无暇参与各校甚至各省 OIer 之间对于具体知识和题目的讨论（在 U 群上参与关于学术的总话题数为 4 次），也无机会了解和借鉴他人对于信息学学习的认识和策略。甚至于集训和讲课，对我来说都只寥寥地存在于数年前的回忆中。我所能学习的，只有那几份高深莫测的集训队论文和良莠不齐的网上博客中那些静止而晦涩的文字，剩下的，便是无尽的思考，跌倒与爬起。\n事实证明，“与外界隔绝”并不会成为失败的理由——因为信息学是一门科学。通过自学和独立思考，我终能在时间的催化下找到问题的正解和进步的阶梯。在科学的训练思路和解题方法的培养下，我收获了属于自己的果实。可遗憾终究是遗憾。曾经在黑暗中摸索的我，多么渴望与外校 OIer 思维碰撞的火花，或是前人从高处射下的一道光，能带来耳目一新的洞见，使我收获灵光乍现的喜悦，激励我向前路迈进。然而事实却是，我的旅途中杳无人迹，只有那一场场 NOI 系列赛事，如灯塔般静静地伫立在远方，等待着时间将我匆匆推近，而后，匆匆离开。\n于我来说，比赛或许不是一次“竞争机会”，而像是一场旅行，一场时空的旅行，一场心灵的旅行。前往那一处赛场，来一回争分夺秒的竞争，我看到的不仅是这城市绚烂的夜景，和千百同我一样为未来奋斗的 OIer，更是自己热血澎湃的奋斗和发光发热的生命，唯有在这时，我的精神不再游离，内心不再封闭，而是注满了勇攀高峰的动力。\n我先前没有写博客的习惯，但我不希望那些记忆被时间冲刷殆尽。这会是唯一一篇关于我的 OI 生涯的完整且具体的叙述，也算是写给自己的吧。\n本文以 NOI 系列赛事为主线，平时训练写得会较简略。\n文中人名以拼音缩写为多，第一次出现或者 id 比较出名的可能会标最常用 id，赛事等也用缩写。大小写比较随意。\n许多回忆不甚准确，若描述与你的印象有冲突之处敬请指正。\n另外，如果你觉得有涉及到与你相关的内容（e.g. 关于你的叙述/你入镜了的照片）使你不舒服，请联系我修改。\n第一场 NOIP 之前 小学三年级，我通过《啊哈 C》接触了 Scratch 以外的编程。\n早早地写完作业。在家里那台笨重的，机箱上沾满灰尘的 XP 系统台式机前，我用单指敲击键盘，跟随书中的指示输入那些奇特的代码，开始了与电脑对话。在小小的绿色 IDE 窗口中，我反复打着用于查看输出的 #include\u0026lt;stdlib.h\u0026gt; 和 system(\u0026quot;pause\u0026quot;);，乐此不疲地制造迷宫字符画和 shutdown -s 的恶作剧。然后被快速排序一节中的小哨兵漫画吸引，又小心翼翼地照抄下一段并查集的代码，在运行成功后惊叹于电脑自动处理“等价关系传递性”的神奇。尽管那本进阶版的《啊哈！算法》对那时的我来说就如同天书，但我就是这样前前后后，不知疲倦地翻着它，我从中感受到了一种共鸣。\n从 16 年开始，在学校兴趣小组，和一个叫爱迪斯的机构里，我初步学习了 Pascal、C、面包板电路和 Arduino 编程（也算是 C），并在 Arduino 电子控制方面做出了几个作品，这是所谓“创客”。我绝对想不到 2023 年第一次翻开《通用技术（选修）》时会发现有一部分自己在四年级学过并且忘光了…\n我实在回忆不起来作为一个小学生的自己是为何被编程吸引的。或许是因为理性中对于自动化和抽象化天然的追求吧？\n在宁波一个不很热闹的小广场旁的写字楼里，有个叫 cx 的机构。16 年暑假我曾去学过一个月的 Pascal，后来到别处改学了 C，再转成 C++。\n2017 年 3 月，我作为唯一一个 C 语言选手参加了宁波市赛，因为不知道 freopen 爆零了。\n17 年暑假，我又来到 cx，在听数学课的同时，也跟着 C 班学些算法。当时写过最长的代码是一份 89 行的普通堆。\n遗憾的是当年的 oj 已经关闭，一些更有意思的代码找不到了\r当时的 cx 还很是热闹，NOIP 和省选赛季时的集训，近百人齐聚一堂，人头攒动，花花绿绿的电脑屏幕从早晨闪烁到深夜。在隔壁摸索着背包和 Prim 的我，时常透过门上的玻璃，瞥见那些初高中的学长们谈笑着涌出 cx 的教室和过道。一些陌生的名字也随着大人们的交谈传入我的耳中：xzt、lyx、yhx、pjq——那些曾孕育或绽放着的神话。\n这是我 OI 的起点，cx 也是我将来 6 年训练的地方。\n2018 年 2 月，我们考了一些 USACO 铜、银组题，开始学习初赛，也听了些算法和高中数学的课。那时隔壁班上有个比较抽象的同学，偶尔会在上课时突然大喊“呀！土豆！”“哇哈哈 AD 钙奶！”或是唱《歌剧 2》。这就是我的 id，YeahPotato 的来由。\n3 月去体验了 ZJOI。4 月开始了短暂半停课，做了少量 NOIP 题，但大部分时间还是在做初中奥数和玩名字大作战。不久后，我确定了就读的初中，jc。\n2018 年的暑假，我第一次尝试了 NOI 同步赛，分数当然惨不忍睹。我也开始跟着大家参加集训，当时讲课的有 小 R、Yazid、Kiana 等老师，我也认识了 ckw(chenkuowen01)、hzy(PYWBKTDA)、ljc 等大佬。同时由于小升初，一部分同学转到 jc、lq 等学校的校队，与我们分离。最后，cx 只剩下我、wt(James)、zrz(wishapig)、why(后 id 改为 hydd) 四个人。还有一些非长期停课的学长间断地和我们一起训练：zjn(GGAutomaton)、lkf(Creeper_LKF)、hgz、pa……19 年后他们中的许多都退役了。\n在那些课堂与集训中，教练向大家介绍 OI 的概况、训练思路和方法，讲述竞赛生的思维优势和前路图景；他也说了一些很遥远的事，他说了金牌，说了清北、MIT，说了未来的一些事业……逻辑清晰，掷地有声的语言，将那些遥远的概念拉到我的眼前，使我开始考虑之前从未想过的事，关于自学和独立思考，关于思维能力，关于梦想与奋斗，关于理念与视野……如同清晨第一次望向窗外，新的观念和信息像阳光一般充满我的双眼，在那一年的时间里，我的思想发生了很大的变化，我周围的人们也是一样。\n但在这光鲜亮丽的面对理想的口号背后，抉择总是现实而艰难的。从一名刚走出小学校园的普通学生，到 OIer，一切都必须推倒，再重建。不必说，那一年我以及我周围的人们做了多少的调整和改变，进行了多少语言和思想上的斗争。\n最后，我们下定决心留在 cx，开始全力全停课训练。用一个形象的英语词组来说：I committed myself to competitive programming.\n我的理由也很简单：我喜欢编程；我想参加比赛；我有了一个清华梦。\n如今，写回忆录的我正坐在离当年集训大教室不远的地方，一切都已回归宁静，办公楼的射灯和机房的日光灯还是有些晃眼，洁净的地砖像曾经那样反射着光晕，满是划痕的墙面却已显示出经年累月的纷杂人事。在恍惚中，那些人们的言谈举止似乎还在我眼前活灵活现一般，那样的明快而充满朝气，使我心中涌起几丝怀念。在那个刚告别小学的夏天——那时的阳光很明媚，一切都满是清新与希望——和同学一起玩着 PVZ 和元气骑士的，稚气未脱的我，怎会料想到，自己将踏上一条特殊的路，会经历几遭酷热与严寒，直到所有人都散去，身边的故事都结束，我仍留在了这里，继续向前走着。\nNOIP2018 开学，在 jc 报到后，我上了一周学，然后停课。\n作为第一次参加正式赛事的选手，初赛前的一个月，我们进行了较高强度的初赛刷题。那本漏洞百出的第一版《信息学奥赛一本通（初赛篇）》，我们考完了它的模拟卷，把千奇百怪的题挨个错了一遍，错题本一页又一页，傻傻地记满了简单的知识点。\n初赛在 yyhs，这是我第一次进入这所中学。我们聚在一个大阶梯教室里考试，这个阶梯教室我去过三次，第二次是 THUSC2024 时作为学生代表上台讲话，第三次是自己的毕业典礼。\n可能是因为总结知识点和错题比较认真，也可能是受益于学习过部分线性代数和组合数学对思维的锻炼，初一的我拿到了不可思议的 $93$ 分（其实我感觉我在初赛上是有天赋的）。然而其他同学的估分不容乐观，返程的车中，凝固的空气使我感到压抑。\n史前画质\r复赛前的训练，教练让我们复习模板、做历年的 NOIP 题的部分分。斗地主、换教室、愤怒的小鸟、天天爱跑步、逛公园、列队……先前只学了模板算法的我并不擅长运用，更不懂什么严格证明，不过也在似懂非懂中勉强写出了代码。几场模拟考我也考得不好。\n考试是在 xj 的紫金港校区，我只报了提高组。那是我第一次，也是唯一一次在体育馆中进行省级比赛，赛场内人来人往，大屏幕上倒计时闪烁。我似乎也受到了这样的阵仗的激发，发挥得不错。\n我当时写了 D1 的游记，放在云剪贴板里，格式比较难看：\n昨晚没睡好...\n清晨的风挺凉爽的\n这次竟然是笔记本，外接键盘、鼠标，不过都挺好用的。\n这解压密码是什么鬼啊。。。\n拿到题，先整个过了一遍，然后就开始做T1——积木大赛铺设道路，线扫就好了嘛，不过为了以防万一，还是打了个对拍。\n第二题想了比较久，证明了一个结论，然后发现是一个背包，然后加一个排序贪心，代码也比较短，主要需要注意的是多组数据。\nT3的话显然不会做全解，然后就开始努(sang xin)力(bing kuang)地打部分分，一个预处理+暴搜，一个链（二分+贪心+线扫），一个$m=1$（树的直径），一个菊花图（二分+贪心+线扫）。4个$namespace$打得整个人都不好了。出来听$dalao$们说是什么二分套二分$log^2$的东西还有树形dp。。。\n电脑Win7,跑的挺快的。考场上还发水和main包。场地挺大的，感觉一个蒟蒻坐在大佬中间好慌%%%\n$\\color{red}\\text{预估分：100+100+55=255pts}$\n假的，肯定是假的。。。\n一起的dalao都比我考得高！o(\u0026gt;\u0026lt;；)oo\n那年的解压密码其实是纪念金庸先生的“飞雪连天射白鹿，笑书神侠倚碧鸳”。\nD1 考完后去吃日料，还看到 kkksc03 在知乎上发 CCF 自己抄自己的段子。\nD2 略难，我尽力将自己能想到的 $80+65+44=189$ 打了出来。$444$ 分的成绩对当时的我来说已是莫大的鼓励。wt 拿到了惊人的 $500+$，why 比我高一些，zrz 略低，但都拿到了一等奖。返程路上教练带我们去喜来登酒店吃自助餐，大家都很开心。\nNOIP 后进入半停课的学校学习状态。\nTHUWC2019 虽然不是 NOI 系列，但也值得记录下来。\nTHU/PKU S/WC 在当时是很有价值的比赛，也是初中 OIer 唯一接触高校的机会。当然作为初一学生，我是以体验的心态去的。\n比赛在广二（科学城校区）。希尔顿酒店是使我印象很深的：在一旁的池塘跳石头，在 17 楼的行政酒廊和 wt、why、hzy 看《猫和老鼠》，一月的广州绿意盎然，充满生机。校园很大，听完讲座后选手和教练们在校门口的阶梯上拍了集体照。\n图片来自 U 群 乖妈\r我一直很喜欢组合问题近似解类型的提答，企盼着能在正式考试中做上（前两年的 THUS/WC 有多道提答）。很可惜，这个梦想至今仍未实现——哦，现在好像再也没有机会实现了。\nD1 把我考懵了，T1 是道莫队，然而我当时只会分块。T2T3 更是毫无头绪，于是我花了 4h 瞎码了 200 行 T1。只拿到了两位数。\nD2 同样将所有时间砸在了 T1 上，T2 交互和 T3 计算几何直接把我吓跑了。\nD2+ 是对我来说相对友善的一场，我较快地分解了说明文档的信息，并写到了 PNG 读入。PNG 输出细节很乱，卡到最后也没写出来（应该有很多选手都是卡在这儿）。最终 pretest 分数为 $63+59+100=222$。\n第一次坐在大佬云集的报告厅中听题的经历着实大大开阔了我的眼界，但这几场考试也使稚气未消的我真切地认识到，自己的水平距离解出 NOIP+ 难度的题还相差甚远。我不出意外地没有进面试，wt 还有其他一些前辈拿到了一等。\n傍晚时分，发约推迟了一个多小时。讲台上下的工作人员进进出出，低头紧张地商量着些什么。最终，招生老师宣布了一条信息：降分协议取消，一等约的优惠政策（原一本线）将不再确定。\n当时的我还不知道，在广州二中宣布的这条消息，成为了 CNOI 的转折点，无数前辈和同辈 OIer 的清北梦随之破碎，决定踏上这条道路的后辈也逐年减少。我的身边，乃至整个 OI 圈，逐渐从人影绰绰，变得灯火阑珊。\n后来 wt 又参加了同样在那里举办的 WC，我由于 NOIP 分数不够无法参加。那是 24 年之前的最后一次全员线下 WC，那最后一次文艺汇演上发生了许多事情——有好的，也有坏的，但我都只能从传言中了解，而或许再也没有机会目睹，那种规模的，OIer 的盛会了。\nZJOI2019 寒假，短暂地回归到生活与文化课中，不过也有几次集训。3 月又开始了全停课，在进行知识点和 NOIP 练习的同时，教练也安排我们以奇怪的方式学习一些文化课内容。\n对了，在这边我想列一下 19 年及之前其他一些通过上课和集训认识的 OIer，我没有忘记你们：\n小学：hjh、sr、zjj\nD 班：jch、syh、tyc、wza、yjc、jwx、czl、zcr、yzt、jds\n其他班：tcb、zty、zhr、syf、zjn、jyt\n后几届：zzb、hmx、gy、hm、gjx、cx、fsz、chk、qqh、wjy、zyc、lyc、zyy、sbn、wb\nlq：mch、pa、sjy、yhj\nyy：hgz、fkc、hjf、fjh、hk、yh、yjz、ylk\n集训：wh、yjh、pd、pdw\n至于 ZJOI，同样还是体验。\n第一场 ZJOI 在 zz。踏入那道朴素但不失风韵的校门，驻足在泮池之上，流连于富的廊，向大成殿内张望……春色将 zz 渲染成一片绿影悠悠的园林（其实这儿以前就是个园林）。另外还记得两个细节：一个是有面墙上有块小黑板，上面写着通知或学长寄语，很有意思；另一个是中午食堂有青椒牛柳。\n课肯定是听不懂的。lyx 在台上选讲《具体数学》，我、zrz 和 why 在后排颓 MC。期间还学了一下 FFT。\nLOJ 上最早的提交\r晚上回家的路上，微信群里传来同学家长发现我们没好好听课，净在玩游戏的信息，于是第二天听课就没得去了。\n考试估分只有 $50$，还因为没脑子忘建子文件夹爆零了。\n第二场在 yyhs，也没有去听课。赛前的晚上，我们在一家有三层楼的粥铺吃饭，走过校门外一条街，看到店面上写有 \u0026ldquo;UKE\u0026rdquo;、\u0026ldquo;Daddy sweety toast\u0026rdquo; 之类有趣名字的灯牌，又到酒店旁的星巴克去，我买了杯抹茶星冰乐。这家酒店叫天港禧悦，在未来来去匆匆的日子里，这里就是我们常至的安顿之所。\n第二天，除了昏暗的走廊和机房，还有一档分块部分分，其他就都记不清了。出来听说同学估分都是 $120$，我好像也是，不知为何最终都挂分了。\n谈起这些早期比赛，我脑海中对它们的印象，其实并不在于考试本身，而是考试之余的所见所闻。那一个个标志性的场景连在一起，拼成了我记忆中的一张张书签。这些记忆点似乎只是最平淡，没有价值的细节，却对我来说有着特殊的意义。它们意味着离开自己熟悉的家，带着自己的本领，怀着自己的梦想，为了自己的命运，到外面的陌生世界去，风餐露宿，用自己的力量去拼搏，去争取人生的机会。这是一种成长，这种成长并不一定在于那三或四道试题，而是一次次经历本身，这些经历让我感受到了自己人生轨迹的变化与延伸。也正是这些经历，将“比赛”与“旅行”这两件看似泾渭分明的概念在我的认知中连接了起来。\n2019 暑期 第一个赛季就这样结束了。主要还是积累知识和经验，继续训练。\n6 月末的集训原本很平常，直到我找到了 http://www.matrix67.com/blog/archives/6039。我被这些图片深深迷住了，我开始研究 Mandelbrot set，又学着写了分形曲线、Martin iteration、牛顿迭代法分形、引力模拟等。zrz 则在 Julia set 及其扩展方面找到了一些有趣的图案。\n数学与程序的美是多维度的：可视化时的冲击、抽象结构的精妙、思考方式的变幻、语言刻画的简洁……随着我投入其中，接触那些浩如烟海的理论，我对编程的理解就愈发地立体与生动，对它的喜爱就愈发地深。这种喜爱伴随着我走过后来漫长的训练时光，使我在解题中，时刻都保持着一种求根问底的好奇。\n我做的一些图案\rzrz 的八次方 Julia set，迭代式为 f(z)=z8+0.268+0.8001358i。他还有很多好康的\r暑假训练强度不大，还是有不少时间用于准备初赛。我对 NOI2019 网络赛并不是很有印象，只记得没 A 题，拿到 $239$ 分。\n8 月初的集训，我遇到了两位和 wt 一起参加过 ISIJ2019 的大佬：crn(127) 和 tsx(qazswedx)，在交流中我了解了许多新的信息和 trick。我的斗志也被激发，AK 了两场考试，其余场次的成绩大多不错（真实情况是，考试中我时常和别人交头接耳），但同时也发现，自己的发挥随考试次数的增多而变差，到最后几天连连失误、挂分。可以说是“耐力不够”。\n期间偷玩了 MC、生火间以及 crn 推荐的 LMOliver 的 mosiyuan。记得有人玩水星迫降，以及我和 why 在教练出差的夜晚打 pvp 和月饼掘一死战，还玩了张 1.14 生存图，是籽岷出过视频的《被掩埋的世界》。\n19 年上半年安排了不少集训和线下课，除去原来已认识的，我又遇到了 wwwwodddd、nirobc、kczno1、jcvb、commonants 等老师。确实，我学 OI 其实起步算比较早，而实际上 18 年 ~ 19 年上是我 OI 生涯中唯一水平突飞猛进的时段。各有专精的老师，各类算法和类型的讲题和考试，在我的思想中穿针引线，初步搭建起了 OI 知识的骨架，使我从基本上只会语法的小学生，一跃成为通晓主席树、点分治、莫反、莫队、AC 自动机、Kruskal 重构树、NTT 等中级算法，并能自主构建基本解题思路的竞赛生——我对 OI 的很多东西开始有了概念。然而学会算法只是踏进了门槛，在此之后，便是一年文化课学习，和煎熬的三年瓶颈期。\n我参与的最后一次线下集训是在 CSP2019 之前。\nCSP2019 初二开始之后，目标愈发明确了。\n开学后 CSP 前大概有三轮集训，别的时间主要就是准备初赛和订正考试题。\n初赛在宁诺的 Siyuan auditorium，名字不错。这是第一次全选择题的初赛，我也拿到了 $90+$ 的分数（似乎是 $94$，记不清了）。我在 U 群的第一次（有效）发言就是关于其中一些题的讨论。\n复赛在文渊，我们的酒店旁是 16 年 G20 旧址。从七楼的露天花园向右走，就能直接到会场。Day 1 考完后的傍晚天气不错，大家就在花园散步，我和 zrz 走到主会场那边，然后沿参观路线穿过宽敞明亮的大楼，反向走到楼下。\nG20 会场楼下\r酒店餐厅比较高级，餐前会送上面包和黄油的那种。我第一次尝试了整块的黄油柠檬三文鱼，就爱上了这道菜，此后心心念念，可惜再也没来过了。wt 和 zrz 后来又在文渊考过试，但都没去那个餐厅。\n赛场则比较阴间，是个地下室，空气不怎么流通。D1 在花了 1.5h A 了 T1T2 后，罚坐了 2h T3 只想到 $10\\text{pts}$。D2 还是只会努力拿部分分，最后是 $100+100+10+84+64+75=433$。\n这是一个不差的分数，全国排名相比前一年上升了 70%。\nTHUWC2020 CSP 之后基本还是半停课，没什么特别的事。比赛前的准备，大概就是连着考了五天题。但我们都知道，这次考试，是真正可能决定命运的第一战。一等约的光环尚未褪去，在 19 年它仍是触及清华的标志，在大家眼中有着不小的分量。\nTHUWC2020 阴差阳错地在 19 年 12 月末举行，人们对未来将发生的事还一无所知。\n提前一天到北京已是日落，我们在鸟巢附近的酒店先住一晚。夜幕降临，我和我妈穿过无人的十字路口，走上奥林匹克公园冬夜的花岗岩道。路旁的草坪覆盖着薄薄的积雪，水立方荡漾着蓝色的幽光。偶有两束暖色的光锥划过身边，随后伴着呼啸声溶回沉寂的黑暗中。我们走了好久。至此，我与 OI 相遇也已两年多了。我回忆起以前，16 年旅游时也曾来过这里——那时我还是一个不谙世事的孩子，只是兴奋于首都这些宏伟的建筑，单纯地好奇着世间的一切；我又开始想象在那并不遥远的未来，踏入更盛大的赛场时，自己将如何经历那些酣战，成长为一名怎样的 OIer。那些画面变幻着在脑海中交织，反衬着当下一切的平静，超然物外之感短暂地占据了我的意识。月光穿过清冷的空气，洒在路前方，似乎投射着一缕黯淡的希望。\n冬奥的倒计时\r考试在东主楼，这是我第二次走进清华。机房不大（有多个），用的是一种奇怪的 Linux，D2+ 时还有同学攻击交互库被老师记名了。考试过程基本上忘了，只记得 pp 了几天的 T1，D2+ 很刺激但 task3 因为不熟悉交互，没拿到会做的部分分。pretest 是 $161+131+96$，确实可以感受到自己的进步，但若放眼看那些更高级的赛事，我所掌握的内容只是冰山一角罢了。\n冬日的清华\r六教的红墙是我对教学区的第一印象。D1 报到后在明理楼听完宣讲，我们就沿着新民路走到南区，去清芬园吃了个午饭。\n在西郊宾馆，我参加了面试，感觉还不错。面试基本上就是自我介绍 + 学习安排 + 英语短文，我没被问到数学题。自我介绍很顺，那篇英语短文是讲区块链和虚拟货币的，还记得有一个单词叫 pseudonym，我虽然不认识，但由于之前学过一些词根的知识，知道 pseudo- 源于古希腊语，是“伪”的意思，并且知道英语里 ps(ψ) 是 silent p，所以发成了 seudo，沾沾自喜了一下。\n下午没有讲题，几个专题讲话后就开始发约。或许是因为面试展示出的表达能力较好吧，我出乎意料地拿到了一等约。why 是三等，zrz 由于不熟悉 D2+ 类型的题考砸了。crn 和 tsx 也是在这次拿到了一等。\n在车上向家人、老师们报告着拿约的喜讯，在机场吃了一碗味千拉面，心里很暖。\n这应该是我的第一次捷报吧。\n2024 年初夏，即将在这里迎接未来的我，站在了同样的位置，拍下了一张同样角度的照片。\n摄于 THUPC2024 决赛当日\r疫情初期 \u0026amp; ZJOI2020 why 离开 cx，转到了 hl。20 年暑假之后，低一两届的同学们也都走了，cx 的老学员就只剩下我们三人。\n网课期间，我也参加了几次线上集训，但成绩一塌糊涂，一方面固然是因为松懈，另外那个时候学校的网课之余接触了些别的爱好，精力比较分散。\n复课后仍然半停，学习了网络流、字符串相关、左偏树等算法。\nZJOI2020 在 xj 西溪校区，题目对我来说还是难得离谱。D1T1 我写了一个新学的 SA，拿了 $40$，其余题都只有 $10\\sim 20$，最终是 $80+30=110$。现在想起来，那时的 ZJ 真的卷啊，各种极具技巧性的题，Lyndon 理论、拉反、随机化、线性规划……榜上有许多一天 $200+$，真是令人叹服。如今在大纲的限制下，题目的思维性和创新性增加，也大大减小了选手的学习压力，但终归有种戴着镣铐跳舞之感。\n2020 暑期 这时开始，我们的训练方式发生了重要的改变。不仅是题目类型上的改变，还有学习节奏的改变，做题要求的改变，以及训练氛围的改变。在这里我可能无法提及过多细节，但可以概括的是，这次改变给我带来了持续的、缓慢的、坚实的进步，但同时，煎熬的三年开始了。\n7 月初，改变开始了，我们面对纸的时间大幅增加。尽管不很适应，但能做出不少 USACO 金组题，感觉还不错。\n但随后就是 NOI2020 网络赛。我考得很差，估分是 $50+24+52+25+16+5=172$，还因为某些原因挂了 $10$ 分。在考完后与 wt 的讨论中我意识到，我拿到的分傻子都能拿，哪怕是一点非平凡的思考我都做不出来。D1T1 的 $(\\max,+)$ 矩阵快速幂、D1T2 的容斥后 dp、D2T1 的贪心构造，有哪个属于我没学过的？有哪个做法是我理解不了的？就是想不到。我开始怀疑自己：从一年前在模拟赛上提前离场的我，成为此时“手无缚题之力”的我，到底发生了什么？\n只能说，NOI 的题目对当时习惯于听课做例题、NOIP 集训模拟考和 CSP 题的我来说，确实是降维打击。我学过的知识点和做过的题，在我的脑中只是一座座孤岛，没有联系，缺乏高度。我的思维还是太浅、太零散了。要在这一步上提升，必须依靠意志力去适应这次改变。\n订正 NOI2020 是训练内容的一部分。我们被要求在没有任何题解、提示和讨论的情况下硬做。最终，在每天 4~5h 的埋头思考下，我在一个多月内都啃出了 D2T3 外的所有题，其中 D1T3 花了两周。\n不必多说那是怎样一个痛苦的过程。但深度思考极大程度地锻炼了我，使我有一种初窥门道的感觉。与此同时，在我们的意识中，解题，从一个解得解不出的问题，转变成了一个解得快慢的问题。然而，这个问题开始无时不刻地困扰我的训练，直至今日。\nCSP2020 \u0026amp; NOIP2020 初赛在镇海职教，应该没下 $90$。考完去东钱湖走了走。\n这两场考试都在 xj 海创园校区，考前的模拟赛发挥还不错。CSP，我利落地在 1h 内做完了 T1T2，但在 T3 上浪费较多时间写了一个假的（带 pushdown 的）线段树合并，T4 是一道有意思的好题，我发现初步的思路跟“海盗分金”问题的思考方式类似，于是会了 $70\\text{pts}$。最终的分数是 $100+100+55+70=325$，还算不错。\nNOIP 则没有那么幸运。在做掉 T1T2 后，T3T4 根本没摸到正解的边。最终 T1 没写高精、T2 卡时间，挂成了 $90+84+40+35=249$。\nwt 和 zrz 则考得比我差些，出现了更多挂分和来不及想的情况。这两次考试过后（结合其前的模拟考情况），我们逐渐注意到，在 NOIP 这一级难度的题时，我一般是考得最好的，教练认为这是因为我基础较扎实；而到 NOI 级别难度时我却成为三个人里考得最差的。这规律就像魔咒一般掌控着我们的成绩。\n2021 年初 \u0026amp; WC2021 \u0026amp; 联合省选 2021 cx 来了几个新同学：lr(linrui)，比我低一级，后来一直一起训练；ckw，冲击最后一年的 NOI；以及其他几位不具名的同学。cx 变得热闹了些，但训练节奏仍然十分紧张。\n21 年初，在原有的训练上又加入了历年省选、WC 真题的模拟以及知识点专题学习。在我们只能考两位数的考试中 ckw 可以拿到 $200+$。WC2021 又是一场只拿到基本分的考试，$32+70+40=142$。花了好几天订正了 WC T1 的 $\\log^2$ 做法后，ckw 直接跟我们讲了线性空间的单 $\\log$ 做法，使用了前两年论文里的 splay 的 finger-search 技巧。也是从那时起，我才开始频繁地学习集训队论文。\n寒假期间一道印象深刻的题是 CF1455E。这道 2400 的题做了好几天还是不会，最后瞎搞过了。同时我们学习了 LCT、ddp、树分治、复杂网络流等算法。后来练手时我和 zrz 一起做了 [ZJOI2019] Minimax 搜索，zrz 拿到了次优解，我则把 uoj 的 std hack 了。\nskip2004 很快就 fix 了\r春节只给一天休息。我向教练要求更多休息，被训了一顿。除夕的下午，窗外下着雨，我们三人在昏暗的教室里写多项式全家桶，直到外面亮起了橙黄色的灯光。这一幕后来时常出现在我的脑海中。\n2 月下旬参加了一个 Innopolis 的比赛，拿了 rk11，但莫名其妙被取消了分数 /fn。\n3 月，教练让我们尝试 CF 和 AT 比赛，然后在打了三场 Div2 和一场 ABC 一场 AGC 后，因为教练判断会影响代码准确性而叫停了。那场 AGC 我花了 1.5h 的假解水过 T1 后摆烂了，赛后发现 jiangly 花了 3.5min 过了 T1。似乎在先前的几年里，不论我怎么训练，都总是会遇到风格从未接触过，却又不那么难的题，扫去我仅有的一点自信心。对此，我也只能不断地摸索和试错。\n第一场 CF\r省选前的模拟考是 CF 3000+ 题，4.5h 内只能做出至多一道。\n省选又回到了阔别三年的紫金港校区，这次开始，我们住在了龙湖天街对面的丽呈东谷。考前我片面地凭自己前几次考试的经验制定了一个很蠢的策略：D1 的 T1T2 都要拿 $100$。在教练的纠正下，我改订了不预设难度的策略。\n考试换到小机房里。D1T1 我因为细节搞错，整个思路就乱了，用了 2h 才调完，后面慌掉了，T2T3 就只拿了基本分。D2 则比较顺利，T1 的思路线很顺，花了 1h 多过了拍，T2 我乱搞想出了一个 meet-in-the-middle 解法，T3 也拿了不错的部分分。\n考完发现 D1T1 和 D1T2 都挂了，但是官方数据没卡，最后是 $100+50+16+100+100+75=441$。wt 想到了 D2T3 正解，可惜由于误认为 dfs 树 $fa_i\u0026lt;i$ 而挂成了 $20$；zrz 想到了 D1T3 更进一步的做法，但来不及写了，D2T3 因为忘记 bitset 用法而手写了一个，但写挂了。\n最终，我拿到了 20 名，并以 D 类报名了 NOI。正式上阵前的演练是必不可缺的。\n5~6 月回去准备中考了。期间考了一次 APIO，发挥很烂，还不如不考。\n然后匆匆地毕业了。\n或许以后会在别处写一些相关的回忆，在此别无多言，暂且借用 wwwwodddd 曾在两道有名的题中写过的话，将它改成了关于我自己的：\nZeit und Raum verbinden dich und mich.\nInformatik trennt dich und mich.\nISIJ2021 \u0026amp; 2021 暑期 我没有时间留恋，因为一切都在加速到来。\n能够参加 ISIJ 真的很幸运，它的年龄限制是出生日期 $\\in[2005.12.31,2008.12.31]$，我刚好是左端点。\n一开始接到通知时我很激动，因为曾听 wt 和 crn 讲过 ISIJ2019 Kazan 的经历：和 300iq 合影，参加 Sabantuy 节传统活动，和隔壁宿舍的外国同学打 MC 和向他们传教 NTT……还有俄罗斯选手把 \u0026ldquo;rooted tree\u0026rdquo; 读成 \u0026ldquo;looted tlee\u0026rdquo; 的笑话。\n去国外参加 OI 绝对是机会难得。情理之中的是因为疫情改线上了。\n模拟赛我的成绩都是前三。我是 B 组，训练赛拿了两场 rk1，数学赛和团队赛大大的差评。Cup 最终是 $100+100+78=278$，T3 是 CF 原题，2600 的脑筋急转弯构造，算上 AB 组是 rk5。有一位初二和一位初一的选手 AK 了 Cup。\n考试期间我见到了不少新的名字，当时还感觉陌生。在接下来的日子里，这些原先默默无闻的名字开始加速进步，实现惊人的反超，冲向每一个排行榜的首页，冲向 OI 圈所有人的视野，冲上 OI 之巅。他们中的许多，将在几年后于我面前出现，冰冷的名字成为鲜活的面孔，成为我的室友、同学，成为与我并肩奋斗的人们。\n7 月开始少量地做 CF 题，形式是 Div1 的乱序、5h、NOI 赛制考试，比较阴间，但我的成绩相对好些。最离谱的一次是 CF1188，我开的顺序是 E→D→C，B 却不会做。8 月考了一次 CTS2019，我却被 wt 大幅超过，结合 NOI 的表现，再次应验了魔咒。\n这个暑假，我们的训练核心从精做题、培养深度思维能力转向了广刷题、提高解题能力，这是一道分水岭。不过这里还欠缺了一些东西——“广”不代表“多”。\n这时起我也开始尝试冲最优解。通过更好的理论解法而非一味的底层优化，我拿到了 NOI2021 D2T2 和 D2T3 的全网最优解。另外一道很有意思的题是 [CTS2019] 无处安放，订正时随便口胡的一个枚举量较大的贪心竟然能得到满分。\n另外我还研究了一些算法（大概到 11 月为止），包括平衡树、KD 树、卷积等。\nNOI2021 Day 0 (7.23) 比赛是 yyhs 承办的，赛场在梦麟中学。\n由于台风“烟花”的影响，我们被通知提前一天到校。傍晚时天阴，学校周围是山和荒地，都笼罩着一层似有似无的灰雾。校门向里立着一面刻字的石墙，后面是一片并不鲜艳的长矩形草坪。校园很新，楼房的墙面没有一点污痕，白与灰的色块分明，但这积雨的天空下也显得暗淡了。我从校门口张望，目光顺着无人来往的长长的走道退向远处：日光灯将报到厅照得透亮，白光射入我的眼睛，牵着我的思绪回到初中的时候——\n初中的傍晚有两种：晴朗的日子，空气都是宁静的，教学楼的白墙和屋顶被晚霞映出从未有过的色彩。我抬着头，流动的霞光铺展开，笼罩校园，眼前这幅火一般的油画趋于静止，留存在我的脑海中；阴雨的日子，我不喜欢撑伞，任凭雨水模糊我的视线，食堂的灯光穿过玻璃和雾，在雨水中折射。我向前看，一条条耀眼的射线与柱子和窗交织在一起，身边的人们仿佛都成为了剪影，只剩下满天的云，和不顾一切向前行走着的自己。如今，在告别初中时光不久后，后一种体验又降临了。我静立着，呼吸着潮湿的空气，感受这里带给我的珍贵的意境。思绪继续向过去的那些印象蔓延，最终在一阵伤感中戛然而止，又回到当下这片清澈的灰色之中。\n是啊，无人时的校园是一个神奇的地方，它有着教堂般的肃穆、山林般的空旷，又比这两者纯粹。我一直觉得，校园的每一处角落都充满着身影、言语和故事，可当我靠近时，那里却坍缩成了当下这一个时间点，幻影消失了，谈笑声停止了，记忆再也无法触及了，这使我怅然若失。夹杂着苔藓的石灰和水泥没有温度，时间的雨水打在上面，须臾便寻不见了踪迹。\n雨开始淅沥地下。我向报到厅走去，暂时忘记了将至的大赛。夜幕渐临，签到后的我拖着行李箱前往宿舍，路灯晕开一片烛火般的光，照亮了斜飞的雨丝。\nDay 1 虽然宿舍有空调，但晚上睡得不大适应，在黑暗中一直盯着上铺的木板发呆。后几天就慢慢习惯了。\n宿舍是三人一间（上铺不使用），有独立卫浴。舍友都是 ZJ 的 D 类，原先我都不认识，不过有一个室友是 why 的同学。另一个室友则经常到同校同学宿舍去打游戏，熄灯后才回来。zrz 和 wt 住在更上面一层，也不是同一个宿舍。zrz 的室友里有 wlzhouzhuan。\n我们去校园里走了走。操场旁有一个露天游泳池。教学楼只开放一个自习室，上二楼的门是锁着的。赛场在报告厅楼上，原先应该是个室内篮球赛场。宿舍和食堂之间有一个池塘，中心还有一个亭子。食堂是自助餐，还不错。\nNOI2021 赛场\r下午去自习。我看了些微积分，准备了笔试，口胡了一下 [NOI2019] I 君的探险的部分分，还想了几道题给 wt 和 zrz 做，记得有一道是，求没有障碍的棋盘上走日字格的哈密顿路径（当时我脑中还没有“构造题”这一概念，也想不到递归、归约构造什么的技巧。最后查到论文才会）。\n晚上在宿舍看东京奥运会。宿舍没有桌子，我只能坐在床中间，电脑架在竖着的行李箱上，刚好能与肩齐平。群友交里还传着一个同学坐在上铺的楼梯上，把脸盆卡在两张床之间用来架电脑的照片。\nDay 2 窗外狂风大作，开幕式取消了。早上我们在一楼的开水间吃海鲜味的合味道。中饭则是冒雨去食堂，道路泥泞湿滑。伞被吹得上翻，伞骨也断了。\n截取自 zrz 拍的视频\r下午去试机，题目是前一年的 NOI D1。笔试满分。\nDay 3 比赛推迟了 0.5h。赛场外人挤人，等待开门时遇见了不少认识但不熟悉的面孔，我也没好意思打招呼。\n开题，T1 一眼 ds 大模拟，但我选择了最烂的写法——直接用树剖维护轻重边而不是上次操作时间戳。细节处理 + 代码 + 对拍共花了 2.5h，写了 200+ 行。T2 也是一眼行列式，但是当时因为太菜，或者可能因为分数比较多有些满足，松懈了，没想到把矩阵先乘起来，只有 $75$。做 T3 时时间所剩不多，非常幸运地看出可以把图缩成一棵树，但是不会有额外边的情况，只有 $44$，感觉给的有些少。wt 把 T2 A 了，zrz T2 的分又少些。\n下午发现评测直接在本机进行，可以直接看测试数据，甚至能拷出来。复评的场面其实挺壮观的。\n晚上听讲课发现大家都 AK 了。还是有很大的差距。\nDay 4 中午 wt 妈给我们点了必胜客，诸老师送了些物资来。\n社会活动因为台风改成嘉年华了，在报到厅旁边，下午。\n我眼力太差，飞镖根本扔不中。zrz 抛骰子抛出了仨 6，他最后把所有项目都玩遍了，拿到一个 NOI 定制狗头金 U 盘以及一些余姚榨菜。还看到 why 在正反拍颠乒乓球，以及 crn 和 tsx 打保龄球。\n结束后外面风雨大作，我没带伞，浑身湿透，蹚着水从一个屋檐跑向另一个屋檐。\nDay 5 由于某些已经忘记的原因，赶到考场时很急，离开考只剩 5min。\n这次我采取了一个很垃圾的策略：三题各粗读 20min，共花 1h 大致看题。事实证明这纯 waste of time。\n看完还是先攻 T1。T1 根本没注意 $k\\le 15$ 这个条件的提示，直接硬对着 trie 想，喜提 $40\\text{pts}$，连全 puts (\u0026quot;0\u0026quot;) 的分都没拿。T2 搞不懂那个运算的意图，只会暴力。T3 只能对着样例解释写容斥，脑抽写了个 FMT，还调不出来了。三题都泛泛地想了想，都不会，只是匆匆写完基本分 $40+35+20=95$ 跑路。\n出来发现 wt 会了 T1，zrz 会了 T2。zrz 担心 T2 写 FHQ Treap 会被卡常，我跟他说挂 $\u0026gt;20$ 分我从上铺直接跳到地上。\n出分，我 T2 挂了 $5$ 分，T3 挂了 $4$ 分。zrz T2 挂了 $30$（当然我说话是算数的，还拍了视频），他说拆掉结构体就 $100$ 了；wt T1 也挂了 $30$ 左右。我还是成了最低分。在赛场里合了个影。另外还祝贺了 crn。\n傍晚报到厅外面挂上了榜，分数线不低。我们三个都是 D 类银牌。wt 考得很不错，差 $50\\text{pts}$ 左右 Au。只算正式选手的话我的排名是 $128$，发现另一位大佬和我同分。\nskc 的分很高，有一种感觉可望不可及的感觉，又有些好像被突然超过（显然这并不是突然）的自我怀疑。\n下午讲题 T1 直接被震撼。T3 ryz 讲完正解后 lca 直接上去反手口胡爆标（原话：“我是一名不知名的 OI 选手”），我虽然没听懂，但回去之后也把那个更优解想出来了。\nDay 6 只能说几家欢喜几家愁。\n另一位高二学长 hjf D1 $275$，D2 崩盘只拿到两位数，整个人崩溃了。也听说了别的人的一些悲伤故事。应该有不少人是 D1 差一点 AK，D2 又发挥失常导致丢金。在那个现场听到这些消息，一刹那就宣告了一名 OIer 竞赛生涯的失败与谢幕，我第一次感受到了那种残酷，离我们这么近。\nckw 告诉我们，hehezhou 去他们寝室说：“这六题哪题有思维难度？“这样的差距使我感到诧异之余，也有些不甘心。\n出校门。天已经放晴，晒得厉害。中午去余姚某广场吃烤肉和糖纸。\n四天后，继续训练。\nCSP2021 后来在较短时间内把 NOI 六题都做掉了，比前一年好，也算有些安慰。\n9 月，我们开始做 ZJOI2016 的题，要求同 NOI2020。也是大概断断续续地做了一个半月，把 D2T3 以外的题都搞定了。另外就是 CF 和 CSP 的模拟考。\n初赛回到了 yyhs，$95.5$。出那道 char 输出 $-1$ 还是 $255$ 的人脑子多少有点问题嗷。\nCSP 又回到了紫金港。T1 比较顺利地脑筋急转弯过去了，T2 调细节卡了一会儿（共 1h）。做 T3 时脑子有些懵，就是差一点点，不会 $100$，感觉不太应该，犹豫着犹豫着，等赶着写完 $60$ 就只剩下 30min 了！我直接开冲 T4 的网络流暴力，20min 写完了！25min 过大样例了！出考场听见有人在喊“对偶图”，突然就反应过来了。\n回去路上把 T3T4 都口胡掉了，发现自己变成了 sb。T3 数据放水了，$100+100+100+60=360$。\n后来交流发现 wt 开局不会 T1，他是先把 T1 放了放把其他题做掉了，最后来做 T1，而且还有一个非常重要的微操：他最后会了 T1 时发现时间来不及，就先写了 $40$，再写 $100$，最后 $100$ 没写完，但是保住了 $40$。这是极为成熟的心理素质和决策，但很可惜，我当时并没有虚心从中学习。\n纵观之前这些考试，除了超出能力过多，只能拿基本分的几场以外，我基本上都是按顺序做题，也没有遇到严重的卡住的情况。尽管随着时间的积累，我在解题方面有了些经验，但竞赛不是单纯的思维竞争，我大赛中没有应对过突破常规的情况，没有临场决策的经验，这给接下来的几场重要考试埋下了无穷的隐患。\nNOIP2021 CSP 之后，继续练习 CF 题，教练进一步提高了做题要求。\n面对第一次真正的比赛，我们都想了很多。我在写了好几张纸的难度分析、预定策略和考试细节。每一天教练都会找我们谈话。当时我们的预判是，T1T2 的难度不确定性大，要做充足的心理准备，于是我就把考虑的重点放在这两题上，根据考试中分析出的难易，制订各种策略变化，时间安排。我也认为在顺利解决了前两题后，T3T4 的变化并不多，无非就是平分时间打部分分，和重点攻一题这两种情况，因此没有过多考虑。\n考前模拟赛都发挥平稳。\n11 月 20 日，还是在紫金港。与预料相反，前两题在读题后不久都有了思路，40min 写完 T1，50min 完成 T2，这场考试的基本分在前 1/3 时间内已紧握手中，没有后顾之忧，我还有大把的时间去思考区分题，发挥自己的实力。看 T3，想了 15min，没想到差分套路，没有后续思路，感到无从下手；看 T4，依照处理这类问题的常规思路向下分析，时光倒流，线段树合并，20min，我会了！\n在思考效率上我绝对与别的选手拉开了差距，还有 2.5h，哪怕需要反复调试，也保底有 $300$，若是时间还有多，还能从 T3 上拿些简单的部分分。这是一次顺利而漂亮的发挥，现在的我只需要顺水推舟，就能将高分收入囊中。现在不要再犹豫，把时间留给 T4 的代码，保证把它写出。\n我不顾 T3 的 $20\\text{pts}$ 基本分，当即开始埋头强攻 T4。\n现在大家都知道，这年的 T4，就是臭名昭著的《棋局》。\n……\n随着考试结束的指令，我终于发现，晚了，一切都完了。我僵硬地起身，我的精神似乎已被那无穷无尽的细节死死扼住而无法挣脱。听家长们说，这是他们第一次看到我神情呆滞地从考场中走出。回去的路上，面对教练的询问，我机械地重复着：“我是能做出 T4 的！”\n回到家，我瘫坐在沙发上。我发现我所作的努力，和我自己，都成了笑话。备考时的无数反思、草稿优化、难度分析、多策略预定、思想心态状态准备，乃至先前为了高一这一年所花费的时间与精力、经受的折磨，哪怕是赛时前两题那么良好的开局，这些都是那么脆弱，在那最后的一念之下，瞬间化作了徒劳。我所积累的实力就是如此成为笑话，我所付出的心血就是这样被辜负，第一次机会就这样如闪电般转瞬即逝，我甚至还没来得及展望未来那些激动人心的试炼，一切就都已结束。为什么？凭什么？\n时间无法倒退回去了，$100+100+0+0$，这一完全没有翻盘可能的分数，既已成白纸黑字。我变得身无分文。\n屋里没有开灯，傍晚的天阴沉沉的，把我们的脸映得苍白。我妈最后说：“如果接下来不行，那没有别的办法，”她哽咽了，“我们只能再熬一年……”\n在复盘后我逐渐意识到，T4 是这场考试最大的坑，我毫不犹豫地跳了进去。当我遇到一道自己想得到的题时，我根本没有客观地分析和平衡风险与性价比等其他因素以及时间的分配，而是被那个实际不一定拿得到的“幻影分数”冲昏了头脑。我希望证明自己的实力，希望通过这一题与别的选手区分，可最后我成了一个贪婪的赌徒，我的赌资——时间被我逐渐投进了这个无底洞，我愈发狂热地坚持做着这题以挽回沉没成本，最后输得精光。\n事实上，教练在考试前就注意到了我这一非常危险的心理状态并反复提醒了我。可语言在传达这种深刻而复杂的道理时显得无力，我的大脑在这场考试以及接下来的多场考试中都难以贯彻这一原则，而只是暴露出原始的、非理性的本性。而这教训，只能在时间的推动下，在一次次刻骨铭心的失败中慢慢烙印在我的意识中。\nwt 基本上把能做的分打满了，T3 拿了 $88$；zrz 也有 $276$。魔咒被向坏的一面打破了。\n由于这两年 CSP 和 NOIP 模拟赛我的发挥都很稳定，教练从此开始在赛前常会说：不管模拟赛考得多好，都不能在正式考试中绝对相信任何人。\n后来又计时做了一下 T4，花了 3.5h；T3 似乎跟我有仇，做了半天还是只会 $48$。\nCTT2021 经历了几天的低沉，还是回到正常的训练节奏中。失利又怎样呢，在下一次曙光来临之前，只有顶住压力，更加严格地训练。\n我们报名了精英培训，练习 OI 中最难的那些题。\n互测确实是令人激动，评测鸭和 uoj 的缝合 + hwhelper 用起来也很舒服。说几道印象深刻的题。\nR1T2 硬推了一个 2-SAT 模型，竟然用神奇的缩点 A 了，增加了不少信心。\nR2T2 对我对 dp 的理解很有启发。\nR5T2 非常好组合模型。\nR5T3 幸运地推出了式子，少有地用上了多项式全家桶。\nR6T2 提答圆梦了？似乎不是最正式的那一类考试。同时也意识到了爬山往往比退火好用。\nR7T1 考了我刚刚研究过的卷积相关，但是没做出来。\nR8T2 在赛后公布题解前拿到了最高分 $45$。\nR8T3 很有意思的交互。\nR9 开始，教练要求我们三题平分 5h 用时，考起来很难受。\nCTT 留给我的也更多是考试以外的回忆。\n忘记是 5 号还是 6 号到深圳的了，与 THUWC2019 的印象相似，深圳的冬天也是绿树成荫，繁花遍布。酒店向南几十公里就是香港。去酒店旁的广式茶餐厅吃了个下午茶，灿烂的阳光透过玻璃照进吧台，空气中充满了暖意。\n皇冠假日酒店的吧台旁立着 CTT 的标牌。zrz 说酒店入口有个假人反复在喊 \u0026ldquo;Happy holidays\u0026rdquo;，然后偶尔会在末尾加一个 \u0026ldquo;to↑you↓\u0026quot;，特别洗脑。在酒店里见到了很多大佬的面孔，我的室友是 ynycoding。\n酒店的早餐算是豪华的那种了。有一天吃早饭时，旁边一个应该是做计算机行业的中年人问我在参加什么比赛，用的什么语言。最后他说：“我高中的时候还不知道在干啥呢。”\n7 号我们第一次走进 CUHKSZ。一群挂着胸牌的高中生走进校园显得有些格格不入——可能更多是气质上的朴素和不成熟吧。我们来到一个类似阶梯教室的房间，这里的布局与中小学的阶梯教室不同，不是一个讲台和投影机在前，后面一排排听讲桌这样的整齐划一的结构，而是一个多层的环形，最中间是空的，环的层数不多，里外层不感到很疏远。这样的设计带来一种平等、共享的气氛。\n我在座位上推自己研究的该死的组合恒等式，那是做了《生活在对角线下》之后推广得到的，$\\sum_i\\binom{3i}{i,i,i}\\binom{3(n-i)}{n-i,n-i,n-i}$，似乎没有个封闭形式。这时开始放 CUHKSZ 的介绍片，之后是一个本科毕业学生做的毕业歌《时间之间》。这首歌的旋律给我留下了很深刻的印象，间奏插入了一首八音盒版《爱的礼赞》，使人眼前一亮的技法。\n校长、副校长和 dzd 主席以及各校教练等入座最里环。校长和副校长讲话时都夹了些英文，讲了一些理念，我当时很认同。具体内容现在大多忘了，只记得一个：nfls 的老师问校长，现在越来越多低年龄的孩子开始学编程，如何引导他们，培养逻辑思维能力？校长说，相比逻辑，他认为培养孩子的直觉——intuition 更重要。这也打破了我的思维惯性，尽管我们都知道 intuition 的益处，但似乎 OI 学习到某个阶段后，intuition 的作用就淡化了，以至于被遗忘甚至否定。\ndzd 讲完后让三名学生发言，前两名女生是事先准备好的，后面又选了一位幸运老哥\r这天在酒店的会议厅吃“晚宴”，选手们围在一个个圆桌周围，dzd 说是促进大家交往，但我所在的桌就是很尬。\nD1 的题难度倒序排列，先做掉了 T3。T1 是静态区间半群查询问题，我在 CTT 结束后一个月才开始研究这个，而当时连其矩阵表述都没看懂，于是爆零了。T2 是一个经典套路（monster hunter）+ 四毛子，我写了个四维 KD 树，自然 T 了。\nD2 比较阴间，T2 我会了一个 $\\Theta(\\log k)$ 次的做法，把自己吓了一跳，后来有人说可以 2 次。wt 几乎把 T3 A 了，我却扔了 T3。\n考完我们到图书馆外面的桌上继续想题，周围都是做功课的大学生，还有人在录制视频，我们都不敢发出声音。有一次出校门打车还看见有选手在球场跟大学生打球和玩飞盘。\n中间有一天活动，我在车上看 3b1b 讲神经网络。先前往神仙湖晨跑，环境不错，据说 CUHKSZ 的学生面临大考前会来这里跑步。早饭是在学校里吃麦当劳。吃完后我们打扑克，这时有个志愿者凑过来（志愿者有好多人），号称自己很强。每人 17 张，结果 zrz 334455 + 三带二 + 三带二 + 大王 给出完了（由 zrz 本人回忆），我、wt 和志愿者一张牌也没出。\n之后就是参观校园。我这组的路线应该是宿舍→图书馆→上园。一路上看到教学楼上挂着书法的条幅，志愿者说是校长写的。有一个写的是“松而不懈”，很有意趣。从挂满各国国旗的长廊走向图书馆，馆内部的设计很独特，有几面跨数层的内墙，很是壮观。整理书的只有一个机器人，听说晚上关闭的这段时间刚好能整完。\n图书馆内外景\r带队的志愿者大姐姐人很好，给我们每人买了一支雪糕。\n后面到上园吃午饭，还有牛乳茶可以买。不远处有四栋宿舍楼，应该有二三十层吧，比居民楼还高。\n下午集中到一个报告厅，有位英语老师讲了节 ??? reading（忘记第一个形容词是啥了，好像是 active 之类的），是读海明威作品的一个片段，还搞了个竞答小程序，大家都很欢乐。开始答题前有参与 id 显示，老师逐一读了出来，读到一位叫 白井黑子 的（后来才知道就是 zzh）时，大家都开始笑。另外也有人问 YeahPotato 是谁，我隐约听见有回答。最后拿了 rk10+，前三名上去 role play，crn 是 rk2 /bx。\n然后来了两个搞过 OI 的 CUHKSZ 学生，有一位好像还是 yyhs 的。老师鼓励着踊跃提问，但大家都比较不好意思。\n这时还早，接下来还安排去参观某个实验室，我们因为镇海疫情的波及得做核酸，就提前走了。\n不知不觉中，开幕式和游校园为我打开了一扇望向未来的窗，我发现自己被这里人们的格局和气质深深地感染了，先前的压抑和狭隘暂时消失了。见到了更广阔的风景的同时，一种微妙的感觉在我心底产生——我意识到在长期的训练中，自己的心境被封闭和偏执所占据，独自艰苦奋斗而力争顶峰成为我眼中唯一的一条路，直到这次经历再次提醒我，这个世界充满着阳光与色彩——可这不是每个人从小就知道的么？我已经将其遗忘了多久？我眼中的世界何时渐渐变得只有黑白两色？\n我不禁感到一丝悲哀。\nD3 全不会。\nD4 的 T2 部分分比较友善，拿了 $70$。T1 是个半阶板子，但当时不会。\n总成绩是精英培训倒数。\n2022 年初 \u0026amp; WC2022 这一段时间，新的训练内容包括 ds 方面国集论文研究讨论以及难题解题分析。尽管彻底理解他人的思想是一件耗时耗脑的事，但我确实收获了不少。结合以前 lca 讲课的点拨以及对论文的深度思考，我对 ds 的认识深入了很多，具体分析了分块、线段树、各类分治、树分块与分治以及亚 $\\log$ ds 的底层原理（当时的一个笑话：经我研究得到，最优的线段树是第一层三叉，后面两叉，比全两叉快了 $0.17$ 的运算量），还“发明”了一个点分治簇结构（本质上就是全局平衡二叉树），取名为“兔耳朵树”；wt 另外研究了几类特殊 ds 问题以及矩乘归约；zrz 研究了更多分块相关，还发明了一个（已经被发明过的）zrz 树分块法。解题分析则使我吸收了一些高级解题套路。\n有两道印象较深的题：CF1503F（Balance the cards，WC 之前做的），我独创了一个有向图贪心压缩法（实际难度估计只有 3000，但是好像当时自己没写严谨证明？），拿到最短解。WC2022T1，肝了出来结果无处提交。\nWC 发挥还行。先攻 T2，写了个根号 $\\log$ 拿了 $80$，然后搞完 T1 $25$ 后开始做 T3，挺好玩的（但是后来被出烂了），$89\\text{pts}$。最后 T1 部分分数据出错了 /ruo。\n可 WC 考得好有什么用呢？\nZJOI2022 及之前 NOIP 失误的乌云并不会因为一些零星的进展而散去，随着省选的迫近，窒息之感愈发严重。\n2~4 月开始训练随机 3000~3300 CF 题，穿插了历届互测题的考试。这是我们第一次集中做固定难度的 CF 题，由于实力的欠缺以及其他一些主客观原因，这几个月我每天都处于很大的压力和痛苦中，也发生了很多事，但这边就没法作详细展开了。\n4 月联合省选进行，我们也跟着模拟。我 D1T1 做了 3h，D2 会了 T2 但来不及写，考出了一个触目惊心的分数。\n因为疫情，浙江在半个月后举行（最后一次）独立命题的 ZJOI，在 jc。D1T1 是道好题。D1T2 想到了正解，但是根号分治其中一半写错了，没过拍，考试结束还没调出来。其余题就拿了基本分。$60+40+40+55+0+20=215$，似乎是一个压线的分数，难以弥补 NOIP 的欠缺。\n最后拿的 C 类。\nNOI2022 之前 \u0026amp; APIO2022 联合省选 D1T1 我们都做得很不正常，尤其是我，花了过多时间处理做法细节，且还是调试很久。教练分析是这类任意类型基础题缺乏熟练度，于是我和 wt 开始刷 CF 2100。随着熟练度提升，逐渐加到 2600。尽管不时也会遇到困难，但我们总算是找到了一个较稳定的训练节奏。这个训练一直持续到 NOIP2022 之前，扎实了基本功，确实是很有收益的。\n期间穿插的是学考自学、几道难题的练习以及 IOI 模拟（考得很烂）。花了近两周做了 ZJOI2022D2T1，喜提最优解。\nAPIO 我是倒序做题。我在 T2 的 $60\\text{pts}$ 上卡住了，先是有一行代码写错位置，调了 1h+，然后是 $\\mathrm{3e7}$ 运算量的链式邻接表竟然卡不过 2s。我知道寻址不连续，但没想到会这么慢……我又不肯放弃 T2，整体就又乱了。最后拿到了生涯第一块铜牌。很喜欢 ix35 的一句话：\n算法竞赛打 apio，就像，只能度过一个相对失败的人生。\nAPIO 后开始逐渐增加了非真题模拟赛的频率（只是我们内部考）。题目类型面广，不乏高质量和有意思的题，我做出了好几道高难度找规律（我的数感竟在这时有了用武之地）以及超纲算法题。但总体而言，我的状态持续低迷。每一次自认为把部分分打满了，别的同学却总能 AC。正解其实不难，但总是因为这样那样的原因没有想到。我的自信渐渐被消磨。教练鼓励说，我们的水平在金牌线上下波动，只要发挥出正常的水平就行。可随着离 NOI 剩余的日子越来越少，我的发挥却从未有抬头的迹象。三个人的考试，一半都是 wt 第一，zrz 也有了不小的进步，开始超过我，拿了数次第一。我却永远无法触碰到模拟考的预估金牌线。\n听说 NOI 推迟的消息时，我的第一反应不是“可以多调整一个月了”，而是失落——我分明地知道，这是因为想早些 end the suffering。NOIP2021 之后，在潜意识里，我对自己水平与进步能力的信心，对此赛季的希望，那些支持我脚踏实地训练进步的意志与观念，已经被蛀空，取而代之的是苟且的侥幸。对 NOI 那颗真诚而炽热的心已然悄悄冷却。\n可能确实无法用少量文字描述出我当时的状态和前因后果，这一部分内容不可避免地显得突兀。只能用两句话概括吧：\n量变导致质变，可我们对量变有正确理解和意识到量不够的时间太晚了，现在，来不及了。\n高一经历的种种事情，已使我无法维持自身精神的稳定。\n2022 年很艰难。\nNOI2022 Day -7 ~ -1 由于疫情管理要求，提前前往昆山。\n我们住在金鹰尚美酒店，旁边是一个广场，吃的很多。\n期间又进行了五场模拟考，发挥一般，身体也因为压力大出现了失眠、流鼻血、拉肚子等情况。七月和八月，我开始有些抑郁的感觉。\n复习板子的时间不够了，后面到学校里还在临时抱佛脚，来不及写一遍就只能在凌乱的桌面上草草翻看自己以前的笔记和代码。\n精疲力竭。\n我屡次躺在床上，闭上眼，脑海中回荡着这样一个声音：“感受绝望吧，因为绝望之后就是希望。”\n可希望，似乎没有那么快到来。\nDay 0 (8.20) 进校。昆山狄邦华曜是一所国际学校，中学部完全是欧式风格，从正门看，综合楼前有六根大理石柱，门楣上印有校徽。上层逐层缩小，顶部有一个钟楼。远看真的和教堂一样。旁边的幼儿园部则是白墙灰瓦的中式建筑。\n综合楼外墙主要是蓝灰色，内部的灯光则是暖色调，和深色木材及米黄色石材配合。签到台后面是旋转楼梯，螺旋逐层缩小，直通最顶层。二楼挂着各国国旗，三楼是图书馆。食堂在左边，旁边还有一个卖点心和饮料的吧台，我点了杯百香果双响炮。右边是签名墙，后面进入一块天花板直达房顶的开放式活动区，架空的楼梯和横廊在上方的空间穿行。二楼再向右就可以看到比赛的体育馆。\nNOI2022 赛场\r食堂再向左就到达宿舍，我们都住在五楼，但是有电梯！房间非常高级，进门右侧是盥洗台，有两个水槽，左侧是独立的洗手间和浴室，再向里才是两张床和桌椅，和酒店双人间差不多。zrz 和 wt 住同一间。我的室友是 lyc(Lynkcat)。\n桌子略小，我就搬到了盥洗台旁边，这样能同时利用台面的空间。\n晚饭饭菜跟前一年差不多。\nDay 1 发物资。除了室友、wt 和 zrz，我只找了 crn 换徽章。\n晚上我们在校园里走了走，看见了 zyy。\n晚霞很美，但少时就暗淡了。\nDay 2 在宿舍里写 ZJOI2022D2T3 深搜，没有参加开幕式，听说有无人机表演。\n试机题是 NOIP2021，我写了一下 T2。匆忙之中忘记测电脑速度了。笔试题和去年一样，但没有当场公布成绩。\n晚上终于 A 了深搜，手忙脚乱地复习一下剩余的知识点，看了眼考试注意事项便睡了。\nDay 3 进考场时查得比前一年严。\n开题。T1 发现是个模拟，写了线段树合并 + 链表，花了 1.25h 搞完了。T2 不会入手，尽管以前做过 dp 套 dp 的题，但一直在想贪心和初步的性质，不会判定，后面只能打表。期间写掉了 T3 的 $10\\text{pts}$。\n最后 T2 总算想到了一个常数巨大的判定性 dp，可以过 $l_i=r_i$ 部分。时间也到了。没有大失误，实力确实还差一点。\n出分时发现 T2 卡常成 $25$，其中第 7 个点跑了 1.073s，开 -Ofast 只要 0.3s。为了处理 1~3 我在判定函数外面套了个 dfs，照理来说 $l_i=r_i$ 时相当于没枚举任何东西，我测试给判定函数加了 inline 之后第 7 个点却刚好跑进 1.000s，搞不懂。T1 的易错细节我都注意到了，但是线段树数组少开了 $\\mathrm{5e5}$，没挂分。\nwt T1 因为 2 操作链表漏细节，挂成 $65$，T2 $15$。zrz T2 $55$ 挂成 $40$，说是 dfa 部分的一个 $11$ 打成了 $10$。\n大家不希望看到的情况还是发生了。\n听说队线大概是 $140$。大家好像都失误了，也多是因为 T2 没想出来，或 T1 挂分。回宿舍的路上我跟教练说，这场考试，瞄得越高，考得越差。\nDay 4 因为疫情，社会活动又取消了。一早，教练来叮嘱我和 zrz 要稳一些，D1 无功无过，D2 正常发挥实力，稳住就行了，然后让我们在宿舍里做 CF 3200 保持手感，于是就没去参加校内活动。下午讨论完题，我们又在校园里徘徊。\nD2 的压力是 D1 的两倍。\n晚饭后做完最后的准备，我们穿过宿舍楼间的草坪和星星点点的灯光，到操场去。无边的漆黑，只有跑道的几段被高柱上的 LED 照得微微发白。我们跑得时快时慢，黑色的人影时而落后，时而又互相赶超，没有说话和呼吸的声音，只是在默默地暗示自己，暗示对方。\n熄灯时，我开始想象第二天的晚上，24 小时后，一切都已天翻地覆了，那时的我会是怎样的心境呢？\n闭上眼，不知该期盼还是祈祷。\nDay 5 拉肚子，开考前 5min 才到考场。这两年的 D2 都没有在开考前留出足够的时间调整状态。\nT1 是个树哈希，我还是大概知道树哈希怎么写的，花了 1.5h 完成了 T1，算是比较快了。我用的哈希是 $h_u=(\\sum h_v\\cdot f({siz}_v))+1$ 这种，实际上是错的，但是没卡。\nT2 我比较快地会了 $48$，同时发现了一个较为难写的 $n^2$ dp，可以有 $72$，并且易于优化。我感觉很乐观，就先写掉了 T3 的 $10\\text{pts}$，开始攻 T2 正解。我联想到了一篇集训队论文里保序回归的做法，发现，套个整体二分上去，整个问题就非常优美地转化成了 $V_i\\in{0,1}$ 的部分分，然后模仿保序回归的思路写了个证明。一切看起来都严丝合缝，是时候一鼓作气，拿下这题了。\n是的，当时的我眼里只有希望，那种无比宝贵而理想的希望，那种使我感到一脚已迈入胜利之门的，自己即将迎来令人振奋的全新的未来的，甚至在那赛场上那令人窒息的最后两小时中能带给我安全感以至于使我心神宁静的希望。我感到自己从未离金牌这么近过。禁锢终于要被褪去，一切都要解放了。\n我向监考的 Itst 一口气要了 10 张草稿纸，奋笔疾书起来。而我没有意识到的是个显而易见的事实——将 NOIP2021 的惨痛教训抛之脑后的自己已经疯了，彻底地疯了。\n我没有代入任何一个样例去验证这个二分，哪怕 $n=2$。所谓“理论证明”的那一大段话就是自我欺骗，欺骗自己赶紧写下代码，我甚至在心中向自己吹嘘，这个解法的复杂程度和这题的难度配合得恰到好处，我已经猜出了出题人的意图。想到这一“高级的、极具技巧性的”做法时，我的头脑就已被冲昏。\n代码写完了，过了第一个样例，没有过第二个。我开始调试。\n当我意识到整个代码都是错的时，只剩下 0.5h 了。我没写出 $n^3$ 的 dp，只写了一个暴搜。\n在这短短的一个小时里，我的心态从天堂重重地掉入地狱，摔了个粉碎。\n场上响起纷乱的脚步声，我出来了。我走到等在门口的诸老师旁，他安慰我：“大家都差不多这个分的。”但我清楚，金牌已与我失之交臂，我又一次把这来之不易，甚至可以说毕生难求的机会搞砸了。\n我没有接教练打来的电话。我们前往宿舍，大家都像失了魂，低着头，在混乱的人流中各管各的，顾不上说话，一味地快步向前走着。wt 和 zrz 还抱有一丝不挂分的希望，而我已经没有希望的权利了。\nwt $100+72+23$，zrz $100+24+21$。zrz 把 T3 的性质 B 暴搜了过去，但 T2 挂了 $16$。我没有挂分，zrz 和 wt 都比我高。未曾想，我最终成为了自己口中的那样，“瞄得越高，考得越差”。\n不欢而散。\n路上，我爸跟我讲了很多。“人生不如意事十之八九”，我再次听见了这句熟悉而陌生的话。行驶在杭州湾跨海大桥上，没有云，没有晚霞，我看着一色海天从金黄变成暗蓝。\nEndless pain, endless hope.\nCSP2022 三块银牌。\n回去只有三天的休息。教练让我们参加数竞初赛，而我们基本没学过数竞。\n做了若干套初赛和 CMO2021，会做的竟然还挺多。我主要补了些平面几何。\n考试也在杭州。考完去六和塔，然后骑车翻越杨梅岭直达西湖。杭州的九月是彼岸花盛放的时节。\n初赛不想说了，$90+$。不会出题就别出。\n9~10 月做了一些 2400/2600 和 3400，错误率比原来高，wt 每道题都比我做的快，而且常有快我一倍。不想再做解题总结，以前每天抠着细节写一堆废话又有多少用呢……错就让它错吧。\n摆烂。\n我提出要听课和做解题分析的训练也被搁置了。\n官网报名 CSP 都差点忘了。\n前面的烂摊子对我的心态和行动力的影响大概持续了两个月。\n模拟题考得还行。由于是多校互测，所以我们也精心准备了两套毒瘤题。我出了两道毒瘤根号 ds（2024.5 upd：那道最阴间的叫天桥的被爆标了），wt 出了道离谱数论，zrz 出了道 200 行链剖（据 zrz：24 年重构代码后优化到了 140 行，速度快了一半）。被喷死了。还给一些低年级的学生讲了线段树和哈希。\nCSP 前两题没什么好说的，T3 一开始不会，先看了 T4，没想到 $k=3$ 的正解。回过头来看 T3，突然就联想到可以用哈希。最后 $100+100+100+76=376$，wt 和我同分，zrz 怒切 T4，T3 $60$。\n也算是运气好吧。\nNOIP2022 三个月很快就过去了，我也逐渐调正了心态。\n我们提前两天到了杭州，大家都表现出一种微妙的平静。教练也没有召集大家强调策略。\n曾经还有很多机会时，我们展望未来，踌躇满志，述说着信息学精神，在考场上挥动思维的利刃。而面对这或许是最后的一战，一切都失去了意义，只有低头祈祷，且行且珍惜。\n考点在杭州师范大学仓前校区。来到机房楼门口的树荫下，我莫名感到熟悉。或许是因为走过太多考场了，我感觉像是回到了小学参加区赛市赛，或是初中体验 ZJOI 的日子，昏暗的楼道，陈旧的机房，排列着的笨拙的台式机……唯一不同的是我的思想，可思想又能存在多久呢？离开竞赛后，那些知识都被淡忘，我对 OI 的印象大概就是这样平凡的一幕吧，这一幕代表着这名普通 OIer 的启程，也代表着这名普通 OIer 的谢幕。故事的起点与终点，总是能带给人相似的感觉。\n进入机房，我的旁边坐的是 hehezhou。开题，T1 秒了。T2 难，我先想了大致处理模式，然后把出问题的栈满的情况往后扩展，总算会了。解法包含复杂的分类讨论，模拟栈的代码细节很多，调完 T2 剩余不足 2h。我慌忙看了一下 T3，读错题浪费了 15min，然后会了树的部分。为了保分先往后看，写掉 T4 的 $20\\text{pts}$，回过头再搞 T3，发现是简单题，这时还剩下 30min。于是开冲，复现了 CSP2021 的一遍过大样例。\n现在看来，这场比赛就是在崩盘的裂谷之上走钢丝。太险了。\n但我总归是守住了希望。\n前方更险的道路在视野里展开。可我知道，无论我能否走过去，一切都离结束不远了：团队即将散去，外驱力即将燃尽，我的 OI 生涯的末期即将到来。\nNOIP2022 后 \u0026amp; CTT2022 wt 和 zrz 都没做出 T2，挂了少量分，$250$ 左右。尽管还有希望，但确实是一鼓作气，再而衰，三而竭……\n12 月开始 CF 3000 的训练，做了不少偏怪题。\n同样说说 CTT 印象比较深的几题。\nR3T3 找规律快乐。\nR4T3 找规律快乐。\nR5T1 花了 4h AC 了，很开心。\nR7T2 拿网络流草过去了。\nR8T2 阴间题。\nR8T3 找规律快乐。\nR9T3 差 8min 没调出来，qswl。\nR10T2 神奇技巧。后来模拟考时用上了。\nR11T2 几百年没写 exLucas，卡常了半天。\nR13T2 物理题。\nR14T1 拿到了全场最高分！\n线下没去。\nzrz 在 9 月之后私自在间断地打 CF、AT 和洛谷的比赛，还拿了道 AT 一血。\n12 月中旬，教练让我们都开始打 CF 和 AT。由于我们训练模式的原因，我提出了异议，但最后还是考了三个月，效果有利有弊吧，代码速度是有些练上来的，但是半夜打比赛确实把身体和训练节奏搞坏了。最后 CF 小号拿了 2666。感觉除 AGC 以外场切的都是水题，而 AGC 又切不出什么题……\n2023 春节前后 疫情政策放开后在家待了一个月。时间的齿轮暂且变慢了些，暂时将思想从 OI 中抽出了部分。期间除考试外只做了 5 道题，没学其他 OI 相关的东西。大部分时间窝在床边和写字台前准备学考、做数学、看书和刷 b 站。同时，我开始不时地回顾我的 OI 生涯，一个个训练阶段，那些不堪回首的经历，感觉就像垂暮的人总会不自觉地回忆年少时的故事一样。很多东西就算在手边，也并非能被自己掌控。我厌恶了成天围绕将至的比赛思前想后，只想暂时沉浸在对往事和对自我的审视中。\n24 号阳了，症状轻。\n12 月 31 日，17 岁生日。宁波没有下雨。厚厚的窗玻璃将外面喧嚣的世界与我隔开，只听见模糊的风声。房间里很暖。我在淡黄的灯光下听着卡拉扬指挥的，那个最经典版本的《四季》，在屏幕上打起了字：\n窗外亮起红、橙和白色的灯光，我又在这个窗内世界度过了许多日夜。记得去年这会儿我也看到这样的景象，哦，前年也一样，不过那次天正下雨，灯光穿过窗上挂着的雨滴，交汇在一起，显得格外耀眼。\n不过有些东西不一样了，比如前年我望向窗外，想的是，“两年后的我会怎么样——会‘自由’吗？”而现在我却回忆着过去的事情，聊以填补空虚。\n这里的时间与外面的并不相同，这里没有四季，只有无尽的日光灯、白纸和屏幕。\n在这里，我每天说着同样的话，做着同样的事，看着同样的景象，逐渐地，在时间带来的麻木中，一周过去了，一个月过去了，一年过去了，眼前各色的灯光，却似乎昨日才看到过。\n快速流动的时间裹挟着我，使我不得脱身。之前并没有意识到这一点，因为那时我还有希望，不，是妄想，妄想着新的事情发生，我告诉自己，就让这段时间简单地过去吧，忍耐是值得的；但后来我发现，时间并不肯就此放开我。我想做些什么，试图抽身，做出改变，可我眼睁睁地看着自己，在令人窒息的时间的缠绕中，可悲而可笑地，无力作为。\n夜深人静的时候，我常望向窗外。我本可以生活在那里，像他们一样，在春天山坡上粉色的空气里沐浴，在夏日树荫下和屋檐下喧哗，在秋天月圆之夜共同欢笑，在冬日初雪的校园并肩漫步。我更爱科学，于是我挥手，转过身去，走进无四季的世界，熬过了一个个思念成河的夜晚。如今我却问起自己来：\n我所热爱的事情啊，为之付出青春而奋斗的事情啊，为什么一步步走向我所不希望看到的境地？我的付出和失去，我想追回的东西啊，都到哪里去了？\n我试图回忆那些过往，找回昨日那些我所珍视的时光。可那些印象模糊了，一句话映入脑海：\n我们不知道，我们将与谁在未来结缘，但我们知道，过去的必将分离，再也不会走到一起了。\n灯光照入眼中挂着的泪珠，交汇在一起，显得格外夺目。\nすべては終わりましたか。\n这是我写的 QQ 空间。\n宁波的深冬，素白而萧瑟。\n春节前打了 WC2023 和 Goodbye Renyin。WC 是倒序做的，T3 应该是拿到了全场最高，T2 部分分在最后 5s 调出来了，踩着点交上。没挂分，排名出奇地好。\n春节过后，状态就必须渐渐恢复了。\n回 cx 后，我开启了自己制订的解题方法计划，从构造开始。另外拿了 USACO 白金组的唯一一次 AK（23JAN）。\n联合省选 2023 之前 2 月中旬开始做 CF 3000，平均 2.5h 一题。教练让我和 wt 做完后讨论思路，我也做了些解题分析。\n但我始终想不明白一点：两年前开始做 3000+ 的 CF，为什么如今仍然需要整场考试的时间才能做出一道 Div 1 里次难的题？CF 题似乎是个漩涡，无数日夜，千篇一律的刷题，到头来只是原地踏步。\n是的，我已经恨透了 CF 题。一是因为与它相关的事情给我留下了一些不好的回忆（这里就不写了），二是因为难度评分不准，三是因为我觉得它的（2800-3200 难度的）出题风格很“贱”，是的，我用了这个非常不适宜的词，“贱”，这是我极端错误的，但真实的个人感受。我觉得 CF 的大部分题都像一道脑筋急转弯，想到了就万事大吉，想不到就难以重回正轨。缺乏综合和系统性分析，缺乏多步思考，缺乏美感，常有偏题怪题。我难以通过刷题获得解题思维和技巧的积累，而只是每天随机思考，如蜻蜓点水，浅尝辄止。我又感到自己很无能，将进步缓慢的原因归结为题目风格。但看到自己的努力似乎成了徒劳，我的信念确实有些崩塌。\n不能否认，CF 的每场考试都凝聚着出题组、审题组和平台团队的心血。如今我也不再像曾经那样认为，因为要真的把 CF 做扎实很难，但收益也大，随着解题样本的增加，水平的增长是潜移默化的。我只是想呈现当时我最真实的感受。这一切不是 CF 的问题，是我自己和训练思路的问题。\n省选很近了。我复习了流、slope trick、wqs 二分等算法，构造题解题方法计划也快完结。这时，教练开始让我们练模板和做 CF 题的模拟考。\n不练贴合省选风格的题，没有时间自己复习其他算法和模板，教练还说如果省选进了，4 月后要一直练模板。\n我的计划都被打乱了，想摆烂。但想到这或许是与 OI 相伴的最后几周，我又收拾着凌乱的心神，试图做得认真些。\n联合省选 2023 考前读完了《三体》。看书时，我的意识游离在书中那完全不同的世界，发散着，想象着。不知道少许这样的体验是否给我的思维带来了一些刺激。\n比赛还是在杭师大，我们住在比上次离学校更近的一个酒店。考前一天晚上，我把构造题项目完结了。\nD1T1 预料之外地简单。T2 我花了较长时间，想到了一个 $1.5$ 次的做法，并用选重心的技巧简化了代码，3h 时开拍，改掉挂的一个小 bug 后就拍上了。T3 我没有想到贪心，想着 $48\\text{pts}$ 用树剖模拟费用流，担心 $\\log^2$ 被卡常，于是决定在只剩下 1h 的情况下写全局平衡二叉树。这时其实犯了和 NOIP2021 一样的错误，我最终没调完，只写了 $22$ 的暴力。\nwt 会了 T3，但来不及。wt 和 zrz 都没做出 T2。虽然考虑 D2 保守些就没事，但晚上还是没睡好。\nD2T1 预料之外地恶心。我在 2h+ 时过了大样例，满屏幕都是中括号。看了一下 T2，和 NOI2022D2T2 相似的部分分表格使我顿感不妙。只会难写的 $64$。T3 写掉 $10\\text{pts}$ 跑路后仅剩 1h，来不及写 T2 的 dp，写了 AB 性质后草草收手。\nzrz T2 写了 $64$，wt 会了 T3，估分都高于我。我们走向校门。我的总分有戏，但是想起 NOI2021 和 NOI2022，我知道，自己在 D2 面前又一次没有撑住，低下了头。\nzrz 的分数很危险，wt 如果不挂分就稳了。我跟 zrz 测了一下民间数据，他 D1T1 和 D2T3 挂了——或许因为比赛开始还没进入状态，zrz D1T1 写了个线段树分治，然后写错了。这题真的挂不起分啊……太可惜了。wt 也挂了很多。我除了 D2T1 比较不放心外没什么问题。why 的 D1T2 挂没了，默哀。\n教练曾经在 cx 的教室里说过：“不要以为你们几年都坐在一起，以后就都能成功了。等你不努力，被淘汰，而别人走上不同的路了之后，你就只能说‘我曾经跟某某某一起训练过’了。”\n21、22、23 年，凶险的挂分遍布于每一场重要比赛，蚕食掉一次次的希望。他们终究无法战胜这一由自己创造的病魔。\n我们逐渐走入命运的岔路，即将分道扬镳。下午，我和 zrz 一起，踏上这今日最后的旅程。\n良渚博物馆外是杭州的春色。金光撒在新生的三叶草上，那种纯粹的嫩绿似乎要流淌起来；微风吹皱了一池绿水，苦草如长发般飘荡，金鱼藻来回摇曳，交织的植物下不时涌出几串气泡。我们走到十字路口，抬头看见澄净的天空中出现一道航迹云。一轮金色的太阳渐渐沉向地平线，却愈发显得耀眼。\n我们再次前往暮色中的西湖，看着对岸随着晚霞的黯淡，一盏一盏亮起的星星点点的灯，保俶塔和雷峰塔的轮廓在水波中碎成片片金光。我们在沉默中走了很久，沿着湖边的雕栏白墙灰瓦，穿过路口的呼啸与喧哗，从六公园走到一公园，回忆着六年来一起与 OI 度过的时光，一切都在眼前如走马灯般浮现，最后，我们转向灯红酒绿的街市，隐没在光影流转中。\nNOI2023 之前 zrz 和 wt 回到 yyhs 开始学文化课，同时在机房做题保持手感。得知没拿到 C 类后，他们的训练就告终了。在此之前，zrz 和 lr 在 5 月拿到了清华的优秀。\ncx 的这个教室只剩下我一个人了。隔壁是 lr。\n就简单写写吧：教练不怎么来找我了，确实他比较信任我对自己在细节上的把握。剩下三个多月的训练也就主要是我自己安排和管理。我做了 dp 解题方法计划，ds 复习，学了 SAM、Ukkonen、拉反、四边形不等式优化（没错，到这个时候我才第一次学这个）、KTT 等。期间做了 5 道难题，包括这年省选的 D2T2 和 D2T3。全部是洛谷 rk1，3 道 uoj rk1。\n1576ms 那个贴的我代码\r回头来看，21~23 年，在一定量的各类型的刷题，频繁而有计划的总结反思，以及深入的算法和专题研究之下，我的解题思维逐渐成熟和系统化，对一些技术及其应用开始有了自己的理解，代码能力也有所提升。这些进步并非源自某段特定的极具针对性的指导，而是在时间与综合训练的共同缓慢作用后的产出。CF 题的反复无常确实使我困惑，但在做解题方法总汇时，它们就成为了宝贵的样本，使我能反刍自己过去的思想，迭代地加深对那些算法思想的理解。\n那时的我会想：NOI2022 之前的我，水平到底有没有达到金牌线？我无从得知。这个问题显然也是毫无意义的。我所知道的是，NOIP2021、APIO2022、NOI2022 的错误化为我总结经验、调整策略的养分，深刻地改变了我的考试发挥与心态，它们带给我的成长，比解题水平的长进重要太多。\n当然，必须承认的是，我的进步速度是过慢的——这个现象当然与训练思路有关，但总的来看原因还是很复杂——所以我后来一直觉得，自己的 OI 成绩完全是靠极大代价的时间与失败堆出来的。但无论如何，终于，至此，我已经准备好了。\n7 月初开始在线上参加了 nfls 的集训，发挥还是有些不稳定，但是相比以前好很多，有些熟能生巧的影子。UNR 超常发挥拿到了并列 rk 2，但是经验告诉我，赛前考得太高并不是件好事。\n教练最后的叮嘱是一定要稳拿 T1。\n是时候了。\nThe End\u0026hellip; Again\u0026hellip;\nNOI2023 这里就把之前写的游记粘过来了，加了几张图片。文风可能跟别的部分差的比较多。\nWritten on 2023.7.31\nDay -6 ~ -3 rp 要被 UNR 和最后两场模拟赛耗光了（悲）\nDay -2 \u0026amp; -1 为了避免飞机晚点导致生物钟紊乱，决定提前两天到成都。飞机是晚上 8:30。\n然后因为宁波有暴雨，飞机晚点了 2h，飞机上想睡睡不着，生物钟成功紊乱（焯）。在飞机上看了 PAM 和保序回归，到酒店快三点了。\n第二天复习了一些 trick 之类的。成都的小吃绝了，头一回吃这么辣还很舒服。从南门向成都七中里望感觉像花园。\n晚上成功把生物钟调回。\nDay 0 (7.22) 中饭后进学校，发现签名墙上写了一些很抽象的东西，还有好多认识的人！以及发现了 Technoblade never dies!。教练还在飞机上，等了会儿学籍证明。然后进宿舍，行李箱单手提到四楼。发现大家都到了，并且差不多已经结束了徽章互换。最终只换到 11 个，非常社恐，没有人认识我 /kk。\n室友是 wmh、fsz(Umbrella_Leaf)（以前一起训练过）、tjm(Clonoth)。见到了仰慕已久的童年偶像 wmh，感觉此生无憾了。\n宿舍不错，就是椅子没有靠背比较难受。后面逛了逛校园，感觉比较小（或许是部分教学楼在施工的缘故），但是环境特别好。有两个小大卖部，感觉比外面的便利店还大。\n帮 zrz 送上了签名墙。\n晚上背笔试。舍友在颓 generals.io 和 phigros 之类的，我完全不会。wmh 在玩某神秘游戏，赢了会有敲锣的声音，我甚至以为是校园里仿古做了什么报时的东西。\nDay 1 参加开幕式。这次节目中主旋律元素较多。中间听同学说陈睿是成都七中的，非常期待，同时第一次知道群友并，原来去年就有了，感觉自己信息封闭 /kel。全场高潮显然是叔叔出现在大屏幕上的时候，当然《我的未来不是梦》唱得也很好听。音响、灯光和无人机表演差评，耳朵瞎了，眼睛聋了。ZJ 队拍照时瑟瑟发抖，自己太菜了。\n回去给舍友科普了一下试机的一些注意点。\n试机时遇到不少熟悉的面孔。线性筛 T1 写了 15min，有种不祥的预感。笔试不出意外还是老题。selfEval 好评！！！感觉 NOI 离 pretest 以及 IOI 赛制不远了！\n考场内很热，向老师请求明天考试空调开冷些，非常可惜忘记了天气预报第二天是雷阵雨。\n晚上执行既定的操场快走+策略复述计划，舍友在联机玩 gen。\n成都的天暗得很晚，在操场上听着《成都》和蝉鸣，感觉自己已经不再紧张了，或许是紧张麻了罢。\n晚上睡得不错。\nDay 2 虽然仍然有些困，但以不错的状态进入了考场。只提前 10min 开放考场。\n开 T1，感觉 $100$ 相对于 $95$ 的复杂程度没有 [NOI2016] 优秀的拆分这么离谱，于是决定写 $100$，不知道为什么花了 30min 码了 3.8K，过了拍。\n赛后发给 zrz，zrz 表示：T1 看起来很可爱。\nT2 想了 1.5h 仍然只会 $70$，而且细节还没推，先看 T3，感觉 $n,m\\le 300$ 很可以做，但是就是不会做。\n然后打了 T3 的 $36$ 和 T2 的 $70$，因为 $n=m=4$ 时暴力会 T，所以打了表，发现答案与树形无关，进一步发现了 $n\\ne 1$ 时的双阶乘规律，于是 $k=0$ 就直接 dp 就行了。仍然不会 $100$，非常难受。\n剩余 1h 只搞了 T3 的链。估分 $100+70+52=222$。\n出考场发现大家都会 T2，被薄纱了，自己拿了一个大众分。wmh 写了 T2 的类正解，还在那里假，说可能会被卡常。真的太有实力了！\n出分没问题，wmh 又在假说自己 T1 没 A。\n晚上听题，T1 题面里没写 $x_1\\le x_2$，不过实际数据是保证了。不卡就在题面里写清吧 /fn。T3 看起来不错。\n舍友在联机玩 gen。\nDay 3 上午嘉年华做了 $3$ 个项目。接棒子那个，我们提前算出如果每次随机选两个位置把手放在下面，期望可以接 $4.8$ 根。然而实际上用这个策略的都失败了。我直接只管一边，拿到了 $5$ 根的成绩。飞盘屡战屡败。\n中午来了一位神秘人，打 hdu 的神秘比赛。\n下午看桌面足球，ZJ 队十个球里有七个是 wmh 进的，烤串法牛逼 /bx！好多巨佬都在打足球，感觉是好的调整心态的方法。lca 在音乐厅门口发明信片，去拿了一张，lcr 太可爱了太可爱了太可爱了！OI Diary 什么时候出啊（\nzrz 也想要一张，后来又问了一下，lca 表示可以给地址寄过去 /bx。\n晚上总结 D1，调整一下技术，继续操场随机游走。舍友在联机玩 gen。\n晚上睡得不行，脑子里充满了奇怪的组合结构。这一天经历了不紧张——紧张——不紧张——紧张的波动。\nDay 4 精神状态略逊于 D1，但秉持着“睡眠不好不大影响大考”的理念，尽量使心态放松些。考试开始后调整自己椅子的位置时手指不小心被木屑扎了，清醒了不少。\nT1 马上就会了，1h 后看 T2；T2 马上就会 $72$ 了！T3 马上就会 $30$ 了！感觉有戏？\n后面浅尝 T2 的正解就放弃了，感觉 SA 计错的部分无法消去。于是写掉已知分数，剩余 1h 想 T3 但没救。估分 $100+72+30=202$。\n出来发现大家都 $230$。经过 wmh T2 的一句话点拨，马上发现自己变成傻逼了！计错的部分是另一个二维数点！\n出分发现 T2 挂了 $-28$ 分，非常地不牛，不过应该稳了。\nNOI2023 赛场\r下午鼓起勇气找 zak 换了徽章。zak nb！\n晚上和舍友联机玩 MC。tjm 非常有实力，了解很多我最近才了解的 MC 技术圈内容，很有共同话题。一开始开局域网时忘记 enable fly 了，结果出现缓降却直接 ban 掉的喜感情况：《此服务器禁止飞行》\nDay 5 去看演讲。感觉有几个选手讲得非常好，很有同感！另外几个不大有信息量。唱歌和萨克斯太好听了！以前其实不怎么听歌的，但《蜂鸟》种草了！到后半场才发现坐在旁边的是 zky /bx。\n下午报榜看到很多认识的同学，大部分都上线了！还有一些高一高分银牌，明年加油！但是为什么 ZJ 不是总分 rk1 /fn？\ndzd 说这是近几年来最成功的一次 NOI，个人觉得这三年来确实这次体验最佳。\n晚上和舍友联机玩 MC。玩经典小游戏 烟花派对，只拿一个弩掌控全场！MC 复健进程顺利 /qiang。\n我的 MC 圈名是 Little_Reuben；乱码是因为没加材质包\r半夜在床上聊一些神秘话题。\nDay 6 到告别的时候了。\n一些废话 尽管拿到了金牌，但这次 NOI 的发挥有不少遗憾：两道 T2 都没 A，考试时基本没有深度思考。或许大考就是这样吧，真正漂亮的发挥可遇不可求，但求不挂分已足矣。希望未来的集训队考试能考出实力 /fendou。\n不过其实个人感觉如果想要拿到后一半金牌，只需在有基本实力的前提下，把部分分打满就行了。挂分是致命的。另外如果 5h 时间内不看错想错，不要过于贪心，时间其实是充裕的。不必担心各种奇怪的因素（例如没睡好、题难等）导致失误，心态上把它当作平常的考试就行了，大不了回去搞文化课。千万不要因为这是 NOI 就想着做些出格的事情，尤其是 D2，一定会失败的。\n首先想感谢自己的成长，这几天的心态和意识调整是至关重要的。\n然后想感谢这次的室友，谢谢你们帮我找到了缺失了四年的校园生活的感觉。我第一次在即将离开比赛地时感到不舍。你们不会因为我们原来素不相识就一直待在同校同学的宿舍间里，只有晚上才来睡一觉；也不会因为我们是竞争关系就缄默不语。我第一次在 OI 的盛会上感受到了交流和交友的快乐，这种快乐不必非常深刻，或许只是聊聊以前的 OI 经历、一些热门话题、自己的爱好，抑或是一起颓 MC，但我却能感受到也有人在经历我曾经历过的事，爱好我爱好着的东西，我不是孤独的，这就够了。\n最后想感谢 NOI。NOI 像一座灯塔，指引着我青春奋斗的方向。现在，我也永远告别了 “NOI 选手” 这一身份。不过回首看来，NOI 也只是人生列车众多站台中的一站，到站之前的日日夜夜，心中有无尽的感慨与希望；到站时的悲欢离合，又使我百感交集；但当列车再次启程，无论成败，我已回归平静，因为经历了，就不再有遗憾了。祝愿所有进站和出站的旅客，都找到属于自己的价值。\n最后的最后，今年下半年，YeahPotato 维护的 LRYP\u0026rsquo;s Blog 即将上线，欢迎各位同学访问品鉴，咱们文理两开花，共创新辉煌！\n（upd：LRYP\u0026rsquo;s Blog 咕了整整一年）\nCSP2023 \u0026amp; NOIP2023 初赛 $100$。\nCSP $400$。最后 1h 玩 Emacs 的游戏，bubbles 最好玩。出来听 fsz 说他 2h 就 AK 了，感觉自己很差劲 /ruo。\nNOIP $400$。T3 实际只会 $75$，我猜了个一定尽量靠右的结论，于是可以 zkw 线段树形式的二分，结果给水过去了。\nCTT2023 开始写博客，极度渴望社交和交流，可有什么途径呢？只能每天点开看过无数次的犇犇和 U 群，然后在失望中关闭。\nDay -? ~ -1 NOI 之后的日子主要是在总结和出题，没去预科。做了些 CF 2600，学了同余代数，把一些神奇技术和方法论系列电子化了，然后就是互测。\n质量较高的题包括 R1T1、R3T1、R5T1、R6T2、R7T1、R8T1、R10T1、R11T1、R12T1、R16T1。怎么全是 T1 啊\n毒瘤题有 R1T2、R2T3、R4T3、R6T3、R8T3、R9T1、R15T3、R17T3。\n科技题有 R1T3、R8T2、R16T2。\n几道解题过程比较有意思的题：\nR3T2 非常地 finger theorem，但不会证，写了一下竟然就过了。\nR4T2 没看到数据更新，白调了 1h /fn。\nR6T1 乱搞过了。\nR7T3 猜结论过了。\nR8T1 感觉儿时做到过，但还是完全不会。\nR9T1 怒码 200+ 行，喜提 $20$。\nR10T3 找规律过了。\nR11T1 乱搞过了。\nR12T2 怒码静态 toptree，结束后发现自己是小丑。\nR13T3 是我的题的子集，结果 R13 2h 过了 T1T3，T2 误以为 2-SAT 可以限定 $n$ 个变量至少一个取 $1$，结果变成了 3h $10\\text{pts}$ 小丑。\nR15T1 是个可追溯化堆，复习了好久板子。\nR16T3 猜结论过了。\n我的题放在了最后的最后。R17 zky 1.5h 过了前两题，然后我看着他 1h 秒了我推了三四天的 $50\\text{pts}$ 公式，然后 1h 秒了我又推了两天的全解公式，1h 秒了我写了一个下午的代码，而且思路基本和我一样。真的强。\n听说 wmh 推了一整场我的题，很感动 /ll。\n拿了 4 场第二，8 场前四。zky 是无法超越的天花板。\n互测中自己最大的感受是代码能力上的突破，可以不打草稿就码上百行，调试时间也不长。这是之前我所无法做到的。\nDay 0 (12.1) 前往苏州。室友是 NOI rk3 的 dyq。\nCCF 业务总部在一个园区，不大的一栋房子，旁边是似乎湿地一样的大池塘，植被都呈深秋的颜色，少有生机。\n除去 NOI 认识的三名室友，其余选手我无一熟悉。或许还有互相知道 ID 或名字的，却也从未交往过。\n晚上订正互测 R1T1 练手感。fsz 来送了我三个 MC 图案的键帽，他说是暑假逛漫展时买的；tjm 约我 D4 考完打 MC；wmh 在看我的题解，并找出了一个 typo，赶紧更正 /kel。\nDay 1 早饭。空气中飘着酒店特有的一股淡淡的香气，轻音乐的节拍在自助餐厅里回荡，抛光的深色大理石台反射着窗外的日光，列着装有各式冷头盘的白色餐碟，眼前的画面与皇冠假日酒店的记忆重合起来。若即若离的过去似乎与当下并无二致，选拔又一次如约举行，CCF 的大巴车与曾经一样载着 OIer 们在冬日的城市中穿梭，可我已不是那个两年前的我，我身边的一切确实也不是两年前的一切了。弹指间，我终于如我曾仰望的“大佬”们一般，走向了故事的尽头。\n对于即将到来的四场考试，的确远不及 NOI 之前那么紧张，但也还没到释然的程度。我的预想是每场会有一两道区分题，在考场上能否找到解题突破口并快速写出代码，对此我并无十足的把握。我的 OI 生涯是否会被画上一个残缺的句号？惴惴不安地坐在大巴上，我尽力调整着自己的精神状态。\nT1 一眼学习轨迹，但是是个变式。先写了个平方，对于开头小拐部分一直调不清楚，过了样例后交上去 $0$ 分。又调了 0.5h，突然公告行末空格判得有问题，火大。可改后还是只能过性质 A 的包，顿感不妙，写了性质 A 的线性后就先看 T2 了。T2 签到，T3 是个整体 dp，线段树部分是之前复习过的带 tag 合并，于是专心码正解。最后一些时间 T1 全解结论也改不明白了，就只补了个性质 B。\n出榜后发现自己 T1 确实失误了，wmh 和 tjm 都 A 了。好在 T1 浪费了 2h 后稳住了后两题（而且感觉时间算宽裕），排名不算差，但对自己不满意。\n下午讲题前电脑黑屏但没关机，实际上是亮度调得很低。我走到自己的座位旁发现有人用手机手电筒照着屏幕念“集训队—（我的名字）”，一转头发现是 zky，旁边是 sjy。我直接慌张跑路。\n昔日的选手已成为出题人，还记得 NOI2021 D1 讲题时 ix35 上去吐槽的场景，很感慨。希望自己以后也能为 OI 做些贡献。\n会场楼下开放了一个博物馆，结果大家直接拿一个展示屏打起了 gen，wmh 甚至赢了一局。然后打牌，认识了 fxt(275307894a)、jbw(lgvc)。\n考完后有些筋疲力尽，回酒店后就一直刷 b 站，没精力复习。\nDay 2 T1 是道初看完全没思路的构造，我其实非常担心开局懵这种情况。硬着头皮做下去，逐渐探出了一条思路，算是幸运，但代码较复杂，留到后面写。T2 是二次离线板子，T3 是不可做题。回过来扛 T1，过样例后就 A 了，松了口气。T3 又搞了 1h+，大概感觉要用 Hensel Lifting，但 Sub2 死活调不出，$5\\text{pts}$ 滚粗。拿了个比较标准的分。\nfsz 很稳，A 了前两题，且解法都和标算不一样。\nDay 3 T1 花了 2h+ 过了，T2 完全没思路，T3 花了 1h+ 过了。后面 T2 先考虑了分治，但愣是没想到分治的每一层并行做，结果就开始考虑小常数 $n^2$，还是不会，最后 1h 没得分。\nwmh 非常牛，A 了 T2。\nT1 说是原，因此降低了 D3 的占比，不知如何评价。\n下午认识的同学都不想去博物馆，我也就留下来打牌了。几位来自北京的同学邀请我们一起打 UNO。\nDay 4 D1 和 D4 是相对较紧张的两天。D1 紧张是担心不在状态，D4 则是因为发现前三天的区分题我解得并不轻松，不知能否再次避免失误，善始善终。\nT1 是个经典模型套增量法，我先写了个平方暴力，大样例也过了，照理来说应该过前四个包，我却只过了前三个，心里咯噔一下。与此同时，出题人正在改 $m=1$ 的锅。修了两次之后，我又下载大样例，打开压缩包，赫然一个 std.cpp。其实当时的我心情更像是，喜忧参半。这题肯定是作废了，我也不必像 D1T1 那样反复调结论了，但后面还会加赛吗？\n场上爆发出笑声，Itst 宣布 D4 只按两题计，并调整了四场的权重，看来没有加赛了。\nT2 和 23OPEN 白金 T3 很像，过了之后算是松了口气，T3 就各种乱搞。可出考场后，我并没有如释重负的感觉，T1 的侥幸逃避并不使我十分开心。\nfsz 考出了 $114.51$ 分的优秀成绩。\n看了一下 Qingyu 的总榜，似乎是集训队 rk6。这四场我写了七道正解，算上 D1T1 和 D4T1 共九道题都较为中规中矩，考察选手的基本功，没什么超纲算法、科技或特别难的无算法纯思维题，我是应该拿下的，有失误，不算很大。但是其余的题却是半点“踮踮脚能拿到的分”都没拿，尤其是 D3T2 和 D4T3，这类交互壳+构造我都只写了基本分。确实不擅长 IOI 风格的题。总体来说，我的表现算是“稳中不求进”吧。\n精英培训选手都很猛，fxt 太强啦！但从另一个角度来看，结合精培和我的排名（显然我自己并没有 rk6 的实力），我认为可以推断出，有很多集训队选手因为读预科丢掉了状态。并不是说预科不好或者不应该将精力花在预科上，而是我真真切切地感受到了 OI 能力的时效性，巅峰易逝，诸事无常，这是残酷而令人伤感的事实……\n下午直接和 fsz、tjm 打的润回酒店玩 MC，晚上我们想搞全成就，结果拿到鞘翅就已经 22:30 了。\n凌晨，回到自己房间（室友下午就走了），坐到床头，我的心不知何时被一层孤独笼罩起来。是的，MC 的内核是寂寞和哀伤，当我手持烟花火箭在末地的暗紫色天空和嶙峋的灰黄色外岛间独自飞翔时，尤能感受到这一点。可此时的孤独却似乎指向刚从中抽身的 MC 之外。回想这五天的经历，除了一起打牌和找我加 QQ 的同学，我和其他任何人没有半点交流，偶然的目光相接、擦肩而过也只是视若无睹。曾经的我满怀期待地幻想 CNOI 的顶点：那里聚着一群并肩前行的人们，他们热切地探讨、辩论、谈笑风生，他们汇聚着各自的思想，讲述着自己的故事……可如今我真正得以一瞥顶峰的样貌，却发现这里只是一小片积雪的空地，陌生而沉默的人们聚成几个不相往来的小团体，剩下的便是漫天云雾。我逐渐地感到无力而心寒，因为我发现自己与他们之间隔着一堵无形的墙。\n我不知道这是自己的幻觉，还是实然如此。确实，我早就清楚，交流并非 OI 所必不可缺的要素；但作为一个普通的人的我，那精神深处一角的空虚与匮乏大抵已经存在很久了吧。我一直认为，这份空虚只是行路上必须经历的精神和思想的磨练，我只是攀登得不够高，没有抓住机会罢了。可经历了那一夜夜独自的思索，一次次企盼的落空，我真的开始怀疑，这孤独是否在自己启程的那一刻，就注定是属于我的。\n我的脑中出现了《全频带阻塞干扰》中的一段话：\n况且，米沙就属于恒星吗？他喜欢恒星，把全部生命投入到对它的研究上面，但他自己却是恒星的反面，他更像冥王星，像那颗寂静、寒冷的行星，孤独地运行在尘世之光照不到的遥远空间。米沙的性格，加上他那白晰清秀的外表，使人很容易觉得他像个女孩子。但列夫森科元帅心里清楚，儿子从本质上一点不像女孩子，女孩儿都怕孤独，但米沙喜欢孤独，孤独是他的营养，他的空气。\n我从孤独中获得了什么，孤独又将我塑造成了怎样呢？先前的我似乎从未认真考虑过，自己应当成为怎样的一个人，我只是经历着这一切。这或许也永远无法预料吧，我想，就随着时间穿行在这世界之中，继续去追寻那个自己吧。\nCTS2024 Written on 2024.2.5\nDay -? ~ -1 两个月的时间看似宽裕，实则是紧得手忙脚乱。\nTHUPC 后开始找论文题材，在多次碰壁之后选择了陈词滥调的 dp。\n论文完稿已经 1.13 了，我只有两周的时间找回手感。最后一周我试图在 qoj 上每天 vp 一场，但越 vp，心态就越糟。\nCTS2023 D1T1 没想到，GDKOI2024 的 D1T1 和 D2T1 调了很久才过，FHQ treap 连着写错两次，拿了好几题最劣解。\nNOI 之后我已几乎忘记了压力大是怎样一种感受，现在终于又回忆起来了：在备赛时我会将任何其余的事、其余的念想拖到赛后，逼自己付出 100% 的精力在复习已在脑中反复过过无数次的东西上，可效率还是远低于预期，还是会出错。这种压抑和焦虑贯穿我的五脏六腑。曾经我有充分的动力，可以透支自己的精神。现在很难了，一天都很难，哪怕我再三提醒自己 CTS 很可能是 OI 生涯中最后的考试。我真的不想再复习了，这样的复习令我恶心。\n不得不说，在这方面，我是一个缺乏毅力的人——没有竞争，没有交流，少有精神支持，在白色的教室里独自沉默着思考和踱步，已经近一年了。确实，我对训练的热情正一点点地被消磨殆尽。大家常说，OI 之外是更广阔的天地。如今我对那更广阔天地的向往占据了上风。很明显，我已力不从心了，或者更客观地说，其实精神状态已经有些失常了。每天不进行任何有效说话，蜷着身子面对电脑 10h，瘫着身子刷 b 站和知乎 2h，也许用词不合适，但以我自己的标准来看，这就是一种麻木而糜烂的生活。\n这两个月，我的心中一直藏着一个念头：我不大想进国家队。用于忽悠自己的借口是害怕上台，根本上则是因为我实在不知道，那样的话随后的七个月该如何熬过。可另一方面，我又希望自己考得好些，能给自己一个交代。NOI 之后我一直很在意自己的实力，说是在意，其实不如说是自卑吧。每当遇到不会的题目或 trick 时我就会以”你连这么简单的都不会怎么配得上金牌“之类的话来刺激自己。这种心态在 9~12 月给了我一点动力，在 CTS 前却促使我彻底地摆烂，同时又使我希望自己最好能卡到 rk7，妄想自己能心满意足地全身而退。\n我为自己的念头感到羞耻，可我的大脑不受控制地一遍遍地重复着这一念头，似乎那是我极度渴望的一般。\n正如后记中提到的，曾经的我天真地以为，有坚定的意念，不论环境、条件多差，都能做到想做的事。直到有了切身经历，我才明白，人的意识和思想，是不受控制地随着生理和心理状态变化的。无论多么宏大的目标，如果精神上没有足够的能量，都是难以完成的。\n不过无论如何，我不希望自己与 OI 的告别方式是不欢而散。\nDay 0 (1.29) 重庆育才。PKUWC 刚落下帷幕，NOIWC 就开始了；THUWC 在巴蜀中学。上一次出现这样的盛况时，我才初一，只参加了 THUWC 并拿到胸牌。现在，如同冥冥之中的约定一般，我得以补齐最后一块拼图，将自己的 OI 赛事连成一个环。\n晚上开幕式。略显无聊。\n室友是 cxy(chenxinyang2006) 和川子(yzc2005)。一直很崇拜和羡慕川子，感觉交往极其广泛，这次能分到一起很幸运。川子人真的很好，很外向，还会提醒起床和带身份证之类的，魏老师过生日时还问我要不要蛋糕。\n其他认识的同学中只有 fsz 来了，还见到了 MO 队爷 shj。\ncqyc 的中晚饭不错，早饭不行。宿管阿姨对于熄灯时间有点过于严格了。最令人不满意的是宿舍间里不能有插头（说为了安全，一堆全缠在外面难道就安全了？不都是 $Q=I^2R$？），以及报告厅座位很小，信号极差。\nDay 1 上午听 lxl 讲课。下午没去。准备答辩 ppt、自我介绍以及练手感做题。看到自习室门口川子坐在台阶上抱着一只猫猫，猫猫长这样：\n不好意思放错图了\r川子还在群里说要买猫粮，买到后不知道为什么就没看到他了。\n晚上是魏老师(Alex_Wei)生日，谁都不认识的我谢绝了川子的邀请。隐约听见隔壁的生日歌和欢声笑语，落寞笼罩了浴室中的我。\nDay 2 上午没去。又看到了猫猫，他叫着，蹭着我的腿绕了一圈，应该还是有些饿。我回宿舍去拿华夫饼，正好川子在，就带上猫粮和我一起下楼。\n川子一边拿出一包猫粮摇着引诱猫猫过来，一边告诉我，昨天猫猫饿坏了，于是他点了外卖，顺便搞了个志愿者牌子得以随意进出。后来抱着猫猫时，他的手疑似被当成猎物咬了一口，不得不到校外去打狂犬病疫苗，让我也当心。他递给我一根猫棒，让我慢慢挤出肉泥。可猫猫性子很急，直接侧着脸开始撕咬塑料壳子。我只好找准时机松手。啃干净后猫猫见没吃的了，就在周围焦急地踱步，他又转向川子放猫粮的纸袋，将前爪扒了上去，试图找到更多的食物，结果把袋子都弄翻了。\n我们转移阵地到阶梯前的柱座上，川子又拆了一包。猫猫跃上台子时，川子顺势把他抱到了腿上。一早上吃了将近 100g，他终于安静了下来，揣起手，在川子的抚摸下闭上了眼睛。\n后来他好像渴了，跳下去到露台旁舔积水的木板。我就从包里掏出矿泉水，把水倒在瓶盖上给他，他喝了两次后，突然一溜烟跑开去，不见了踪迹。\n下午的量子计算机很有意思，全程没掉线，很喜欢。\n晚上睡不着觉。\n试机\rDay 3 省流：彻底爆了。\nT1 感觉可做，首先想到一个 dp，但是认为区间并可能会导致端点数爆炸，就没写。后来又分析了一个峰/谷值对于 $L$ 的限制，不小心把符号弄反了，以为也不行。这时我认为这题本质跟染色数组的模型类似，就去分析选择反射的钦定，结果花了 2h 只搞了 $35$。\nT2 和 T3 中规中矩，各写了 $23$。T2 能看到一个极复杂的正解，写不了。T3 有 $10$ 分是 random_shuffle。\n出来听见大家都是 $100+$，我意识到可能出事了。\nzak 用极其简洁的调整法过了 T3，杀死了比赛。\n路上听到 Kubic 说 T1 分析峰谷对 $L$ 的限制是对的；碰到 fsz，他说 T1 的 dp 猜区间并连续的结论可以过大样例，于是可以直接线段树维护矩乘，他就写了 40min。\n我成功遇上并排除了两个正确思路。寄。\n倒 5，先前稳定但不出彩的成绩是无法经受失误的，总排大跌至 18。\n还是讲讲文艺汇演吧。\n汇演其实是个民间活动。skc、川子等人志愿组织了这次汇演，报名截止是 1.30 晚 22:40，我在犹豫中错过了。\n因为沟通上的问题，育才也派了学生过来，先表演了半小时左右。\n节目共有 22 个（实际是 21，ylx 没上），大部分是唱歌，有 5 首日语歌（一首是竹笛）、3 首米哈游的歌。个人觉得唱得很好的有：Zeardoe 的 《夜に駆ける》、川子的《灰色と青》、Kubic 的《人是_》、好想做温迪的狗（？）的《风与飞鸟》、云浅的《蜂鸟》、xtq 的《温柔》。大家唱功真的很强！\n虽然没有《当班长》，但我们有两篇《机器人朋友》！\n竹笛和钢琴听起来功底都很强。\n中场的谁是卧底节目效果很好，完全没有因为第一次搞显得尬。ylx 太擅长这个游戏了，全场最佳。\n《蜂鸟》应当成为 OI 界的难忘今宵。\n我和 fsz 一直坐在最前排，与舞台只隔着一米的过道。我看到上台的同学们，他们在光束里，沉浸在自己的歌声中，闪耀着自信，展开胸怀，游刃有余地掌控全场的气氛，他们是多么地享受，多么地快乐。而我在这最后的机会迎面走来时选择了永远坐在台下。我明明知道自己五音俱全，也会背一些歌词，那之前的我在犹豫什么？我不甘地轻声跟 fsz 说，又像是在喃喃自语：“我早该报名的……”这话已经不是第一次了，在两天前的营员交流我也同样说过。在距离顶峰的最后一级阶梯，我止住了步伐。\nskc 上台陈词，慷慨激昂，气氛高涨。罕有地，我也感到了作为 OI 群体的一员的认同感与自豪感。\n在掌声雷动中，我踏上向出口的台阶，远离变幻的舞台。在这最终的 OIer 的盛会中，我终究留在阴影之中，错过了那耀眼的追光。\nDay 4 自觉遗憾已难以弥补。\nDay 5 T1 搞了半天才想到一眼的 $59$ 分做法，或许离 $88$ 也只差一步吧。T2 顺利些，摞暴力 $70$，T3 来不及想了，$25$。\n临出考场时，一旁的 skc 问我的分数。还记得上次他问我分数的场景，时间如白驹过隙，改变了我们的心境，改变了一切。\nrk14，总排不变。看了一下，如果 D1T1 过了有 rk8，可我在“如果”些什么呢。\nD1 和我一样也失误的 cxy 发挥极好，翻到 rk6。很钦佩这样能逆风翻盘的韧劲。\n下午，继续在校园里游荡。我沉思着，在料峭的风的包裹中走上高台，望向重庆模糊的高楼和久阴不晴的天空。我很清楚，两天 T1 的失误和临场发挥没有半点关系，单纯就是手感差。赛前两周的准备并没有充分恢复我的手感。可现在想这些又有什么用？不论将此归因于自己的不争气还是训练环境的缺陷，一切都已经结束了，多余的思绪只能是越理越乱。环境与气氛对我的状态的影响是毋庸置疑的，此刻的我固然无比挣扎和懊恼——那是因为我正身处赛场边，因为宴席高潮后的尾声已然降临。要是再回到一个月前呢？我相信我仍会做与原先相同的事。\n那还有什么可后悔的呢。\nDay 6 向所有候选队的同学致以最崇高的敬意。\n我与 OI 的故事要暂时告一段落了，但我对它的热爱不会褪去。我会蛰伏着、继续独自努力着，拥抱我所向往的那些改变，等待下一次与 OI 全新的相会。\nOur story will continue.\n后记 我常常问自己：我真正喜欢的，是信息学，还是信息学竞赛？\n我毋庸置疑地热爱着信息学——我热衷于发现问题模型和解题算法之间的对应关系，那种关系是多么奇妙，像高维的、千变万化的锁和钥匙，在世界诞生之初就已经确立了神秘的、千丝万缕的联系，却从未为人所知。我见到一把看似平平无奇的锁，在它所对应钥匙被我思索之前，我甚至不能想象出它的形式，我充满着期待，直到我推导出那把钥匙，就如同依据一条短短的迭代公式生成出如画般的图案，通过茫茫星图的无尽线索找到一颗宜居的星球，那精妙而自洽的系统豁然眼前，使我同时感受到发现和创造一体的喜悦。我着迷于解题过程中思维的趣味，那种趣味不仅仅是练习中偶有出现的 \u0026ldquo;Aha moment\u0026rdquo;，更是日复一日的解题中，面对各异的模型，我的思想如旅行者般在无尽的可能性中遨游，逢山开路，遇水架桥，突破层层难点，一往无前，与出题人进行跨越时空的交锋，寻找爆标的更优解……从青涩到成熟，我足以从更高的视角俯视那些思维技巧和解题路线，发现它们不是随机的思考试探，而是具有理论上的有效性和必然性，我意识到，这个客观世界，这宇宙中的“上帝之指纹”，是能通过人类的理性去感知，去把握的，这使我感受到信息学那深邃的力量。\n但想到信息学竞赛，我犹豫了。\nOI 很残酷。从 2019.1、2021.7、2022.8，直到 2023.4，最初是 cx 的前辈们，然后是 OI 圈一些广为人知的名字，最后到我的两名“战友”，我目睹了 OI 中的无常，那些大起大落，那些泪洒赛场和黯然离去，那些青春热血付之东流。随着一条条鲜明的个人简介被改成 \u0026ldquo;AFO\u0026rdquo;，我开始感到恐慌，因为我不知道哪一场比赛，哪一个念头，哪一次键盘的敲击，会宣告轮到自己的死刑——OI，不允许失误。\nOI 很功利。尽管有“OI 是给学有余力的同学参与的”“要办纯粹的竞赛”的呼吁，但内卷没有暂停键，从我决定停课训练的那一刻起，便被卷入了无尽的竞争。我发现自己成为了“管中人”，别无选择地向着那唯一的方向，最高的目标奋力爬行，因为背后除了文化课的深渊，便是“失败”二字——OI，没有退路。\nOI 很迷茫。正如 ISIJ2021 里所说，从那时开始，我看着一群雨后春笋般的名字开始飞速向前赶超，我自己却再也无法迎来 18、19 年那样的突飞猛进了。几十场模拟考的领先，最终落得 NOIP2021 的重创；对训练方式的日思夜想，换来的是争执与自我怀疑；反反复复的进步与落后，到头看似乎只是随机波动。22 年初的低谷紧随而至，我发现自己从未“做得快”过，从未“融会贯通”过，与日俱增的却尽是“错误的解题习惯和态度”，煞费苦心的努力只换来一个烂摊子，触目惊心的烂。进步似乎就是一个笑话，我开始自责，怀疑自己的理智，质疑这条训练道路是否还能继续下去。OI 的训练太难了，在这资源匮乏，思路单一，没有历史成功经验与他人帮助的小小机构，只有强撑着，在黑暗中摸索——OI，看不见光明。\n我是幸运的，或者用更贴切的词，是幸存的。我忘不了家人无怨无悔的支持，一起训练的同学带来的乐趣和交流，还有我的教练：他培育了我的独立思考、自学和反思能力，教会了我什么是坚持、奋斗、追求和百折不挠。六年来，是他心怀那看似遥不可及的追求，带着我们从零开始，硬生生地开辟出了一条前所未有的信息学训练道路。他肩负起来自内外的压力：文化课的紧迫、外人的唱衰与冲突、我们竞赛发挥的失常、退步甚至崩盘……不论遇到怎样阻碍，他都没有放弃过，他永远那么自信，他永远追求着更高的目标，他的心中永葆着乐观主义和理想主义。他是我的领路人。\n可那些刻骨铭心的痛和代价又岂能一笑而过？？\n（以下这部分内容，仔细考虑后我认为不适合放出来，因此以缺文号代替。或许未来有一天会公开。）\n□□□□，□□□□，□□□□□□□□□，□□□□□□□□□□□，□□□□□□□□□□□□□□□□□□□□□□，□□□□□□□□□□□□□□□。□□□□□□□□□□，□□□□□□□□□□□□□□，□□□□□□□□□。\n□□□□□□□□□□、□□□□□。□□□□，□□□□□□。□□□□□，□□□□□□□□□□□□。□□□□□□□，□□□□，□□□□，□□□□□□□□□□□，□□□□□□□□□□□□□，□□□□□□□□□□□□□□□□□□。□□□□□□□□？□□！□□□□□□□□□□□□□，□□□□□□□。□□□□□□□□□□□□□□□□□，□□□□□□□□□□□□□□□。□□□□□□□□□□□□□。\n□□□□□，□□□□□□□□□□□□□□□，□□□□□□□□□□，□□□□□□□□□□“□□□□”，□□□□□□□□□□□□□□□，□□□□□□□□□□□。□□□□□□□□□□□□□□□，□□□□□□□□□□□□□□□□，□□□□“□□”□□□□□□□□□□□□□□，□□□□□□□□□□□□□□□□□□□□，□□□□□□□□□□□□□□□□□□□□□□□，□□□□□□□，□□□□，□□□□□□□□□□□□□□□□□。\n□□□□□，□□□□□□□，□□□□□□□□□□□□□□□，□□□□□□□□□，□□□□□□□□□□□□□□□□□，□□□□。□□□□□□□□□□□□□□□□、□□□□□□□□□□□□□□，□□□□□：□□□□，□□□□□，□□□□□□□□□□□□□□□□□□□；□□□□□□□□□□□□□□□，□□□□□□□□□□□“□□□□□□□□□□□”□□□□□，□□□□□□□□□。□□□□□□，□□□□□□□。\n□□□□□，□□□□□□□□□□□，□□□□□□□□□□□，□□□□□□□□□□□□□□□，□□，□□□□，□□□□□□□□□，□□□□□□□□□□□□□□□□□□□。□□□□□□□□□□□□□□□□□，□□□□□□□□□□□□□□□——□□□□□□□□□□□□□□□□□□□□。□□□□□□□□□□□□□□□□□□□□□□□□□，□□□□□□□□□□□□□□□□□，□□□□□□□□，□□□□□□□□□□□□□□□。□□，□□□□□□□□□□□□□□□□□，□□□□□□□□□。\n□□□□□□□□□、□□□，□□□□□□□□，□□□□□□□□，□□□□□□□。□□□□□，□□□□□□□□□□□□□□□□□。□□□□□□□□□□□：□□□□□□□□□□□□□□□□□□，□□□□□□□□□□□□□□□□：□□□□□□。□□□□□□□□□□□□□□□□，□□□□□□□□；□□□□□□□，□□□□□□□□□□□□□□□□□□。□□□□□□□□□□□□□□□□□□□□□□□□□□□□，□□□□，□□□□。\n□□□□□□□□□□□□□□□□。\n□□□□，□□□□□，□□□□□□。\n□□□□□□□□□。□□□□□□□□□□□□□□□□。\n□□□□，□□□□□□□，□□□□□□□□□□□□□□□□□□□□，□□□□□□□□□□□□□□□□。□□□□□，□□□□□□□□□□□□；□□□□□，□□□□□□□□□□□□□□□□，□□□□，□□□□□□□□□□□，□□□□□。\n直到 NOI2023 之前，每当走进那间教练办公室，我的心脏都会条件反射般地跳动得剧烈。若有一段时间不去那间教室，我就常会在夜里做起关于训练的噩梦。\n在他之前，我从未对一个人有着如此复杂的情感。\n我的 OI，就是在自己所热爱的领域，做着令自己痛苦的事情。\n那是怎样一种折磨啊。\n22 年初我曾企划在 NOI 后写一篇以时间为主题的，记录训练经历的长文。随着后来的变故，我也就没有提笔。跨年的空间算是写了一部分，也有些没提的，还是想凭记忆补几句。\n在我看来，因其固有性质，OI 是训练周期最长，训练效率最低，发挥不确定性最大的竞赛，学习 OI 耗费的时间是其他竞赛的数倍。我所知道的 OIer 们基本上在初一及之前就接触了 OI，而他们未来数年的大块时间都被停课占据，在这漫漫长路中，他们承受了太多。\n我自身更尤为如此。从六年级下的半停课起到 23 年末，我在校园里的时间不足三学期，除此之外几乎都在 cx，朝九晚十。前言也提到，cx 对我来说是一个与世隔绝的地方，它带来的是精神上的隔绝——但更残酷的是这里的时间。我曾读过柳文扬的短篇《一日囚》，主人公被时间困住，他的生命与世界切断了联系，他的“活着”成了悖论。我在 cx 体验到了类似的感觉——刷题的日子里，没有进步，没有新的经历，我的生命只剩下大脑无止尽的机械的运作。在我还没反应过来自己实质上做了什么时，一天甚至一周就毫无预兆地结束了，我猛地回头，想抓住些什么，可两手空空。这样味同嚼蜡的日子看不到尽头，三个月、半年、一年……与小说唯一不同的是，时间在真真切切地向前，我的青春在浑浑噩噩中逝去。\n这不是 cx 的问题，当我做出走上校外训练 OI 这条路的决定时，就注定了，我会在这样的时空封闭中，走向偏执、孤僻和自暴自弃。我变得没有见闻，没有朋友，没有爱好，没有情感，没有曙光。我的感性世界坍缩了。那时我的脑中常常回荡着这样一句话：“日子像断了线的串珠般落下，散失无踪”；而我是失了魂的少年，日趋麻木。\n支撑那时的我的不是未来那块虚无缥缈的金牌，而是关于初中非 OI 经历的回忆。我记不清有多少个夜，沉浸在那如星河般流动的记忆里：2020 年在 MC 地形圈的声名鹊起，2021 年和初中同学的书生意气、激扬思潮……从艺术、科学到哲学，从思辩世界、批判糟粕到认识自己，那些一去不返的日子，那些我所珍视的人和事，我在其中找到了自己生命的意义。我多么想再续与他们的故事，可那些夜：\n只剩下我独孤与彷徨作伴，哪怕只言片语却也无人倾诉，万千思绪伴着我炽热的心，随风而动，无处安放……\n—— [CTS2019] 无处安放（有改动）\n我的思念从未干涸，只是越发地浓。\n我是一个看重过程的人，因为我知道那些成功只是一瞬，当我的呼吸化为空气，我的记忆散作青烟，一切都会在时间的流水中化成泡沫而破碎。我能做的，只有全身心地感受我所经历的一切——这就决定着意义本身。\n可我的 OI，就是在支离破碎，痛苦不堪的过程后，一个尚可接受的结果。\n那是怎样一种遗憾啊。\n呼，还是走过来了。\n如果要回答开头那个问题，我会说：我也喜欢信息学竞赛。\n抚平训练的伤痕，擦干眼角的泪水，每一场比赛都是新的开始。\n通过正文，你可能会感受到，我很看重分数和排名，甚至有些过分注重结果——这本质上是我与生俱来的对竞争的渴求。当我与走在信息学前沿的同龄人们同台竞技，平日训练的镣铐不复存在，我内心深处的野火熊熊燃起，将自己全身心地，用尽一切精力地投入竞赛。我沉浸于争分夺秒的紧张感中：思维发散收敛，流转突破；指尖随风跳动，代码倾泻；心中下定决策，破釜沉舟……那些瞬间，我的心中闪动的不是胜负欲，而是教练常说的一句话：\n人生能有几回搏？\n要强的特点使我赛出过许多漂亮的发挥，但也正是这种好冒险的性格，带来了我的大起大落。NOIP2021 和 NOI2022，因为心态上太过强求，过分激进，我在决策时头脑一热，就触发了惨剧。我引以为傲的优点变成了死穴，平时的模拟赛不会暴露，可在那些决定命运的大考上，在比赛趋近白热化，当我孤注一掷之时，它就是那枚定时炸弹。明明实力俱备，却因为心态和失误将金牌拱手让人，这是最令我痛苦和无法接受的事实。\n后来我逐渐明白：心态也是实力的一部分。我最大的敌人不是切题如麻的对手，不是停滞不前的实力，而是我的意识和人性，是克服自己——这贯穿一生的课题。\n这不是一句华而不实的名言，也不是只需勇往直前，不畏险阻的励志故事，而是在那复杂多变的解题状况下与本能与时间的博弈，是自我修行过程中悟得的那种微妙而准确的对内心的理解与控制。\nFinally, I made it.\nNOI2023“我与 NOI”的演讲活动上，skc 讲述了他从初三到高二的心理历程。尽管与我经历的险阻与挫折不同，但在最后，从那位从未共同交流训练过的对手的口中，我听到了一句在耳边回响过无数次的，熟悉的话语：\n拿到自己该拿的分。\n当一名 OIer 摆脱了贪婪、侥幸、冲动和自负，能在赛场上处变不惊地发挥出自己最真实的水平，他就从稚拙变得成熟，从赌徒变成一名真正的选手，他就将命运紧握在了自己的手中。最终，他将在顶峰与那群人会聚。\nOI，是时间的结晶，是成长的故事。\n时间终究是一去不复返了。\n我从未后悔走上 OI 这条路。但假如时间能重来一次，我还会选择它吗？\n我不敢肯定。\n我曾经练过 ZJ 2021 年高考卷作文，关于得与失。我的标题是《其实无谓得失，人生在于奋斗》，其中一段是这样写的：\n当得失降临时，我们该如何面对？有人说，得失是新的起点；有人说，得失是一个阶段的终结。在我眼里，得失不是起跑线，更不是目的地，它只是人生道路上的起起伏伏，曲曲折折。有人倒在上坡，他们因失而放弃，就再也不敢爬起；有的人摔在下坡，他们被得迷住了双眼，停止前行的步伐。有的人心怀远方，他们知道，脚下的曲折是警示，是磨练，是“所以动心忍性，曾益其所不能”，而绝不是苟且安身之所。他们的征途，是星辰大海。\n那时的我以为，所谓得失只是利益上的盈亏和事业上的成败——长风破浪会有时，但定能千金散尽还复来。可如今走过青春的半程，回首 OI 带来的得失，我意识到，人生历程的得失是无法逆转的，更是无法衡量的。\n那时的我以为，只要守住自己的初心，知行合一，勇敢地大步向前做自己，就定能到达向往的彼岸。可如今体验了斗争与绝望，扪心自问，我开始明白，在残酷现实的飓风之下，没有人能幸免于违心的妥协与让步，只有把那份冲动一层一层深深地埋入心底，闪烁着的希望越发‌孱弱而渺小。\n有梦，肯奋斗，这固是不凡的品格；然倘若一个人为了唯一的终生的奋斗，逼着自己变得刻板，走向精神的极端，放弃了生活，放弃了亲情、友情和爱情，放弃了快乐与积极阳光，放弃了爱好，放弃了自我的其余潜能，放弃了体验与经历这个世界、这个自然、这些社会、这些文化的其他方方面面，那样的人生岂不为一束苍白的火焰、一株皱瘪的干花？那样的人还何以为人呢？\n我不愿成为一个符号。\n可那些沉重的代价，已深深地烙印在了我的生命中。\n思来想去，如果我在那岔路口选择了另一个方向，就真能度过无怨无悔的六年，乃至未来吗？\n答案是显而易见的。\n我总是那么完美主义，希望自己所经历的都没有徒劳，没有缺憾，没有剑走偏锋，没有事与愿违。可我何以改变裹挟着自己的环境，这世上又怎会真正存在一条理想当中的路呢？\n在这即将结束的部分，我想对自己说：不要再总是回头了，你所经历的都值得。\nNOI2023 的开幕式后，刚拍了集体照。在报告厅里徘徊的我，微微听见有旋律从门外流淌进来，便顺着阶梯向上走。外面是晴天，一切都涂上了一层金色，斑驳的红砖地上叶影摇曳，日光照进玻璃房，一名志愿者学生借门旁的钢琴弹奏着久石让的《君をのせて》和《あの夏へ》，琴声回响，空灵的音符将我的思绪牵向远方。\n我带着对世界的好奇来到人间，至今已度过了 18 个夏天。记忆中的一幕幕，晚霞洒下的波光，雨雾笼罩的城市，阳光下的汗水与笑靥，黑夜中的荧幕与泪花……我喜欢伸手去抓那些瞬息，如同儿时在自行车道上撩蜻蜓，挥起网兜，它们便闪开去；我接着向前奔跑四顾，却发现它们仍振着翅盘旋，与我一同前进。后来，雨夜到来了，它们化作萤火虫萦回在身边，使我不被黑暗吞噬。不久后，霞光又将染上地平线，可来时的路已在澄澈的积水中隐去，那些存在已幻化成风，留下茕茕孑立的我。我将去向何方？我又能再经历几个如约而至的夏天？只有在这水天一色之间，怀揣着悸动而期冀的心，紧攥着光阴流转的印记，走向天际，去拥抱，那永恒的未知。\n《千と千尋の神隠し》——海\r我又想起电影中那个夏天，熟悉的旋律再次响起，白龙与千寻在石阶上告别，白龙说的最后一句话是：\nさあ、行きな。振り向かないで。\n好了，去吧。不要回头哦。\n是的，要带上那些祝福与回忆，更有力量地活下去。\n——这不也正是回忆录的意义吗？\n最后，我想以这首歌的歌词作为结尾，也是它在我 OI 那些最黑暗的时刻给了我走下去的精神力量。\n『いつも何度でも』\n詞：覚和歌子　曲：木村弓\n呼んでいる　胸のどこか奥で\nいつも心踊る　夢を見たい\n悲しみは数え切れないけれど\nその向こうできっと　あなたに会える\n繰り返す過ちの　その度　人は\nただ青い空の　青さを知る\n果てしなく　道は続いて見えるけれど\nこの両手は　光を抱ける\nさよならの時の　静かな胸\nゼロになる体が　耳を澄ませる\n生きている不思議　死んでいく不思議\n花も風も街も　皆同じ\n呼んでいる　胸のどこか奥で\nいつも何度でも　夢を描こう\n悲しみの数を　言い尽くすより\n同じ唇で　そっと歌おう\n閉じていく思い出の　その中にいつも\n忘れたくない　囁きを聞く\n粉々に砕かれた　鏡の上にも\n新しい景色が　映される\n始まりの朝の　静かな窓\nゼロになる体　充たされてゆけ\n海の彼方には　もう探さない\n輝く物は　いつもここに\n私の中に　見つけられたから\n动笔于 2023.8.3初稿完成于 2024.2.8第一次修改完成于 2024.9.17感谢 zrz 帮忙审稿第二次修改完成于 2025.2.5\n","date":"2025-02-05T00:00:00Z","image":"https://littlereuben.github.io/life/oi-memoir/cover.jpg","permalink":"https://littlereuben.github.io/life/oi-memoir/","title":"我与 OI 的故事"},{"content":"这是一篇学习笔记。\rC 动态内存 malloc (字节数) // 返回 void* 类型，可以隐式与别的指针类型转换 calloc (数量, 单个元素字节数) // 全置 0 realloc (指针, 新的字节数) // 指针可以是先前申请的或 NULL，如果是申请的，相当于 free，malloc 并复制。 free (指针) // 释放 糖：int * p = calloc(10, sizeof * p);\n对了，关于 C++ 的 new 有两点提一下，一个时 new int [1] 必须用 delete [] 因为 new 数组时会额外申请空间记录数组大小。另一个是 placement new。\n多文件编译 ODR In any translation unit, a template, type, function, or object can have no more than one definition. Some of these can have any number of declarations. A definition provides an instance. In the entire program, an object or non-inline function cannot have more than one definition; if an object or function is used, it must have exactly one definition. You can declare an object or function that is never used, in which case you don\u0026rsquo;t have to provide a definition. In no event can there be more than one definition. Some things, like types, templates, and extern inline functions, can be defined in more than one translation unit. For a given entity, each definition must have the same sequence of tokens. Non-extern objects and functions in different translation units are different entities, even if their names and types are the same. 头文件 ifndef 多文件编译的原理为：将 .h 中的内容加到每个 .cpp 中（preprocess），然后编译这些 .cpp，然后把他们链接起来。\n.h 里的 #ifndef 那些东西是为了避免同一个 .cpp include 多次同一个 .h。例如\n// a.cpp #include \u0026#34;h1.h\u0026#34; #include \u0026#34;h2.h\u0026#34; // h1.h #include \u0026#34;h.h\u0026#34; // h2.h #include \u0026#34;h.h\u0026#34; // h.h const int PI = 3.14; class node { int a, b, c; } 常量、类定义等内容不能在一个翻译单元中定义多次。\n注意，这个技巧不能避免多个文件之间的重复定义，例如在 .h 里加了 int a; 之类的照样会造成 redefinition。\n链接性 链接性分为外部、内部、无。外部链接性意味着作用域可以在多个 .cpp，前提是在定义所在的文件以外的文件中，要写 extern（并且不初始化）。内部链接性意味着作用域只在当前文件内，无链接性就是在代码块内。\n全局变量、函数都是默认外部的，这就意味着它们不能在多个文件里或头文件里定义（但是函数可以多次声明，甚至在同一个文件里连续写两次 int f(int) ; 都没问题）。如果要变成内部就在开头加 static。\n头文件里可以定义什么 #define 肯定没什么问题。\nconst 比较特殊，它是内部链接的，所以可以写在头文件里。如果要强制它变成外部的，就加 extern。\nstruct 和 class 可以，但是成员函数不能在头文件里放在外面。类不能重复定义，但是可以在链接是出现重复，但是两个重复的不能不同，否则会出一些奇怪的情况。例如：\n// a.cpp #include \u0026#34;h.h\u0026#34; struct node { int a, b, c; } // b.cpp #include \u0026#34;h.h\u0026#34; struct node { int a, b, d; } // h.h struct node ; 这样不会 CE，但是会出现一些诡异的问题，比如一个文件里得按另一个的名字来。\n类定义不能在外部链接，也就是说不能在另一个文件里写 extern node x; 来定义一个 node（在另一个文件里定义的类）的实例。\nCMake cmake 目录 指令会对目录中的文件（含 CMakeLists.txt、源文件）生成 build system。这一步还没有编译，可以理解为生成了以 Makefile 为代表的一系列文件。\n如果要进一步指定目录，-B 可指定输出目录，-S 可指定输入目录。如果没有这个目录，直接 cmake 目录 会报错，但 cmake -B 目录 则会自动创建一个。\n如果 cmake 报错\nRunning \u0026#39;nmake\u0026#39; \u0026#39;-?\u0026#39; failed with: 系统找不到指定的文件。 就在 cmake 后面加 -G \u0026quot;MinGW Makefiles\u0026quot;。或者直接改环境变量：setx CMAKE_GENERATOR \u0026quot;MinGW Makefiles\u0026quot; /m（需要管理员模式运行 Powershell，或者直接图形界面改也行）。\n注意一旦 cmake 失败一次，就需要删掉所有相关文件再重新 cmake，不然会傻傻地仍然报错，或提示已经 build 过。\n然后正式编译，使用 make [-C 目录]（不写 -C 只能 make 当前目录）或 cmake --build [目录]。\n以后改代码，只需重新 make 就行。\n一般习惯把 build system 的部分放到子文件夹里。汇总：\nmkdir build cd build cmake .. make ./对应名字 参考：\nhttps://wshibin.github.io/misc/cmake/\nhttps://cmake.org/cmake/help/latest/guide/tutorial/index.html\nhttps://www.bilibili.com/video/BV14h41187FZ/\nvcpkg vs 或 wsl，请。\n类 基本结构、重载运算符、后置 const、构造析构略。\nC struct struct node { int a, b, c; } x1; struct node x2; struct node x3 = {1, 2, 3}; typedef struct _ { int a, b, c; } node; node x1, x2; 这里 _ 可省，直接写成匿名结构体。\n静态成员变量和函数 顾名思义，加 static，就是与类关联而不是与某个对象关联。注意 C++11 之前，类里是不能 const 的，只能 static const，或者 enum。\n成员函数 成员函数如果传同类参，可以访问对方的 private 成员。\n类内定义的成员函数是自动内联的。\n成员函数可以类外定义，必须再类内先声明，定义时要加 ::：\nclass A { int a, b; int f() ; } int A :: f() { return a + b; } 众所周知，在成员函数头后加 const 可以保证成员不被改变。但是它还能用于重载，拓宽了可使用情景：\nstruct node { int a; void f(int x) { cerr \u0026lt;\u0026lt; \u0026#34;non-const\\n\u0026#34;; a = x; } void f(int x) const { cerr \u0026lt;\u0026lt; \u0026#34;const\\n\u0026#34;; } } ; int main() { node t; t. f(1); const node s {1}; s. f(1); } 这段代码会输出 non-const\\nconst\\n。\n友元 友元函数是一种非成员函数，其声明必须在类内，定义可以在类内或类外，但在类内时不能直接使用成员变量。其关键作用是能在类外访问私有成员。显然这种东西不可能是私有的。\nclass A { int a, b; friend ostream \u0026amp; operator \u0026lt;\u0026lt; (ostream \u0026amp;, const A \u0026amp;) ; } ; ostream \u0026amp; operator \u0026lt;\u0026lt; (ostream \u0026amp;out, const A \u0026amp; x) { out \u0026lt;\u0026lt; x. a \u0026lt;\u0026lt; \u0026#39;/\u0026#39; \u0026lt;\u0026lt; x. b \u0026lt;\u0026lt; endl; return out; } 注意声明时参列里 \u0026amp; 不能少。\n友元类是在类定义中写 friend class 另一个类的名字，然后另一个类就可以访问这个类的私有成员了。\nclass A { int a, b; friend class B; } ; class B { int sa, sb; void add(const A \u0026amp;x) { sa += x. a, sb += x. b; } } ; 如果只希望 B 的某个函数可以访问 A 的私有成员（以限制 B 不在别的地方瞎搞），可以用友元成员函数：\nclass A ; class B { int sa, sb; public: // 必须要有！ void add(const A \u0026amp;) ; } ; class A { int a, b; friend void B :: add(const A \u0026amp;) ; } ; void B :: add(const A \u0026amp; x) { sa += x. a, sb += x. b; } 我们来仔细考虑一下：\nA 定义 → B 定义：A 里根本写不了 B。 B 定义 → A 定义：B 里根本写不了 A。 A 声明 → B 定义 → A 定义：B 定义里要用 A 的成员，但 A 没定义。 B 声明 → A 定义 → B 定义：A 要写 friend void B :: ...，B 是得定义完的。 所以最后只能 A → B → A → B。\n唐。\n类继承 思想：两个类有共同特征，不想重复写这部分。\nclass 派生类名 : [public|protected|private] 基类名 { 定义派生类独有的内容 } ;\n如果要继承多个，就用 , 分隔。注意 class C : public A, B 相当于 class C : public A, private B。\n基类中 private 的无法在派生类中访问，如果想访问但不希望被外面访问，就用 protected。\n继承方式\\基类内权限 public protected private public public protected inaccessible protected protected protected inaccessible private private private inaccessible 构造函数：推荐在派生类初始化列表中调用基类的构造函数，而不是直接赋值基类的元素。如果不写，则调用基类的默认构造函数。注意，唯一不行的是在初始化列表中初始化基类的元素，因为构造函数是先调用基类的构造函数，如果这样写就重复了。\n如果不写构造函数，也可以用初始化列表的方式（C++ 17），注意列表对应顺序是先基类后派生类。\n派生类无法使用基类的重载运算符和友元函数。\n多态 派生类可以重载基类的变量和函数，如果要使用基类中的，就用 ::。\n多态可以展开讲的最大的点就是虚方法。考虑：\nclass A { public: int a; void print() { cout \u0026lt;\u0026lt; \u0026#34;Value = \u0026#34; \u0026lt;\u0026lt; a \u0026lt;\u0026lt; endl; } } ; class B : public A { public: int sum; void rec() { sum += a; } void print() { cout \u0026lt;\u0026lt; \u0026#34;Sum = \u0026#34; \u0026lt;\u0026lt; sum \u0026lt;\u0026lt; endl; } } b1, b2; class C : public A { public: int prod = 1; void rec() { prod *= a; } void print() { cout \u0026lt;\u0026lt; \u0026#34;Product = \u0026#34; \u0026lt;\u0026lt; prod \u0026lt;\u0026lt; endl; } } c1, c2; int main() { // do something to b1, b2, c1, c2. A * List[4] {\u0026amp; b1, \u0026amp; b2, \u0026amp; c1, \u0026amp; c2}; // 指针和引用可以从派生类隐式转换到基类 for (int i=0; i\u0026lt;4; i++) List[i] -\u0026gt; print(); } 显然他会输出四行 Value = ...，但是我们希望它能输出两行 Sum，两行 Product，又懒得一个个 . print()。那怎么办呢？\n我们在基类的函数开头加一个 virtual（必须），然后在派生类的函数大括号前加 override（可选）。在多重继承时，会自动找到最深的重载。\n如果强制一个类的派生类不能重载，就加 final。\n问题：如何使继承链中途不再虚？\n问题：如果真的基类对象调用纯虚函数会怎样？\n抽象基类是具有纯虚函数的类，纯虚函数是不给出定义的虚函数：\nvirtual void f() = 0; 这种情况下，不能建立该类的对象，且必须在（要有对象的）派生类中给出纯虚函数的定义。\n析构函数是一类在类继承中往往必须要是虚函数的函数。考虑以下代码：\nclass A { public: // 析构函数必须是公有的或保护的，不然程序结束时都调用不了，直接 CE ~ A () { cout \u0026lt;\u0026lt; \u0026#39;a\u0026#39;; } } ; class B : public A { public: ~ B () { cout \u0026lt;\u0026lt; \u0026#39;b\u0026#39;; } } b; 程序结束时会调用 b 的析构函数，先执行 ~B()，再执行 ~A()，输出 ba。这没啥问题。（注意：动态分配内存的对象在程序结束时不会调用析构函数）\n但是如果 main 里有这样的代码：\nA * p = new B; delete p; 那就会导致只有基类的析构函数被调用。这在派生类里没有单独的动态内存时是没问题的（有静态变量是没问题的，也会跟着删掉），但是如果：\nclass B : public A { public: int * p; B () { p = new int [10] {}; } ~ B () { delete [] p; } } ; 那就会造成内存泄露。所以如果存在基类指针指向派生类对象的情况，析构函数就必须要是虚的。\n虚函数的多态的原理，是动态联编，大概就是每个对象都记录了一个函数指针表，用于查找它应该调用哪一级的重载的函数。因为类指针指向的对象类型可能取决于输入之类的，所以不得不边运行边确定，导致很慢。\n虚继承 复杂的继承会出问题，比如：\nclass A { public: int a; } ; class B : public A { public: int b; } ; class C : public A { public: int c; } ; class D : public B, public C { public: int d; } ; 一个 D 对象，没法直接访问 .a，必须指定是 .B::a 还是 .C::a，函数同理。\n如果希望合并两个 a，需要把 B 和 C 的继承方式改成虚继承 virtual public A，与此同时当 D 的构造函数递归调用 B 和 C 的构造函数时，将会忽略对 A 的构造函数的递归调用，需要单独调用 A。\n但是重载的函数还是没法合并，所以最好 D 自己写一个，当然可以直接调用 B:: 和 C:: 的，这个的重复就无法避免了。\n模板 最基础的略。\ndouble res = max(2.5, 3); 不行，double res = max \u0026lt;double\u0026gt; (2.5, 3); 可以。\n显式实例化：template 返回类型 函数名 \u0026lt;具体化类型\u0026gt; (参数列表) ; 表示生成一个对应的实例。\n显式具体化：template \u0026lt;\u0026gt; 返回类型 函数名 (\u0026lt;具体化类型\u0026gt;) (参数列表) { ... } 其中第二个 \u0026lt;\u0026gt; 是可选的。和实例化不同的是，它相当于一种“内容不同的重载”，必须有函数定义，且出现在第一次调用之前（否则与隐式实例化冲突）。例如\ntemplate \u0026lt;\u0026gt; char * max \u0026lt;char *\u0026gt; (char * a, char * b) { return strcmp(a, b) \u0026gt; 0 ? a : b; } 模板类：开头加一样的东西就行。类外定义函数： template \u0026lt;typename T\u0026gt; 返回类型 类名 \u0026lt;T\u0026gt; :: 函数头 { ... }\n然后我们考虑一个例子：希望写一个 max，它能接受一个 int 和一个 double（之类的），并返回 double（选择级别高的类型）。如果这样：\ntemplate \u0026lt;typename T, typename U\u0026gt; (T? U?) max (T a, U b) { return a \u0026gt; b ? a : b; } int main() { cout \u0026lt;\u0026lt; max(3.5, 3) \u0026lt;\u0026lt; \u0026#39; \u0026#39; \u0026lt;\u0026lt; max(3, 3.5); } 这个就会有问题。可以用 C++14 的特性，自动推导返回类型：\ntemplate \u0026lt;typename T, typename U\u0026gt; auto max (T a, U b) { return a \u0026gt; b ? a : b; } STL 查漏补缺 遍历一些 STL 对象时，建议用 const_iterator，对应 . cbegin() 和 . cend()。作用是无法修改内容。\n++ it 比 it ++ 快，考虑 it ++ 具体该怎么实现：\niterator operator ++ (int) { iterator tmp (* this); // do increment return tmp; } STL 提供了一个一般的 find，它是暴力，不要将它用于已经有自己的 find 的类。\n移动语义和右值引用 左值是有地址的，可以赋值的变量。\n右值的例子包括字面量、四则运算的结果、函数的非引用返回值等。\n能否引用 非常量左值引用 常量左值引用 非常量右值引用 常量右值引用 非常量左值 × × 常量左值 × × × 右值 × 目前不知道常量右值是什么，也不知道常量右值引用有啥用。\n右值引用实际上是开了空间的。因此可以这样：int \u0026amp;\u0026amp; p = 1; p = 2;\n可以用 move（C++ 11）将左值转成右值。\n目前看起来右值引用没啥用。在复杂的类的应用中，考虑提高这段代码的效率：\nclass Data { public: Data (int _size) : size (_size) { data = new int [size]; } Data (const Data \u0026amp; t) { size = t. size, data = new int [size], memcpy (data, t. data, size * sizeof (int)); } Data \u0026amp; operator = (const Data \u0026amp; t) { if (\u0026amp; t == this) return * this; delete [] data, size = t. size, data = new int [size], memcpy (data, t. data, size * sizeof (int)); return * this; } ~ Data () { delete [] data; } private: int size, * data; } ; 注意必须重载复制构造函数和赋值，否则会导致多对一。\n如果将一个对象复制给另一个对象，且这个对象不再使用（例如，这个对象是函数的返回值），那么暴力赋值就可以优化——我们希望直接把赋值者的内容转移给被赋值者，但是为了避免多对一析构爆炸，得把赋值者清空（delete nullptr 不会发生任何事）。这就必须要求我们能修改等号右边的东西，这就是右值引用在移动语义中的作用。我们可以新增一个“移动构造函数”：\nData (const Data \u0026amp;\u0026amp; t) { size = t. size, data = t. data, t. size = 0, t. data = nullptr; } 移动赋值同理。如果要将 a 赋值给 b 且 a 不再用了，写 b = move(a)。\n智能指针 我们现在希望偷懒不写 delete，于是类似上面，我们会写个指针类来自动 delete，但是与上面不同的是，指针类并不负责申请内存，也不负责复制内容，只负责自动释放空间。这就导致如果两个指针指向同一片内存就会爆。\n头文件 memory。C++98 有 auto_ptr，略。C++11 有 unique_ptr 和 shared_ptr。unique_ptr 禁止复制（构造和赋值），只能 move 之后再赋；shared_ptr 会维护一个计数器，等最后一个相关智能指针对象析构时才 delete。\n用法 1：unique/shared_ptr \u0026lt;int\u0026gt; p (new int [100]);\n不推荐用法 2：int * p = new int [100]; unique/shared_ptr \u0026lt;int\u0026gt; q (p); 会导致多对一。\n用法 3：auto p (make_unique/shared \u0026lt;int\u0026gt; (100));\n类型转换 C++ 的类型转换：static_cast \u0026lt;转换成的类型\u0026gt; (原变量)。在编译时会检查转换是否合法。\nC 中，这样的代码是可以的（逆天）：\nconst int a = 1; int \u0026amp; b = (int \u0026amp;) a; b = 2; C++ 中，不能这样 static_cast \u0026lt;int \u0026amp;\u0026gt; 但是可以 const_cast \u0026lt;int \u0026amp;\u0026gt;。只有特殊情况需要修改时才用。\nC 中，这样的代码是可以的：\nstruct node { int a, b; } ; int main() { int * p = new int [2]; p[0] = 1, p[1] = 2; node * q = (node *) p; } C++ 中，不能这样 static_cast \u0026lt;node *\u0026gt; 但是可以 reinterpret_cast \u0026lt;node *\u0026gt;。总的来说，感觉就是避免你无意识地瞎转类型，但是你硬要转也是可以的，效果和 C 的一样，就是“棒转”，不做任何事情。\n有且只有 dynamic_cast 只能用于指针和引用。dynamic_cast 可以把基类转换到派生类（static_cast 也可以做）。如果被转换者类型不对（包括把本身就指向基类对象的指针转成派生类），会返回 nullptr。dynamic_cast 转换的必须是多态类型，即至少声明或继承（可以在本身 override）了一个虚函数的类。\n异常 抛出异常 throw 信息。 try 开始代码块，里面可以用 throw。 捕获异常 catch (信息类型 [变量名字]) { ... } 接在 try 的代码块后，可以接多个处理方式。catch (...) 通用。 可以跨函数处理（再抛出）。跨的函数有返回值的赋值也会跳过。\n为了区分不同（大类的）异常情况，可以建立各种异常类。值得注意的是，如果抛出的类型是派生类，而捕获的类型中既有基类又有派生类，且前者写在前面，那就会被前者捕获。\nSTL 中的东西的异常都是 std :: exception 的派生类，可以调用 . what() 知道它是哪种。\n优化原理 分支预测 循环展开 并行处理、SIMD 循环顺序 标准属性 发现有个 project 里有些 [[...]] 这种东西，加在声明或定义的类型名前面。这是起到修改编译器对一些特殊情况的反应的。包括：\n[[nodiscard]] 加在函数声明前，如果该函数的返回值未被使用会报警告，可以通过 [[nodiscard(\u0026quot;...\u0026quot;)]] 加警告信息。 [[deprecated]] 表示对应东西可能被弃用，不鼓励使用（使用会警告），同上。 [[noreturn]] 表示对应函数不会正常返回（exit 或 throw 之类），提示编译器优化。 [[likely]] 和 [[unlikely]] 加在分支语句后，表示更可能进入哪个分支，提示编译器优化。 可变参数 https://zhuanlan.zhihu.com/p/694317432\n例题 有个题感觉还是很 educational 的。如何实现一个高维数组，每维的长度都是 $n$，但维数 $d$ 不定？可以用模板类：\ntemplate \u0026lt;typename T, int n, int d\u0026gt; class Array { Array \u0026lt;T, n, d - 1\u0026gt; a[n]; ... } ; 但这里的问题是 $d=0$ 的时候爆了。可以用部分具体化：\ntemplate \u0026lt;typename T, int n\u0026gt; class Array \u0026lt;T, n, 0\u0026gt; { T a; ... } ","date":"2025-01-22T00:00:00Z","image":"https://littlereuben.github.io/study/course-cppstudio/cover.png","permalink":"https://littlereuben.github.io/study/course-cppstudio/","title":"OIer 速通编入门"},{"content":"$\\gdef\\unit#1{\\,\\mathrm{#1}}$\n这是一篇学习笔记。\r前言 如果您真的对天文学感兴趣的话，可以考虑报这门课，但同时要做好花费一定精力的准备。这门课所需要的学习时间可能比其他 $2/3$ 学分的课多。\n这门课是 $3$ 学分，$10\\%$ 雨课堂随堂测验，$10\\%$ 作业（需交五次），$10\\%$ 观星报告（一学期有五六次观星活动），$10\\%$ 微科幻写作（可以完全用 AI），$60\\%$ 期末。\n上课主要是按照 ppt 讲，ppt 基于的教材是 21st Century Astronomy (fifth edition)，现在最新的是第七版。ppt 一千多张，知识量很大，一晚上三节课下来脑袋嗡嗡的，尤其是后半学期赶进度讲得很快，而且经常拖课。个人感觉老师很会讲，很有水平、有幽默感，但是思路比较跳跃，作为初学者很容易感觉各个知识点之间没有逻辑联系，或者单个知识点颠来倒去讲有点乱。我的笔记可能稍微梳理得清楚些，但也没法避免因为一些细碎的知识点而显得不够成系统。还是需要时间自己课后消化理解。\n几个其他的任务都简单。关于观星活动有两个值得注意的点：一个是建议西操观星带个三脚架，一个是直接用自带相机拍木星和土星必然过曝，整个行星变成一个光斑。\n期末个人感觉难度适中，不会考得很偏，不复习肯定会出事。$50$ 道选择，$20$ 道填空，$10$ 道简单的计算，考点全部来自 ppt，建议背 ppt，ppt 里打 * 的不考。上课时务必留意老师说“这个考试要考的啊”之类的话并记下来，甚至观星活动时都会说（例如冬季大三角），这些是真的可能会考的。\n推荐 zzh 的带你速通 天文学导论和星空摄影入门、Alex_Wei 的笔记。\n以下的图片与数据来源于教材和 Wikipedia。\n第一节课 太阳系→银河系→本星系群→室女座超星系团→拉尼亚凯亚超星系团\n恒星、星系只占很小一部分，之间——宇宙尘埃、暗物质、暗能量。\n膨胀、加速膨胀。\n行星系在我们的宇宙中普遍存在。\n$1\\unit{AU}=1.5\\times 10^8\\unit{km}$，$8.3$ 光分。太阳—海王星：$60\\unit{AU}$。\n离太阳最近的恒星比邻星，$4.2\\unit{ly}$。比邻星是红矮星，把周围的行星潮汐锁定。\n太阳系离银河系中心：$2.8\\times 10^4\\unit{AU}$\n银河系直径：$(1\\sim 2)\\times 10^5\\unit{AU}$\n银河系离仙女星系（M31，最近大星系，本星系群中最大星系）：$2.5\\times 10^6\\unit{AU}$\n麦哲伦大小星云是银河系的伴星系。\n天文观测 如何定义一天（太阳日）？太阳连续两次经过从同一地点来看天空最高点（子午线）之间的时间，不等于地球自转周期。每天的时长是不一样的，这是因为地球的公转轨道不是正圆。取平均值得到平太阳日。\n恒星日就是自转周期。\n如何定义一年？古埃及：每年尼罗河洪水泛滥到孟菲斯城的时候，发现天狼星和太阳同时从地平线升起。这个间隔就是 $365$ 天。\n基本概念 黄道是地球绕太阳公转的轨道平面。\n东西的定义是，自转自西向东。东西是在地球表面特定点才说的。如果脱离特定点看整个地球，东西就是一个“旋转方向”，而不是一个矢量。\n南北极的定义是，根据右手定则，得到自转的旋转向量从球心指向正北。南北相应定义，但可以脱离地球上的特定点说。\n纬度是指当地地面法线对赤道面的夹角。经度指当地所在球面大圆与 0 度经度（格林尼治天文台）对应球面大圆的夹角。\n地轴，就是地球的自转轴。\n赤道是地球表面的点随地球自转产生的轨迹中周长最长的圆周线。赤道平面与南北极连线垂直。\n转轴倾角是赤道平面与黄道平面的夹角，地球的转轴倾角约为 $23.44^\\circ$。也可以定义为自转的旋转向量和公转的旋转向量的夹角，其取值可以是 $[0,\\pi]$。\n地球公转的方向与自转方向相同，这个“相同”的本质就是 $23.44^\\circ\u0026lt;90^\\circ$。\n不要再说自转是顺/逆时针了！那会取决于观察的方向。\n地磁南/北极，是地球磁场的北/南极。地磁北极，也就是地球磁场的南极，在地理北极附近，并且在持续移动。\n星座 古代的星座是往图案上靠，连起来的。现在是通过将全天划分为 $88$ 个天区，每个天区对应一个星座。\n星图上的信息：分区（直线为边界）、各个星座、亮度、黄道、天赤道、观测的日期时间。\n（较亮）恒星的命名方式：星座 + 希腊字母（一般而言越靠前越亮）。\n一般而言，一个星座的各星无物理联系，但，如果一个星位置放大了，里面有多个星，那就可能有关系了（双星系统等，例如天狼星可以算双星，它有一个伴星，是颗白矮星。很亮的星大都是多星系统），如果数量多的，就叫做星团。星团周围有光晕，是星际尘埃散射的结果。\n中国古代：星官，三垣、二十八宿。\n最亮的星：天狼星（大犬座 α）。\n夏季大三角：织女一（天琴座 α）、河鼓二（天鹰座 α，牛郎星）、天津四（天鹅座 α）。\n冬季大三角：天狼星、南河三（小犬座 α）、参宿四（猎户座 α）。\n离太阳系最近的恒星系统：半人马座 α，三星。\n典型造父变星：北极星（小熊座 α，三星）、造父一（仙王座 δ）。\n天体的周日视运动 天球是从地球上看星空，将星空假想成一个球面，没有半径。\n星星在天球上视作固定不动（随着天球动）。太阳系内的会乱动，太阳在天球上一年绕一圈。\n天球赤道，就是地球赤道平面与天球的交圆。\n天球的天极，就是地轴与天球相交的两点。\n在地球上任何位置，都恰好能看见天球的一半。可以认为天球作为一个“屏幕”，是自东向西转动的，那么现在可以认为地球不自转。\n星轨是天体随天球转动的轨迹。\n所有的星星的星轨对应平面都垂直于地轴。可以结合在地球的位置，算出哪些星在当地可以永远看到（拱极星，星轨和地平面相切），哪些星永远看不到。\n上图中，小球表示地球，大球表示天球，天球从右往左转。顶部蓝点为北天极和地理北极。侧面蓝点为观察点。蓝色球面为天球可见部分。橙色实线这圈及以上为拱极星，橙色虚线这圈及以下为永远看不到的星。如果观测地纬度为 $\\phi$，那么拱极星的纬度在 $\\pi/2-\\phi$ 以上。同时，赤道面（以及星轨面）和地平面的夹角也是 $\\pi/2-\\phi$。\n在该点处看北边天空，星是逆时针转；看南边天空，是顺时针；看东边天空，左下—右上升起；看西边天空，左上—右下降落。\n天顶，就是当地的地平面法线与天球的交点。当地的正北—正南在地球球面上的弦，就是子午线。当地—北天极（附近有北极星）与当地—地面正北的夹角，可用于推导所处的纬度。\n天球动，星星动，天顶不动，子午线不动。\n要描述一颗星的位置怎么办？用地平坐标系。但是星星的坐标会变……\n地平坐标系是以观测地为中心点的坐标系。描述天球上的一点，可以用高度角和方位角两个参数来表示。高度角是连线与地平面的夹角，方位角是水平方向的，从正北 $0$ 度开始向东（顺时针）增加。\n子午线可以对应到天球上（方位角 $=0^\\circ/180^\\circ$，高度角 $\\in[0^\\circ,90^\\circ]$）。任何通过子午线的天体都处于其距观测者地平面的最高位置，称为过中天。\n不同经度——看到星的时间不同，不同纬度——看到星的范围不同。只有在赤道上，才能一天看尽整个天球。\n我们的时间都是太阳时，只不过经度不同。正午：太阳经过子午线的时刻，不等于 12 点，因为国家有经度上的跨度。北京时间是【东经 120 度正午对应 12 时】的时间，北京本身也不是 120 度。\n正午的太阳高度角为 $90^∘−(观测地纬度−太阳直射点纬度)$。\n恒星日是地球上某（任意）点，某（任意）个星连续两次过中天的时间间隔。\n太阳日是地球上某（任意）点，太阳连续两次过中天的时间间隔。\n天体的周年视运动 回顾一天长度不等于地球自转周期的原因（“硬币悖论”）：\n每天白天的同一时刻，太阳的位置是往东移动的。并且太阳日的长度是不同的。与太阳的距离越小，角速度越大，太阳日的时间越长。太阳日的时间可能小于，也可能大于 $24\\unit{h}$。平太阳日就是 $24\\unit{h}$。一恒星日约比平太阳日短 $4\\unit{min}$。\n每天夜里的同一时刻，星的位置是往西移动的，或者说，每天都会提前升起，提前通过子午线，提前落下。这个提前的时间就是 $4\\unit{min}$。\n在黄道附近的星座，称为黄道星座。黄道星座被分为十二个，就是现在常说的星座。但现在十二个星座和十二宫已经不对应了，是岁差导致的。\n恒星年的定义：太阳相对背景星，从一处回到原处的间隔。也就是公转周期，但不是公历年，这是因为两次太阳相对天球在同一位置的时候，地球的自转相位可能是不同的。恒星年约为 $365.25636\\unit{d}$（太阳日）。\n回归年（太阳年）的定义：太阳两次通过春分点的间隔。由于自转轴进动的原因，约为 $365.2422\\unit d$，略短于恒星年 $20.5\\unit{min}$。这个差称为岁差。\n总结： $$ \\left\\{ \\begin{align*} 恒星日\u0026amp;=\\frac{2\\pi}{\\omega_自}\\\\ 太阳日\u0026amp;=\\frac{2\\pi}{\\omega_自-\\omega_公}\\\\ 恒星年\u0026amp;=\\frac{2\\pi}{\\omega_公}\\\\ 太阳日\u0026amp;=24\\unit h=1440\\unit{min}=86400\\unit s\\\\ 恒星年\u0026amp;\\approx 365.25636\\times 太阳日 \\end{align*} \\right. $$ 可以认为，除了最后一条，其他都是定义。\n我们一般的直觉，恒星日和太阳日之差，经过一年后地球刚好多转一个 $360^\\circ$，它的原理是： $$ (太阳日-恒星日)\\times\\frac{恒星年}{太阳日}=\\frac{2\\pi\\omega_公}{(\\omega_自-\\omega_公)\\omega_自}\\cdot\\frac{\\omega_自-\\omega_公}{\\omega_公}=\\frac{2\\pi}{\\omega_自}=恒星日 $$\n赤道坐标系 春秋分点：天球赤道与黄道的交点。春秋分是一个时刻，不是一天。\n赤经（RA, α）和赤纬（Dec, δ），就是地球的经纬线在天球上的投影。特殊地，赤经的 $0$ 不是格林尼治天文台，而是春分点。赤经的单位是时间，从春分点向东转一圈为 $24\\unit{h^\\prime}$（一恒星日）。赤纬还是一样 $-90^\\circ\\sim+90^\\circ$。\n赤纬相同时，赤经越小，越早升起。\n地方恒星时的定义：某地子午线对应的赤经。地方恒星时是不断在变的，变的速度略快于太阳时，每天增加约 $4\\unit{min^\\prime}$ 左右。\n实际上在某一天内，各个地方在同一个当地太阳时时的地方恒星时基本是一样的，其计算思路是：由于春分时，该地 $12$ 点时的地方恒星时接近为 $0\\unit{h^\\prime}$，因此该地 $x$ 日 $y$ 时的地方恒星时就是 $$ [(x-春分)\\times 4\\unit{min^\\prime}+y-12\\unit{h^\\prime}]\\bmod 24\\unit{h^\\prime} $$\n但是当地的时间并非绝对标准的太阳时，而是国家标准时间，因此还要算一下。例如北京的经度如果算作 $116^\\circ$ 的话，恒星时就要再减去 $4^\\circ\\times 24\\unit{h^\\prime}/360^\\circ$。\n我们再详细说一下这个 $4\\unit{min^\\prime}$。每个恒星日，恒星时比太阳时多走 $$ \\left(\\frac{太阳日}{恒星日}-1\\right)\\times24\\unit{h^\\prime}=\\frac{\\omega_公}{\\omega_自-\\omega_公}\\times24\\unit{h^\\prime}\\approx\\frac{24\\unit{h^\\prime}}{365.25636}\\approx 3.94\\unit{min^\\prime} $$ 恒星时角 $\\tau=$ 恒星时 $\\theta-{}$恒星赤经 $\\alpha$。$\\tau\u0026gt;0$ 时，恒星在子午线以西。\n岁差：太阳对地球引力的力矩，导致地球自转的同时进动。地轴会绕黄道平面法线（过地心）转。那么相应地，赤道平面也会转，春秋分点也会变（向西移动，提前到来，以 $\\sim 25800\\unit y$ 为周期），因此一年的时间略短于 $365.25\\unit{d}$，需要通过百年不闰解决。同时，赤道坐标系也会变，即星的坐标往东移（赤经增加）。因此每隔几十年要修正。\n拓展：\n科氏力 太阳的 8 字形轨迹 物理基础 历史 古希腊：亚里士多德提出地心说，托勒密完善（均轮、本轮）。\n中世纪：哥白尼提出日心说（反驳了一部分地心说，当时仍然支持天球事实存在，且由于精度不足，日心说的预测并不比地心说准确），第谷观测仪器+数据（介于地心日心之间），开普勒观测数据 + 三定律（完备日心说），伽利略开启近代天文学、物理学，用望远镜观察天体（彻底否定地心说，金星的盈亏，越亮越小），牛顿发现万有引力定律，第一台反射式光学望远镜。\n万有引力 高中物理。略。\n潮汐力 月球的公转轨道于黄道夹角为 $5^\\circ$ 左右，与黄赤夹角方向相反。\n地球在运动的时候，整个视作刚体，每个点的加速度相同。而地球由于相对于月球不能完全视作质点，各点受到月球的引力不同，故这里以地球为参考系，地球上的水的相同的惯性力与受到月球的不同的引力，导致了潮汐（https://www.zhihu.com/question/31294983/answer/72019418）。 $$ a_{潮汐}=\\frac{2GMr}{R^3} $$ 如果月球不公转，那么基本上就是每天两个潮汐周期。但是公转就会导致略微变长（$\\sim 25\\unit h$）。\n月球对地球的潮汐力导致了潮汐隆起，但是地球自转比月球公转快，这就导致隆起和地月连线不共线，这就对地球产生了与自转方向相反的力矩导致自转速度变慢，以及对月球产生了切向力导致月球公转变快从而做离心运动（https://www.zhihu.com/question/299894978/answer/3632821076）。太阳对地球也有潮汐力（是月球的），与月球共同导致大潮和小潮。地球对月球的潮汐力导致了潮汐锁定。\n双星系统要考。可以证明（https://farside.ph.utexas.edu/teaching/336k/Newton/node50.html），双星系统的两个星一定是绕着它们的公共质心做（成比例的）等价于单星的运动。\n两体近似：仅考虑太阳引力作用下的行星轨道的计算。其它质量对两体近似的偏离称为引力摄动。通过考虑太阳、木星土星之后仍然不对，根据引力摄动，可以预言别的行星的存在。\n相对论 牛顿万有引力定律的问题：水星的椭圆轨道也会进动。但是如果只靠万有引力，只能解释一部分（火神星），需要相对论才能完整解释。万有引力只能解释弱引力的情况，而水星离太阳太近了。\n相对论细节就不写了，一个提纲：\n狭义相对论的内容，时空观。\n速度接近光速时，长度变短，时间变慢，质量变大。 μ 子的例子 计算：洛伦兹变换、质能方程。 广义相对论的内容（主要多处理了非惯性等效引力相关）。\n光线在大质量天体周围的弯曲（太阳在日食时看、引力透镜），反而会变亮！\n靠近大质量天体时，长度变短（引力红移），时间变慢（相对论时间修正）。红移公式为（$\\gamma$ 根据逃逸速度计算）$1+z=\\gamma$。\n辐射 电磁辐射依然是了解宇宙的主要载体，有关宇宙信息的绝大多部分来源于天体发出或反射的电磁辐射。\n电磁波相关的知识：高中物理。\n黑体（普朗克）辐射谱：不同温度的黑体辐射的光谱。规律：\n温度上升，峰值波长减小，两者成反比。（从而能测星体的光谱得到其温度） 温度上升，（单位面积单位时间辐射出的）能量增加，能量与温度的四次方成正比。 流强 $F$：一个天体单位时间从其表面单位面积所辐射出的能量。注意这个定义和一般理解的光通量不同，它的国际单位是 $\\unit{J\\cdot s^{-1}\\cdot m^{-2}}$。可以类比的概念应该是光出射度。\n光度 $L$：一个天体单位时间的总辐射能量。类比发光强度。\n亮度 $B$：观测仪器单位面积单位时间所接收到的天体的辐射能量。类比照度。\n除此之外，还有距离、半径、温度等量。\n通过观测，我们可以得到波长峰值和亮度。 $$ \\left\\{\\begin{aligned} T\u0026amp;=\\frac{2.9\\times 10^6\\unit{nm\\cdot K}}{\\textcolor{green}{\\lambda_{\\text{peak}}}}\\\\ F\u0026amp;=\\sigma T^4\\\\ L\u0026amp;=4\\pi r^2F\\\\ \\textcolor{green}B\u0026amp;=\\frac{L}{4\\pi d^2} \\end{aligned}\\right. $$ 因此只靠分析光谱，只能得到 $r:d$。\n辐射相关的内容在 L9 还有。\n除了用 $\\rm\\mu m$ 等 $10^3$ 为一级的长度单位描述波长，还有一个单位 Å（埃斯特朗），是 $10^{-10}\\unit m$。\n当然，天体不能完全看作黑体，因为它表面的大气会吸收或发射特定频率的光子，形成光谱中的吸收线或发射线。根据这些线，可以推得其大气的化学成分及丰度。\n具体关于原子能级的概念：高中物理，略。氢原子的光谱记一下。\n问题：为什么吸收和发射不会抵消？回答，主要就是吸收再发射就是各个方向了，不是天体—观测者连线方向了。\n原子的电离：天文学里标记的方法是用罗马数字（例如 H II = H+）。\nH II 区 : 所有氢被近邻的炽热恒星的强烈紫外辐射（至少 $13.6\\unit{eV}$ 才能电离）所电离的区域，是大质量恒星正在形成的标志。气体云里面是等离子体。\n分子光谱：分子内的电子跃迁：可见光和紫外谱线；分子振动的变化：红外谱线；分子转动的变化：射电谱线。\n多普勒效应：靠近蓝移，远离红移。 $$ \\frac{\\Delta\\lambda}{\\lambda}=\\frac{v}{c} $$ 其中 $v$ 是视向速度（乘个 $\\cos$）。注意只有低速情况下适用。\n推导：观测到的波长定义为相邻两个波峰之间的距离。假设恒星以 $v$ 的速度远离观测者，那么相邻波峰中后一个比前一个多走 $\\frac\\lambda cv$ 的路程，于是 $\\Delta\\lambda=\\frac\\lambda cv$。\n可以通过对比标准的谱线系列（例如氢的巴尔末谱系）来确定恒星是在远离还是靠近。\n天文望远镜 伽利略发明望远镜（1609）。\n折射望远镜：很简单，就是利用凸透镜成实像，和实际情况是中心对称的。没法造大，因为色散问题会愈发严重（波长越短，折射率越大，高中物理）。加长焦距可以减小色差，复合透镜可以补偿色差。\n反射望远镜：利用凹面镜成实像，就没有色散问题了。但是成像位置很尴尬，所以一般再加个平面镜，在侧面（牛顿）或者底面（卡塞格林）开个小口观看。\n反射望远镜的球面像差：根据高中数学，把反射镜做成抛物面的形状，才能使光汇聚到一点，结果哈勃望远镜做成了球面，就要有宇航员上去装“眼镜”，于是就有了新概念二里那篇 Trouble with the Hubble。\n望远镜的主要功能不是放大，而是聚光和提高分辨率。同样长的曝光时间，同样大的像，口径越大，接受的光越多，最后光强越大。口径越大，不是看得越远，而是能看到的越暗。\n口径越大，角分辨率越小。具体来说，当某处发出的光通过透镜被汇聚到光屏上一点的过程中，会发生衍射，形成艾里斑。中央亮斑的角半径为 $\\sin\\theta=1.22\\lambda/D$，$D$ 为透镜直径，因此半径为 $f\\tan\\theta\\approx 1.22f\\lambda/D$。如果两个亮斑，一个的中心处于另一个的第一暗环以内，就认为分不清。从而定义角分辨率 $\\theta=1.22\\lambda/D$，单位为弧度。\n课本里的话，是忽略的这个 $1.22$ 倍，$\\theta=\\lambda/D\\unit{rad}=2.06\\times10^5\\lambda/D\\unit{arcsec}$。\n参考：https://zhuanlan.zhihu.com/p/548289357、https://www.telescope-optics.net/diffraction.htm、https://astronomy.stackexchange.com/questions/35894/how-does-diffraction-occur-in-a-reflecting-telescope\n大气极限：视宁度。\n星芒的原因\n胡克望远镜（1917），哈勃通过它发现宇宙膨胀，通过红移。\n还有 Hale、Keck、VLT、Gemini、ESO、LBT、Subaru 等。最新：E-ELT。\n为什么现在大型望远镜都是两个四个一组的？干涉仪（astronomical interferometer），分辨率可以达到相当于它们距离的大镜。\n光学望远镜：望远镜（镜筒+赤道仪）+ 终端设备。终端设备（光学探测器与仪器）：目镜、探测器（照相机，CCD/CMOS）、分光仪器（摄谱仪/分光仪）。\n受限于大气层（反射、吸收、扰动），在地面能看到的，只有可见光、射电、部分红外与毫米波。\n之所以射电望远镜口径都这么大（或者需要阵列），就是因为 $\\theta\\propto\\lambda/D$。大的：Arecibo、FAST。\n空间望远镜就可以看各波段了，但是造价太高。大的：哈勃、JWST、GMT、TMT。\nTHU：MUST。PKU：EAST。上交：JUST。国内最大的是 LAMOST。\n太阳系 行星可以认为是恒星形成的“副产品”。\n行星系是环绕一颗恒星（也可以是死亡后的恒星）的天体集合，包括行星、矮行星、小天体（卫星、小行星、彗星、流星体等）。恒星系不考虑行星，只是若干恒星，比如南门二（含比邻星）。\n行星的定义：质量够大足以使自己成为球体，轨道清晰无杂物。目前有发现“流浪”行星（没有围绕恒星）。\n矮行星的定义：不具有能清除轨道上其他天体的能力，别的和行星一样。\n太阳系里的矮行星：谷神星是小行星带中唯一的，别的（冥王星、阋神星（直接触发了冥王星的降级）之类的）都在‌柯伊伯带。\n彗星：来自柯伊伯带或奥尔特星云（更外围）。有彗星的轨道是扁椭圆（例如哈雷彗星），来自柯伊伯带，还有一些是双曲线（只能靠近太阳一次），来自奥尔特星云。\n太阳系的形成 太阳系形成的星云假说：康德 → 拉普拉斯（天体力学之父）\n太阳系的早期图景：原太阳（尚未开始燃烧氢）被一个自转着的，扁平的气体尘埃盘环绕。这个旋转的盘不仅为太阳的成长提供物质和能量（质量集中在盘中心，最后形成太阳），而这个盘中的少量剩余物质形成了太阳系的行星等其它天体。一个自转的星际云通过引力坍缩形成了太阳及太阳系。\n支持星云假说的证据：\n已观测到许多年轻恒星被气体尘埃盘（星周盘/原行星盘）环绕。这个盘本身是不可见的（发出的光不是可见光波段的），但是会散射恒星的光。另外还有喷流，垂直于盘面。我们目前看见的那些盘面的图片，都是比如毫米波段的望远镜的图像合成出来的。会发现盘是一个个圆环状，暗环就对应正在形成的行星。可以看 L1527 IRS。 所有行星轨道基本位于同一平面内 → 早期太阳系必定是扁平的。所有行星公转和自转方向，与太阳自转方向相同（有反例：金星、天王星，解释：随机大碰撞） → 形成行星的物质必定沿相同方向围绕太阳转动。 陨石是落到地球表面的年轻太阳系的遗留碎片。其结构清晰地表明，陨石（再大就发展成（小）行星）是由许多小块物质聚合而成的，被称为时间胶囊。 原行星盘是怎么形成的？关键是角动量。虽然太阳系的质量几乎全在太阳上，但角动量主要在行星（木星）上。\n恒星系一开始是个星际云。一个星际云绕银河系中心公转，由于不断被恒星爆炸推挤，或与其它星际云碰撞，使得星际云有一定的轻微自转。星际云非常延展巨大，具有巨大的角动量。星际云在自引力（需要有足够的质量和密度）的作用下开始坍缩变小。由于角动量守恒，其自转随着坍缩变小而越来越快。而引力坍缩具有方向性——考虑一块物质，在垂直于自转轴的方向，它确实受到引力，但一部分用于充当向心力了，因此坍缩得慢；而平行于自转轴的方向没有向心力，因此就坍缩得快，于是就形成一个盘状。由于坍缩更快， 与外区分离的内区形成原恒星与吸积盘。外区物质首先下落到具有转动的吸积盘，然后沿近似椭圆轨道靠近原恒星。吸积盘相当于一个“中转站”，它的半径是恒星的约几千倍，同时有很大的角动量，但其大部分物质成为恒星的材料的同时，角动量大的部分，通过射流被抛回星际空间，或是等剩下到足够稀了之后，和外区一起（也是角动量很大，不然就掉进来了），就成为行星的材料。\n一个可能要考的公式：角动量为 $$ L=\\frac{4\\pi mR^2}{5T} $$ 星体的成长：\n微粒之间的吸附，气体将小颗粒吹入大颗粒，合并。 大了（$100\\unit m$）之后，猛烈的碰撞会导致再碎成小的；如果不猛烈，可以继续增大。 再大（$1\\unit{km}$）称为星子，它的引力可以吸引周围的小物体，不断加快增长。最后变成原行星。这一过程中有大量的撞击，这在岩质行星上留下了陨石坑。 原行星盘内热外冷（原恒星的热辐射、下落气体的引力势能、粘滞（摩擦））。这导致各种物质在不同行星上的状态不同，所以太阳星外围的行星都是气态行星（太阳系的行星排列：内区，星子由岩石和金属组成；外区，主要由岩石、金属、水冰和冰态的挥发性有机物组成）。系外行星系的行星排列并非都是如此，可能发生了行星迁移（气体导致行星角动量损失，内移，热木星；天海王星是因为木星和土星的引力散射）。\n巨行星的成长：固态行星（核）一旦形成，它将继续吸积原行星盘中的气体而成长。 质量巨大的固态行星对聚集和维系氢和氦等轻元素气体具有明显的优势。强大的引力使得大质量的年轻固态行星在其周围形成“微型吸积盘”，物质（气体）通过吸积盘旋入固态行星。很多小行星就是这样被木星、土星捕获的。\n还有个假说是盘不稳定性，说的是原行星盘会碎开，每个对应一个巨行星。\n行星形成时从原行星盘中所获得的气体称为原始大气。巨行星能维持一开始捕获的气体，小质量行星不能。所以像地球、金星的大气层，都是次生大气，源自火山从行星内部喷出来的二氧化碳等气体，或彗星撞击。\n小行星和彗星核是存活到今天的星子，几乎保持太阳系刚形成时的状态。火星和木星之间的小行星带，是因为受到木星强大引力的搅动没能凝聚为一个行星。\n系外行星 2017 年人类首次在太阳系内发现系外天体 Oumuamua。\n行星很常见，但由于小而暗弱，且靠近明亮的恒星，所以探测很困难。\n发现的第一颗系外行星：1995 年，飞马座 51 b，视向速度法。目前已经确认的系外行星已有数千颗。\n系外行星是绕恒星公转的且质量小于 $13$ 倍木星质量的天体。褐矮星是大于 $13$ 倍木星质量，小于 $0.08$ 倍太阳质量，性质类似于木星。恒星是大于 $0.08$ 倍太阳质量，这样才能氢核聚变。\n发现行星的方法：\n视向速度法：观察恒星光谱吸收线的周期性的频移。就是认为行星和恒星形成一个双星系统。 凌星法：当行星运行到恒星前面时，会遮挡很小一部分恒星光，从而使得恒星周期性地变暗。可以用于计算行星大小。 微引力透镜法：当一颗恒星及其行星从远处背景恒星前经过时，引力透镜效应增强背景恒星的亮度，从而能够显示恒星及其行星的存在。可估算行星的质量，还能发现流浪行星。注意，可以区分恒星本身亮度变化与引力透镜造成的变化：引力透镜对各波段的影响（亮度变化比例）是一样的，自身变化（比如温度变化）显然是不同的。 直接成像法：在天文望远镜上加装星（日）冕仪，降低恒星亮度，直接拍摄行星。 天体测量法：直接观测恒星位置受行星影响的周期性变化。 以下是目前已知的系外行星的分布：\n关于凌星法，这里有一个问题，就是，为什么太阳看起来是圆盘上各处亮度相同的？这是因为太阳是朗伯辐射体，对于一个小面 $\\mathrm{d}a$，如果观察角度（观察点与其连线，和面的法向量的夹角）为 $\\theta$，则看到的发光强度就是 $I\\cos\\theta$。朗伯辐射体的特性是，“视亮度”（观察到的光通量与视大小之比）与观察角度无关，因为这个 $\\mathrm{d}a$ 从 $\\theta$ 角度来看，面积就只剩下 $\\mathrm{d}a\\cos\\theta$ 了，除一下刚好抵消。因此我们可以严格地说，凌星法中，理论上，太阳亮度的减少量就正比于遮住的面积。实际上的话太阳的远离更复杂些，还有周边昏暗效应，所以拍出来的图片还是周围暗。\n历史：\n1992 年：发现至少三颗围绕中子星转的系外行星。 1995 年：发现围绕主序星（飞马座 51）旋转的系外行星。方法：视向速度法。 2021 年：首颗被确定的河外行星，M51-ULS-1b。 后续发现方法：开普勒望远镜，发现首批地球大小的系外行星（凌星法，确定大小）；进一步证认：地面大口径望远镜（视向速度法，确定质量）。 科学家还是很关心类地行星。要有生命产生，需要有液态水的存在（在宜居带内），和地球大小差别不太大，围绕类似太阳的恒星转。也会考虑光谱与地球的类似。\n开普勒 452b：第一个地球 2.0（后来发现观测到的信号是假的？）\n比邻星：至少三颗行星，且都已被潮汐锁定，不太可能有生命。且红矮星耀斑爆发剧烈，容易杀死行星上的生命。\n太阳 相关数据自己看\n太阳为什么是稳定的？太阳的结构是向外压力（气体产生）与向内引力平衡的结果。在向外辐射能量的同时，核心进行的核聚变补充能量，形成平衡。压力、密度与温度向太阳中心增加。\n太阳通过热核聚变把质量转化为能量。（氢）核聚变需要足够高的温度与密度，克服电斥力，使强相互作用力将两个质子结合在一起，产生新原子核与其它粒子，释放能量。链式反应（PP 链）。四个氢原子聚变成一个氦原子。能量产生的根源。核聚变比化学燃烧的能量转换效率高很多。其他核聚变方式：碳氮氧循环。\n太阳的主序寿命约为 $10^{10}$ 年，目前已过了约一半。\n太阳中心产生的能量去向：\n中微子直接逃逸到宇宙空间 加热太阳内部 向外转移到太阳表面辐射出去 能量传输方式：主要是辐射与对流。\n层：核反应区 → 辐射区 → 对流区 → 太阳大气\n核反应区是等离子态，核聚变只在核反应区发生。\n光子在辐射区的传播比较困难，需要与电子碰撞很多次才能到对流区，这部分的气体更密了，就会把光子吸收，变热，往外飘，辐射出能量，再往内沉。对流的强弱取决于温度梯度与不透明度。气体的对流运动在光球层形成被称为日面米粒组织的斑驳图像。有点像味噌汤\n到大气之后，光子又能自由运动了，再过约 $8.3\\unit{min}$ 到地球。一个光子从产生到太阳表面，得经过数万年的时间，并且是由伽马射线变成了可见光左右（包括红外和紫外）波段的。\n可以通过观测中微子（不受太阳气体影响）来分析太阳内部核聚变的情况。中微子探测器都在地底下深处。建立的太阳物理模型，其他数据都与观测相符，但观测到的中微子数量（单位流量）只是预言的 $1/3$。解释是中微子有质量，存在中微子振荡，中微子在 $e$、$\\mu$、$\\tau$ 三类中转化，而观测只能观测到 $e$（电子中微子）。\n太阳表面不同的小区域同时发生很多不同频率的振荡。\n太阳大气从内到外分为光球层、色球层和日冕。\n太阳的密度和温度从内向外降低，但在色球层温度增高，在日冕温度突然增高，密度突然减小。\n我们看到的太阳是光球层。温度约 $5780\\unit K\\,(6600\\unit K\\to 4400\\unit K)$，厚 $500\\unit{km}$，相比别的层较薄（所以太阳边界清晰）。临边昏暗效应就是因为在边上只有浅的部分的光，量和温度都小。从光球层发出的光会被太阳大气吸收部分，可以通过分析太阳光谱得到太阳大气的成分。\n光球层之上的 $1500\\unit{km}$ 厚的区域称为色球层，温度 $4500\\unit K\\to6000\\unit K$。要观测必须把光球层的影响去掉，需要特殊的望远镜。它是深红色的，不是光滑的球状而是针状等离子喷泉。\n在色球层外部的约 $100\\unit{km}$ 的区域（过渡区），气体温度急剧上升，在此区域之上是太阳大气的最外层日冕，密度低，温度极高（百万 $\\unit K$），延伸至 ${\\sim}10$ 倍太阳半径。\n太阳活动：太阳黑子、日珥、太阳耀斑、拱形冕环。和磁场有关。由于太阳是等离子体，故变化的电场产生磁场，导致复杂的太阳磁场结构。另外，太阳存在较差自转（不同纬度，不同深度转动角速度都不同），以及对流，因此磁场被扭曲，产生这些“不稳定”的现象。\n太阳黑子温度也没那么低（可以用 $F\\propto T^4$ 算）。它的大小可以达到地球直径的数十倍。太阳光谱观测表明太阳黑子磁场很强（塞曼效应）。磁场垂直进出的地方出现黑子，这种地方和附近的等离子体无法对流，温度变低。太阳黑子经常成对出现，每对黑子皆有在太阳表面上方的拱形磁力线相连，体现为冕环。两个黑子磁场方向相反，南北半球黑子极性相反。黑子寿命 $\u0026lt;11$ 天。日珥也是磁场的体现。总之可以认为表面等离子体的纹理反映磁感线（\n太阳耀斑：最剧烈的太阳活动形式，一次喷发的磁能与日珥相当（但是耀斑时间短，日珥时间长），喷出速度极快。\n日珥和耀斑由磁重联造成。\n日珥和耀斑的日冕物质抛射到地球大气形成极光。日冕物质抛射一般都需要日珥和耀斑，但日珥和耀斑不一定有日冕物质抛射。喷射的东西包括磁能、高能射线、热等离子体。\n最有名：1859 年的卡林顿事件。\n太阳风相对温和，持续，它是由磁场指向外部的冕洞（几乎无高能辐射）造成的。\n黑子反映太阳活动强度，$11$ 年周期，两侧黑子越靠近赤道，强度越弱。黑子数最多的年称为太阳峰年。蝴蝶图。太阳磁极每一周期翻转。\n太阳系中的各行星 这部分是自学不考内容，主要就是讲各行星的地质特点，可以看 zzh 的博客。\n恒星 一些定量分析的方法 恒星是一个自引力束缚的气态球。氢的燃烧（核聚变）是恒星的主要阶段，称为主序阶段。\n恒星的视差 $p$（小学就学过啦）：在相隔半年时间内，恒星视位置变化的角大小的一半，或者应该说是恒星在天球上最两侧的角差（因为有的半年可能不对，必须是地日连线垂直于日星连线），小到角秒级。\n$1\\unit{arcsec}$ 对应的距离为 $1\\unit{parsec}$（秒差距），就是 $1\\unit{parsec}=d_{\\text{地日}}\\cdot\\cot(1\\unit{arcsec})\\approx 3.26\\unit{ly}$。\n因为 $\\cot$ 算起来麻烦，所以考虑近似。$p$ 和 $d$ 在数值上的关系： $$ d=d_{\\text{地日}}\\cdot\\cot p=d_{\\text{地日}}\\cdot\\cot(1\\unit{arcsec})\\cdot\\frac{\\cot p}{\\cot(1\\unit{arcsec})}\\approx 1\\unit{parsec}\\cdot\\frac{\\mathrm{arcsec}}{p} $$ 什么？你不知道为什么能这样 $\\approx$？ $$ \\frac{\\cot k\\theta}{\\cot\\theta}=\\frac{\\tan\\theta}{\\tan k\\theta}=\\frac{\\theta+\\Omicron(\\theta^3)}{k\\theta+\\Omicron(\\theta^3)}=\\frac{1+\\Omicron(\\theta^2)}{k+\\Omicron(\\theta^2)}\\sim\\frac1k $$ 简而言之，可以写成 $d=1/p$。\n视星等：体现视亮度。最初制定时分为 $1\\sim 6$ 等，$1$ 等最亮，$6$ 等最暗，$1$ 是 $6$ 的 $100$ 倍，也就是一等 $\\sqrt[5]{100}\\approx 2.512$ 倍。恒星视亮度用视星等表示，即以恒星视亮度的对数来表示。同一颗星，不同波段的视星等不同。\n实际上星等都是小数，还能是负的。如果 $0$ 等星的视亮度为 $b_0$，那么 $m$ 等星的视亮度为 $$ b=b_0{100}^{-m/5} $$ 也可以反推视星等 $$ m=-5\\log_{100}\\frac{b}{b_0}=-2.5\\log_{10}\\frac{b}{b_0} $$ 例如从地球上看太阳，$m\\approx-26.7$。\n不同观测仪器有不同的可观测最暗星等，比如眼睛是 $6$。\n低光度恒星数量比高光度恒星数量多得多，比太阳光度高的恒星只占总样本的 $20\\%$ 这样（而且暗恒星只会发现得越来越多）。\n绝对星等：体现光度，放在标准距离处的亮度。距离模数 $=$ 视星等 $-$ 绝对星等 体现距离。\n将星放在 $10\\unit{parsec}$ 处的视星等，就等于绝对星等。 $$ M=-2.5\\log_{10}\\frac{L}{4\\pi(10\\unit{parsec})^2b_0} $$ 距离模数通过光度和视亮度给出距离： $$ m-M=-2.5\\log_{10}\\frac{b\\cdot4\\pi(10\\unit{parsec})^2}{L}=-2.5\\log_{10}\\frac{\\frac{L}{4\\pi d^2}4\\pi(10\\unit{parsec})^2}{L}=5\\log_{10}\\frac{d}{10\\unit{parsec}} $$ 所以从数值上来说（$d$ 单位 $\\mathrm{parsec}$） $$ m-M=5\\log_{10}d-5 $$ 分析恒星的表面温度固然可以分析光谱，但更简单的方法是直接用两个窄波段滤光片，看这两个波段的亮度的比值得到温度。这两个波段的视（无所谓）星等之差，被称为色指数。定性地看，表面温度越高，色指数越小。色指数与温度没有简单的比例关系，只能用 Ballesteros\u0026rsquo; formula 近似。\n所以，要确定一颗星的半径，实操上可以用以下方法：\n通过周年视差 $p$ 确定距离 $d$。 测得视亮度 $B$，求得光度 $L=4\\pi d^2B$。 测得色指数 $B\\text{-}\\!V$ 确定温度 $T$。 $R^2=L/4\\pi\\sigma T^4$。 双星系统的推导等下学期普物一，这里就记两个公式：一个是，轨道半径（周长）与质量成反比，一个是开普勒第三定律 $$ T^2=\\frac{4\\pi^2A^3}{G(m_1+m_2)} $$ 实际应用时， $$ \\frac{m_1+m_2}{M_{\\odot}}=\\frac{A_{\\rm AU}^3}{T_{\\rm years}^2} $$ 根据发现的方法，双星分为四类：\n目视双星。离地球较近或两星距离较远，可以直接观测位置来分析。 分光双星。虽然无法直接区分两星，通过分析光谱可以发现两组多普勒效应偏移相反的谱线，就可以确定是双星。通过得到的视向速度（多普勒速度）曲线，可以得到周期、轨道半径等。考试题应该都会假设地球在其轨道平面上。如果速度关于时间轴对称（$\\max=-\\min$），那么就是圆轨道（但是我感觉椭圆轨道也可能这样啊……）。这种曲线图要会读，可能会考。 食双星。其关键是，当地球和两星共线时，视亮度会降低。降低程度取决于哪颗在前，因此有主食和次食。 天体测量双星。如果一颗星似乎绕着空的位置在转，就意味着可能存在另一颗没观测到的星。 光谱型：从热到冷 $\\rm OBAFGKM$，每个内部又有 $0\\sim 9$ 级。一开始是按照氢的谱线分类的。\n赫茨普龙—罗素图 赫—罗图：横坐标是温度，纵坐标是光度，都是对数坐标。由于 $$ \\log R=\\frac12\\log L-2\\log T+C $$ 因此在图上，等半径线是斜率为正的直线（$T$ 反过来了）\n有 $90\\%$ 的恒星（主序星）位于主序带上，它们就是处于氢燃烧阶段。它们处于主序带的哪里，取决于它们的质量。太阳是 $\\rm G2V$，$\\rm V$ 表示主序。\n这张图一个有用的东西是，原来测一个主序星的半径，需要先测距离，但是太远的话视差就太小了。现在只需分析光谱得到温度，就可以直接推得光度和半径，还能反推距离。当然这个关系的参数需要一些已知的近邻恒星样本。这个叫第一类标准烛光法，或分光视差法。\n质量也可以推：\n质光关系 $L\\propto M^{3.5}$，半径 $R\\propto M^{0.8}$。\n主序恒星只需要温度就可以确定了，非主序恒星仍需要光度，光度不好测，还是只能分析光谱。比如巨星大气压力小，故谱线宽度宽。\n主序恒星揭示恒星的属性及运行机制。 非主序恒星揭示恒星如何形成、演化及消亡。 实在太远的恒星，光太微弱了，观测得利用引力透镜。\n星际介质与恒星形成 恒星总是一批批形成，也就是星团。在星团里，$d$、化学成分基本都一样，所以研究时只需关心质量。\n星系内的恒星仅占据很小的空间。星系内的空间叫做星际空间（星系间的就是星系际空间），充满了星际介质，$\\sim90\\%$ 是氢，$\\sim10\\%$ 是氦，极少数是重元素，这些气体称为星际气体。星际介质非常稀薄，但相对整个宇宙的平均水平又高些。星际介质中 $\\sim1\\%$ 质量的物质是称为星际尘埃的固体颗粒，这些颗粒也很小，最多跟紫外线波长差不多。\n在致密、冷的环境中，尘埃会粘合在一起，还可吸附其它的原子和分子。\n星际尘埃会导致尘埃效果/星际消光（散射 + 吸收），影响观测。在可见光波段附近，波长越长，消光效果越弱（船喻）。所以，看到的星光偏暗、偏红——星际红化。所以需要修正。\n既然星际尘埃也会吸收光，所以它也有黑体辐射，反正就是温度比较低，主要在红外波段。\n大约一半的星际介质集中在 $\\sim2\\%$ 的星际空间中，这些相对致密的区域称为星际云，其余的被称作云际气体。越热的星际气体越少。炽热的云际气体主要是被近邻的超新星爆炸加热产生。\n氢：\nH II。星际云，恒星形成。 H-α。云际气体产生的最强的可见光谱线。 中性氢，产生 $21$ 厘米辐射，不受尘埃影响，有利于研究银河系的结构。 H II 区是被大质量、炽热、极亮的 $\\rm O$ 型和 $\\rm B$ 型恒星的强烈紫外辐射所电离的相对致密的星际云。在星际云最致密的核心区，分子可以存活。这些暗云被称为分子云，是恒星形成的场所。这些地方温度反而是低的，才能使分子稳定。说密，它密度也超不过我们抽的真空中剩余的分子密度。分子发射线（射电、红外）是分子（云）的指纹。分子云仅占银河系星际空间的 $\\sim0.1\\%$。最大的分子云称为巨分子云。\n分子云里除了 H，还有 CO 和少量有机物。\n可见光波段的暗斑的轮廓体现了分子云的轮廓（全被致密的尘埃吸收了），从红外波段看就可以透过看。分子的射电辐射不受星际尘埃的影响，是研究最致密最不透明的分子云的核心的窗口。\n分子云的自引力比向外的压力小很多，但因为周围有更热的云际气体，所以就使它维持着不扩散。如果分子云质量足够大、足够致密、足够冷，其自引力就会相对于压力更显著，才会发生引力坍缩。一旦开始坍缩，就会越来越快。坍缩是不均匀的，所以分子云会裂变成多个分子云核（因此会有很多星团，一堆在一起的恒星）。分子云核中心坍缩比外层坍缩快，中心与外层分离，然后后面就是和太阳类似的故事，原恒星，吸积盘……\n把原恒星和其最终形成的恒星比较。原恒星比恒星大很多、亮很多，但表面温度低（辐射红外），还在为氢聚变积累温度。坍缩是缺乏能量的体现。这个时候中心其实是有聚变的（氘（产生于大爆炸，只消耗不产生）和氕聚变成氦 3，但温度还是小于氢聚变所需的温度 $\\sim10^7\\unit K$），中心核发生对流，暂时阻止气体下落。等氘耗尽后，继续加速下落。等到足够小，密度足够大，温度足够高时，氢聚变开始，不再坍缩，结构稳定后，进入主序阶段。\n褐矮星是质量过小使温度不足以使核聚变发生的情况，情况介于木星和太阳之间。就一直发射红外波段的光。温度从高到低分为 $\\rm LTY$ 型（接在光谱型那个后面）。\n小质量原恒星收缩时，内部变热，但其表面温度基本维持不变（负氢离子理论），于是光度下降。我们可以在赫—罗图上画出原恒星变成恒星时物理量的变化，称为演化程。\n林忠四郎线特指原恒星到主序恒星的这一族演化程。\n原恒星的喷流（还有星风、外向流）驱散分子云核与吸积盘，终止物质流入原恒星。原恒星的喷流是最菜的。喷流撞击到星际介质，加热星际气体（弓形激波）产生发光的气体结，称为 HH 天体。创生之柱的红外波段照片中的柱子里的红色点点就是这个东西。\n太阳形成需时大约三千万年。\n在主序阶段缓慢燃烧的过程中，恒星在赫罗图上向左上移动，光度增加，表面温度降低（为什么我查到有些说温度也升高？），半径变大。\n质量越大，恒星的主序寿命越短（原恒星的寿命也最短）。具体的定量关系没法给出。对于与太阳性质相似的恒星： $$ \\tau_{\\text{MS}}=10^{10}\\unit{y}\\cdot\\frac{M/M_\\odot}{L/L_\\odot} $$ 根据质光关系， $$ \\tau_{\\text{MS}}\\propto M^{-2.5} $$ 氦与氢的比，离中心越近越大，主序阶段燃烧越后越大。当核心的氢越来越少，核心压力就减小（氦目前可不会燃烧（聚变），它需要高得多的温度），开始坍缩，这会导致中心燃烧效率增加，压力增加，外部就膨胀了。核心的氢尚未耗尽时，这一过程是缓慢的（基本稳定），等到完全耗尽了变成红巨星的过程就快了。所以现在整个的情况就是，核心收缩，外部扩张。十亿年后，地球已不宜居。\n来源\r主序阶段之后——小质量恒星 当核反应区的中心一块很小的区域的氢彻底烧完后，这部分再坍缩也没法促进燃烧了。所以氦核会不断坍缩，坍缩至电子简并状态（？？都说了是氦核，为啥会有电子？），会提供电子简并压力抵抗引力。所以现在分成三个区域——简并态的氦、氢壳层（也属于核反应区，还在燃烧）、氢包层。既然氦坍缩了，氢壳层就会缩小，引力增加，燃烧加快。所以还是接着，光度增加、温度降低、半径变大。氦核质量增加和氢壳层燃烧加快互相促进，是一个滚雪球的过程。\n恒星脱离主序后的第一个阶段称为亚巨星，表面温度下降。当温度下降一些后，又由于负氢离子理论，温度又开始维持，但继续变大变亮，这个是红巨星阶段。\n虽然表面温度变低再不变，但氦核区的温度是持续升高的。当温度到一亿 $\\mathrm{K}$ 左右时，开始氦核聚变，也称为 3α 过程（He→Be→C）。简并物质是很好的热导体，一旦氦核的中心开始燃烧，整个氦核一下子就被“点燃”了。但是由于热压相比电子简并压力可以忽略不计，故氦核几乎不膨胀。于是温度升高与燃烧互相促进，所以说简并氦核的燃烧是失控的，称为氦闪。当然最后热压会大到超过电子简并压力，起主导作用，导致氦核内爆，膨胀冷却，电子简并很快被解除。氦闪从外面是看不出的。氦闪这个过程时间很短，只有几小时。氦闪后，氦核和氢壳层的引力减弱，压力减小，导致核反应率明显降低，表面明显变暗，但是实际上温度升高（我也不知道为啥），称为水平支恒星。\n这个状态又会稳定一段时间，同时进行氢和氦的燃烧，但相对主序阶段短很多。离开水平支阶段，也就是碳核开始坍缩至电子简并态，进入渐近巨星支阶段，再次变大变亮但变暗，同样可能发生碳闪。太阳由于质量不够，无法达到碳核聚变的温度。\n随着恒星膨胀得越来越大，导致其外层的逃逸速度越来越小，外层物质越来越容易逃逸到星际空间。于是恒星就慢慢只剩下了碳核、氦燃烧壳层、氢燃烧壳层了，光度依然很高，温度开始越来越高，这个阶段称为后渐近巨星。现在的温度足以辐射紫外波段的光，它会加热并电离被抛射出的气体，使气体电离发光，形成行星状星云（和行星半毛钱关系都没有）。最后燃烧完了，碳核就变成白矮星了，质量约为原来恒星的 $\\sim70\\%$。当然球表面还是有氦的，碳会和氦聚变形成氧，太阳未来会变成碳—氧白矮星，碳核收缩为大小在地球这样，压力与引力平衡，不再变小，只是还在往外辐射能量。最后没东西辐射了就变成黑矮星。\n如果太阳质量损失量比较大，地球的轨道就会外移，继续围绕那时的太阳公转；否则地球会因与气体的摩擦降低速度，坠入太阳中心，这会使太阳短暂地变大变亮。\n主序阶段之后——大质量恒星 大质量恒星的主序阶段氢燃烧以碳氮氧循环为主。\n即便在主序阶段，高辐射压导致大质量恒星猛烈地抛射其外层物质，产生高速星风，显著影响恒星的演化。\n由于质量大，温度在氦、碳进入电子简并状态前就已经达到对应的核聚变温度了，因此不发生简并，核燃烧由一种元素平稳过渡到另一种元素。元素越重，燃烧的持续时间越短。大质量恒星在脱离主序带之后被称为红超巨星。\n许多红超巨星都是变星。恒星在赫罗图上形成不稳定带，周期性交替膨胀与收缩，引起其光度和颜色（表面温度）相应改变，这样的变星称为脉动变星。这种周期性变化的原因很复杂，主要是跟氦的电离与复合有关。详见 https://www.zhihu.com/question/61799031/answer/3481304995。在变动的过程中，是小热亮↔大冷暗。脉冲变星有很多类，代表性的有 I 型造父变星（黄超巨星）、II 型造父变星（小、水平支）、天琴 RR 型变星（小、水平支）。每一类都有一个周光关系（都是光度与周期正相关）。也就是说，只要观测出周期，就可以得到光度，从而这个变星可以作为标准烛光。\n铁核永远不会燃烧，这是因为铁原子的结合能最大。铁聚变要吸收能量，这是做不到的。铁核会坍缩，也会进入电子简并态。但电子简并压力也抗衡不了引力，还会继续坍缩。坍缩的能量会被消耗掉，加速坍缩。当铁核内部坍缩到原子核与原子核之间紧挨在一起时，坍缩终止，外部仍然在坍缩，就会撞击在内核上反弹。中微子会造成一个气泡，和反弹共同，形成向外的激波。这个激波就造成超新星爆炸。爆炸产生膨胀的尘埃气体云，核以中子星（中子简并压维持）的形式遗留，如果质量再大，连中子简并压力都不足以对抗引力，就会变成黑洞。\n以这种原理产生的超新星爆炸根据恒星质量从小到大分为 II 型、Ib 型、Ic 型，这个是根据观测到的光谱分的，而光谱取决于外层的氢和氦是否已经被剥离。II 型有 H，Ib 型有 He，Ic 型没 He。\n致密星 白矮星：由 $\u0026lt;8\\sim 9M_\\odot$ 的恒星演化而来（例如太阳最后会变成 $\\sim 0.5M_\\odot$ 的白矮星），半径跟地球差不多，因此密度很高，自转周期也很短。在同一温度下，白矮星的质量越小，半径越大，光度越高。具体来说，$R\\propto M^{-1/3}$。同一白矮星半径不会显著变化。球状星团中的白矮星多。\n中子星：超过钱德拉塞卡极限后，不断坍缩，电子速度会接近光速，质子和电子结合“逆衰变”为中子。原子核瓦解，整个星体变为中子海洋，中子简并压力抗衡引力。半径只有几十公里，密度比白矮星大很多，表面温度在刚形成时很高（但会很快耗散）。自转周期是毫秒级。根据广义相对论，中子星上的时间比地球慢（中子星表面已经有很明显的相对论效应了）。同样，中子星质量越大，半径越小，它的质量极限称为奥本海默极限，不确定，$\\sim 3M_\\odot$。\n中子星的类别：\n脉冲星（注意与脉冲变星区分！）。一些中子星会在磁轴发射电磁波，而磁轴与自转轴不共线，所以如果从地球能观测到，那周期就是中子星的自转周期。脉冲周期很稳定。 磁陀星。就是磁场很强的中子星。快速射电暴可能来源于它。 一般的中子星。 夸克星。质量较大的中子星，核心处夸克都变成自由的了。是一种假说的中子星。 虽说中子星在形成时表面温度很高，但半径太小了，没法借助黑体辐射观测。发现中子星的方式是观察周期性变化的电磁波，也就是“脉冲”。\n黑洞：由质量 $\u0026gt;\\sim 20M_\\odot$ 的恒星演化而来。任何力都不足以抵抗引力，另一个表述是，表面的逃逸速度超过光速，即 $\\sqrt{2GM/R}\u0026gt;c$。这个式子如果以 $R$ 作为未知数，得到 $R=2GM/c^2$ 称为引力半径或史瓦西半径。黑洞只有质量、角动量和电荷三个量，这称为黑洞无（三）毛定理。黑洞的平均密度 $$ \\rho=\\frac{M}{\\frac43\\pi R^3}=\\frac{M}{\\frac43\\pi\\frac{8G^3M^3}{c^6}}=\\frac{3c^6}{32\\pi G^3M^2} $$ 这个结果和白矮星、中子星的“质量越大半径越小”是反的，因为黑洞没法再坍缩了。当然实际上黑洞的所有质量集中在奇点。\n黑洞分为史瓦西黑洞（不旋转，不带电）、R–N 黑洞（不旋转，带电）、克尔黑洞（旋转，不带电）、克尔—纽曼黑洞（旋转，带电）。\n黑洞附近的光会被弯曲。黑洞的视界是指光能否逃逸的分界。对于史瓦西黑洞，引力半径等于视界半径；克尔黑洞有外视界和静界两个界，两者之间是能层，在能层不能保持静止，但可以逃离黑洞。黑洞的视界是单向的，在内部的事件无法对外部产生影响，在内部的时间对外部来说是静止的，视界处引力红移无限大，在内部的东西无法到外部来（尽管逃逸速度是指中途不加速的最大初速度，但即使在视界内向外走有燃料也是走不出来的，具体原因要用广相解释，科普文章）。黑洞的潮汐力会将进入它的物体撕碎。质量越大，视界处潮汐力越小。\n克尔黑洞看起来很有意思。\n如果太阳系的某个天体突然变成黑洞，它只会对附近的物质产生影响，质量不变，可以认为它是等效于原来的天体的。\n致密星的演化 如果是单个孤立的致密星，白矮星和中子星会逐渐冷却（需要极长时间，$138$ 亿年内还不足以使白矮星或中子星冷却到较低温度，目前已知白矮星最低 $3000\\unit{K}$ 不到，中子星最低 $42000\\unit{K}$ 不到），白矮星最终变为黑矮星。它们的简并态都会维持。\n黑洞会有霍金辐射，具体原理我也不知道。辐射与质量成反比： $$ T=\\frac{hc^3}{8\\pi GkM} $$ 因此黑洞会慢慢蒸发，寿命与质量平方成正比。\n双星系统的情况就很不一样，最后都会并合。两个白矮星、中子星、黑洞并合的时候都会释放引力波。\n小质量双星的演化：洛希瓣是一个恒星引力影响范围的边界。双星中质量较大的，先离开主序阶段，在膨胀超过洛希瓣后，其物质会被另一个星吸收，使另一颗星演化加快。前者最终变成白矮星，另一颗星随后膨胀，就反过来吸。这一吸的过程主要是氢下落到白矮星（仍有角动量）的吸积盘，同时引力势能转化为热能（数十万 $\\text{K}$），发出以紫外波段为主的辐射，这个叫激变变星。在吸积的过程中，氢一直在白矮星的表面堆积，实际上因为白矮星是简并态，所以它反而会收缩，所以温度越来越高。当温度足以使氢核聚变时，会突然爆发，造成新星。多次新星称为再发新星。新星现象不会摧毁白矮星，反而会使白矮星质量增加。当白矮星的质量接近 $1.4M_\\odot$ 时才会摧毁，这个称为 Ia 型超新星爆炸。\n钱德拉塞卡极限：当白矮星质量增加时，电子简并压力增加（受相对论效应影响，$\\propto M^{4/3}$）比引力增加（$\\propto M^2$）慢。超过这个极限，无论怎样坍缩，电子简并压力都无法克服引力。\n关于 Ia 型超新星爆炸的细节：其本质是在接近钱德拉塞卡极限时，温度升高足以使碳核聚变，然后发生失控核聚变，整个炸掉。实际上这个质量会在 $1.38M_\\odot$（不同类型的白矮星略有不同）。不可能出现达到钱德拉塞卡极限然后温和地坍缩成中子星。Ia 型超新星爆炸不会留下任何核心，只剩下超新星遗迹。中子星和黑洞只能通过其他几种超新星爆炸产生。\n如果吸积不足以使这颗白矮星爆炸，就会剩下白矮星双星。它们互相公转会辐射（可观量的）引力波，角动量减小，最后会合并，同样产生 Ia 型爆炸（如果和小于 $1.4M_\\odot$ 就合并成一颗白矮星）。\n由于 Ia 型爆炸的光度一般都比较固定，所以也能当标准烛光。\n宇宙中的铁主要来自 Ia 型爆炸。\n超新星的命名是 SN + 年份 + 字母编号（同 Excel 列）。\n超新星爆炸的主要能量释放途径是中微子。\n超新星爆发所抛出的大量物质在向外运动膨胀过程中与星际物质和磁场相互作用而形成的气体星云，形成超新星遗迹（注意与行星状星云区分），是包括 X 射线在内的高能辐射源，这就是宇宙射线的起源。\n许多中子星也都不是孤立的。中子星双星通过脉冲周期的周期性变化发现，同样双星也会释放引力波，逐渐靠近，最后合并，一般都会成为黑洞。\n黑洞有两类，X 射线双星系统中的恒星级质量黑洞和星系中心的超大质量黑洞。\n中子星和黑洞的转轴方向都有喷流，是由弯曲的磁场导致的。这个喷流叫相对论喷流，因为速度很快。不同级别的黑洞喷流的长度级别也不一样。\n寻找恒星级黑洞，一般是寻找 X 射线双星。X 射线是怎么产生的呢？伴星的物质被黑洞吸积时，引力势能转化为内能，可以达到百万 $\\text{K}$，发出的黑体辐射是 X 射线波段的。辐射的功率为 $$ L=\\frac{GM\\dot M}{r}=\\eta\\dot Mc^2,\\,\\eta=\\frac{GM}{rc^2} $$ 其实很简单，就是引力势能的表达式（从伴星吸积的那个 $1/R$ 忽略），$M$ 表示黑洞的质量，$\\dot{M}$ 表示吸积的质量效率，$r$ 表示吸积盘到中心的距离。化成后面这个式子就是为了长得像质能方程。$\\eta$ 称为能量转换效率。代入史瓦西半径，黑洞的 $\\eta\u0026lt;50\\%$。\n黑洞的发出的 X 射线是快速变化的（没仔细讲，我猜就是一下子吸了一堆？），因此如果观测到 X 射线峰，可以通过其时长推得黑洞的半径上限（近地球的一侧和垂直侧的距离（远地球一侧会被遮住），就是时长乘光速）。同时通过分析视向速度曲线可以得到质量。那么这样就可以确定是否是黑洞及其属性。典型例子：天鹅座 X-1。\n黑洞是宇宙中最亮的。\n伽马射线暴：短时间观测到大量伽马射线。产生机制是大质量恒星坍缩为中子星或黑洞（长爆），或者中子星与中子星、中子星与黑洞合并（短爆）。双黑洞合并不产生。喷流的物质与喷流的物质相撞产生的内部激波是伽马射线，而喷流的物质与星际物质相撞产生的外部激波，和超新星遗迹一样，产生的是 X 射线及以下的辐射。\n如果较近的伽马射线暴的喷流指向地球，会有相对论聚束效应，对地球产生较大影响。\n伽马射线暴和引力波的同时被观测验证了合并现象。\n星团与星系 疏散星团年轻，球状星团年老，原因可以简单理解为，疏散星团引力不强，容易散开。如何得到一个星团的寿命？看这个星团的赫罗图上恰好进入或离开主序带的星，根据寿命与光度的关系推。\n银河系 银河系的结构 因为太阳系处在银河系之中，所以银河系本身的结构难以以可见光观测得到（有星际消光）。漩涡结构是通过中性氢 21 厘米射电辐射观测到的，棒旋星系结构是通过红外波段观测。\n这是银河系的结构，主要有几个部分：\n银心 \u0026amp; 核球。银心有个超大质量黑洞，核球处恒星密度很高。 银盘。俯视来看，银盘分为数条旋臂，最大的四条为英仙臂、人马臂、猎户臂、天鹅臂。平视来看，有薄盘和厚盘。薄盘的恒星密度更高。 银晕。从内到外分为内晕、外晕和热气体云。 星团。疏散星团主要分布在银盘内，球状星团主要分布在银晕内，数量较少。 银河系中还有大量暗物质。通过观测中性氢的射电的多普勒效应，分析距离银河系中心不同距离处的公转速率（自转曲线），可以得到质量分布。如果只考虑中心天体作为引力源，应该有 $v\\propto r^{-1/2}$。但是银河系不太靠中心的部分速度并不随着距离增加而减小，而是速度曲线相对平直，这个称为“较差自转”（我们上面在太阳中物质的转动中也提到过这个概念），我们可以据此预测质量分布。但预测的质量分布与实际的亮物质的分布不符，所以科学家预言暗物质的存在。暗物质主要分布于太阳轨道以外的区域，主导着银河系的总质量，其范围远超亮物质的范围。 但是如果只考虑较差自转，按说旋臂会消失。解释旋臂图案稳定的理论是密度波理论。旋臂并不是大量物质驻留的地方，而是物质密度高的地方（物质一直在移动，类比车流）。旋臂是少量的年轻的大质量、高光度、炽热恒星聚集的表现。 银河系中心有个大质量黑洞，且恒星聚集。通过高分辨率望远镜观测银心附近的恒星轨道，可以推算黑洞的质量。也偶有观测到中心的黑洞的 X 射线暴——潮汐瓦解事件。偶有，说明黑洞不太活跃。发现的银河系伽马射线泡说明以前黑洞是活跃的。 银河系中的恒星 这里提一下星族的定义：I 是含金属丰富的恒星（如太阳），II 是金属很少的恒星（如第二代恒星），III 是不含金属的恒星（第一代恒星）。\n银河系中的恒星分为：\n盘族恒星（I），在银盘面中环绕银心转动，比如太阳。相对年轻。 晕族恒星（II），轨道面方向任意。相对年老。一些晕族恒星的轨道穿越太阳附近的银盘。 棒族恒星（II）。 上面我们提到了，大爆炸只产生了氢、氦、锂，而重元素是通过红巨星、红超巨星、超新星爆炸、中子星合并产生的。所以我们说，重元素丰度随星际介质和恒星间的循环而增加，一颗恒星中重元素的丰度和其诞生时间是正相关的。于是可以通过分析恒星的光谱知道它的年龄。科学家希望找到含重元素很少很少（甚至没有）的恒星，就是宇宙早期形成的恒星。\n银河系的恒星的年龄分布：\n银晕和核球外层的恒星年老。银晕和核球外层气体含量较少，这些地方恒星形成早已停止。尽管年老，但仍有较少的重元素，并非第一代恒星。 银盘和核球内层的恒星相对年轻。核球内层气体密度很高，性质与银盘类似，恒星还在一代代持续形成。从银盘内区到外区，气体密度逐渐降低，恒星形成率逐渐降低，重元素丰度逐渐降低。 形成银盘及其恒星的气体，之前已经历显著的恒星形成。 本星系群 本星系群中主要的星系有：仙女座星系 M31（质量最大，旋涡）、银河系、三角座星系 M33、大小麦哲伦星云（矮星系，其中恒星正在形成）、还有一堆其他的矮星系环绕着主要的星系（像卫星一样，也成为伴星系）。推测：一个巨大的暗物质团块中的气体坍缩成许多原星系。一些原星系并合成为银河系和仙女星系，其他就是矮星系。\n通过比较不同距离（不同年龄）星系的大小、形态、黑洞质量，可以推测星系的并合历史。通过年老恒星可以推测，在并合成银河系之前，已经有恒星形成了。\n银河系未来会与人马座矮星系发生次并合（不影响银河系结构），在之后会和仙女星系主并合（使得并合后变成巨椭圆星系）。\n星系 星系是由引力束缚的，尘埃、气体、大量恒星组成的集合体。伽利略发现银河由众多恒星组成。以前由于观测能力限制，星系、星团、星云被统一认为成是星云，后来才区分。\n梅西叶天体列表（1784）是 110 个经典的天体，包括两类星团、三类星云、星系。其中的天体命名就是 M + 序号，几个经典的要记的有：M1 蟹状星云、M31、M33、M42 猎户座大星云、M45 昴星团（它是疏散星团）。说到这里要巩固一下三类星云的定义区分：弥漫星云就是正常的星际尘埃与气体，就是相对密些罢了，主要成分是氢，可能未来会形成或正在形成恒星，能观测到它们是因为被附近（或其中）的恒星照亮。恒星状星云和超新星遗迹上面有提。\n希望有一天也能自己拍这个列表。\n后面：星云和星团总表（CN，1786）→ 星云和星团总表（GC，1864）→ 星云和星团新总表（NGC，1888）。所以后来就用 NGC + 序号了。\n星系的哈勃分类 按照星系在可见光波段的形态分，没有星系演化的意义。\n椭圆星系。看起来就是个放射渐变的椭圆形。按照扁率分为 E0~E7 共八类。具体来说， $$ E=10\\left(1-\\frac ab\\right) $$ 其中 $a$ 是短轴长，$b$ 是长轴长，所以说越扁 $E$ 越大。椭球照理说有三个参数，但关于星系的转轴应该是旋转对称的，所以就只有两个。\n也有一种分类是分巨椭圆星系和矮椭圆星系。\n椭圆星系中的恒星多是年老的小质量恒星，且其不再产生恒星。颜色一般偏红。正常来说不会有尘埃带。\n旋涡星系。中间一个核球，周围一个星系盘上有旋臂。分为 Sa、Sb、Sc 三类，按顺序核球变小，旋臂变松、展开。\n棒旋星系。中间恒星聚集成棒状结构，穿过中心，延伸到星系盘。分为 SBa、SBb、SBc 三类，类似。\n这两类星系有星系晕，主要包含年老的小质量恒星。星系盘上的恒星相对较年轻。星系盘上会有尘埃带（遮光）。核球和星系盘偏红，星系盘偏蓝。\n透镜状星系分为 S0 和 SB0，可以理解为没有旋臂的旋涡/棒旋星系。是介于这两者与椭圆星系之间的一类。\n不规则星系。无核球，无旋臂，无对称性，记作 Irr（也可以细分 Irr I、Irr II、dIrr），其中多年轻恒星且正在形成恒星。形成原因是被附近星系的引力扭曲。\n几乎所有星系中心都有超大质量黑洞。（部分矮星系没有，例如麦哲伦）\n恒星的运动决定星系形态，在椭圆星系以及旋涡/棒旋星系的核球中，恒星的运动方向随机，可能某个平面方向上速度较大些，整个看起来就是扁的。\n银河系是 SBb/SBc，M31 是 SBb，M33 是 Sc，大小麦哲伦是 Irr。\n星系中的暗物质 暗物质占星系总质量的 $\\sim90\\%$，范围也比亮物质大，称为暗物质晕。\n旋涡星系的自转速度曲线需要暗物质，椭圆星系的热气体的存在需要暗物质（椭圆星系没法用测量转速来分析，因为其中的恒星轨道不在同一平面上。椭圆星系外围弥散着 X 射线，说明有温度很高的气体，从而知道这些气体的速率很大（why？热运动和正常运动应该是分开的呀），从而推得转速曲线，说明有额外的引力，也就是由暗物质产生）。\n关于暗物质是什么，最主流的观点是 WIMPs。微引力透镜的观测否定了暗物质是 MACHOs 的说法。\n活动星系核 二十世纪天文四大发现：类星体、脉冲星、宇宙微波背景辐射和星际有机分子。\n类星体：非常远的（所以是在宇宙年轻时的），致密的亮射电源，从可见光波段来看，没法放到赫罗图上（因为光度太高了），而且光谱上都是发射线（一般的恒星射电辐射是很弱的，且恒星都是吸收线）通过哈勃红移可以得出（极远的）距离，得到光度极高。观测得到类星体有喷流。那么实际上类星体是星系的剧烈活动的核心——它是活动星系核的一种。\n具有剧烈活动现象的星系称为活动星系，核心不活动的星系称为正常星系或宁静星系，比如银河系。活动星系的分类：\n星爆星系，剧烈恒星形成。通常是两个星系合并时出现。 活动星系核（AGN），就是中心的大质量黑洞在不断吸物质。活动星系核有高光度、光谱有发射线、快速光变、辐射波段广、高偏振等特点。具体来说，根据辐射在各波段的特征，它具体又分为： 类星体。细分为射电噪的和射电宁静的。类星体和其他情况的一个不同点是，它必须要距离很远，或者说红移很大。 赛弗特星系。注意这个并不是某个特定星系的名称！这个是射电宁静的一类，处于旋涡星系或不规则星系的中心。 射电星系。处于椭圆星系中。有明显的射电瓣。 耀变体。能量很高，光度很大，射电噪的。 更加精确地分析活动星系核，我们从光度和结构来说：\nAGN 的能量来自太阳系大小的区域。这里有个考点是根据光变时标算尺寸：假设黑洞吸积了一堆物质，吸积盘突然发光，那么如果地球在盘所在平面，那么从地球观测到的辐射峰的时长，就是吸积盘的宽度除以光速。当然这个算出的只是一个很松的上限。\n同时 AGN 有非常长直的相对论性喷流，可以达到数千万光年。\n在这么一个小区域内能产生千亿倍太阳光度的辐射，它的辐射压就很大，一定有很大的自引力，也就是很大的质量，才能维持它的稳定。爱丁顿光度 $L_{\\text{edd}}\\propto M$ 表示对应质量的恒星的最大光度（同时可以推出不存在质量大于约 $100$ 倍太阳质量的恒星）。那么根据测得的数据，可以确定黑洞的质量下限。\n对于不活跃的黑洞，它吸积的效率是很低的。根据光度和能量转换率可以算出，比如说 M87 中心黑洞一年大概吸积半个木星质量。\n从结构上来说，活动星系核可以分为几部分：黑洞、吸积盘、喷流、宽线区、窄线区、尘埃环。宽窄线的意思就是观测到的光谱的发射线宽度不同，这个是因为产生发射线的被电离气体的速度范围不同，靠近中心而速度大的，因为多普勒效应就会使发射线展宽。\n目前公认的说法是，不同种类的 AGN 是与观测夹角不同的，但同样性质的活跃黑洞。因为 AGN 的结构这么复杂，从不同角度看，可能会因为尘埃、和喷流的夹角、相对论效应等，得到很不同的观测结果：\n早期（遥远）星系中，AGN 比例要高很多。\n蟹状星云可以作为标准烛光。\n事件视界望远镜（EHT）拍到了 M87 中心的和人马座 A（银河系中心）黑洞，当一个星系确认黑洞后，其代号后面就会加上星号。\n黑洞的质量测量方法就是观测中心附近的气体、恒星等的运动。\n宇宙 宇宙的膨胀 历史：弗里德曼建立宇宙的数学模型，斯莱弗发现宇宙学红移，勒梅特提出大爆炸假说，哈勃发现退行速度与距离成正比。\n宇宙不存在边界，可以类比吹气球的过程。\n宇宙学原理：宇宙是处处一样的，物理定律处处使用。在大尺度上，宇宙是均匀的，各向同性的。宇宙任何地方的“观测者”都应看到相同的宇宙。这个可以通过观测验证——一方面是各个方向的恒星密度均匀，一个就是几乎所有星系都在远离我们。\n接下来我们说的都是不考虑相对论效应的情况，因此不能处理速度太大，距离太远的情况。\n那么既然宇宙是各向同性的，宇宙的膨胀也是各向同性的。这个性质用数学语言描述，就是相对于每个位置的观测者来说，都有 $$ \\boldsymbol{v}=k(t)\\boldsymbol{r} $$ 远离速度只与当前的时间与距离有关。\n现在我们引入第二个假设，就是等速膨胀——宇宙膨胀速度是不变的（实际早期是减速膨胀的）。这句话的意思是说，取宇宙中的两个点，它们随着膨胀互相远离，远离的速度时时刻刻是一样的。用数学语言来说，假设两点的距离是 $d(t)$，那么 $$ \\left\\{\\begin{aligned} d(t)\u0026amp;=\\int_0^tv(t^\\prime)\\mathrm{d}t^\\prime=\\int_0^tk(t^\\prime)d(t^\\prime)\\mathrm{d}t^\\prime\\\\ k(t)d(t)\u0026amp;=C \\end{aligned}\\right. $$\n从而 $d(t)=Ct$，$k(t)=1/t$。也就是说两个点之间的距离关于时间是正比例函数。这就是哈勃定律 $$ v_r=H_0d_G $$ $H_0$ 就是宇宙年龄的倒数。\n现在我们考虑实际的问题：在观测到一个天体时，我们既不知道它的退行速度，也不知道它的距离，我们只知道它的光谱，可以通过比对几个关键谱线推出宇宙学红移 $z=\\Delta\\lambda/\\lambda$。那么怎么推出现在它的距离呢？上课讲的是，直接用 $$ z=\\frac vc,\\,d=\\frac v{H_0} $$ 来算。但是我们面对的毕竟是空间膨胀而不是简单的远离啊，$z=v/c$ 这事真对吗？所以我想仔细算一遍。\n考虑它发射当前观测到的光时，距离地球 $d_0$，宇宙年龄 $t_0$。以它的发射点为数轴原点，在光以 $c$ 的速度正向移动的同时，空间在膨胀，设光所在位置为 $y$，单单膨胀带给它的速度为 $y/t$。两个速度叠加，得到 $y^\\prime=c+y/t$。如果最终在 $t_1$ 时间到达地球，那么 $y|_{t=t_1}=d_0t_1/t_0$。\n先解这个微分方程。齐次解为 $y=Ct$，非齐次解为 $y=ct\\ln t+Ct$，代入初始条件得 $y=ct\\ln(t/t_0)$。结合另一个方程解得 $t_1=t_0\\mathrm{e}^{d_0/ct_0}$。光线到达地球的时候，红移为 $z=t_1/t_0-1$，距离就是 $d_0t_1/t_0$。\n在假定距离不太大，也就是 $d_0/ct_0$ 不太大的情况下，可以用 $\\mathrm{e}^x\\approx 1+x$ 来估算：$t_1=t_0(1+d_0/ct_0)$，$z=d_0/ct_0$，$d_1=d_0t_1/t_0=zt_1=zct_1=zc/H_0$。嘿，它是对的。也就是说，我们可以通过观测以前发出的光来推断发光的天体现在的距离。\n$z$ 很大的情况，就算用的是不估计的表达式，也会因为相对论问题出错。比如说在一个模型下（Friedmann 方程）： $$ t=\\frac1{H_0}\\int_0^{1/(1+z)}\\frac{\\mathrm{d}a}{a\\sqrt{0.3a^{-3}+0.7}} $$ 但无论如何有个东西还是对的，就是 $z=t_1/t_0-1$，或者说在这光发出的时候，宇宙尺度因子（现在是 $1$）是 $R_{\\rm U}=1/(1+z)$。\n那现在的问题就是测得哈勃常数 $H_0$。不能选太近的天体，不然本动速度（除去随着膨胀，相对于地球的速度）就会严重影响结果。但太远的本身就不知道距离，怎么办呢？这里有一个距离阶梯的方法：\n比如说，我们知道造父变星的光度，并发现有一个星系里既有造父变星，又有一个 Ia 超新星，那么就可以得到超新星的光度，从而往更远的推。哈勃当时用的标准烛光是造父变星，测得偏大了很多。\n宇宙微波背景辐射 热大爆炸宇宙学模型：1948，伽莫夫，αβγ 论文。\n宇宙大爆炸只合成了最轻的元素：氢、氦、锂（宇宙中锂铍硼的丰度很低是因为它们不是核聚变的产物，而是被核聚变消耗）。铁及之前的元素是通过大质量恒星的核聚变出现，比铁重的原子是通过中子俘获 + β 衰变形成，在例如超新星爆炸、中子星并合等事件中。\n宇宙微波背景辐射（CMB）是宇宙大爆炸发生的重要证据。它是能看到的宇宙最早期的辐射。最早由上面的这篇论文预测，后来，1964、65 年由贝尔实验室的几位科学家偶然观测到（最早的好像是苏联的科学家）。\n$38$ 万年之前的信息没法从电磁波角度了解，因为那个时候之前因为原子都被电离了，光子没法自由移动，或者说宇宙对电磁波是不透明的。在那之后，宇宙复合（中性化），温度约三千 $\\rm K$。随着宇宙膨胀，温度继续下降。CMB 也随着从伽马射线波段（冷却）到红外波段，再（红移）到微波波段，现在宇宙的平均温度只有个位数 $\\rm K$，总体来说，宇宙膨胀了 $1100$ 倍，温度下降了 $1100$ 倍，CMB 波长峰值红移了 $1100$ 倍。\nCMB 的谱需要到太空中观测，COBE 观测得到，它极其完美地符合 $2.73\\unit K$ 黑体辐射谱。\nCMB 高度各向同性，但是从地球来看有轻微的不同性，因为地球相对于宇宙空间有一个速度，这就是 CMB 的偶极不对称性。当扣除这部分，以及其他微波辐射源、尘埃消光的影响，发现 CMB 在高度各项同性的基础上有十万分之几的各向异性。（这种各向异性很重要，因为它这种不均匀是形成各种天体的种子）\nWMAP 探测器观察的角分辨率更高，把背景辐射的极差提高到了万分之二。后面还有 Planck。这些观测都进一步给出了更精确的哈勃常数以及宇宙中的物质分布比例。\n大爆炸核合成的说法，解释了氦的观测得丰度高于恒星核合成的产量对应的预估。在大爆炸后的短时间内，质子碰撞合成轻原子核，这个叫大爆炸（原初）核合成。\n通过数学预测的各元素比例和实测的各元素比例，可以得到宇宙的亮物质（重子）密度。\n宇宙结构的起源 我们希望找到宇宙最早的天体发出来的光。\n上面我们提到，星系的形成是因为引力，那么这个引力主要是暗物质。星系也会聚集起来形成星系群或星系团（星系群里星系少，星系团里星系多）。总体来说，矮星系数量远多于巨星系，旋涡星系常见。少部分星系团中，椭圆星系（主要由旋涡星系并合而成）主导。本星系群（银河系、M31、M33、大小麦哲伦）的周围有室女星系团（中心 M87）、后发星系团等，都是形如中心一个椭圆星系，周围一堆旋涡星系。本星系群和室女星系团都（不含后发）属于室女（本）超星系团，中心在室女星系团附近。\n绘制宇宙的大尺度结构，就用哈勃红移算距离。星系不是随机分布，而是组成复杂的网状结构。由星系组成的纤维和“墙”环绕着巨洞。像海绵或者说泡泡的结构。\n暗物质也主导星系团、群的质量。测的方法跟星系内是一样的（看各星系速度、看炽热气体的 X 射线、引力透镜）。星系团的暗物质先于星系的暗物质被提出。\n宇宙一开始是非常均匀的，其极其微小的“微扰”不均匀性是形成现在复杂星系结构的原因，有个蝴蝶效应在里面。大爆炸后 $38$ 万年到数亿年期间，没有恒星（正在形成），这段时期称为黑暗时期。这段时期的研究是靠观测中性氢的 $21$ 厘米辐射。\n宇宙暴胀时期的量子涨落产生了密度涨落，为星系和星系组合提供了“团块（种子）”，引力不稳定性把宇宙的密度涨落转变为星系。CMB 各项异性是量子涨落的印记。目前的说法是，形成的过程是自下而上等级式成团：小结构先形成，再形成大结构。\n大爆炸宇宙学的标准模型是 ΛCDM 模型，可以通过计算机模拟来研究。它有四个参数：暗能量（Λ）、（冷）暗物质（CDM）、亮物质、哈勃常数。这些参数取不同的值，宇宙的演化情况是不同的，只有特定的参数组合才能导致现在宇宙的大尺度结构。但是无论如何，初始情况不能绝对均匀，得有形成结构的种子，这就靠 CMB 的观测数据得出。亮、暗物质开始于等同的密度涨落（也等同于 CMB），但 $38$ 万年后，亮物质受到辐射压的影响，模糊的程度强于暗物质（暗物质不与辐射互动）。暗物质分冷暗物质（未知基本粒子，质量大、运动慢）和热暗物质（粒子质量轻、运动极快）。热、冷暗物质共同形成最大尺度的结构，冷暗物质形成星系尺度的结构。冷暗物质和亮物质一起坍缩，冷暗物质为亮物质提供引力。当坍缩到一定程度时，暗物质因为无法发出辐射，引力和辐射压就平衡了，无法坍缩，亮物质可以通过辐射失去热量，而逐渐变小。这就是为什么亮物质形成小而扁的星系，而暗物质弥漫在大得多的范围。\n黑暗时期过后（$5.5$ 亿年），第一代恒星开始在在暗物质微晕中形成，原初气体云在一小部分中性氢形成分子氢、冷却气体云后，因压力降低而引力坍缩。因为开始的时候，无重元素，无尘埃，无冷而致密的分子云，只有氢和氦，它们的能级少，不容易通过辐射散热，所以气体云必须足够大才能坍缩，所以就没法形成小质量的恒星。这些大质量的恒星，辐射紫外线，电离周围的气体。它们寿命短，经历超新星爆炸后，结局都是 X 射线双星，黑洞。甚至可能从气体云直接坍缩成黑洞。有说法说，并合的恒星质量黑洞成为星系中心超大质量黑洞的种子。\n第二代有了重元素（当然还是丰度很低），就跟现在差不多了。第二代恒星提供关于第一代恒星的性质与银河系早期的物理条件的线索。根据上面说的自下而上的形成顺序，第一代矮星系和第二代恒星同时形成，其中有些小质量恒星现在仍处于主序阶段，这些在第二轮中首次出现的小质量恒星称为第一代小质量恒星。本星系群里也有大量这个时候形成的超弱矮星系，光度很低，暗物质比例很高，极低金属丰度。在第二代恒星形成后，可能没有再形成恒星。是第一代星系的化石。还有球状星团，球状星团相比矮星系，其中的暗物质密度更低，大小也小。\n早期宇宙更小、星体数量更多、星体更靠近，所以并合更频繁。在大的旋涡星系附近，存在大量矮椭球星系与球状星团，它们可能是大星系由小星系并合而来的证据。越早期的星系，越暗弱、混乱、形状不规则。\n超大质量黑洞的质量与旋涡星系的核球和椭圆星系（整个椭圆星系就可以视为核球）的质量正相关。星系（黑洞）在并合时会触发恒星形成区。恒星形成率在宇宙 $20$ 到 $30$ 亿年时最高。\n两个星系团碰撞时，恒星和暗物质不改变，热气体会减速。\n韦布望远镜发现，早期星系中规则的星系数量远多于标准模型所预言的。\n宇宙的未来与极早期 实际上宇宙不是等速膨胀的。\n在没有暗能量的概念时，科学家认为，因为宇宙有质量，就有引力，所以膨胀一定时减速的。那么具体的减速情况就取决于宇宙本身的“逃逸速度”。假设现在宇宙的平均密度为 $\\rho$，有个距离地球 $d$ 的天体，它以 $H_0d$ 的速度远离。它所受的指向地球的引力，可以视作半径为 $d$ 的球里面的物质的引力，质量为 $\\frac43\\pi d^3\\rho$。那么逃逸速度为 $$ \\sqrt{\\frac{2GM}d}=\\sqrt{\\frac{8\\pi Gd^2\\rho}3} $$ 能够逃逸的临界情况为 $$ H_0d=\\sqrt{\\frac{8\\pi Gd^2\\rho}3}\\Longrightarrow\\rho=\\frac{3H_0^2}{8\\pi G} $$ 与 $d$ 无关。也就是说，如果 $\\rho$ 小于等于这个值，宇宙就能一直减速膨胀下去，否则最后就会宇宙大收缩。这个临界值称为宇宙的临界密度 $\\rho_{\\rm c}$。宇宙的物质密度参数定义为 $$ \\Omega_{\\rm mass}=\\frac\\rho{\\rho_{\\rm c}} $$ 其中 $\\rho$ 为观测得到的密度。如果 $\\Omega_{\\rm mass}\\le 1$ 就会一直膨胀。实际测得它约为 $0.32$。\n如果宇宙真的是减速膨胀的，那我们通过标准烛光法（实际）和哈勃定律（假定是匀速膨胀）得出来的某个遥远天体的距离会怎样不同呢？\n首先明确标准烛光法测得的是当前的距离而不是发光时的距离，设为 $d$。我们认为 $H_0$ 取的是真实测得的，当前宇宙的膨胀速度比例。设 $z$ 为测得的红移。那么发光时天体与地球的距离比当前的距离就是 $1/(1+z)$，这个前面提过。那就是说，从 $d/(1+z)$ 到 $d$，是通过一个减加速（上凸）的过程，光刚好能传到地球。如果我们用匀速的方法（即 $zc/H_0$）来测，那么就不可能是从 $d/(1+z)$ 到 $d$，因为在匀速的情况下，光因膨胀而“吃到”的减速没有那么多，所以在膨胀到 $d$ 之前就已经到达了地球，这就不对了。解决这个的方法就是增大 $d$。所以匀速模型下测得的结果，如果要自洽，就是距离偏大。\n这个东西老师上课没仔细讲，然后实际上你简单想想很容易觉得，它不应该是减速模型距离偏大吗？这个东西实际上还真没这么简单，你仔细分析，实际上考虑的是这么一个问题：对于微分方程 $$ y^\\prime=c+\\frac{a^\\prime(t)}{a(t)}y $$ （$a$ 就是尺度因子），其中 $a(0)=1/(1+z)$，$a(t_0)=1$，$y|_{t=0}=0$。考虑方程 $$ y=a(t)d_0 $$ 的解 $t_1$，那么当 $a(t)$ 是一次函数时，这个解一定比 $a(t)$ 是上凸函数时的解小。可以得到解为 $$ y=a(t)\\cdot c\\int_0^t\\frac{\\mathrm{d}u}{a(u)} $$ 因此等式相当于 $$ \\int_0^{t_1}\\frac{\\mathrm{d}u}{a(u)}=\\frac{d_0}c $$ 肯定是一次函数累积得最快。\n如果你有更简单的解释请留言。\n哎呀反正考试的时候记得是减速偏小就行啦。\n那么实际结果观测结果恰恰相反。这说明宇宙中有一个斥力。爱因斯坦在用广义相对论预言宇宙发展时，为了符合他认为的宇宙稳定，加入了起长程斥力的宇宙学常数 $\\Lambda$。现在这个量反而可以用来对应斥力了。这个斥力是由暗能量造成的。暗能量均匀分布，不聚集成团，仅在巨大时空尺度上起作用。同样有一个暗能量密度 $\\Omega_\\Lambda$。暗能量在宇宙早期不重要，在约一半宇宙年龄前宇宙膨胀是减速的。随着宇宙膨胀，引力越来越弱，暗能量（密度不变）占主导，使减速转为加速。但暗能量具体是什么还不知道。宇宙的膨胀模式是物质和暗能量（时间演化）共同作用的结果。\n如果宇宙膨胀减速，则宇宙年龄 $\u0026lt;1/H_0$；宇宙膨胀加速，则宇宙年龄 $\u0026gt;1/H_0$。\n宇宙的总密度参数 $\\Omega_0=\\Omega_{\\rm mass}+\\Omega_\\Lambda$ 决定宇宙的形状，它是等于 $1$ 的，这意味着宇宙是平直的。\n关于早期宇宙，就几个知识点：\n粒子的创建需要很高的温度。产生：两个伽马射线光子碰撞，产生正反粒子对。湮灭：粒子与反粒子对湮灭， 质量转为能量。辐射场温度越高，所创建的粒子的质量越大。在阈值温度之上，粒子—反粒子对和辐射处于热平衡状态，即对产生和对湮灭平衡；在阈值温度之下，对湮灭之后粒子不能再被创建。宇宙年龄 $\\sim 0.0001\\unit s$ 后，质子不再创生。宇宙年龄 $\\sim 100\\unit s$ 后，电子不再创生。物质略微超过反物，每十亿个粒子—反粒子对，多出一个额外的粒子。随着宇宙膨胀冷却，对湮灭后对产生不再发生，这些幸存的没有配对的正粒子从辐射场中冻结出来，其数量一直恒定至今。\n后面是宇宙初期演化的八个时代，然后平直疑难问题、视界疑难问题、宇宙的结局。\n宇宙的未来有两个说法，大撕裂和热寂。\n如何证明人类在宇宙中存在过？\n雨课堂测试的几个知识点 金星的盈亏（越亮越小，伽利略发现）彻底否定了地心说。 伽利略是通过造父变星测距而得到星云不属于银河系的，因为他没有区分 I 型和 II 型，所以测得 $H_0$ 误差大。 空间望远镜的最大不利因素是昂贵。 地球表面不能探测 X、γ 射线。 目前最常用的发现系外行星的方法是凌星法。 天狼星的白矮星伴星是通过天体测量法发现的。 双黑洞的并合不产生 γ 射线暴，只有大质量恒星坍缩，或者合并中有至少一者为中子星才能。 年轻恒星主要位于银河系的旋臂，而不能说银盘。 哈勃确定（旋涡）星云是银河系外的星系的关键是，他（利用造父变星）测量出了其距离。 考试的一些知识点 这边列出的是一些我不太清楚的或者觉得相对容易忽视的。您需要先保证复习完主要的知识点和雨课堂测试题。每届的题目肯定是不一样的。\n中国农民丰收节的时间是秋分。 冬季大三角。 狭义相对论效应能解释 μ 介子。 变星的周光关系与多普勒效应无关，其他很多天体的发现都和多普勒有关。 双射电脉冲星一定是两颗中子星。两颗中子星合并后不一定是黑洞。发现第一颗双射电脉冲星获诺贝尔奖。 太阳表面的震荡可以体现内部结构。 太阳具有 $22$ 年的磁周期。 B-V 值的严格定义——峰值波长越短，B-V 越小。 太阳是 G2V 型。 黑暗时期靠中性氢研究。 活动星系核不包含恒星。 行星状星云是由气体被电离所致。 球状星团中暗物质比例较小。 原太阳与太阳比，光度、大小、颜色中，颜色差的相对来说最小。 疏散星团几乎没有白矮星，球状星团里有很多。 天琴 RR 主要在银河系内被观测到，造父变星则相反。 白矮星 Ia 爆发有两种：经典是吸积到钱德拉塞卡极限，超亮是两颗白矮星并合。我不知道为啥试卷里是单选。 通过两个星团中正在离开主序带的恒星的年龄等，比较星团的年龄。 人马座 A* 黑洞就是银河系中心。 大爆炸核合成预言了今天宇宙的轻元素丰度。 两个星系高速碰撞时，亮物质热气体减速，暗物质不减速。 暴胀期解释了视界问题。 附录 课内公式 $r$ 和 $R$ 均表示半径，$m$ 和 $M$ 均表示质量。\n太阳日和恒星日的差： $$ 太阳日-恒星日=恒星日\\times\\frac{太阳日}{恒星年}\\approx\\frac{24\\unit{h}}{365} $$ 某地 $x$ 日（从春分日起）$y$ 时的地方恒星时： $$ \\left(x\\times 4\\unit{min}+y-12\\unit{h}+\\frac{该地经度-该地时区中央子午线}{360^\\circ}\\cdot 24\\unit{h}\\right)\\bmod 24\\unit{h} $$ 向心加速度： $$ a=\\frac{v^2}{r}=v\\omega=\\omega^2r=\\frac{4\\pi^2r}{T^2}=4\\pi^2f^2r $$ 万有引力： $$ F=\\frac{Gm_1m_2}{r^2} $$\n黄金代换： $$ GM=v^2r=gr^2 $$ 宇宙速度： $$ v_1=\\sqrt{gR},\\,v_2=\\sqrt{2gR} $$ 开普勒第三定律： $$ \\frac{a^3}{T^2}=\\frac{GM}{4\\pi^2} $$ 双星系统： $$ \\frac{(r_1+r_2)^3}{T^2}=\\frac{G(m_1+m_2)}{4\\pi^2} $$\n$$ r_1m_1=r_2m_2 $$\n潮汐加速度（$r$ 是受力星球的半径）： $$ a=\\frac{2GMr}{d^3} $$ 波： $$ E=hf $$\n$$ \\lambda f=c $$\n红移（$v$ 是视向靠近速度）： $$ z=\\frac{\\Delta\\lambda}{\\lambda}=\\frac vc $$ 黑体辐射定律（光谱辐射亮度）： $$ B_\\nu(\\nu,T)=\\frac{2h\\nu^3}{c^2}\\frac{1}{\\mathrm{e}^{h\\nu/k_BT}-1} $$ 峰值波长与温度的关系： $$ T=\\frac{2.9\\times 10^6\\unit{nm\\cdot K}}{\\lambda_{\\text{peak}}} $$ 流强： $$ F=\\sigma T^4 $$ 光度： $$ L=4\\pi R^2F $$ 亮度： $$ B=\\frac{L}{4\\pi d^2}=\\frac{r^2}{d^2}\\sigma T^4 $$ 凌星亮度下降率（假设恒星是朗伯辐射体）： $$ p=\\frac{R^2_{\\text{planet}}}{R^2_{\\text{star}}} $$ 聚光能力（$D$ 是光圈大小）： $$ A=\\frac{\\pi D^2}{4} $$ 角分辨率： $$ \\theta=2.06\\times10^5\\frac\\lambda D\\unit{arcsec} $$ 角动量： $$ L=\\iiint(\\boldsymbol{r}\\times\\boldsymbol{v})\\mathrm{d}m $$ 均匀球体的角动量： $$ L=\\frac{4\\pi mR^2}{5T} $$ 太阳核聚变的能量： $$ \\Delta E=\\Delta mc^2 $$ 距离与视差的关系： $$ d=\\frac1p $$ 视星等： $$ m=-2.5\\log_{10}\\frac{b}{b_0} $$ 绝对星等： $$ M=-2.5\\log_{10}\\frac{L}{4\\pi(10\\unit{parsec})^2b_0} $$ 距离模数： $$ \\mu=m-M=5\\log_{10}d-5 $$ 色指数： $$ B\\text{-}\\!V=-2.5\\log_{10}\\frac{b_B}{b_V} $$\n质寿关系（类日）： $$ \\tau_{\\text{MS}}=10^{10}\\unit{y}\\cdot\\frac{M/M_\\odot}{L/L_\\odot} $$ 史瓦西半径： $$ r=\\frac{2GM}{c^2} $$ 黑洞平均密度： $$ \\rho=\\frac{3c^6}{32\\pi G^3M^2} $$ 黑洞的能量转换效率： $$ \\eta=\\frac{GM}{rc^2} $$ 哈勃定律： $$ v_r=H_0d_G $$ 宇宙的临界密度： $$ \\rho=\\frac{3H_0^2}{8\\pi G} $$\n常数表 以下，秒分时日（$\\rm s,min,h,d$）均靠铯原子钟定义，平太阳日和 $1\\unit{d}$ 差别极小。\n部分数据取自 https://nssdc.gsfc.nasa.gov/planetary/factsheet/sunfact.html。\n名称 符号 数值 光速 $c$ $2.9979\\times 10^8\\unit{m/s}$ 天文单位 $1\\unit{AU}$ $1.4960\\times 10^8\\unit{km}$ 光年 $1\\unit{ly}$ $9.4607\\times 10^{15}\\unit{m}$ 恒星日 $23.934\\unit{h}$ 平太阳日 $24\\unit{h}$ 恒星年 $365.256\\unit{d}$ 太阳年 $365.242\\unit{d}$ 月亮公转周期 $27.32\\unit{d}$ 月相周期 $29.53\\unit{d}$ 目前地球自转轴进动周期 $25772\\unit{y}$ 万有引力常数 $G$ $6.6743\\times 10^{-11}\\unit{m^3/(kg\\cdot s^2)}$ 太阳质量 $M_\\odot$ $1.9884\\times 10^{30}\\unit{kg}$ 地球质量 $M_\\oplus$ $5.9722\\times 10^{24}\\unit{kg}$ 太阳半径 $r_\\odot$ $6.957\\times 10^5\\unit{km}$ 地球半径 $r_\\oplus$ $6371\\unit{km}$ 光球层温度 $5772\\unit{K}$ 太阳光度 $L_\\odot$ $3.828\\times 10^{26}\\unit{W}$ 太阳赤道自转周期 $25.05\\unit{d}$ 第一宇宙速度 $7.9\\unit{km/s}$ 第二宇宙速度 $11.2\\unit{km/s}$ 普朗克常数 $h$ $6.6261\\times 10^{-34}\\unit{m^2\\cdot kg/s}$ 维恩位移定律的分子 $2.8978\\times 10^6\\unit{\\mu m\\cdot K}$ 斯忒藩—玻耳兹曼常数 $\\sigma$ $5.6704\\times 10^{-8}\\unit{W/(m^2\\cdot K^4)}$ 可见光波长范围 $380\\sim 750\\unit{nm}$ 氢原子的电离能 $13.598\\unit{eV}$ 角分辨率的常数（课内） $1\\unit{rad}$ $2.0626\\times 10^5\\unit{arcsec}$ 角分辨率的常数（课外） $1.2197$ 质子—质子链的能量转换效率 $0.7\\%$ 太阳寿命 $\\sim 10^{10}\\unit{y}$ 秒差距 $1\\unit{pc}$ $3.2616\\unit{ly}$ 钱德拉塞卡极限 $1.4M_\\odot$ $2.765\\times 10^{30}\\unit{kg}$ 银盘直径 $26.8\\pm 1.1\\unit{kpc}$ 太阳距银心 $8.32\\pm 0.14\\unit{kpc}$ 薄盘厚度 $220\\sim 450\\unit{pc}$ 厚盘厚度 $2.6\\pm 0.5\\unit{kpc}$ 哈勃常数 $H_0$ $70\\unit{km/s/Mpc}$ 宇宙年龄 $1.38\\times 10^{10}\\unit{y}$ 宇宙背景辐射温度 $2.72548\\pm 0.00057\\unit{k}$ 宇宙物质密度 $3\\times 10^{-27}\\unit{kg/m^3}$ 宇宙临界密度 $\\rho_{\\rm c}$ $9.5\\times 10^{27}\\unit{kg/m^3}$ 中英对照表 您甚至可以看术语来期末复习。\n术语 中文 英文 天文单位 astronomical unit 光年 light-year 星座 constellation 极 pole 赤道 equator 北回归线 the Tropic of Cancer 南回归线 the Tropic of Capricorn 纬度 latitude 经度 longitude 子午线 meridian 本初子午线 prime meridian 天球 celestial sphere 天顶 zenith 地底 nadir 赤纬 declination 赤经 right ascension 黄道 ecliptic 地平（线） horizon 中天 culmination 过中天 meridian transits 高度角 altitude 方位角 azimuth 拱极星 circumpolar star 星轨 star trail 太阳日 solar day 恒星日 sidereal day 黄道带 the zodiac 自转 rotate 公转 revolve 春/秋分 the spring(vernal)/autumn(autumnal) equinox 夏/冬至 the summer/winter solstice 进动 precession 岁差 precession of the equinoxes 章动 nutation 月相 phase of the moon 新月 new moon 娥眉月 waxing crescent 上弦月 first quarter 上凸月 waxing gibbous 满月 full moon 下凸月 waning gibbous 下弦月 last quarter 残月 waning crescent 恒星年 sidereal year 回归年 tropical year 恒星周期 sidereal period 会合周期 synodic period 潮汐锁定 tidal locking 同步自转 synchronous rotation 日食 solar eclipse 日全食 total solar eclipse 日环食 annular solar eclipse 日偏食 partial solar eclipse 本影 umbra 半影 penumbra 地心 geocentric 本轮 epicycle 均轮 deferent 日心 heliocentric 顺行 prograde motion 逆行 retrograde motion 近日点 perihelion 远日点 aphelion 椭圆 ellipse 万有引力定律 universal law of gravitation 逃逸速度 escape velocity 潮汐隆起 tidal bulge 辐射 radiation 光谱 spectrum 紫外线 ultraviolet radiation, UV 红外线 infrared radiation, IR 光子 photon 质子 proton 中子 neutron 电子 electron 中微子 neutrino 发射线 emission line 吸收线 absorption line 红移 redshift 蓝移 blueshift 热辐射 thermal radiation 辐射强度 radiant intensity 流强 flux 光度 luminosity 亮度 brightness 光学望远镜 optical telescope 折射式望远镜 refracting telescope 反射式望远镜 reflecting telescope 物镜 objective lens 目镜 eyepiece 色差 chromatic aberration 色散 dispersion 立体角 solid angle 角分辨率 angular resolution 衍射极限 diffraction limit 视宁度 seeing 光谱仪 spectrograph 恒星 star 行星系 planetary system 卫星 moon 星云 nebula 流星 meteor 陨石 meteorite 原恒星 protostar 原行星盘 protoplanetary disk 角动量 angular momentum 吸积盘 accretion disk 双极流 bipolar outflow 喷流 jet 星子 planetesimal 行星迁移 planet migration 原始大气 primary atmosphere 次生大气 secondary atmosphere 彗星 comet 彗核 comet nucleus 类地行星 terrestrial planet 巨行星 giant planet 系外行星 extrasolar planet/exoplanet 矮行星 dwarf planet 褐矮星 brown dwarf 视向速度法 radial-velocity method 凌星法 transit method 微引力透镜法 gravitational microlensing 天体测量法 astrometric method 直接成像法 direct imaging 核合成 nucleosynthesis 核聚变 nuclear fusion 氢燃烧（氢核聚变） hydrogen burning （热）传导 conduction 对流 convection 不透明度 opacity 日面米粒组织 granulation 日震 helioseismology 光球层 photosphere 色球层 chromosphere 日冕 corona 临边昏暗 limb darkening 太阳黑子 sunspot 太阳黑子周期 sunspot cycle 太阳耀斑 solar flare 冕环 coronal loop 日珥 solar prominence 日冕物质抛射 coronal mass ejection 冕洞 coronal hole 太阳风 solar wind 极光 aurora 视差角 parallactic angle 视差 parallax 视星等 apparent magnitude 绝对星等 absolute magnitude 距离模数 distance modulus 色指数 color index 滤光片 optical filter 双星 binary star 质心 center of mass 视双星 visual binary 食双星 eclipsing binary 分光双星 spectroscopic binary 天体测量双星 astrometric binary 光谱型 spectral type 主序 main sequence, MS 巨星 giant 星际介质 interstellar medium 星际尘埃 interstellar dust 星际消光 interstellar extinction 红化 reddening 星际云 interstellar cloud 云际气体 intercloud gas 星云 nebula 电离 ionize 分子云 molecular cloud 巨分子云 giant molecular cloud 演化程 evolutionary track 星团 star cluster 球状星团 globular cluster 疏散星团 open cluster 褐矮星 brown dwarf 寿命 lifetime 质光关系 mass-luminosity relation 亚巨星（支） subgiant (branch), SB 红巨星（支） red giant (branch), RGB 简并 degenerate 氦闪 helium flash 水平支 horizontal branch, HB 渐近巨星支 asymptotic giant branch, AGB 后渐近巨星支 post asymptotic giant branch, post-AGB 行星状星云 planetary nebula 白矮星 white dwarf 黑矮星 black dwarf 不稳定带 instability strip 脉动变星 pulsating variable stars 造父变星 Cepheid variable 天琴座 RR 型变星 RR Lyrae variable 超新星 supernova 超新星遗迹 supernova remnant 中子星 neutron star 脉冲星 pulsar 黑洞 black hole 激变变星 cataclysmic variable stars 新星 nova 再发新星 recurrent nova X 射线双星 X-ray binary 主序转折点 main-sequence turnoff 磁星 magnetar 夸克（奇异）星 quark star 快速射电暴 fast radio burst, FRB 视界 event horizon 奇点 singularity 能层 ergosphere 相对论性喷流 astrophysical(relativistic) jet 恒星级质量黑洞 stellar black hole 超大质量黑洞 supermassive black hole 伽马射线暴 gamma-ray burst, GRB 引力波 gravitational wave 旋臂 spiral arm 核球 bulge 星系盘 galactic disk 星系晕 galactic halo 尘埃带 dust lane 宇宙射线 cosmic ray 密度波 density wave 潮汐瓦解 tidal disruption 椭圆星系 elliptical galaxy 旋涡星系 spiral galaxy 棒旋星系 barred spiral galaxy 不规则星系 irregular galaxy 矮星系 dwarf galaxy 河外星系 extragalactic system 暗物质 dark matter 标准烛光 standard candle 距离阶梯 distance ladder 类星体 quasar 引力红移 gravitational redshift 宇宙学红移 cosmological redshift 活动星系核 active galactic nucleus, AGN 射电噪的 radio-loud 射电宁静的 radio-quiet 射电星系 radio galaxy 耀变体 blazar 辐射压 radiation pressure 尘埃环 obscuring torus 宇宙学原理 cosmological principle （宇宙是）均匀的 homogeneous （宇宙是）各向同性的 isotropic 退行速度 recessional velocity 本动速度 peculiar velocity 回溯时间 look-back time 宇宙大爆炸 the Big Bang 宇宙尺度因子 scale factor 宇宙微波背景辐射 cosmic microwave background radiation, CMB 复合（光子退耦） recombination 星系群 galaxy group 星系团 galaxy cluster 超星系团 supercluster 巨洞 void 大尺度结构 large-scale structure 等级式成团 hierarchical clustering 黑暗时代 the Dark Ages 再电离 reionization 量子涨落 quantum fluctuation 临界密度 critical density 宇宙学常数 the cosmological constant 暗能量 dark energy 大挤压 the Big Crunch 大撕裂 the Big Rip 平直宇宙 flat universe 暴涨 inflation 多重宇宙 multiverse 天体 中文 英文 太阳系 the Solar System 银河系 the Milky Way 本星系群 the Local Group of Galaxies 本（室女座）超星系群 the Local(Virgo) Supercluster 拉尼亚凯亚超星系团 the Laniakea Supercluster 仙女座星系 the Andromeda Galaxy 三角座星系 the Triangulum Galaxy 大/小麦哲伦星云 the Large/Small Magellanic Cloud 北极星 Polaris 天狼星 Sirius 比邻星 Proxima Centauri 昴星团 the Pleiades 蟹状星云 the Crab Nebula 人名 中文 英文 贡献 诺贝尔奖 托勒密 Ptolemy 地心说（150 年《天文学大成》） 哥白尼 Copernicus 日心说（1543 年《天体运行论》） 第谷 Tycho 望远镜之前最好的天文仪器和观测 开普勒 Kepler 观测、开普勒三定律（1619 年《世界的和谐》） 伽利略 Galileo 第一位使用望远镜，彻底否定地心说，发现银河由众多恒星组成 牛顿 Newton 第一台反射式望远镜、物理（1687 年《自然哲学的数学原理》） 爱因斯坦 Einstein 相对论等 根策尔、盖兹 Genzel, Ghez 发现银河系中心的黑洞 2020 韦斯、巴里什、索恩 Weiss, Barish, Thorne LIGO 探测装置（探测引力波） 2017 麦克斯韦 Maxwell 电磁场理论（1873 年《论电和磁》） 普朗克 Planck 黑体辐射谱、量子力学创始人之一 1918 韦恩 Wien 位移定律 斯特藩、玻尔兹曼 Stefan, Boltzmann 斯特藩—玻尔兹曼定律 玻尔 Bohr 原子模型 1922 巴尔末 Balmer 巴尔末线系 莱曼 Lyman 莱曼线系 多普勒 Doppler 多普勒效应 卡塞格林 Cassegrain 反射式望远镜 艾里 Airy 艾里斑 瑞利 Rayleigh 瑞利散射、判据 康德 Kant 首先提出太阳系形成的星云假说、认为旋涡星云是“岛宇宙” 拉普拉斯 Laplace 提供星云假说的定量化版本 马约尔、奎洛兹 Mayor, Queloz 发现第一颗系外行星 2019 贝特 Bethe 恒星能源及核反应 1967 戴维斯、小柴昌俊 Davis, Koshiba 对天体物理学，特别是对探测宇宙中微子的开拓性贡献 2022 麦克唐纳、梶田隆章 McDonald, Kajita 发现了中微子振荡，证实了中微子有质量 2015 赫茨普龙 Hertzsprung 赫—罗图 罗素 Russell 赫—罗图 林忠四郎 Hayashi 恒星形成模型和前主序列演化模型 赫比格、阿罗 Herbig, Haro HH 天体 洛希 Roche 洛希极限、洛希瓣 钱德拉塞卡 Chandrasekhar 钱德拉塞卡极限 1983 休伊什 Hewish 发现第一颗脉冲星 1974 泰勒、赫尔斯 Taylor, Hulse 发现第一颗双星射电脉冲星 1993 洛里默 Lorimer 发现首例快速射电暴 史瓦西 Schwarzschild 史瓦西度规与史瓦西半径 霍金 Hawking 黑洞辐射 林家翘 密度波理论 梅西耶 Messier 梅西耶星表 赫歇尔 Herschel 银河系结构、NGC、发现天王星，并发现天王星的轨道预言和实际观测不一致 沙普利 Shapley 发现球状星团三维分布、太阳系不是银河系的中心 哈勃 Hubble 哈勃分类、哈勃定律 施密特 Schmidt 首次发现类星体 塞弗特 Seyfert 赛弗特星系 爱丁顿 Eddington 爱丁顿光度 弗里德曼 Friedmann 弗里德曼宇宙模型 勒梅特 Lemaître 宇宙膨胀模型 伽莫夫 Gamow αβγ 论文 皮布尔斯 Peebles 对于物理宇宙学方面的理论发现 2019 彭齐亚斯、威尔逊 Penzias, Wilson 发现宇宙微波背景辐射 1978 马瑟、斯穆特 Mather, Smoot 发现了宇宙微波背景辐射的黑体谱形式和各项异性 2006 兹威基 Zwicky 星系团的暗物质 鲁宾 Rubin 星系的暗物质 珀尔马特、施密特、里斯 Perlmutter, Schmidt, Riess 通过观测遥远的超新星发现宇宙正在加速膨胀 2011 古斯 Guth 提出大爆炸后暴胀期 望远镜 中文 缩写 贡献 韦布太空望远镜 JWST 首张“全彩”红外照片、早期星系、“长城”、最遥远的黑洞合并、创世之柱（红外） 胡克望远镜 Hooker 为哈勃定律、赫—罗图提供数据 哈勃太空望远镜 HST 深空、创世之柱（可见光） 钱德拉 X 射线太空望远镜 CXO 蟹状星云 X 射线图像、一些黑洞的 X 射线图像 事件视界望远镜 EHT M87* 黑洞、Sgr A* 黑洞 ","date":"2025-01-22T00:00:00Z","image":"https://littlereuben.github.io/study/course-astronomy/cover.png","permalink":"https://littlereuben.github.io/study/course-astronomy/","title":"带你慢通 天文学导论"},{"content":"$\\gdef\\b#1{\\boldsymbol{#1}}\\gdef\\d{\\mathrm{d}}\\gdef\\p{\\partial}\\gdef\\J{\\mathbf{J}}\\gdef\\H{\\mathbf{H}}\\gdef\\eps{\\varepsilon}\\gdef\\i{\\mathrm{i}}\\gdef\\unit#1{\\,\\mathrm{#1}}\\gdef\\re{\\operatorname{Re}}\\gdef\\im{\\operatorname{Im}}\\gdef\\e{\\mathrm{e}}$\n这是一篇学习笔记。\r前言 普通物理一点都不普通。\n本文适合非物竞但大概学过高中物理的同学看。\n这个课是点名 $10\\%$，作业 $30\\%$，期中 $25\\%$，期末 $35\\%$，这次好像是点了两次，都在下半学期。\n教材是费曼物理学讲义第二卷，会考的是 $1\\sim8$、$10$、$13\\sim18$、$20\\sim24$。最后会用 Microwave Engineering (Pozar) 的第三章。作业很多都取自 Introduction to Electrodynamics (Griffiths)。\n前置知识就是微积分，但其实没什么难度，知道 $\\nabla$ 相关和 Stokes 公式的原理就行，第一节课会过一遍。上半学期只讲静电学的内容，包括库仑定律、高斯定律、电多极子、含导体情况的解法、静电能、电介质。下半学期讲剩余的内容，包括安培定律、毕奥—萨伐尔定律、磁矢势、磁偶极子、静磁能、法拉第电磁感应定律、麦克斯韦方程组、电磁波、交流电路、谐振腔、波导。期末会考上半学期中的电介质。\n上课的 ppt 基本是照着教材写，讲也是照着讲。作为初学者，我经常会不明白为什么某个物理图景能用这个公式去刻画，或者没搞清楚讲的对象或（一些用于简化问题的）假设是什么，或者为什么突然要提这个例子。听过很多人说费曼物理学讲义其实不适合初学者，书里举的一些例子和内容的详略安排都是给完整学过一遍基础知识的人看的，视角比较高，为的是看到一些更本质的东西。\n我的笔记里会尽量讲清一些例子它严谨的推理过程是怎样的，另外有一些例子比如涉及玻尔玆曼分布之类的，不会考。\n建议从一开始就跟着进度看 Introduction to Electrodynamics。\n作业平均六道，可能会放一道比较难的。\n听说去年考试是期中巨难，今年是期中巨简单期末巨难，难到那种非物竞生容易不及格的那种。可以做好在若干节课和某次考试中心态爆炸的准备。当然过难肯定是会调分的。\n关于考试的一些 tips：\n复习基本公式的推导，与基本原理相关的一些例子，比如为什么导体表面越尖锐电荷密度越大。考试第一题是四个小简答题，会问这种。 简单的考试会出作业题或作业题改编。 需要练熟练度，强推。 保证会做的做对。 课上讲了但不考的知识点：\n一些需要用到普物一知识的例子 推迟势 圆柱形谐振腔 课上没讲的一些知识点：\n张量 狄拉克 $\\delta$ 函数（记了） 调和函数 保角变换（记了） 介质中的电像法（期末） 磁标势 磁多极子（记了） 偶极子的受力 磁介质 含介质情况的麦克斯韦方程组 含介质情况的能量 平面波导、圆柱形波导 谐振腔和波导的能量耗散（期末） 能量密度（期末） 坡印廷矢量 电磁场的动量 电磁场的相对论变换及麦克斯韦方程组的相对论形式 真正解一般情况下的麦克斯韦方程组，例如一个匀速直线运动电荷引起的电磁场 有空多复习 ppt 和作业，多刷《大题典》，不要像我这样记太多笔记。\n我的 cheat sheet\n致谢 Huge thanks to mjy, zzy, lhz, psy, qkx. 感谢你们解答了我这么多傻逼问题。\n第一节课 物理思想 数学和物理的差异：\n牛顿力学和电磁学的视角的差异：\n光的波粒二象性 延迟选择实验。\n浅灰色的是半透镜，透 $50\\%$ 反 $50\\%$。如果右上没有半透镜，那么两个光屏上各 $50\\%$，这体现出光的粒子性（左下处 $50\\%$ 向右，$50\\%$ 向上）。如果右上有，那么会发生干涉，导致两个光屏的亮度不同（尽管和为 $100\\%$）。\n问题：第二个半透镜处的干涉是如何发生的？\n答案。例如两束入射第二个半透镜的光线的振幅分别为 $\\frac A{\\sqrt{2}}\\sin(\\omega x+\\varphi_1)$ 和 $\\frac A{\\sqrt{2}}\\sin(\\omega x+\\varphi_2)$。那么两束出射光线就会是 $\\frac A2[\\sin(\\omega x+\\varphi_1)+\\sin(\\omega x+\\varphi_2)]$ 和 $\\frac A2[\\sin(\\omega x+\\varphi_1+\\pi)+\\sin(\\omega x+\\varphi_2)]$，两者振幅分别为 $A\\cos\\frac{\\varphi_1-\\varphi_2}2$ 和 $A\\sin\\frac{\\varphi_1-\\varphi_2}2$，符合强度之和为 $A^2$ 的守恒性。\n追问：两束相位差为 $\\pi$ 的光干涉，不就违反能量守恒了吗？https://www.zhihu.com/question/525841505/answer/2424533220\n场的数学描述 老问题：为什么场线（本质是积分曲线）的密度可以体现场强？\n答：我们要明确的是，当我们说“场线越密场强越强”时，我们说的对象是“同一束场线”。\n假设场是连续的。对于同一束场线，考虑它们所处的两个“截”曲面（实际上这个截面是无数条场线形成的，形成方法是每个点处的场线都是截面在该处切面的法向量），密度越密，截面面积越小，而因为是同一束场线，故通量相等，故场强越大。\n练习：证明 $\\nabla T(\\b x_0)$ 与 $T(\\b x_0)$ 所在的等高线（面）在 $\\b x_0$ 处的切线（面）垂直。\n事实上，$n-1$ 维超平面的法向量就是用 $\\nabla$ 定义的，所以是弱智。\n详细说一下，$T(\\b x_0)$ 所在的等高线（面）$T(\\b x)=T(\\b x_0)$ 在 $\\b x_0$ 处的切面，这个切面中的所有向量 $\\Delta\\b x$，它们都是形如“从 $\\b x_0$ 出发往 $\\b x_0$ 方向走，近似看来不会使 $T(\\b x_0+\\Delta x)$ 变化”，用数学语言说，就是 $\\nabla T(\\b x_0)\\cdot\\Delta\\b x=0$。\n矢量分析 基本定义 梯度（gradient）标量→矢量 $$ \\nabla f=\\left(\\frac{\\p f}{\\p x},\\frac{\\p f}{\\p y},\\frac{\\p f}{\\p z}\\right) $$\n散度（divergence）矢量→标量 $$ \\nabla\\cdot\\b F=\\frac{\\p\\b F_x}{\\p x}+\\frac{\\p\\b F_y}{\\p y}+\\frac{\\p\\b F_z}{\\p z} $$\n旋度（curl）矢量→矢量 $$ \\nabla\\times\\b F=\\left(\\frac{\\p\\b F_z}{\\p y}-\\frac{\\p\\b F_y}{\\p z},\\frac{\\p\\b F_x}{\\p z}-\\frac{\\p\\b F_z}{\\p x},\\frac{\\p\\b F_y}{\\p x}-\\frac{\\p\\b F_x}{\\p y}\\right) $$\n通量（flux） $$ \\Phi=\\iint_S\\b F\\cdot\\d\\b s $$\n环量（circulation） $$ \\Gamma=\\oint_L\\b F\\cdot\\d\\b l $$\n当我们把 $\\nabla$ 当作一个“向量算子”时，我们的依据是，点乘和叉乘在空间变换下形式不变，而与偏导相关的也是如此。\n接下来，我们要做的，就是借助通量和环量的几何直观，证明散度和旋度的几何直观。\nStokes 公式相关 Gauss 公式 显然，一个大曲面的通量可以拆分成多个小曲面的通量之和。考虑一个极小立方体（左下角所处位置 $(x,y,z)$）。\n两个 $yz$ 平面的通量为 $[\\b F_x(x+\\d x,y,z)-\\b F_x(x,y,z)]\\d y\\d z$。\n注意，这里 $x+\\d x$ 和 $x$ 要区分，而 $y$、$z$ 不需要区分。\n这个式子可以写成 $\\frac{\\p\\b F_x}{\\p x}\\d x\\d y\\d z$。其余两个方向同理。\n于是 $$ \\oiint_S\\b F\\cdot \\d\\b s=\\iiint_{V}\\left(\\frac{\\p\\b F_x}{\\p x}+\\frac{\\p\\b F_y}{\\p y}+\\frac{\\p\\b F_z}{\\p z}\\right)\\d v=\\iiint_V(\\nabla\\cdot\\b F)\\d v $$ 那么在一个实际的矢量场中，我们认为场的分布是连续的，那么我们认为一个点 $(x,y,z)$ 附近的每个点和它的性质是相近的，所以我们认为 $\\Phi=VQ$，这里 $Q$ 就是我们希望得到的“体积流率”。对上式两侧除以 $V$ 并 $V\\to 0$，得 $Q=\\nabla\\times\\b F$。这就是散度的物理意义——一个点出流的量。\nGreen 公式 \u0026amp; Stokes 公式 同样，闭曲线的环量也可以拆分。先看二维情况，考虑一个极小正方形。\n环量为 $(\\b F_x(x,y)-\\b F_x(x,y+\\d y))\\d x+(\\b F_y(x+\\d x,y)-\\b F_y(x,y))\\d y=\\left(\\frac{\\p\\b F_y}{\\p x}-\\frac{\\p\\b F_x}{\\p y}\\right)\\d x\\d y$。\n于是有 $$ \\oint_L\\b F\\cdot\\d\\b l=\\iint_S\\left(\\frac{\\p\\b F_y}{\\p x}-\\frac{\\p\\b F_x}{\\p y}\\right)\\d s $$ 那么对于三维的情况，如果只考虑 $xy$ 平面，那么得到的是旋度的 $z$ 方向（根据旋转方式—转轴的右手定则）。因此考虑另两维，就得到的完整的公式。对于理解“拆分维度分量”有困难的情况，我们可以这样考虑：一般化面积微元，设小块是两边为 $\\b d_1,\\b d_2$ 的平行四边形。环量为 $$ \\begin{align*} \u0026amp;(\\b F(\\b x)-\\b F(\\b x+\\b d_2))\\cdot\\b d_1+(\\b F(\\b x+\\b d_1)-\\b F(\\b x))\\cdot\\b d_2\\\\ ={}\u0026amp;-(\\nabla\\cdot\\b F_x\\cdot\\b d_2,\\nabla\\cdot\\b F_y\\cdot\\b d_2,\\nabla\\cdot\\b F_z\\cdot\\b d_2)\\cdot\\b d_1+(\\nabla\\cdot\\b F_x\\cdot\\b d_1,\\nabla\\cdot\\b F_y\\cdot\\b d_1,\\nabla\\cdot\\b F_z\\cdot\\b d_1)\\cdot\\b d_2\\\\ ={}\u0026amp;-\\b d_1\\J_{\\b F}\\b d_2^\\top+\\b d_2\\J_{\\b F}\\b d_1^\\top\\\\ ={}\u0026amp;\\sum\\frac{\\p\\b F_i}{\\p x_j}({\\b d_2}_i{\\b d_1}_j-{\\b d_1}_i{\\b d_2}_j)\\\\ ={}\u0026amp;\\left(\\frac{\\p\\b F_z}{\\p y},\\frac{\\p\\b F_x}{\\p z},\\frac{\\p\\b F_y}{\\p x}\\right)\\cdot(\\b d_1\\times\\b d_2)-\\left(\\frac{\\p\\b F_y}{\\p z},\\frac{\\p\\b F_z}{\\p x},\\frac{\\p\\b F_x}{\\p y}\\right)\\cdot(\\b d_1\\times\\b d_2)\\\\ ={}\u0026amp;(\\nabla\\times\\b F)\\cdot(\\b d_1\\times\\b d_2) \\end{align*} $$\n而这个 $\\b d_1\\times\\b d_2$ 就是面积向量。因此我们得到 $$ \\oint_L\\b F\\cdot\\d\\b l=\\iint_S(\\nabla\\times\\b F)\\cdot\\d\\b s $$ 同样，考虑不断缩小面积 $S$，就可以得到旋度的物理意义：一个点周围单位面积旋转的强度（这个强度是相对于转轴而言的，由旋度点乘转轴方向得到的，可以类比梯度），其中最强的就是与旋度同向的转轴。\n无旋场 $$ \\boxed{\\nabla\\times(\\nabla f)=\\b 0} $$\n梯度的旋度等于 $0$，直觉，沿着某个方向增加的场不会侧向旋转。\n换句话说，梯度场一定是无旋场。\n接下来说明，无旋场一定是某个梯度场。\n对于无旋场 $\\b F$，它是路径无关的，因为由格林公式， $$ \\oint_L\\b F\\cdot\\d\\b l=\\iint_S(\\nabla\\times\\b F)\\cdot\\d\\b s=0 $$ 那么，构造函数 $f$： $$ f(\\b x)=\\int_{\\b x_0}^{\\b x}\\b F\\cdot\\d\\b l $$ 其中 $\\b x_0$ 是任选的一个点。\n这里，能用上下限的形式来表示大于一维空间的积分，其良定义性是由路径无关保证的。具体而言：\n定义 $$ \\int_{\\b x_1}^{\\b x_2}\\nabla f\\cdot\\d\\b l=\\int_{\\b x_1}^{\\b x_2}\\d f=f(\\b x_2)-f(\\b x_1) $$\n现在，显然有 $\\nabla f=\\b F$（严格证明）。\n另外，保守场意味着，任意回路的环量都是 $0$。由于回路可以任取，故必须要求 $\\nabla\\times\\b F$ 处处为 $\\b 0$。\n一句话概括：梯度场 $\\Longleftrightarrow$ 无旋场 $\\Longleftrightarrow$ 保守场。\n例 1 考虑静电场。这里，电场力就是上文的 $\\b F$。\n证明对于单个点电荷，其形成的电场无旋： $$ \\b F=-\\frac{kQ\\b r}{|\\b r|^3}\\\\ \\frac{\\p\\b F_x}{\\p y}=3kQ\\frac{xy}{|\\b r|^5}=\\frac{\\p\\b F_y}{\\p x} $$ 我们也可以从环路积分的角度验证它无旋。\n那现在，我们就可以定义电势，这里定义的积分是 $\\int_{\\b x}^{无穷远处}$。得到 $$ \\varphi=-\\frac{kQ}{|\\b r|} $$\n无散场 $$ \\boxed{\\nabla\\cdot(\\nabla\\times\\b F)=0} $$\n旋度的散度等于 0，直觉，旋转的场不会有起点和终点。可以从磁场的角度理解——磁感线一定是闭合的。\n无散场有性质 $$ \\oiint_S\\b F\\cdot\\d\\b s=\\iiint_V(\\nabla\\cdot\\b F)\\d v=0 $$ 不是特别好用“保守”之类的说法描述。\n然后无散场一定是某个矢量场的旋度（这样的一个旋度被称为矢量势能）。证明如下：\n设 $\\b F=\\nabla\\times\\b f$。令 $\\b f_z=0$。方程化为 $$ \\left\\{\\begin{align*} -\\frac{\\p\\b f_y}{\\p z}\u0026amp;=\\b F_x\\\\ \\frac{\\p\\b f_x}{\\p z}\u0026amp;=\\b F_y\\\\ \\frac{\\p\\b f_y}{\\p x}-\\frac{\\p\\b f_x}{\\p y}\u0026amp;=\\b F_z \\end{align*}\\right. $$ 所以可以取 $$ \\left\\{ \\begin{align*} \\b f_x\u0026amp;=\\int_{z_0}^z\\b F_y\\d t_z+C_x(x,y)\\\\ \\b f_y\u0026amp;=-\\int_{z_0}^z\\b F_x\\d t_z+C_y(x,y) \\end{align*} \\right. $$ 代入最后一式，得 $$ -\\int_{z_0}^z\\left(\\frac{\\p\\b F_x}{\\p x}+\\frac{\\p\\b F_y}{\\p y}\\right)\\d t_z+\\frac{\\p C_y}{\\p x}-\\frac{\\p C_x}{\\p y}=\\b F_z $$ 取 $C_x\\equiv 0$，那么 $$ \\begin{align*} \\frac{\\p C_y}{\\p x}\u0026amp;=\\b F_z+\\int_{z_0}^z\\left(\\frac{\\p\\b F_x}{\\p x}+\\frac{\\p\\b F_y}{\\p y}\\right)\\d t_z\\\\ \u0026amp;=\\b F_z-\\int_{z_0}^z\\frac{\\p\\b F_z}{\\p z}\\d t_z\\\\ \u0026amp;=\\left.\\b F_z\\right|_{z=z_0} \\end{align*} $$ 这保证了 $C_y$ 与 $z$ 维无关，否则就无解了。\n因此 $$ C_y(x,y)=\\int_{x_0}^x\\b F_z(t_x,y,z_0)\\d t_x $$ 同时，任何 $f+\\nabla C$ 都是解。\n最后我们给出 Helmholtz decomposition：\n任何一阶微分连续的向量场，都可以表示为一个无旋场和无散场的叠加。\n常用公式 见 cheat sheet。\n一些技巧 $$ \\nabla\\cdot(\\b g\\times\\b f)=\\nabla_{\\b g}\\cdot(\\b g\\times\\b f)+\\nabla_{\\b f}\\cdot(\\b g\\times\\b f)=\\b f\\cdot(\\nabla\\times\\b g)-\\b g\\cdot(\\nabla\\times\\b f)\\\\ \\nabla\\times(\\b g\\times\\b f)=\\nabla_{\\b g}\\times(\\b g\\times\\b f)+\\nabla_{\\b f}\\times(\\b g\\times\\b f)=(\\b f\\cdot\\nabla)\\b g-(\\nabla\\cdot\\b g)\\b f+(\\nabla\\cdot\\b f)\\b g-(\\b g\\cdot\\nabla)\\b f $$\n遇到 $\\nabla\\circ(\\b f_1\\circ\\b f_2)$ 形式，其展开式中，每个单项式都形如 $$ \\frac{\\p({\\b f_1}_i{\\b f_2}_j)}{\\p x_k} $$ 因此它一定能拆成两个只对其中一个项求偏导之和的形式。因此上文中 $\\nabla_{\\b g}$、$\\nabla_{\\b f}$ 的意思就是说，“碰到 $\\b g/\\b f$ 才偏导，另一个直接数乘”。这个方便记忆，推导不是很正规。\n关于求电场和电势，各有三种方法：① 直接积分；② 高斯定律+对称性；③ $-\\nabla\\varphi$。① 直接积分；② $\\nabla^2\\varphi=-\\rho/\\eps_0$；③ $\\int\\b E$。\n曲线坐标系相关 当时我在看这个的时候很困惑，其实只需要明确几点原则就行：曲线坐标系里的向量是有起点的，不是平移不变的。向量坐标直接运算是没有意义的，因此（除非起点为原点，这时向量就表示位置）向量的终点也没有意义，只是表示朝向和大小。曲线坐标系里分基向量和单位基向量。各处的基向量不同。这个课里只考虑各单位向量均互相垂直的坐标系，包括极坐标系、柱坐标系、球坐标系。\n接下来以球坐标系 $\\rho\\theta\\phi$ 为例。\n对于一个位置 $\\b r$，定义各基向量为 $$ \\b e_i=\\frac{\\p\\b r}{\\p x_i} $$ 其中 $x_i$ 表示某维。对于具体情况一般习惯写 $\\b e_\\rho$、$\\b e_\\theta$、$\\b e_\\phi$ 或 $\\b\\rho$、$\\b\\theta$、$\\b\\phi$。\n定义单位基向量为单位化的基向量。基向量的模长称为拉梅系数 $h_i$。单位基向量写作 $\\b{\\hat e}_\\rho$ 等或 $\\b{\\hat\\rho}$ 等。这篇笔记里我们统一把单位基向量写成后面这种，包括直角坐标系。\n在球坐标系中，$h_\\rho=1$，$h_\\theta=\\rho$，$h_\\phi=\\rho\\sin\\theta$。“定义”全微分 $$ \\d\\b r=\\b\\rho\\d\\rho+\\b\\theta\\d\\theta+\\b\\phi\\d\\phi=\\b{\\hat\\rho}h_\\rho\\d\\rho+\\b{\\hat\\theta}h_\\theta\\d\\theta+\\b{\\hat\\phi}h_\\phi\\d\\phi $$ 求各种微分形式（这个词能这么用吗…）的球面坐标表示，可以把直角坐标系的表达式用坐标变换公式转过去，期间用多元函数的链式求导法则把 $/\\p x$ 变成 $/\\p\\rho$ 等。一个更直接的方法就是，我们知道，比如说 $$ \\nabla f\\cdot\\b{\\hat\\phi}=\\frac{\\nabla f\\cdot\\b\\phi}{h_\\phi}=\\frac1{h_\\phi}\\frac{\\p f}{\\p\\phi} $$ 第二个等号是因为梯度的定义。所以 $$ \\nabla=\\frac{\\b{\\hat\\rho}}{h_\\rho}\\frac{\\p}{\\p\\rho}+\\frac{\\b{\\hat\\theta}}{h_\\theta}\\frac{\\p}{\\p\\theta}+\\frac{\\b{\\hat\\phi}}{h_\\phi}\\frac{\\p}{\\p\\phi} $$ 其实基于各基向量垂直，这个是很直观的。\n求散度、旋度这些，一种思路是，还是像上面这样，但是注意到 $\\p{\\b{\\hat x}_i}/\\p x_j$ 这种东西的结果不是 $\\b 0$。通过转直角坐标系求出它们之后就简单了。\n所以为什么三种 $\\nabla$ 都可以用这个式子呢？或者应该问为什么 $\\nabla$ 在不同坐标系下有某个不变性呢？\n看到过有同学用更简洁的方法推 $\\nabla^2$，好像是用的一些更高端的方法。\n静电学的基本公式 电势的思想略，这边默认会高中的内容。\n高斯定律 $$ \\left\\{\\begin{align*} \\nabla\\cdot\\b E\u0026amp;=\\frac{\\rho}{\\eps_0}\\\\ \\nabla\\times\\b E\u0026amp;=-\\frac{\\p\\b B}{\\p t}\\\\ \\nabla\\cdot\\b B\u0026amp;=0\\\\ \\nabla\\times\\b B\u0026amp;=\\mu_0\\b j+\\mu_0\\eps_0\\frac{\\p\\b E}{\\p t} \\end{align*}\\right. $$\n当 $\\b E$ 和 $\\b B$ 都是恒定时，方程变为 $$ \\left\\{\\begin{align*} \\nabla\\cdot\\b E\u0026amp;=\\frac{\\rho}{\\eps_0}\\\\ \\nabla\\times\\b E\u0026amp;=0\\\\ \\nabla\\cdot\\b B\u0026amp;=0\\\\ \\nabla\\times\\b B\u0026amp;=\\mu_0\\b j \\end{align*}\\right. $$ 于是电磁场就分开了。\n$\\rho$（电荷密度）确定了 $\\Rightarrow$ 散度和旋度都确定了 $\\Rightarrow$ 电场确定了（除了加常数，说明）\n电荷是量子化的——油滴实验\n电场是保守场，这个和 $\\nabla\\times\\b E=\\b 0$ 对应，这意味着，单个点电荷的电场一定是与 $\\b r$ 共线的。虽然如此，具体的强度（平方反比）没有要求，因此还需要另一个方程。为什么说 $\\nabla\\cdot\\b E=\\rho/\\eps_0$ 限制了平方反比呢？考虑圆心上有个点电荷的球面： $$ \\Phi=\\oiint_S\\b E\\d\\b s=4\\pi r^2\\cdot\\frac{q}{4\\pi\\eps_0r^2}=\\frac{q}{\\eps_0} $$ 只有平方，才能使电通量与球半径无关。诶，可以类比光通量。\n库仑定律（$\\b F=\\frac{1}{4\\pi\\eps_0}\\frac{q_1q_2}{|\\b r|^3}\\b r$）和叠加定律，和麦克斯韦方程组的前两个可以互推。\n这里 $\\eps_0\\approx 8.85\\times 10^{-12}\\unit{C^2/(N\\cdot m^2)}$ 是真空的介电常数。注意量纲！\n推导 关键式子：对于 $\\b r\\ne\\b r_0$， $$ \\nabla\\cdot\\frac{\\b r-\\b r_0}{|\\b r-\\b r_0|^3}=\\frac{\\nabla\\cdot(\\b r-\\b r_0)}{|\\b r-\\b r_0|^3}+(\\nabla\\frac{1}{|\\b r-\\b r_0|^3})\\cdot(\\b r-\\b r_0)=\\frac{3}{|\\b r-\\b r_0|^3}-\\frac{3(\\b r-\\b r_0)\\cdot(\\b r-\\b r_0)}{|\\b r-\\b r_0|^5}=0\\\\ \\nabla\\times\\frac{\\b r-\\b r_0}{|\\b r-\\b r_0|^3}=\\frac{\\nabla\\times(\\b r-\\b r_0)}{|\\b r-\\b r_0|^3}+(\\nabla\\frac{1}{|\\b r-\\b r_0|^3})\\times(\\b r-\\b r_0)=\\b 0+\\frac{3(\\b r-\\b r_0)\\times(\\b r-\\b r_0)}{|\\b r-\\b r_0|^5}=\\b 0 $$\n（有些书里会管 $\\b r-\\b r^\\prime$ 叫花体的 r）\n库仑定律 $+$ 叠加定律 $\\Rightarrow$ 高斯定律积分形式：（$V^\\prime\\subseteq V$，$B_\\eps(\\cdot)$ 是球，$S_\\eps(\\cdot)$ 是球面） $$ \\begin{align*} \\Phi(V^\\prime)\u0026amp;=\\oiint_{\\p V^\\prime}\\b E(\\b r)\\cdot\\d\\b s\\\\ \u0026amp;=\\oiint_{\\p V^\\prime}\\iiint_{V}\\frac{\\rho(\\b r^\\prime)\\d v}{4\\pi\\eps_0}\\cdot\\frac{\\b r-\\b r^\\prime}{|\\b r-\\b r^\\prime|^3}\\cdot\\d\\b s\\\\ \u0026amp;=\\oiint_{\\p V^\\prime}\\iiint_{V^\\prime}\\frac{\\rho(\\b r^\\prime)\\d v}{4\\pi\\eps_0}\\cdot\\frac{\\b r-\\b r^\\prime}{|\\b r-\\b r^\\prime|^3}\\cdot\\d\\b s\\\\ \u0026amp;+\\oiint_{\\p V^\\prime}\\iiint_{V\\setminus V^\\prime}\\frac{\\rho(\\b r^\\prime)\\d v}{4\\pi\\eps_0}\\cdot\\frac{\\b r-\\b r^\\prime}{|\\b r-\\b r^\\prime|^3}\\cdot\\d\\b s\\\\ \u0026amp;=\\iiint_{V^\\prime}\\frac{\\rho(\\b r^\\prime)\\d v}{4\\pi\\eps_0}\\oiint_{\\p V^\\prime}\\frac{\\b r-\\b r^\\prime}{|\\b r-\\b r^\\prime|^3}\\cdot\\d\\b s\\\\ \u0026amp;+\\iiint_{V^\\prime}\\d v^\\prime\\boxed{\\nabla\\cdot\\iiint_{V\\setminus V^\\prime}\\frac{\\rho(\\b r^\\prime)\\d v}{4\\pi\\eps_0}\\cdot\\frac{\\b r-\\b r^\\prime}{|\\b r-\\b r^\\prime|^3}}_{=0}\\\\ \u0026amp;=\\iiint_{V^\\prime}\\frac{\\rho(\\b r^\\prime)\\d v}{4\\pi\\eps_0}\\left(\\boxed{\\oiint_{\\p(V^\\prime\\setminus B_\\delta(\\b r^\\prime))}\\frac{\\b r-\\b r^\\prime}{|\\b r-\\b r^\\prime|^3}\\cdot\\d\\b s}_{=0}+\\oiint_{S_\\delta(\\b r^\\prime)}\\frac{\\b r-\\b r^\\prime}{|\\b r-\\b r^\\prime|^3}\\cdot\\d\\b s\\right)\\\\ \u0026amp;=\\iiint_{V^\\prime}\\frac{\\rho(\\b r^\\prime)\\d v}{4\\pi\\eps_0}\\oiint_{S_\\delta(\\b r^\\prime)}\\frac{\\d\\b n}{\\delta^2}\\\\ \u0026amp;=\\iiint_{V^\\prime}\\frac{\\rho(\\b r^\\prime)}{\\eps_0}\\d v \\end{align*} $$ 高斯定律积分形式 $\\Rightarrow$ 高斯定律微分形式： $$ \\iiint_{V^\\prime}\\nabla\\cdot\\b E(\\b r)\\d v=\\oiint_{\\p V^\\prime}\\b E(\\b r)\\cdot\\d\\b s=\\iiint_{V^\\prime}\\frac{\\rho(\\b r^\\prime)}{\\eps_0}\\d v\\\\ \\Downarrow\\\\ \\nabla\\cdot\\b E=\\frac{\\rho}{\\eps_0} $$\n高斯定律 $\\Rightarrow$ 库仑定律：太简单了。注意空间中不能弥漫着一个常数矢量的电场，否则就违反了球面对称性。\n库仑定律 $+$ 叠加定律 $\\Rightarrow$ 无旋性质：这里我们就只推单点电荷的了。（以下，$S$ 是包含 $\\b r_0$ 的任意曲面） $$ \\begin{align*} \u0026amp;\\oint_{\\p S}\\b E(\\b r)\\cdot\\d\\b l\\\\ ={}\u0026amp;\\boxed{\\iint_{S\\setminus B_\\delta(\\b r_0)}(\\nabla\\times\\b E(\\b r))\\cdot\\d\\b s}_{=0}+\\oint_{\\p(S\\cap B_\\delta(\\b r_0))}\\b E(\\b r)\\cdot\\d\\b l\\\\ ={}\u0026amp;\\oint_{S\\cap S_\\delta(\\b r_0)}\\frac{q}{4\\pi\\eps_0}\\frac{\\boxed{(\\b r-\\b r_0)\\cdot\\d\\b l}_{=0}}{|\\b r-\\b r_0|^3}\\\\ ={}\u0026amp;0 \\end{align*} $$\n这个利用的是球面上的切向量与径向量垂直。然后再比对： $$ 0=\\oint_{\\p S}\\b E(\\b r)\\cdot\\d\\b l=\\iint_S(\\nabla\\times\\b E(\\b r))\\cdot\\d\\b s $$ 这看起来像废话，如果把单个电荷换成连续分布的电荷密度就显得不是废话了，我只是懒得写了。\n最后提一句，高斯定律必须在有界区域上用，不然你考虑一个点电荷的球邻域的补，它就爆了。\n狄拉克 δ 函数 我们注意到，上面的推导核心思路是这样的：\n利用 Stokes 公式家庭在两个维数之间转化，充分利用关键式子，将与中心相离的部分扔掉，剩下中心的一个球形邻域，利用球的性质直接搞掉。最后再利用 Stokes 公式家庭，比对两个积分式，得出微分形式的结果。\n这里我们逃不开比对，有什么好的方法吗？我们要引入狄拉克 $\\delta$ 函数。\n定义\n这里最关键的两个事是：\n$$ \\begin{align*} \u0026amp;\\forall a\u0026lt;b\\in\\R\\cup\\set{\\pm\\infty}\\setminus\\set{0},\\lim_{n\\to\\infty}\\int_a^b\\delta_n(x)\\d x=[0\\in(a,b)]\\\\ \\Longrightarrow{}\u0026amp;\\forall f\\in C(\\R),\\lim_{n\\to\\infty}\\int_{-\\infty}^{+\\infty}\\delta_n(x)f(x)=f(0) \\end{align*} $$\n当我们说一个玩意 $*$ 等于 $\\delta(x)$ 之类的东西的时候，我们本质上在说的是存在一种通过狄拉克 $\\delta$ 函数列逼近 $*$ 的方式。\n所以说回来，之所以 $$ \\nabla\\cdot\\left(\\frac{\\b{\\hat r}}{r^2}\\right)=4\\pi\\delta^3(\\b r) $$ （这里 $\\b{\\hat r}$ 指被单位化过的 $\\b r$）是因为我们存在一系列，例如说 $$ \\left\\{{\\frac{4}{3}\\pi\\delta_i^3f_i(\\b x)=\\iiint_{B_{\\delta_i}(\\b x)}\\nabla\\cdot\\left(\\frac{\\b{\\hat r}}{r^2}\\right)\\d v=\\oiint_{S_{\\delta_i}(\\b x)}\\frac{\\b{\\hat r}}{r^2}\\cdot\\d\\b s=\\big([|\\b x|\u0026lt;\\delta_i]+[|\\b x|\\le\\delta_i]\\big)2\\pi}\\right\\} $$ （其中 $\\set{\\delta_i}$ 趋近于 $0$）这样的函数列 $\\set{f_i(\\b x)}$，它一方面趋近于 $\\nabla\\cdot(\\b{\\hat r}/r^2)$，一方面符合狄拉克 $\\delta$ 函数列的定义的三次方 $4\\pi$ 倍，于是就可以画上一个等号，意思是说 $\\nabla\\cdot(\\b{\\hat r}/r^2)$ 的行为和一般的狄拉克 $\\delta$ 函数类似，能够替换。注意 $\\delta^3(\\b r)=\\delta(x)\\delta(y)\\delta(z)$。\n这时， $$ \\begin{align*} \\nabla\\cdot\\b E(\\b r)\u0026amp;=\\iiint_V\\frac{\\rho(\\b r^\\prime)\\d v}{4\\pi\\eps_0}\\left(\\nabla\\cdot\\frac{\\b r-\\b r^\\prime}{|\\b r-\\b r^\\prime|^3}\\right)\\\\ \u0026amp;=\\iiint_V\\frac{\\rho(\\b r^\\prime)\\d v}{\\eps_0}\\delta^3(\\b r-\\b r^\\prime)\\\\ \u0026amp;=\\frac{\\rho(\\b r^\\prime)}{\\eps_0} \\end{align*} $$\n这个时候你会感觉，我好像说了很多，但好像又什么也没说。这里的问题在于，不平凡的推导部分本质上是 狄拉克 $\\delta$ 函数的常规定义（其他地方（积分）趋近于 $0$，整个积分（趋近于）为 $1$）$\\Longrightarrow$ 它的卷积“萃取”性质。但这个我不会证（悲）\n但是在这里具体的情况下还是可以证的： $$ \\nabla\\cdot\\b E(\\b r)=\\lim_{\\delta\\to 0^+}\\left[\\boxed{\\iiint_{V\\setminus B_\\delta(\\b r)}\\frac{\\rho(\\b r^\\prime)\\d v}{4\\pi\\eps_0}\\left(\\nabla\\cdot\\frac{\\b r-\\b r^\\prime}{|\\b r-\\b r^\\prime|^3}\\right)}_{=0}+\\nabla\\cdot\\iiint_{B_\\delta(\\b r)}\\frac{\\rho(\\b r^\\prime)\\d v}{4\\pi\\eps_0}\\frac{\\b r-\\b r^\\prime}{|\\b r-\\b r^\\prime|^3}\\right] $$ 注意，这里 $\\nabla$ 并非对 $B_\\delta(\\b r)$、$\\rho(\\b r)$、$(\\b r-\\b r^\\prime)/|\\b r-\\b r^\\prime|^3$ 这三者都求导，只是对最后一个求。如果要都求会导致 $\\rho$ 提不出来。\n由于 $\\rho$ 是连续函数，故在 $B_{\\delta}(\\b r)$ 上一致连续，把这个连续和左边 $\\lim$ 的 $\\eps-\\delta$ 定义写开来搞一搞，可以得到 $$ \\begin{align*} \\nabla\\cdot\\b E(\\b r)\u0026amp;=\\frac{\\rho(\\b r)}{4\\pi\\eps_0}\\lim_{\\delta\\to 0^+}\\left(\\nabla\\cdot\\iiint_{B_\\delta(\\b r)}\\frac{\\b r-\\b r^\\prime}{|\\b r-\\b r^\\prime|^3}\\d v\\right)\\\\ \u0026amp;=\\frac{\\rho(\\b r)}{4\\pi\\eps_0}\\lim_{\\delta\\to 0^+}\\left(\\iiint_{B_\\delta(\\b r)}\\nabla_{\\b r}\\cdot\\frac{\\b r-\\b r^\\prime}{|\\b r-\\b r^\\prime|^3}\\d v\\right)\\\\ \u0026amp;=-\\frac{\\rho(\\b r)}{4\\pi\\eps_0}\\lim_{\\delta\\to 0^+}\\left(\\iiint_{B_\\delta(\\b r)}\\nabla_{\\b r^\\prime}\\cdot\\frac{\\b r-\\b r^\\prime}{|\\b r-\\b r^\\prime|^3}\\d v\\right)\\\\ \u0026amp;=-\\frac{\\rho(\\b r)}{4\\pi\\eps_0}\\lim_{\\delta\\to 0^+}\\oiint_{S_\\delta(\\b r)}\\frac{\\b r-\\b r^\\prime}{|\\b r-\\b r^\\prime|^3}\\cdot\\d\\b s\\\\ \u0026amp;=-\\frac{\\rho(\\b r)}{4\\pi\\eps_0}(-4\\pi)=\\frac{\\rho(\\b r)}{\\eps_0} \\end{align*} $$ 写完上式后，我不禁开始问自己，在处理这种无穷的时候，我们本质上在做什么？就是在积分时把未定义点抠掉。这个抠掉并不会影响结果，但并不能因此就说，我们可以利用 $\\nabla\\cdot(\\b{\\hat r}/r^2)=0$ 把整个式子都化成零，因为 $\\nabla$，求导，它是一个极限过程。尽管极限过程中不断有邻域外的部分贡献变为 $0$，但邻域内永远是有贡献的。那这里我们发现这个贡献恒为 $4\\pi$。所以严谨地来说，这里的积分区域应当去掉 $\\set{\\b r}$，然后 $\\nabla$ 不能直接换进积分里，只能在外面展开成 $\\lim$。狄拉克 $\\delta$ 函数，其实就是在允许 $\\nabla$ 换进积分的同时，保证极限过程不丢。于是其实可以这样严谨地写： $$ \\begin{align*} \\nabla\\cdot\\b E(\\b r_0)\u0026amp;=\\lim_{\\delta\\to 0^+}\\frac{3}{4\\pi\\delta^3}\\iiint_{B_\\delta(\\b r_0)}\\nabla\\cdot\\b E(\\b r)\\d v\\\\ \u0026amp;=\\lim_{\\delta\\to 0^+}\\frac{3}{4\\pi\\delta^3}\\oiint_{S_\\delta(\\b r_0)}\\b E(\\b r)\\cdot\\d\\b s\\\\ \u0026amp;=\\lim_{\\delta\\to 0^+}\\frac{3}{4\\pi\\delta^3}\\oiint_{S_\\delta(\\b r_0)}\\iiint_V\\frac{\\rho(\\b r^\\prime)\\d v}{4\\pi\\eps_0}\\cdot\\frac{\\b r-\\b r^\\prime}{|\\b r-\\b r^\\prime|^3}\\cdot\\d\\b s\\\\ \u0026amp;=\\lim_{\\delta\\to 0^+}\\frac{3}{4\\pi\\delta^3}\\iiint_V\\frac{\\rho(\\b r^\\prime)\\d v}{4\\pi\\eps_0}\\oiint_{S_\\delta(\\b r_0)}\\frac{\\b r-\\b r^\\prime}{|\\b r-\\b r^\\prime|^3}\\cdot\\d\\b s\\\\ \u0026amp;=\\lim_{\\delta\\to 0^+}\\frac{3}{4\\pi\\delta^3}\\iiint_{B(\\b r_0,\\delta)}\\frac{\\rho(\\b r^\\prime)\\d v}{\\eps_0}\\\\ \u0026amp;=\\lim_{\\delta\\to 0^+}\\frac{3\\rho(\\b r_0)}{4\\pi\\delta^3}\\iiint_{B(\\b r_0,\\delta)}\\frac{\\d v}{\\eps_0}\\\\ \u0026amp;=\\frac{\\rho(\\b r_0)}{\\eps_0} \\end{align*} $$ 所以说相比积分形式，微分形式就是多了个取极限，多了个利用连续性把 $\\rho(\\cdot)$ 提出来的操作。\n同样的，旋度也可以用极限的方式来考虑。但是旋度不一样的地方在于，它涉及两个形式对称的导数的差，所以就是严格的 $0$。\n题外话 如何构造一个电场，使得一个正电荷在一处稳定平衡？\n这样一个电场直觉上，任何包含正电荷的封闭面，电通量都得是负的，这说明这个正电荷处本身得有个负电荷！\n但是交变电场是可以的，离子阱。\n如果我们在八个顶点 $(\\pm1,\\pm1,\\pm1)$ 放等量电荷，那么电场为： $$ \\b E=\\frac{q}{4\\pi\\eps_0}\\sum_{\\b x_0}\\frac{\\b x-\\b x_0}{|\\b x-\\b x_0|^3} $$\n$$ \\frac{\\p\\b E_i}{\\p x_i}=\\frac{q}{4\\pi\\eps_0}\\sum_{\\b x_0}\\left(\\frac{1}{|\\b x-\\b x_0|^3}-\\frac{3(\\b x_i-{\\b x_0}_i)^2}{|\\b x-\\b x_0|^5}\\right) $$\n$$ \\frac{\\p\\b E_i}{\\p x_j}=-\\frac{q}{4\\pi\\eps_0}\\sum_{\\b x_0}\\frac{3(\\b x_i-{\\b x_0}_i)(\\b x_j-{\\b x_0}_j)}{|\\b x-\\b x_0|^5} $$\n显然 $\\b E|_{\\b x=\\b 0}=\\b 0$，但是 $$ \\left.\\frac{\\p\\b E_i}{\\p x_i}\\right|_{\\b x=\\b 0}=\\left.\\frac{\\p\\b E_i}{\\p x_j}\\right|_{\\b x=\\b 0}=0 $$ （额，怎么爆了啊）\n别急，我们有 $$ \\left.\\frac{\\p^3\\b E_i}{\\p x_i^3}\\right|_{\\b x=\\b 0}=\\frac{224}{27\\sqrt3} $$ 也就是说 $\\varphi$ 在坐标轴方向的一、二、三阶偏导都是 $0$，而四阶 $\u0026lt;0$，所以它至少不是极小值点。所以这是不能稳定的。\n但是，如果我们将电荷限制在一个平面内，四个角摆上电荷，那么 $$ \\left.\\frac{\\p\\b E_i}{\\p x_i}\\right|_{\\b x=\\b 0}=-\\frac{1}{\\sqrt2},\\;\\left.\\frac{\\p\\b E_i}{\\p x_j}\\right|_{\\b x=\\b 0}=0 $$ 这就说明 $\\H_\\varphi(\\b 0)\u0026gt;0$，而且 $\\varphi_{xx}(\\b 0)\u0026gt;0$，从而可以稳定。\n这个事情说明，二维和三维是有本质区别的，不能把电学问题放到二维去看。\n例 1 高斯定律应用于一些常见的构形。可以记一下。\n无限长导线：显然 $\\b E\\parallel \\b d$。做一个半径为 $d$，高为 $l$ 的圆柱。 $$ 2\\pi dl\\cdot E=\\frac{l\\lambda}{\\eps_0}\\Rightarrow E=\\frac{\\lambda}{2\\pi\\eps_0d} $$ 无限大平面：显然 $\\b E\\parallel\\b d$。做一个以带点平面为对称面的，高为 $2d$，底面积为 $S$ 的柱体。 $$ 2S\\cdot E=\\frac{S\\sigma}{\\eps_0}\\Rightarrow E=\\frac{\\sigma}{2\\eps_0} $$ 半径为 $r$ 的球：显然 $\\b E\\parallel\\b d$（这里 $\\b d=\\overrightarrow{OP}$）。 $$ 4\\pi d^2\\cdot E=\\frac{\\rho\\frac{4}{3}\\pi\\min(d,r)^3}{\\eps_0}\\Rightarrow E=\\frac{\\rho\\min(d,r)^3}{3\\eps_0d^2}=\\left\\{\\begin{align*}\u0026amp;\\frac{\\rho d}{3\\eps_0},\u0026amp;d\\le r\\\\ \u0026amp;\\frac{\\rho r^3}{3\\eps_0d^2},\u0026amp;d\u0026gt;r\\end{align*}\\right. $$ 半径为 $r$ 的球壳： $$ E=\\left\\{\\begin{align*}\u0026amp;0,\u0026amp;d\u0026lt;r\\\\ \u0026amp;\\frac{\\sigma r^2}{2\\eps_0d^2}m,\u0026amp;d=r\\\\ \u0026amp;\\frac{\\sigma r^2}{\\eps_0d^2},\u0026amp;d\u0026gt;r\\end{align*}\\right. $$\n这里值得提的一点是，对于一个无限大平面，平面内的场强为 $\\b 0$。我们最好避免高斯面和带电平面有测度非零的交，不然会出现奇怪的问题。可以参见后面导体情况的讨论。\n有多个平面的结构，会出现高斯定理给出的方程不够用的情况，这是要加个对称性的方程。\n电偶极子 分析思路 考虑两个分别处于 $(0,0,\\pm d/2)$ 的，带电量相反 $\\pm Q$ 的点电荷，然后考虑较远处的电势。\n法 1：直接泰勒展开硬展。 $$ \\begin{align*} \\varphi\u0026amp;=\\frac{Q}{4\\pi\\eps_0}\\left(\\frac{1}{\\sqrt{R^2+d^2/4-Rd\\cos\\theta}}-\\frac{1}{\\sqrt{R^2+d^2/4+Rd\\cos\\theta}}\\right)\\\\ \u0026amp;=\\frac{Q}{4\\pi\\eps_0R}\\left(1+\\frac{\\cos\\theta}{2}\\frac{d}{R}-1+\\frac{\\cos\\theta}{2}\\frac{d}{R}+\\omicron\\left(\\frac dR\\right)\\right)\\\\ \u0026amp;\\approx\\frac{Qd\\cos\\theta}{4\\pi\\eps_0R^2} \\end{align*} $$ 法 2：我们可以把 $r_+$ 估成 $R-(d/2)\\cos\\theta$，把 $r_-$ 估成 $R+(d/2)\\cos\\theta$。据说可以通过几何方法证明这样只会和真正的值差高阶小量。然后 $$ \\frac{1}{r_+}=\\frac{1/R}{1-(d/2R)\\cos\\theta}=\\frac1R\\left(1+\\frac{d}{2R}\\cos\\theta+\\omicron\\left(\\frac{d}{2R}\\right)\\right) $$ 于是同样就得出上面那个式子。\n然后考虑 $\\cos\\theta$ 的几何意义——实际上就是（负电荷到正电荷的向量）和 $\\overrightarrow{OP}$ 的夹角。如果我们把前者和 $Q$ 的积称为 $\\b p$（偶极矩）的话，就可以得到（这里开始 $R$ 相关的全部小写了）： $$ \\b p=Qd\\b{\\hat z}\\\\ \\varphi=\\frac{\\b p\\cdot\\b r}{4\\pi\\eps_0r^3}\\\\ \\b E=\\frac{1}{4\\pi\\eps_0}\\left(\\frac{3(\\b p\\cdot\\b r)\\b r}{r^5}-\\frac{\\b p}{r^3}\\right) $$\n法 3：一开始正负电荷都在原点，对于正电荷来说， $$ \\varphi_0=\\frac{1}{4\\pi\\eps_0r} $$ 考虑正电荷向上移动了 $\\Delta z=d/2$。那么 $$ \\Delta\\varphi^+=\\frac{\\p\\varphi_0}{\\p z}(-\\Delta z) $$ 同理 $$ \\Delta\\varphi^-=\\frac{\\p(-\\varphi_0)}{\\p z}\\Delta z $$ 因此 $$ \\Delta\\varphi=-\\frac{\\p\\varphi_0}{\\p z}d=-\\frac{\\p}{\\p z}\\frac{Q}{4\\pi\\eps_0r}d=\\frac{Qdz}{4\\pi\\eps_0r^3}=-\\frac{1}{4\\pi\\eps_0}\\b p\\cdot\\left(\\nabla\\frac{1}{r}\\right) $$ 电四极子是电偶极子再求导。一种“离散”的电四极子的推导：\n假设中心是 $O$，然后这个在 $xy$ 平面上，边长为 $l$。先考虑单个沿 $y$ 轴的电偶极子 $$ \\varphi^{(1)}(\\b r)=\\frac{ql}{4\\pi\\eps_0}\\cdot\\frac{y}{r^3} $$ 然后往两边“分裂” $$ \\Delta\\varphi_+^{(1)}(\\b r)=\\Delta\\varphi_-^{(1)}(\\b r)=-\\frac{\\p\\varphi(\\b r)}{\\p x}\\left(\\frac{l}{2}\\right)=\\frac{3ql^2xy}{8\\pi\\eps_0r^5} $$ 于是 $$ \\varphi^{(2)}(\\b r)=\\frac{3ql^2xy}{4\\pi\\eps_0r^5} $$\n电势的多级展开 回顾多元函数的泰勒展开： $$ f(\\b x)=\\sum_{i=0}^n\\sum_{\\sum c_j=i}\\frac{1}{\\prod c_j!}\\cdot\\frac{\\p^i f}{\\p x_j^{c_j}}(\\b x_0)\\cdot\\prod(x_j-{x_0}_j)^{c_j}+\\omicron(\\lVert\\b x-\\b x_0\\rVert^n) $$ 现在考虑在原点附近，一块小的有电荷的区域（不能视作点电荷），对较远处一点 $\\b r$ 所造成的电势 $$ \\varphi(\\b r)=\\frac{1}{4\\pi\\eps_0}\\iiint_{V}\\frac{\\rho(\\b r^\\prime)\\d v}{|\\b r-\\b r^\\prime|} $$ 如果区域不在原点附近，考虑任取其中一点 $\\b r_0$，然后 $1/|\\b r-\\b r^\\prime|$ 变成 $1/|(\\b r-\\b r_0)-(\\b r^\\prime-\\b r_0)|$ 之后也是一样的，后面不讨论。\n泰勒展开当然不能直接用于 $\\b r$ 啊，那就考虑在 $\\b r$ 处展开 $f(\\b x)=1/|\\b x|$ 吧： $$ f(\\b r-\\b r^\\prime)=\\frac{1}{|\\b r|}-\\sum_{i=1}^3\\frac{\\p\\frac{1}{|\\b r|}}{\\p x_i}\\b r^\\prime_{i}+\\frac{1}{2}\\sum_{i=1}^3\\sum_{j=1}^3\\frac{\\p^2\\frac{1}{|\\b r|}}{\\p x_i\\p x_j}\\b r^\\prime_i\\b r^\\prime_j-\\cdots $$ 将积分写进来，就得到 $$ \\begin{align*} 4\\pi\\eps_0\\varphi(\\b r)\u0026amp;=\\frac{1}{|\\b r|}\\iiint_V\\rho(\\b r^\\prime)\\d v-\\sum_{i=1}^3\\frac{\\p\\frac{1}{|\\b r|}}{\\p x_i}\\iiint_{V}\\b r^\\prime_{i}\\rho(\\b r^\\prime)\\d v+\\frac{1}{2}\\sum_{i=1}^3\\sum_{j=1}^3\\frac{\\p^2\\frac{1}{|\\b r|}}{\\p x_i\\p x_j}\\iiint_V\\b r^\\prime_i\\b r^\\prime_j\\rho(\\b r^\\prime)\\d v-\\cdots\\\\ \u0026amp;=\\frac{Q}{|\\b r|}-\\left(\\nabla\\frac{1}{|\\b r|}\\right)\\cdot\\iiint_V\\b r^\\prime\\rho(\\b r^\\prime)\\d v+\\frac{1}{2}\\H_{1/|\\b r|}:\\iiint_V\\b r^\\prime\\otimes\\b r^\\prime\\rho(\\b r^\\prime)\\d v-\\cdots \\end{align*} $$ 这里我们管 $$ \\b p=\\iiint_V\\b r^\\prime\\rho(\\b r^\\prime)\\d v $$ 叫电偶极矩。可以这样理解：在计算第一项 $Q/|\\b r|$ 后，我们考虑了净电荷，但是没考虑这些电荷的空间分布。那么第二项就是对于每个 $\\b r^\\prime$，把它对应的电荷量 $\\rho(\\b r^\\prime)\\d v$ 从原点减去，然后加到它本身来，那么单个这样的东西就是我们上面说的电偶极子，全部积分起来也可以认为是。当然这一步的估算仍然是有误差的，但是电四极矩在展开式中几何意义我就不太会解释了。\n当我们在说一个系统的电偶极矩时，就有两个点需要注意：\n它的净电荷不等于 $0$，也可以有电偶极矩，即把它的电荷强制加成零之后再算。 电偶极矩的方向和大小取决于原点的选择，或者说零阶项部分视作点电荷的位置。 二阶项中的那个积分对应电四极矩是个张量 $$ \\b D_{ij}=\\iiint_V(3\\b r_i\\b r_j-\\delta_{ij}\\b r^2)\\rho(\\b r)\\d v $$ 也就是说展开式中这项一般会写成 $\\frac{1}{6}\\H:\\b D$。\n至于为什么在上面添油加醋，我也不知道，但是似乎有个相关的东西说明这个形式比较好，就是说，如果电荷分布是球面对称的，那么二阶项为零。\n如果 $\\rho(\\b r)=\\rho(r)$，那么 $i\\ne j$ 的部分直接可以变成零，而 $i=j$ 的部分有 $$ \\left\\{ \\begin{align*} \u0026amp;\\b D_{11}=\\b D_{22}=\\b D_{33}\\\\ \u0026amp;\\b D_{11}+\\b D_{22}+\\b D_{33}=0 \\end{align*} \\right. $$ 所以三者也各自等于 $0$。\n至于更后面的项，尽管知道它的表达式，但对更具体的东西（比如电八极矩该怎样添油加醋，或者 $\\nabla^k(1/|\\b r|)$ 该怎么算之类的），我就不太清楚了。\n最后给出 $$ \\H_{1/r}=\\frac{1}{r^5}\\begin{bmatrix}3x^2-r^2\u0026amp;3xy\u0026amp;3xz\\\\ 3xy\u0026amp;3y^2-r^2\u0026amp;3yz\\\\ 3xz\u0026amp;3yz\u0026amp;3z^2-r^2\\end{bmatrix} $$ $\\b D$ 会不会模仿的就是这个东西呢？\n含导体的情况 在静电平衡时，导体内部是有自由电荷的，只不过电势为零，电场强度为零，净电荷为零。只有表面有净电荷，且表面的电场强度垂直于表面。无论是内部场强非零，还是表面不垂直，都会导致自由电荷的移动。\n考虑导体时，内侧合场强为 $0$，根据高斯定理，外侧合场强为 $\\sigma/\\eps_0$，因此表面上的合场强为 $\\sigma/2\\eps_0$。如何理解呢？可以这样想：挖去当前点附近的一小块表面，这个时候，无论时内、上、外，只要足够近，它们的场强都是相等的。然后再拼上这一块，把这一块当作一个无限大带电 $\\sigma$ 的平面即可。所以可以列出两个方程，解出导体表面的场强。\n如果导体是个空腔，那么：\n考虑取一个实心部分内的，绕空腔的高斯面，得到内表面净电荷为零。\n如何得到内表面电荷处处为零呢？考虑如果不是的话，必能找到一条电场线，然后这么搞：\n与无旋矛盾。\n同样，空腔内电场处处为零，否则用 2 的方法也可以搞出矛盾。\n为什么表面尖的地方电荷密度大？简而言之，考虑一个简单情况：一大一小的导体球相离充分远但被导线连接。这个也可以用于解释导体球相碰时的电荷分配。\n电容 $C=Q/U$。\n平行板电容器，$U=Ed=\\sigma d/\\eps_0$ 故 $C=\\sigma S/U=\\eps_0S/d$。\n同轴柱形电容器，根据高斯定律，$E=\\lambda/2\\pi\\eps_0r$（无所谓内层是实心还是空心），$U=\\lambda/2\\pi\\eps_0\\cdot\\ln(r_2/r_1)$，$C=l\\lambda/U=2\\pi\\eps_0l/\\ln(r_2/r_1)$。\n唯一性定理 已知源电荷分布。 导体表面等势。 能否确定导体表面的电荷分布？\n唯一性定理：对于区域 $V$，如果内部的电荷分布已知，且 ① $\\p V$ 上的势能分布已知；或 ② $\\p V$ 上的电场垂直分量已知；则 $V$ 内的电场唯一确定。\n证：若有两种电势分布 $\\varphi_1$、$\\varphi_2$，令 $U=\\varphi_1-\\varphi_2$。第一，我们知道 $\\nabla^2 U=\\rho/\\eps_0-\\rho/\\eps_0=0$；第二，上面两个条件可以翻译为 $U|_{\\p V}=0$ 或 $(\\p U/\\p n)|_{\\p V}=0$，我们可以把它写成 $$ U\\frac{\\p U}{\\p n}=0 $$ 积分 $$ 0=\\oiint_{\\p V}U\\frac{\\p U}{\\p n}\\d s=\\oiint_{\\p V}U(\\nabla U)\\cdot\\d\\b s=\\iiint_V\\nabla\\cdot(U\\nabla U)\\d v=\\iiint_V(\\nabla U)^2\\d v+\\iiint_VU(\\nabla^2 U)\\d v=\\iiint_V(\\nabla U)^2\\d v $$ 于是 $\\nabla U=0$。\n注意：这里这个区域可以是无界的，至于为什么有的必须有界有的可以无界，我也不知道。似乎是整个空间净电荷为零的时候才可以无界？\n推论：对于区域 $V$，如果在上述唯一性定理的条件基础上，$V$ 中还被抠了一些洞，每个洞对应一个导体，我们既不知道这个导体表面的电势，又不知道导体表面的场强，但是知道导体的净电荷，那么 $V$ 内的电场也能唯一确定。\n证：这些导体的电势是定值，于是 $$ \\iiint_{\\p V_i}U\\frac{\\p U}{\\p n}\\d s=U_i\\iiint_{\\p V_i}(\\b E_1\\cdot\\d\\b s-\\b E_2\\cdot\\d\\b s)=U_i\\left(\\frac{Q}{\\eps_0}-\\frac{Q}{\\eps_0}\\right)=0 $$ 别的都是一样的。\n直觉上来说，除了垂直那个条件不是特别好理解外，别的都可以通过拉普拉斯方程的解不会在边界以外的地方取到最值，从而如果边界处都相等（$=0$）内部也都是，这样的方式来理解。\n电像法 尽管我们知道了唯一性，但是还是不好搞。为了避免直面拉普拉斯/泊松方程，这里有个电像法：就是把导体表面的电荷分布等效于一个更简单的，导体内部的电荷分布，使得导体表面的势能分布不变（允许内部不对），这样由唯一性定理，外面的电场分布在等效后不变。\n算出电场分布之后，利用 $E=\\sigma/\\eps_0$ 可得出导体表面的电荷分布。根据高斯定律，净电荷和像电荷相等。\n例 1 这个无限大导体板是接地的（不然这题会出 bug）。\n假设板是 $yz$ 方向且过 $O$ 的。板上一点的场强是垂直于板的，大小为 $$ E(\\b r)=\\frac{qd}{2\\pi\\eps_0(r^2+d^2)^{3/2}} $$ 因此 $$ \\sigma(\\b r)=-\\frac{qd}{2\\pi(r^2+d^2)^{3/2}} $$ 验证总电荷 $=-q$： $$ \\int_{0}^{+\\infty}\\sigma(r)2\\pi r\\d r=qd\\left.\\frac{1}{\\sqrt{r^2+d^2}}\\right|_{r=0}^{+\\infty}=-q $$ 如果不接地，由于这题选取的区域不得不是无界的，就会爆，或者说没法同时保证净的像电荷 $=0$，以及板上等势。\n注意这种结构在上下是不同介值时，像电荷的电荷量不是 $-q$。\n例 2 我们知道（阿波罗尼斯圆），与两个点距离之比为定值 $\\ne 1$ 的点集形成一个圆（球）。也就是说，在这里我们希望构造像电荷使得 $$ \\frac{q}{r_1}+\\frac{q^\\prime}{r_2}=0 $$ 刚好是这个导体球。\n首先 $Q^\\prime$ 一定在 $OQ$ 上，设与圆心距离为 $d$。设 $OQ$ 与圆交于 $C$，连接 $OP$、$CP$。可以通过倍长中线可以得到 $CP$ 平分 $\\angle QPQ^\\prime$，于是 $\\angle Q=\\pi-\\angle PCQ-\\angle QPC=\\angle PCO-\\angle Q^\\prime PC=\\angle OPQ^\\prime$，于是 $\\triangle OPQ^\\prime\\sim\\triangle OQP$， $$ \\frac{OQ^\\prime}{OP}=\\frac{OP}{OQ}=\\frac{PQ^\\prime}{PQ} $$ 即 $$ \\frac{OQ^\\prime}{a}=\\frac{a}{b}=\\frac{r_2}{r_1}=-\\frac{q^\\prime}{q} $$ 得 $$ OQ^\\prime=\\frac{a^2}{b},\\,q^\\prime=-\\frac{a}{b}q $$ 所以说，如果接地的话，导体球的电荷就是 $-a/b\\cdot q$，换句话说，球会“吸收”$a/b$ 的电场；如果不接地或者规定球的电荷或规定球表面的电势的话，就再在球心塞一个像电荷。\n静电场的复势 首先要明确的一点是，当无穷远处有电荷时，无穷远处的势能就不一定能是零了，甚至可能出现两个方向的无穷远处势能不同的情况。另外“地”等于无穷远处。\n现在我们考虑二维电场，这里二维的意思是，在 $z$ 轴方向电荷均匀分布。\n解析函数：在一个区域内处处可微。复变解析函数 $f(z)=U(x,y)+\\i V(x,y)\\,(z=x+\\i y)$ 满足 Cauchy-Riemann 方程 $$ \\left\\{\\begin{aligned} \\frac{\\p U}{\\p x}\u0026amp;=\\frac{\\p V}{\\p y}\\\\ \\frac{\\p U}{\\p y}\u0026amp;=-\\frac{\\p V}{\\p x} \\end{aligned}\\right. \\Longrightarrow \\left\\{\\begin{aligned} \\nabla^2 U\u0026amp;=0\\\\ \\nabla^2 V\u0026amp;=0 \\end{aligned}\\right. \\Longrightarrow \\nabla U\\cdot\\nabla V=0 $$ 证：可微要求各个方向导数相等，也就是 $$ \\frac{\\p U}{\\p x}+\\i\\frac{\\p V}{\\p x}=\\frac{\\p f}{\\p x}=\\frac{\\p f}{\\p(\\i y)}=\\frac{\\p V}{\\p y}-\\i\\frac{\\p U}{\\p y} $$ 现在 $\\nabla^2$ 等于 $0$，说明 $U$ 和 $V$ 能作为势能。点乘等于 $0$，意味着 $U$ 和 $V$ 的等势线的法向量互相垂直，也就是等势线互相垂直。于是我们可以把一个当作等势线，一个当作电场线，尽管意义看起来有些诡异。\n比如说，$E=-\\nabla V$。现在我们可以说什么呢？如果把 $V=\\varphi$ 代进 $f$ 里，然后根据 $U$ 和 $V$ 的关系解得 $U$，那么 $U$ 就可以表示电场线。目前看起来这是废话，后面会发现有一些魔法。根据积分，我们会发现，可以把 $U$ 视作“等通线”，或者说，两点之间 $U$ 的差就是两点间连线对应的电通量。这个也很好理解，如果有个路径完全跟电场线重合，那么点乘就都等于 $0$，所以通量为 $0$。\n例 1 考虑沿 $z$ 轴的无限长均匀导线。 $$ \\b E(\\b r)=\\frac{\\lambda\\b r}{2\\pi\\eps_0r^2} $$ 写成复数形式就是 $$ E(z)=\\frac{\\lambda z}{2\\pi\\eps_0|z|^2}=\\frac{\\lambda z}{2\\pi\\eps_0z\\bar{z}}=\\frac{\\lambda}{2\\pi\\eps_0\\bar z} $$ 代入 $E=-\\nabla V$，这里从复数的角度来说，$\\nabla g=\\nabla g\\cdot(1,\\i)$。 $$ E=-\\nabla V=-\\frac{\\p V}{\\p x}-\\i\\frac{\\p V}{\\p y}=-\\frac{\\p V}{\\p x}-\\i\\frac{\\p U}{\\p x}=-\\i\\bar{f^\\prime} $$ 于是 $$ f^\\prime=\\overline{\\i E}=-\\i\\overline{E}=-\\i\\frac{\\lambda}{2\\pi\\eps_0z} $$ 这个很像一个势能的形式，所以我们管 $f$ 叫 $E$ 的复势。\n由于复变函数有着与一元函数类似的运算规律（可参见 https://www.math.utah.edu/~yplee/teaching/4200f18/Ch2_pages.pdf）， $$ f(z)=-\\i\\frac{\\lambda}{2\\pi\\eps_0}\\ln z=\\frac{\\lambda}{2\\pi\\eps_0}\\left(\\arg z-\\i\\ln|z|\\right) $$ 于是 $$ U(\\rho,\\theta)=\\frac{\\lambda}{2\\pi\\eps_0}\\theta,\\,V(\\rho,\\theta)=-\\frac{\\lambda}{2\\pi\\eps_0}\\ln\\rho $$ $U$ 的等高线就形成一堆从原点发出的射线，符合无限长导线（或点电荷）的电场线。\n但是这种运用还是太凑巧了，更常见的运用是这样：给定导体的构造以及其电势，求空间中电场的分布。那么我们考虑找到一个解析的复变函数，其实部或虚部等势线刚好和导体重合。这样，这个函数的实部或虚部就是电势。\n例 2 $f(z)=z^2=(x^2-y^2)+2xy\\i$：\n取 $\\im f=0$ 的部分，也就是坐标轴十字的这部分。那么空间中的电势可以分布为 $\\varphi(x,y)=2xy$，或者进一步说，可以是 $xy$ 的任意倍数。具体来说，这样的电场是如何达成的呢？我们只需要利用 $\\sigma/\\eps_0=\\p\\varphi/\\p n$ 即可，得到 $x$ 轴上的是 $2x$，$y$ 轴上的是 $2y$。\n但是实际上算一下，你会发现根本不对！比如考虑 $(1,1)$ 点： $$ \\b E=\\int_{-\\infty}^{+\\infty}\\frac{2x\\d x}{2\\pi\\eps_0}\\frac{(1-x,1)}{(1-x)^2+1}+\\int_{-\\infty}^{+\\infty}\\frac{2y\\d x}{2\\pi\\eps_0}\\frac{(1,1-y)}{1+(1-y)^2} $$ 然后你发现它根本不收敛！\n所以我也不知道我们现在到底在干什么，可能只是 playing with math 吧……\n一个看起来比较靠谱的情况是，$x^2-y^2=1$ 的部分有 $+\\varphi$ 的导体板，$y^2-x^2=1$ 的部分有 $-\\varphi$ 的导体板，那么四个导体板之间（可以视作封闭区域）的电势就是 $\\varphi(x^2-y^2)$。\n这个方法其实确实严谨性有很大的问题，我们会怀疑的，第一个是这样的电荷分布是否真能稳定，第二个是有无穷多的总电荷是怎么做到的，第三个是无穷远处被弄的一团糟，第四个是有界性和解的唯一性，第五个是能否只在等势线的一部分上放上导体板（似乎只需在关注的区域内的等势线上全部放就行？），第六个是为啥 tmd 求出来的电荷分布无法形成正常的电场啊！\n通过跟一些同学进一步讨论，我大概得出两个结论：一个是必须规定无穷远处的电势，一个是肯定是无穷远处有一些场源在操纵整个结构。不管怎么说，复势只能解决这样的问题：形如规定了某个（足够）封闭的边界条件（电势），求中间的电势。\n例 3 又例如 $f(z)=z^{1/2}$（取 $\\theta\\in(-\\pi,\\pi]$），可以得到 $$ z^{1/2}=\\left(\\frac{\\sqrt{x^2+y^2}+x}{2}\\right)^{1/2}+\\i\\operatorname{sgn}(y)\\left(\\frac{\\sqrt{x^2+y^2}-x}{2}\\right)^{1/2} $$\n考虑 $x$ 正半轴对应的导体板，它形成的电场是虚线部分。然后， $$ \\sigma=\\frac{\\p\\im z}{\\p y}=-\\frac{1}{2x} $$ 还是积不对。\n特别注意 期中考试考了一道导线形成的电偶极子的复势（实部是势能），我答案写了个 $\\varphi=\\lambda d/2\\pi\\eps_0\\bar{z}$ 爆了，因为！$1/{\\bar z}$ 压根不是解析的！\n复势必须是解析的。解析函数有：\n$z^n$（$n\u0026lt;0$ 时除去 $z=0$） $\\e^z$ $\\ln z$（除去原点与负半轴） $\\sin z,\\cos z,\\sinh z,\\cosh z$ 等 以上函数的四则运算、复合 非解析函数有：\n$|z|,|z|^2$ $\\bar z,1/{\\bar z}$ $\\re z,\\im z$ 保角变换 推荐《数学物理方法》（梁昆淼）。\n考虑一个电场，势能 $\\varphi(z)$（$\\varphi:\\mathbb{C}\\to\\R$）的一些边界条件给定。我们现在想一个问题：假设解得了 $\\varphi$。现在换元 $z^\\prime=w(z)$，或者说 $\\varphi\\circ w^{-1}$，这个函数是否也是一个合法的势能呢？反过来呢？\n如果 $w$ 是解析函数，答案是肯定的。这样的一个变换叫保角变换，保角变换的名字是这样解释的：考虑某点 $z$，它变化了 $\\d z$，那么函数值变化了 $w(z+\\d z)-w(z)=w^\\prime(z)\\d z$。这个差就是复变函数可视化下，一条斜线的局部变成了另一个样子的斜线。那么如果有另一条与 $z+t\\d z$ 夹角为 $\\theta$ 的斜线，它经过映射后，方向就成了 $w(z+\\e^{\\i\\theta}\\d z)-w(z)=w^\\prime(z)\\e^{\\i\\theta}\\d z$。这就是说，如果 $w^\\prime(z)\\ne 0$，则两者的交角不变。那么如果 $w^\\prime(z)=0$，导数给出的信息就不足，有可能交角不对。例如 $w(z)=z^n$ 在原点处将角放大 $n$ 倍。\n但是用于解决电场问题的保角变换和这里的保角性没有直接的联系。因为我们考虑的是，只要拉普拉斯方程或泊松方程被保持就行。\n设 $w(x+\\i y)=\\xi+\\i\\eta$。这里我们把保角变换看成一种“坐标表示变换”，而不是直接函数复合。假设有泊松方程，我们进行推导： $$ \\begin{align*} \\frac{\\rho}{\\eps_0}\u0026amp;=\\frac{\\p^2\\varphi}{\\p x^2}+\\frac{\\p^2\\varphi}{\\p y^2}\\\\ \u0026amp;=\\frac{\\p}{\\p x}\\left(\\frac{\\p\\varphi}{\\p\\xi}\\frac{\\p\\xi}{\\p x}+\\frac{\\p\\varphi}{\\p\\eta}\\frac{\\p\\eta}{\\p x}\\right)+\\frac{\\p}{\\p y}\\left(\\frac{\\p\\varphi}{\\p\\xi}\\frac{\\p\\xi}{\\p y}+\\frac{\\p\\varphi}{\\p\\eta}\\frac{\\p\\eta}{\\p y}\\right)\\\\ \u0026amp;=\\left[\\left(\\frac{\\p\\xi}{\\p x}\\right)^2+\\left(\\frac{\\p\\xi}{\\p y}\\right)^2\\right]\\frac{\\p^2\\varphi}{\\p\\xi^2}+2\\left(\\frac{\\p\\xi}{\\p x}\\frac{\\p\\eta}{\\p x}+\\frac{\\p\\xi}{\\p y}\\frac{\\p\\eta}{\\p y}\\right)\\frac{\\p^2\\varphi}{\\p\\xi\\p\\eta}+\\left[\\left(\\frac{\\p\\eta}{\\p x}\\right)^2+\\left(\\frac{\\p\\eta}{\\p y}\\right)^2\\right]\\frac{\\p^2\\varphi}{\\p\\eta^2}\\\\ \u0026amp;+\\left(\\frac{\\p^2\\xi}{\\p x^2}+\\frac{\\p^2\\xi}{\\p y^2}\\right)\\frac{\\p\\varphi}{\\p\\xi}+\\left(\\frac{\\p^2\\eta}{\\p x^2}+\\frac{\\p^2\\eta}{\\p y^2}\\right)\\frac{\\p\\varphi}{\\p\\eta}\\\\ \u0026amp;=|w^\\prime(z)|^2\\left(\\frac{\\p^2\\varphi}{\\p\\xi^2}+\\frac{\\p^2\\varphi}{\\p\\eta^2}\\right) \\end{align*} $$ 因此，我们可以得到一个方法：现在，$xy$ 平面上给出了一些边界条件和电荷分布，要求电场分布，比较难求。那么我们就考虑通过解析函数 $w$，将 $(x,y)\\mapsto(\\xi,\\eta)$，将边界条件和电荷位置通过 $w$ 变换，将电荷值除以 $|w^\\prime|^2$，这样之后，如果能解出电场关于 $\\xi,\\eta$ 的表达式，再通过 $w^{-1}$ 把它变换回来就行了。\n为了严谨起见，我们要求：\n$w$ 形成原考虑区域（比如 $z^n$，我们只考虑一个角内）和变换后考虑区域的一个双射，这样才能保证两种情况下解形成一个双射。或者区域有界也行。 $w^\\prime(z)\\ne 0$。如果有等于 $0$ 且对应点无电荷，实际上是对 $\\varphi(\\xi,\\eta)$ 要求更严了些，这个应该不会有什么问题？ 如果 $w$ 多值，要规定一下辐角范围，当心一下取值两端点重合处如果值不等就不能处于区域内（可以处于边界）。\n再补充一下，关于这种变换，初学最容易搞晕的就是变量之间的关系。最合适的理解方式就是认为 $\\varphi$ 一直不变，变的只是坐标系。也就是说，我们最好不要用 $\\varphi(z)$ 这种表示，或者说原模型的电势永远只能是 $\\varphi(z)$，而不能是 $\\varphi(w(z))$ 或者 $\\varphi(w^{-1}(z))$ 之类的。$\\varphi$ 是和 $z$ 相关的一个变量，在我们说 $\\xi,\\eta$ 和 $\\varphi$ 的关系的时候，我们本质上是说 $\\xi+\\i\\eta\\to z\\to \\varphi$ 这样的决定关系。当我们说能容易求出 $\\xi,\\eta$ 下电场分布 $\\phi(\\xi+\\i\\eta)$ 时，我们实际上在说的是 $\\varphi(z)=\\phi(w(z))$。\n例 1 考虑两极板形成角 $\\alpha$，电势为 $\\varphi_0$。\n那么边界条件为 $\\varphi(t)=\\varphi(t\\e^{i\\alpha})=\\varphi_0\\,(t\\ge 0)$。\n设计变换 $w(z)=z^{\\pi/\\alpha}\\,(\\theta\\in[0,2\\pi))$。那么边界被变换为与 $x$ 轴重合的板。我们我们知道平的情况，$\\phi(z)=\\varphi_0+C\\im z$。因此我们得到的是： $$ \\varphi(z)=\\varphi_0+C\\im(z^{\\pi/\\alpha})=\\varphi_0+C|z|^{\\pi/\\alpha}\\sin\\left(\\frac\\pi\\alpha\\arg z\\right) $$ 例如 $\\alpha=\\pi/3$ 时， $$ \\varphi(x,y)=\\varphi_0+C(3x^2y-y^2) $$ 这个例子没有电荷，所以形式比较好，能直接写出复势，如果有电荷的话直接和解析函数的定义矛盾了。\n其实基本上都是变换成平的。\n例 2 考虑一个这样的形状：\n$(x_0,y_0)$ 处有个导线，线密度为 $\\lambda$。这题刚好可以直接用电像法做，就是关于 $x$ 轴对称一下，再用例 2 的套路作圆内的两个。\n一个神奇的变换（解释详见《数学物理方法》（梁昆淼））： $$ w(z)=\\left(\\frac{z-1}{z+1}\\right)^2 $$ 可以把图形变成 $x$ 轴。\n这里半圆弧部分被映射到了负半轴，Mathematica 刚好画不出来。\n令 $z_0=x_0+\\i y_0$。电荷被变换到 $w(z_0)$ 处，电荷密度除以 $|w^\\prime(z_0)|^2=16\\left\\lvert\\frac{z_0-1}{z_0+1}\\right\\rvert^2$。\n现在利用电像法就很简单了。最后我们求得 $$ \\varphi(z)=\\frac{\\lambda}{32\\pi\\eps_0\\left\\lvert\\frac{z_0-1}{z_0+1}\\right\\rvert^2}\\left[\\ln\\left\\lvert\\left(\\frac{z-1}{z+1}\\right)^2-\\left(\\frac{z_0-1}{z_0+1}\\right)^2\\right\\rvert-\\ln\\left\\lvert\\left(\\frac{z-1}{z+1}\\right)^2-\\left(\\frac{\\overline{z_0}-1}{\\overline{z_0}+1}\\right)^2\\right\\rvert\\right] $$ 例如 $(x_0,y_0)=(1,1)$ 时\n这就是势能（过小的忽略，所以有个洞）、等势线和电场线。\n莫名其妙提到的一些例子 等离子振荡 等离子态：能量足够高，电子脱离原子核束缚自由运动，可以导电。我们考虑一个 $yz$ 方向的有厚度的无限大等离子体平面，我们认为离子不懂，只有电子沿 $x$ 方向动，并且所有电子的位移相同。考虑电子偏移了平衡位置 $s$：\n这时，可以想象它形成了一正一负两个极板。那么中间的电场为（这里 $q_e$ 是负的，$n_0$ 是数密度）： $$ -\\frac{n_0q_es}{\\eps_0} $$ 利用牛二 $$ -\\frac{n_0q_es}{\\eps_0}q_e=m_e\\ddot s $$ 解得 $$ s=C_1\\sin\\left(\\sqrt{\\frac{n_0q_e^2}{\\eps_0m_e}}t+C_2\\right) $$ 其中关键为频率满足 $$ \\omega^2=\\frac{n_0q_e^2}{\\eps_0m_e} $$ 这个就是等离子态物质的固有频率。\n问题：为什么不用考虑磁场？\n一个应用是短波通信。大气层中的电离层，会反射频率小于它固有频率的波，大于的可以穿透。\n代入实际情况 $$ \\omega\\approx9\\times10^{-3}\\sqrt{n_0\\unit{cm^3}}\\unit{MHz} $$ 代入 $n_0=10^6\\unit{cm^{-3}}$，得 $$ \\omega\\approx9\\unit{MHz} $$ 最常用的短波通信就大概是这个波段，可以反射。\n另一个应用是解释为什么金属的反射率高。因为金属里面电子也是自由的，也可以看作等离子体，而可见光的频率远小于固有频率，所以会反射。\n静电能 一个系统的电场能定义：就是它的总势能——将所有电荷从互相距离无穷远（能量为 $0$），放到当前状态，所需要做的功。\n对于两个距离为 $r$ 的电荷，它们形成的电势能为 $$ U=\\frac{q_1q_2}{4\\pi\\eps_0r} $$ 这个值既是 $q_1$ 自己的电势能，又是 $q_2$ 自己的电势能。因此 $$ U=\\frac{q_1\\varphi_1+q_2\\varphi_2}{2} $$ 注意这个 $1/2$ 是很重要的，去掉就和能量守恒矛盾了。可以理解为这个势能是两个电荷共享的。\n对于复杂系统， $$ U=\\frac12\\sum q_i\\varphi_i $$ 用积分形式， $$ U=\\frac12\\iiint\\varphi\\rho\\d v $$\n例 1 例如一个实心的，半径为 $R$ 的，均匀带电 $Q$ 的球： $$ \\begin{align*} U\u0026amp;=\\frac12\\int_{0}^R\\left[\\frac{Q}{4\\pi\\eps_0R}+\\frac{Q}{8\\pi\\eps_0R^3}(R^2-r^2)\\right]\\frac{Q}{\\frac43\\pi R^3}4\\pi r^2\\d r\\\\ \u0026amp;=\\frac{3Q^2}{16\\pi\\eps_0R^6}\\int_{0}^R(3R^2-r^2)r^2\\d r\\\\ \u0026amp;=\\frac{3Q^2}{20\\pi\\eps_0R} \\end{align*} $$ 另外一种简单些的算法是，考虑 $$ U=\\sum_{j\u0026lt;i}q_i\\varphi_{j\\to i} $$ 因此可以写成 $$ U=\\int_0^R\\frac{Qr^2}{4\\pi\\eps_0R^3}\\frac{Q}{\\frac43\\pi R^3}4\\pi r^2\\d r $$ 实际意义就是一层层从无穷远处取材裹起来，其中每一层内部的相互作用产生的电势能是高阶无穷小量。\n导体球： $$ \\frac12\\frac{Q}{4\\pi\\eps_0R}Q=\\frac{Q^2}{8\\pi\\eps_0R}=\\int_0^Q\\frac{q\\d q}{4\\pi\\eps_0R} $$ 平行板电容器：\n一种算法是直接考虑两个极板。 $$ U=\\frac12Q\\varphi_1-\\frac12Q\\varphi_2=\\frac12QV=\\frac{Q^2}{2C} $$ 另一种算法是考虑逐渐给电容充电。每次加 $\\d q$ 的电荷，正的比负的需要多增加 $V$ 的电势。 $$ U=\\int_0^QV\\d q=\\int_0^Q\\frac{q}{C}\\d q=\\frac{Q^2}{2C} $$\n所以说无论电阻是多少，给电容充电的过程中一定有一般的能量会转变成内能。\n现在我们推导 $U$ 的另一种表达式（这里 $V$ 是整个空间） $$ \\begin{align*} U\u0026amp;=\\frac12\\iiint_V\\varphi\\rho\\d v\\\\ \u0026amp;=\\frac12\\iiint_V\\varphi(-\\eps_0\\nabla^2\\varphi)\\d v\\\\ \u0026amp;=-\\frac{\\eps_0}2\\iiint_V[\\nabla\\cdot(\\varphi\\nabla\\varphi)-\\nabla\\varphi\\cdot\\nabla\\varphi]\\d v\\\\ \u0026amp;=-\\frac{\\eps_0}2\\left(\\lim_{V^\\prime\\to V}\\oiint_{\\p V^\\prime}\\varphi\\nabla\\varphi\\cdot \\d\\b s-\\iiint_V\\b E\\cdot\\b E\\d v\\right) \\end{align*} $$ 当 $V^\\prime\\to V$ 时，$\\varphi\\propto r^{-1}$，$|\\b E|\\propto r^{-2}$，$S\\propto r^2$，故前一项 $\\to 0$。因此 $$ U=\\frac{\\eps_0}{2}\\iiint_V\\b E^2\\d v $$ 这个更加本质，因为电场能是和场有关，即使是取真空中没有电荷的一块，然后这块区域外有电荷，这块区域内也应当贡献电场能。\n拿这个去算单点电荷的电场能，会发现它是发散的，所以点电荷的假设不成立。代入 $U=m_ec^2$ 可以解得电子的经典半径。在实操中，由于点电荷在场景内和在无穷远处的“自势能”是不变的，而且一般要求求需要做的功（求差），因此可以直接忽略。\n例 2 考虑两个分别在 $x=\\pm d/2$ 的 $yz$ 方向无限大接地极板以及在原点的点电荷 $q$。像电荷的推导会出现“连锁反应”，为：$x=kd$ 处 $(-1)^kq$ 的像电荷。\n考虑计算原点电荷对的左极板的力，由牛三，它与左极板对原电荷的力，也就是左边这串像电荷对原电荷的力等大反向。这个东西是 $$ F=\\frac{1}{4\\pi\\eps_0}\\sum_{i\\ge 1}\\frac{(-1)^iq^2}{i^2d^2}=-\\frac{q^2}{4\\pi\\eps_0d^2}\\cdot\\frac{\\pi^2}{12} $$ 整个系统的电场能为板的电势能与点的电势能之和除以二，而板的部分是 $0$，点的部分是： $$ E=\\frac{1}{4\\pi\\eps_0}\\sum_{i\\ge 1}\\frac{(-1)^i2q^2}{id}=-\\frac{q^2}{2\\pi\\eps_0d}\\ln2 $$ 于是可以计算出把点电荷移到无穷远处所做的功。注意它是负的电场能。\n电介质 考虑往平行板电容器中间塞个宽为 $b$ 的导体，于是 $V$ 从 $\\sigma/\\eps_0d$ 减小到 $\\sigma/\\eps_0(d-b)$，所以 $C=Q/V$ 增加了。如果中间塞的是绝缘体，那屏蔽效果会弱很多，但绝缘体内部的电场强度仍然会下降，从而 $V$ 也是偏小。\n那么绝缘体具体是怎么样的呢？考虑其中一个原子，电子无法自由运动，但是原子核会往电场方向偏移，电子云会往反向偏移，整体会有形变，于是核和电子的等效中心形成了一个电偶极子 $\\b p=q\\b\\delta$，极化矢量就是单位体积的电偶极矩 $\\b P=Nq\\b\\delta$。在一块厚厚的绝缘体，每个原子这样的变化叠加起来，中间的部分就抵消了，于是净电荷就是形如两个对面分别带上了正负电荷，我们认为每个原子的变化是一样的，于是正负电荷层的厚度也就是单个电荷的 $\\delta$，则 $$ \\sigma_{\\text{pol}}=Nq\\delta $$ 它刚好就等于 $P$。\n与此同时，实验说（其中 $\\chi$ 称为极化率，注意这个是近似，因为不一定是线性关系） $$ \\b P=\\chi\\eps_0\\b E $$ 这个很好理解。\n于是可以列方程 $$ \\left\\{\\begin{align*} E\u0026amp;=\\frac{\\sigma-P}{\\eps_0}\\\\ P\u0026amp;=\\chi\\eps_0E \\end{align*}\\right. $$ 解得 $$ E=\\frac{1}{1+\\chi}\\frac{\\sigma}{\\eps_0} $$ 于是 $$ C=\\frac{Q}{V}=\\frac{\\sigma S}{Ed}=(1+\\chi)\\frac{\\eps_0S}{d} $$ 称 $$ \\kappa=1+\\chi $$ （又叫做 $\\eps_r$ 或 $\\eps/\\eps_0$）为相对介电常数。\n考虑介质内一个假想面上，有多少的电荷通过它。计算思路是，先考虑垂直的情况，它就是电荷密度，乘上位移，这个就是 $\\sigma_{\\text{pol}}=P$ 的原因。那么如果面是斜的，就乘上个 $\\cos$。 $$ \\sigma_{\\text{pol}}=\\b P\\cdot\\b n $$ 在内部如果 $\\b P$ 均匀，那这个东西是 $0$，因为通过这个面的两个方向的电荷抵消了，但在表面就有净的了。\n这个玩意的用处是，例如，考虑一个均匀极化的介质球，它表面的电荷分布就是 $$ \\sigma_{\\text{pol}}=P\\cos\\theta $$ 其中 $x$ 轴取的与电场强度相同。\n如果介质的极化不均匀，那么就会产生极化电荷——介质内部一块区域呈现出”额外的净电荷“的现象。这是因为，考虑一个区域 $V$，由电荷守恒， $$ Q_{\\text{pol}}=-\\oiint_{\\p V}\\b P\\cdot\\b n\\d s $$ 最基本地， $$ Q_{\\text{pol}}=\\iiint_V\\rho_{\\text{pol}}\\d v $$ 由高斯公式，我们可以把两个式子联系起来： $$ \\rho_{\\text{pol}}=-\\nabla\\cdot\\b P $$ 现在，考虑有另外的”真正的净电荷“分布 $\\rho_{\\text{free}}$（这个 $\\text{free}$ 指的不是能自由移动）的情况： $$ \\nabla\\cdot\\b E=\\frac{\\rho}{\\eps_0}=\\frac{\\rho_{\\text{free}}+\\rho_{\\text{pol}}}{\\eps_0}=\\frac{\\rho_{\\text{free}}-\\nabla\\cdot\\b P}{\\eps_0} $$ 于是 $$ \\rho_{\\text{free}}=\\nabla\\cdot(\\eps_0\\b E+\\b P)=\\kappa\\eps_0\\nabla\\cdot\\b E $$ $\\b D=\\eps_0\\b E+\\b P$ 被称为电位移矢量。我们现在有关系： $$ \\begin{align*} \\nabla\\cdot\\b D\u0026amp;=\\rho_{\\text{free}}\\\\ \\nabla\\cdot\\b E\u0026amp;=\\frac{\\rho_{\\text{free}}}{\\kappa\\eps_0}\\\\ \\b D\u0026amp;=\\kappa\\eps_0\\b E \\end{align*} $$ 另外，仍有 $\\nabla\\times\\b E=\\b 0$，但在非均匀介质的情况下，$\\nabla\\times\\b D$ 可能不是 $\\b 0$；在非均匀极化的情况下，局部会产生”净极化电荷“$\\rho_{\\text{pol}}$。在均匀介质中，只有介质表面和 $\\rho_{\\text{free}}$ 附近（无限近处）才会有极化电荷。\n在均匀介质中，我们就有，对于一个点电荷， $$ \\b E=\\frac{q\\b r}{4\\pi\\kappa\\eps_0\\b r^3} $$ 值得注意的是，当介质不均匀时，$\\nabla\\cdot\\b D=\\rho_{\\text{free}}$ 成立，但 $$ \\b D=\\iiint_V\\frac{\\rho_{\\text{free}}\\d v}{4\\pi}\\frac{\\b r-\\b r^\\prime}{|\\b r-\\b r^\\prime|^3} $$ 不再成立。\n总的来说，非均匀电介质相关问题的求解思路是\n分析对称性（并加以猜测）。 通过偏导或 $\\b D$ 的高斯定律求出 $\\b D$。 根据 $\\b D$ 与 $\\b E$、$\\b P$ 的关系求出它们。 根据 $\\b D$ 与 $\\rho_{\\text{free}}$ 或 $\\sigma_{\\text{free}}$ 的关系求出它们。 根据 $\\b P$ 与 $\\rho_{\\text{pol}}$ 与 $\\rho_{\\text{free}}$ 的关系求出它们。 例 1 考虑一个 $\\rho_{\\text{free}}=\\rho_0$ 的，厚度为 $d$ 的，相对介电常数为 $\\eps_r$ 的 $yz$ 方向无限大介质板。 $$ \\frac{\\p D}{\\p x}=\\left\\{\\begin{aligned}\u0026amp;\\rho_0,\u0026amp;|x|\\le\\frac d2\\\\ \u0026amp;0,\u0026amp;|x|\u0026gt;\\frac d2\\end{aligned}\\right.\\Longrightarrow D=\\rho_0\\max\\Set{\\min\\Set{x,\\frac d2},-\\frac d2} $$ 导一下别的： $$ \\left\\{\\begin{align*} E\u0026amp;=\\frac{\\rho_0}{\\eps_0\\eps_r}\\max\\Set{\\min\\Set{x,\\frac d2},-\\frac d2}\\\\ P\u0026amp;=\\rho_0\\left(1-\\frac{1}{\\eps_r}\\right)\\max\\Set{\\min\\Set{x,\\frac d2},-\\frac d2}\\\\ \\rho_{\\text{pol}}\u0026amp;=-\\rho_0\\left(1-\\frac{1}{\\eps_r}\\right)\\left[|x|\\le\\frac d2\\right]\\\\ \\sigma_{\\text{pol}}\u0026amp;=\\rho_0\\left(1-\\frac{1}{\\eps_r}\\right)\\frac{d}{2}\\left[|x|=\\frac d2\\right] \\end{align*}\\right. $$\n发现极化面电荷刚好可以可以跟极化体电荷抵消，符合电荷守恒。值得注意的是，这两者是需要分开计算的，面电荷其实相当于是出现了“无限密”的情况，会导致电场突变。\n例 2 考虑一个表面积为 $S$ 的平行板电容器，一半塞上了 $\\eps_r$ 的介质，可以理解为两个不同的电容并联。\n两个极板仍然分别是等势体，由 $V=Ed$，电场仍然是垂直的，均匀的（为什么？）。\n真空的部分 $C_1=\\eps_0S/2d$，有介质的部分 $C_2=\\eps_0\\eps_rS/2d$。新的总电容就是 $C^\\prime=C_1+C_2=\\frac{1+\\eps_r}2C$。新的电压是 $V^\\prime=Q/C^\\prime=\\frac2{1+\\eps_r}V$，电场强度是 $E^\\prime=V^\\prime/d=\\frac{2}{1+\\eps_r}E$。于是，真空部分的极板的面电荷密度为 $\\sigma_1=\\frac2{1+\\eps_r}\\sigma_0$，有介质部分 $\\sigma_2=\\frac{2\\eps_r}{1+\\eps_r}\\sigma_0$。所以说，真空部分的电荷密度减小，有介质部分的电荷密度增加。\n例 3 对于复杂的介质分布，我们难以直接解出电场分布。这时考虑得到一组解，然后用唯一性定理。\n考虑一个 $\\b E_0$ 的匀强电场，其中放了一个半径为 $R$，相对介电常数为 $\\eps_r$ 的介质球，求它对电场的影响。\n为了分析这个问题，我们必须先回答这个问题：当一个球，它表面分布了密度为 $P\\cos\\theta$（或者叫 $\\sigma_0\\cos\\theta$ 舒服些）的电荷，那它会形成的电场分布是怎样的？（下图理解为立体角为 $\\theta$ 的圆锥面与球的交圆部分 $\\sigma=\\sigma_0\\cos\\theta$）\n考虑这样一个模型，设两个球心的距离为 $d$。我们可以想象是两个球相减。在内部的空腔中，右侧球对其电场为 $$ \\b E=\\frac{\\frac43\\pi\\left|\\b r-\\frac d2\\b{\\hat x}\\right|^3\\rho_0}{4\\pi\\eps_0}\\cdot\\frac{\\b r-\\frac d2\\b{\\hat x}}{\\left|\\b r-\\frac d2\\b{\\hat x}\\right|^3}=\\frac{\\rho_0}{3\\eps_0}\\left(\\b r-\\frac d2\\b{\\hat x}\\right) $$ 左侧同理，所以总的就是 $$ \\b E=-\\frac{\\rho_0}{3\\eps_0}d\\b{\\hat x} $$ 而在外面，两个球可以视作是电偶极子（实际上内部也可以），$\\b p=4\\pi R^3\\rho_0 d\\b{\\hat x}/3$。 $$ \\b E=\\frac{1}{4\\pi\\eps_0}\\left(\\frac{3(\\b p\\cdot\\b r)\\b r}{r^5}-\\frac{\\b p}{r^3}\\right)=\\frac{R^3\\rho_0d}{3\\eps_0}\\frac{3\\b r_x\\b r-r^2\\b{\\hat x}}{r^5} $$ 另外，$\\b r$ 方向的电荷面密度（虚线截灰色部分乘电荷体密度）为 $\\rho_0d\\cos\\theta$。\n固定 $\\rho_0d$ 为常数 $\\sigma_0$，让 $d\\to 0$。最终就可以得到按要求分布的电荷导致的电场。球内外分别为 $$ -\\frac{\\sigma_0}{3\\eps_0}\\b{\\hat x};\\;\\frac{R^3\\sigma_0}{3\\eps_0}\\frac{3\\b r_x\\b r-r^2\\b{\\hat x}}{r^5}=\\frac{R^3\\sigma_0}{\\eps_0r^3}\\left(\\cos\\theta-\\frac13,\\cos\\theta\\sin\\theta\\right) $$ 极化强度和电场强度互相影响，有方程 $$ \\left\\{ \\begin{align*} E\u0026amp;=E_0-\\frac{P}{3\\eps_0}\\\\ P\u0026amp;=\\eps_0(\\eps_r-1)E \\end{align*} \\right. $$ 解得 $$ \\left\\{ \\begin{align*} E\u0026amp;=\\frac{3\\eps_0}{\\eps_r+2}E_0\\\\ P\u0026amp;=\\frac{\\eps_r-1}{\\eps_r+2}3\\eps_0E_0 \\end{align*} \\right. $$ $\\eps_r\\to+\\infty$ 时相当于导体，它长这样（可以与这里对比验证）：\n这里有三个问题：\n为什么是均匀极化？猜的，由唯一性定理这个导出的就是答案。 为什么是 $E=E_0-P/3\\eps_0$ 而不是 $E=E_0-P/3\\eps_r\\eps_0$？因为 ${}-P/3\\eps_0$ 的这部分本身考虑的就是极化，在已经考虑极化的影响下，球内部由于是均匀极化，就相当于没东西。 不是说这种电荷聚集在表面的，它的表面电场是内外电场的平均吗？为什么这里用的是内部？好问题，我也想知道。 静磁学的基本公式 电和磁的关系 有一根电中性的直导线，其中自由电荷密度为 $\\lambda$，移动速度为 $v$，从而电流为 $I$。一个距离导线 $r$ 的电荷 $q$ 与自由电荷一样以速度 $v$（与电流方向相反）移动。下面我们可以求得它所在处的磁场为 $\\mu_0I/2\\pi r$，因此它受力 $\\mu_0Iqv/2\\pi r$。\n称刚才考虑的参考系为 $A$，导线中的正电荷在 $A$ 中静止。考虑 $q$ 静止的参考系 $A^\\prime$。$q$ 就不受力了吗？并不是。不同的参考系中电荷量不变，而长度变，所以导线中的正负电荷的密度不同了。对于正电荷，根据尺缩效应，它的密度变为了 $\\lambda_+^\\prime=\\gamma\\lambda$。负电荷需要反过来用，因为它在 $A^\\prime$ 中也是静止的，所以 $\\lambda_-^\\prime=\\lambda/\\gamma$。从而 $q$ 受库仑力 $(\\lambda_+^\\prime-\\lambda_-^\\prime)q/2\\pi\\eps_0r=\\gamma v^2\\lambda q/2\\pi\\eps_0c^2r=\\gamma\\mu_0Iqv/2\\pi r$。\n由于这个力是垂直于导线方向的，所以洛伦兹变换只需乘/除以 $\\gamma$，求得的结果自洽。\n这个事情说明电场和磁场本质上是一个事情，或者说，“磁场是电场的相对论修正”（知乎上看到的一句句子）。这个事情告诉我们，有时候就算是低速情况，也要考虑相对论效应。下面给出电流、电荷密度的洛伦兹变换（通过 $\\nabla\\cdot\\b j+\\p\\rho/\\p t=0$ 推得）： $$ \\left\\{\\begin{aligned} \\b j_x^\\prime\u0026amp;=\\gamma\\left(\\b j_x-v\\rho\\right)\\\\ \\b j_y^\\prime\u0026amp;=\\b j_y\\\\ \\b j_z^\\prime\u0026amp;=\\b j_z\\\\ \\rho^\\prime\u0026amp;=\\gamma\\left(\\rho-\\frac v{c^2}\\b j_x\\right) \\end{aligned}\\right. $$\n公式及推导 物理量/关系 静电场 静磁场 公理 1.1：点场源与场的关系 库仑定律 $\\b E=\\frac{1}{4\\pi\\eps_0}\\frac{Q\\b{\\hat r}}{r^2}$ 毕奥—萨伐尔定律 $\\b B=\\frac{\\mu_0}{4\\pi}\\frac{Q\\b v\\times\\b{\\hat r}}{r^2}$ 公理 1.2：场源与通/环量的关系，微分形式 高斯定律 $\\nabla\\cdot\\b E=\\frac{\\rho}{\\eps_0}$ 安培定律 $\\nabla\\times\\b B=\\mu_0\\b j$ 公理 1.2：场源与通/环量的关系，积分形式 高斯定律 $\\oiint\\b E\\cdot\\d\\b s=\\frac{Q}{\\eps_0}$ 安培定律 $\\oint\\b B\\cdot\\d\\b l=\\mu_0I$ 公理 1.3：场的无旋/源特征 电场无旋 $\\nabla\\times\\b E=\\b 0$ 磁场无源 $\\nabla\\cdot\\b B=0$ 公理 2：场与力的关系 洛伦兹力 $\\b F=q\\b E$ 洛伦兹力 $\\b F=q\\b v\\times\\b B$ 点（总）场源 电荷 $Q$ “动”电荷 $Q\\b v$ 场源的体密度 （体）电荷密度 $\\rho$ （体）电流密度 $\\b j$ 场源的面密度 面电荷密度 $\\sigma$ 面电流密度 $\\b J$ 场源的线密度 线电荷密度 $\\lambda$ 电流 $\\b I$ 场源的变化 $-$ $\\nabla\\cdot\\b j=-\\frac{\\d\\rho}{\\d t}$ 常数 真空介电常数 $\\eps_0$ 真空磁导率 $\\mu_0$ 场 电场（强度）$\\b E$ 磁场（强度）$\\b B$ 一般场源与场的关系，叠加定律 $\\b E=\\frac{1}{4\\pi\\eps_0}\\iiint\\frac{\\rho\\d v(\\b r-\\b r_0)}{|\\b r-\\b r_0|^3}$ $\\b B=\\frac{\\mu_0}{4\\pi}\\iiint\\frac{\\b j\\d v\\times(\\b r-\\b r_0)}{|\\b r-\\b r_0|^3}$ 势 电势 $\\varphi$ 磁矢势 $\\b A$ 势与场源的关系，微分形式 $\\nabla^2\\varphi=-\\frac{\\rho}{\\eps_0}$ $\\nabla^2\\b A=-\\mu_0\\b j$ 势与场源的关系，积分形式 $\\varphi=\\frac{1}{4\\pi\\eps_0}\\iiint\\frac{\\rho\\d v}{|\\b r-\\b r_0|}$ $\\b A=\\frac{\\mu_0}{4\\pi}\\iiint\\frac{\\b j\\d v}{|\\b r-\\b r_0|}$ 场与势的关系 $\\b E=-\\nabla\\varphi$ $\\b B=\\nabla\\times\\b A$ 势能 电势能 $W=\\varphi q$ $-$ 势能与做功的关系 路径无关 $\\varphi=\\int\\b E\\cdot\\d\\b l$ 磁场的洛伦兹力不做功 偶极子 电偶极子 $\\b p=Q\\b d$ 磁偶极子 $\\b\\mu=I\\b S$ 偶极子的势 $\\varphi=\\frac{1}{4\\pi\\eps_0}\\frac{\\b p\\cdot\\b{\\hat r}}{r^2}$ $\\b A=\\frac{\\mu_0}{4\\pi}\\frac{\\b\\mu\\times\\b{\\hat r}}{r^2}$ 偶极子的场 $\\b E=\\frac{1}{4\\pi\\eps_0}\\big(\\frac{3(\\b p\\cdot\\b r)\\b r}{r^5}-\\frac{\\b p}{r^3}\\big)$ $\\b B=\\frac{\\mu_0}{4\\pi}\\big(\\frac{3(\\b\\mu\\cdot\\b r)\\b r}{r^5}-\\frac{\\b\\mu}{r^3}\\big)$ 偶极子受力 $\\b F=\\nabla(\\b p\\cdot\\b E)$ $\\b F=\\nabla(\\b\\mu\\cdot\\b B)$ 场能 1 静电能 $U=\\frac12\\iiint\\varphi\\rho\\d v$ 静磁能 $U=\\frac12\\iiint\\b A\\cdot\\b j\\d v$ 场能 2 $U=\\frac{\\eps_0}2\\iiint\\b E^2\\d v$ $U=\\frac1{2\\mu_0}\\iiint\\b B^2\\d v$ 注：\n公理 1.1 和 1.2+1.3 可互推。 疑似书里是把 $\\b B$ 作为磁场强度而非磁感应强度来讲的，也就是说可以全部当作 $\\b H$。我在网上看到磁感应强度（考虑介质之后）是比磁场强度更本质的量，不太能理解。这不是跟 $\\b E-\\b D$ 关系刚好反过来了吗？ 静电场、静磁场的定义：电荷密度恒定（可以有电流），电流恒定。\n磁场是由运动的电荷产生的。我们可以对电场和磁场进行一个比对：\n电荷 $\\xrightarrow{/r^2}$ 电场 $\\xrightarrow{\\cdot q}$ 电场力\n电荷 $\\xrightarrow{/\\d t}$ 电流 $\\xrightarrow{/r^2}$ 磁场 $\\xrightarrow{\\times q\\b v}$ 磁场力\n所以相较而言，现在需要额外考虑的恒定的电荷运动的描述。\nPart 1. 电流密度 $\\b j$：单位时间，单位面积，电荷通过量。我们有： $$ \\begin{align*} \u0026amp;\\b j=\\frac{\\rho\\d\\b l}{\\d t}=\\rho\\b v=Nq\\b v\\\\ \u0026amp;\\d Q=\\b j\\cdot\\d\\b s\\d t=\\rho\\b v\\cdot\\d\\b s\\d t\\\\ \u0026amp;I=\\iint_S\\b j\\cdot\\d\\b s \\end{align*} $$ 你可能会觉得，（体）电流密度和（体）电荷密度是对照的，但它是单位面积通过的电荷量，这个不好记忆。可以这样记：它是单位体积电荷在单位时间内走过的“总路程”，即电荷量乘路程。\n有时候，我们也会把电流当作矢量，即沿导线方向。\n电流密度变化与电荷密度变化的关系：由电荷守恒（这里电荷只能移动，不能由你再往里放或者从里拿），对于一个体 $V$， $$ \\oiint_{\\p V}\\b j\\cdot\\d\\b s=-\\frac{\\d Q}{\\d t}=-\\frac{\\d}{\\d t}\\iiint_V\\rho\\d v\\Longrightarrow\\nabla\\cdot\\b j=-\\frac{\\d\\rho}{\\d t} $$ 静磁场的等价刻画是 $\\d\\rho/\\d t=0$ 或 $\\d\\b E/\\d t=\\b 0$。以下推导验证了两个条件的等价： $$ 0=\\nabla\\cdot(\\nabla\\times\\b B)=\\mu_0\\nabla\\cdot\\b j=-\\mu_0\\frac{\\d\\rho}{\\d t}=0 $$ 所以说电流一定成环。无限长导线可以认为成头尾在无限远处相接。\n没有磁荷，这个是实验得出的。\nPart 2. 静磁场的麦克斯韦方程： $$ \\left\\{\\begin{align*} \\nabla\\cdot\\b B\u0026amp;=0\\\\ \\nabla\\times\\b B\u0026amp;=\\mu_0\\b j \\end{align*}\\right. $$ $\\mu_0$ 被称为真空磁导率，一个重要的关系是 $c^2\\eps_0\\mu_0=1$，$c$ 是光速。\n这个和毕奥—萨伐尔定律是可以互推的，课上根本没提后者，了解一下就行，推导和电场的那些基本是一样的。值得注意的一个点是，毕奥—萨伐尔定律加洛伦兹力会导致出现两段电流元之间的作用力违反牛三的情况。\nPart 3. 现在关注力的部分。洛伦兹力： $$ F=q(\\b E+\\b v\\times\\b B) $$\n从洛伦兹力到安培力： $$ \\b F=\\iiint_VN\\d v(q\\b v\\times\\b B)=\\iiint_V(\\b j\\times\\b B)\\d v=\\iiint_V(\\b j\\d s\\times\\b B)\\d l=\\int_L(\\b I\\times\\b B)\\d l\\Longrightarrow\\frac{\\d\\b F}{\\d l}=\\b I\\times\\b B $$\nPart 4. 安培定律： $$ \\oint_L\\b B\\cdot\\d\\b l=\\iint_S(\\nabla\\times\\b B)\\cdot\\d\\b s=\\mu_0\\iint_S\\b j\\cdot\\d\\b s=\\mu_0I $$ 注意这里的 $I$ 指的是穿过 $S$ 的电流，而不是任意方向的！\n另外这个只适用于静磁场。变化的时候要用安培—麦克斯韦定律。\n两个电流同向的平行导线是互相吸引的。在电流的值通过 $1\\unit{C/s}$ 定义之前，它就是通过平行导线的受力为某个值来定义的。\n安培定律 $\\Rightarrow$ 毕奥—萨伐尔定律： $$ \\begin{align*} \\b B\u0026amp;=\\nabla\\times\\b A\\\\ \u0026amp;=\\frac{\\mu_0}{4\\pi}\\nabla\\times\\iiint_V\\frac{\\b j\\d v}{|\\b r-\\b r^\\prime|}\\\\ \u0026amp;=\\frac{\\mu_0}{4\\pi}\\iiint_V\\left(\\nabla\\frac{1}{|\\b r-\\b r^\\prime|}\\right)\\times\\b j\\d v\u0026amp;(\\nabla\\times(f\\b A)=f\\nabla\\times\\b A+\\nabla f\\times\\b A)\\\\ \u0026amp;=-\\frac{\\mu_0}{4\\pi}\\iiint_V\\frac{(\\b r-\\b r^\\prime)\\times\\b j\\d v}{|\\b r-\\b r^\\prime|^3}\\\\ \u0026amp;=\\frac{\\mu_0}{4\\pi}\\iiint_V\\frac{\\b j\\d v\\times(\\b r-\\b r^\\prime)}{|\\b r-\\b r^\\prime|^3}\\\\ \u0026amp;=\\frac{\\mu_0}{4\\pi}\\iiint_V\\frac{I\\d\\b l\\times(\\b r-\\b r^\\prime)}{|\\b r-\\b r^\\prime|^3} \\end{align*} $$ 反过来（需假设无穷远处无电流，或者至少除以 $r$ 一次方后趋近于零）： $$ \\begin{align*} \\b B\u0026amp;=\\frac{\\mu_0}{4\\pi}\\iiint_V\\frac{\\b j\\d v\\times(\\b r-\\b r^\\prime)}{|\\b r-\\b r^\\prime|^3}\\\\ \u0026amp;=\\nabla\\times\\frac{\\mu_0}{4\\pi}\\iiint_V\\frac{\\b j\\d v}{|\\b r-\\b r^\\prime|}\\\\ \\nabla\\times\\b B\u0026amp;=\\frac{\\mu_0}{4\\pi}\\nabla\\times\\left(\\nabla\\times\\iiint_V\\frac{\\b j\\d v}{|\\b r-\\b r^\\prime|}\\right)\\\\ \u0026amp;=\\frac{\\mu_0}{4\\pi}\\left[\\nabla\\left(\\nabla\\cdot\\iiint_V\\frac{\\b j\\d v}{|\\b r-\\b r^\\prime|}\\right)-\\nabla^2\\iiint_V\\frac{\\b j\\d v}{|\\b r-\\b r^\\prime|}\\right]\\\\ \u0026amp;=\\frac{\\mu_0}{4\\pi}\\left[\\nabla\\left(-\\iiint_V\\b j\\d v\\nabla^\\prime\\cdot\\frac1{|\\b r-\\b r^\\prime|}\\right)-\\nabla^2\\iiint_V\\frac{\\b j\\d v}{|\\b r-\\b r^\\prime|}\\right]\\\\ \u0026amp;=\\frac{\\mu_0}{4\\pi}\\left[\\nabla\\left(-\\oiint_{\\p V}\\frac{\\b j\\cdot\\d\\b s}{|\\b r-\\b r^\\prime|}-\\iiint_V\\frac{\\nabla^\\prime\\cdot\\b j\\d v}{|\\b r-\\b r^\\prime|}\\right)-\\nabla^2\\iiint_V\\frac{\\b j\\d v}{|\\b r-\\b r^\\prime|}\\right]\\\\ \u0026amp;=-\\frac{\\mu_0}{4\\pi}\\nabla^2\\iiint_V\\frac{\\b j\\d v}{|\\b r-\\b r^\\prime|}\\\\ \u0026amp;=\\mu_0\\iiint_V\\delta^3(\\b r-\\b r^\\prime)\\b j\\d v\\\\ \u0026amp;=\\mu_0\\b j(\\b r) \\end{align*} $$\nPart 5. 磁矢势：由于 $\\nabla\\cdot\\b B=0$，故 $\\b B=\\nabla\\times\\b A$，这个 $\\b A$ 称为磁矢势。由于 $\\b A+\\nabla(\\forall\\varphi)$ 都不影响 $\\nabla\\times\\b A$，故 $\\b A$ 有很大的不确定度。实际上加了一个库仑规范，要求 $\\nabla\\cdot\\b A=0$。但是仍然不唯一……\n为什么要定这个库仑规范呢？考虑 $$ \\mu_0\\b j=\\nabla\\times\\b B=\\nabla\\times(\\nabla\\times\\b A)=\\nabla(\\nabla\\cdot\\b A)-\\nabla^2\\b A=-\\nabla^2\\b A $$ 这很好，因为它和电势的形式一模一样！ $$ \\begin{align*} \u0026amp;\\nabla^2\\varphi=-\\frac{\\rho}{\\eps_0}\\\\ \u0026amp;\\nabla^2\\b A_i=-\\mu_0\\b j_i \\end{align*} $$ 于是 $$ \\b A(\\b r)=\\frac{\\mu_0}{4\\pi}\\iiint_V\\frac{\\b j(\\b r^\\prime)\\d v}{|\\b r-\\b r^\\prime|} $$ 注意在 $\\b B=0$ 处 $\\b A$ 可能变化。\n我们验证一下这个式子必定符合库仑规范： $$ \\begin{align*} \\nabla\\cdot\\b A(\\b r)\u0026amp;=\\frac{\\mu_0}{4\\pi}\\iiint_V\\b j(\\b r^\\prime)\\d v\\nabla_{\\b r}\\cdot\\left(\\frac1{|\\b r-\\b r^\\prime|}\\right)\\\\ \u0026amp;=-\\frac{\\mu_0}{4\\pi}\\iiint_V\\b j(\\b r^\\prime)\\d v\\nabla_{\\b r^\\prime}\\cdot\\left(\\frac1{|\\b r-\\b r^\\prime|}\\right)\\\\ \u0026amp;=-\\frac{\\mu_0}{4\\pi}\\iiint_{\\p V}\\frac{\\b j(\\b r^\\prime)\\cdot\\d\\b s}{|\\b r-\\b r^\\prime|}+\\frac{\\mu_0}{4\\pi}\\iiint_V\\frac{\\nabla_{\\b r^\\prime}\\cdot\\b j(\\b r^\\prime)\\d v}{|\\b r-\\b r^\\prime|}\\\\ \u0026amp;=0 \\end{align*} $$ 倒数第二个等号是分部积分，最后一个等号第一项为零是因为可以把边界取得足够远，第二项为零是因为是静的情况。\n例 1 通电直导线的磁场。首先可以用安培定律，取一个圆环。通过圆面的电流量就是 $I$，于是 $$ \\b B=\\frac{\\mu_0\\b I\\times\\b{\\hat r}}{2\\pi r} $$ 也可以先求磁矢势，这个结构和 $\\lambda=I$ 的直棒没什么两样，因此（这里 $r$ 是柱坐标系的） $$ \\b A_z=-\\frac{\\mu_0I}{2\\pi}\\ln r $$ 于是 $$ \\b B=\\nabla\\times\\left(0,0,-\\frac{\\mu_0I}{2\\pi}\\ln r\\right)=\\left(-\\frac{\\mu_0Iy}{2\\pi(x^2+y^2)},\\frac{\\mu_0Ix}{2\\pi(x^2+y^2)},0\\right)=\\frac{\\mu_0I}{2\\pi r}\\b{\\hat\\phi} $$ 也可以用毕奥—萨伐尔定律： $$ \\begin{align*} \\b B\u0026amp;=\\frac{\\mu_0}{4\\pi}\\int_{-\\infty}^{+\\infty}\\frac{I\\d z(\\b{\\hat z}\\times(\\b r-z\\b{\\hat z}))}{|\\b r-z\\b{\\hat z}|^3}\\\\ \u0026amp;=\\frac{\\mu_0I}{4\\pi}\\int_{-\\infty}^{+\\infty}\\frac{(0,0,1)\\times(x_0,y_0,z_0-z)}{\\left[x_0^2+y_0^2+(z-z_0)^2\\right]^{3/2}}\\d z\\\\ \u0026amp;=\\frac{\\mu_0I}{4\\pi}\\int_{-\\infty}^{+\\infty}\\frac{(-y_0,x_0,0)}{\\left[x_0^2+y_0^2+(z_0-z)^2\\right]^{3/2}}\\d z\\\\ \u0026amp;=\\frac{\\mu_0I}{4\\pi}(-y_0,x_0)\\left.\\frac{z_0-z}{\\left(x_0^2+y_0^2\\right)\\sqrt{x_0^2+y_0^2+(z_0-z)^2}}\\right|_{-\\infty}^{+\\infty}\\\\ \u0026amp;=\\frac{\\mu_0I(-y_0,x_0)}{2\\pi\\left(x_0^2+y_0^2\\right)} \\end{align*} $$\n例 2 无限长通电螺线管的磁场：首先通过环绕螺线管的安培回路得出外部无磁场，其次通过一半在内的安培回路得出内部 $$ B=\\mu_0nI $$ 其中 $n$ 是单位长度的导线股数。\n如果用磁矢势或毕奥—萨伐尔算，则是灾难。为了演示还是用磁矢势算一下：\n假设轴是沿 $z$ 轴方向的。令面电荷密度为 $J=nI$，写出方向就是 $\\b J=(-J\\sin\\varphi,J\\cos\\varphi,0)$。为了算 $\\b A_y$，考虑用之前遇到过的套路，就是两个轴分别偏移了 $d/2$ 的实心均匀带点柱，让 $d\\to 0$。\n对于一个圆柱，我们让它表面 $\\varphi=0$（虽然直接是两个圆柱时无法自洽，但取了 $\\p$ 之后实际上我们只关心变化量，所以说就隐含改为无穷远处为 $0$ 了）。在内部距轴 $r$ 处的电势为 $$ \\varphi=\\frac{\\lambda}{4\\pi\\eps_0}-\\frac{\\lambda r^2}{4\\pi\\eps_0R^2} $$ 两个位移取极限，我们希望 $$ \\frac{\\lambda}{\\pi R^2}d=J $$ 所以最终的电势是 $$ \\lim_{d\\to 0}-\\frac{\\p\\varphi}{\\p x}\\cdot d\\cdot\\frac{J}{\\lambda d/\\pi R^2}=\\frac{Jx}{2\\eps_0} $$ 在外部则是 $$ \\varphi=-\\frac{\\lambda}{2\\pi\\eps_0}\\ln r $$ 同样完整的电势是 $$ -\\frac{\\p\\varphi}{\\p x}\\cdot\\frac{J\\pi R^2}{\\lambda}=\\frac{2\\lambda x}{4\\pi\\eps_0r^2}\\cdot\\frac{J\\pi R^2}{\\lambda}=\\frac{JxR^2}{2\\eps_0r^2} $$ $x$ 维类似。所以总的来说，（在柱坐标系下） $$ \\b A=\\left\\{\\begin{aligned}\u0026amp;\\frac{\\mu_0Jr}{2}\\b{\\hat\\phi},\u0026amp;r\u0026lt;R\\\\ \u0026amp;\\frac{\\mu_0JR^2}{2r}\\b{\\hat\\phi},\u0026amp;r\u0026gt;R\\end{aligned}\\right. $$ 于是 $$ \\b B=\\left\\{\\begin{aligned}\u0026amp;\\mu_0J\\b{\\hat z},\u0026amp;r\u0026lt;R\\\\ \u0026amp;\\b 0,\u0026amp;r\u0026gt;R\\end{aligned}\\right. $$ 用毕奥—萨伐尔算，我在另一篇里写过了。\n磁偶极子 磁铁的原理：磁铁中的电子自旋方向一致，而一般金属的电子自旋都是乱的，所以不显磁性。一堆小的电流回路等效于一个大的回路，这个原理就是 Stokes 公式。\n磁偶极子：考虑两根长度为 $a$，距离为 $b$ 的，平行的短超导线，电流为相反的 $I$。这个可以类比电偶极子。电偶极子是 $p=Qd$，这里，$Q$ 类比 $Ia$，$d$ 就是 $b$。所以 $p=Iab$。如果这两个导线是沿 $x$ 方向的，那么 $$ \\b A_x=-\\frac{\\mu_0}{4\\pi}\\frac{Iaby}{r^3} $$ 当然孤立的两根导线是无法电荷守恒的，在 $y$ 方向再有一对导线，就可以形成一个回路。于是 $$ \\b A_y=\\frac{\\mu_0}{4\\pi}\\frac{Iabx}{r^3} $$ 于是 $$ \\b A=\\frac{\\mu_0}{4\\pi}\\frac{Iab\\b{\\hat z}\\times\\b{\\hat r}}{r^2} $$ 所以我们可以定义磁偶极矩 $$ \\b\\mu=I\\b S $$ 其中 $\\b S$ 就是面积矢量。就有 $$ \\b A=\\frac{\\mu_0}{4\\pi}\\frac{\\b\\mu\\times\\b{\\hat r}}{r^2} $$ 容易发现，一处的势是和电流方向相同的。\n然后可以导出 $$ \\b B=\\frac{\\mu_0}{4\\pi}\\left(\\frac{3(\\b\\mu\\cdot\\b r)\\b r}{r^5}-\\frac{\\b\\mu}{r^3}\\right) $$ 对比电偶极子的情况，我们可以发现，一个回路（磁偶极子），和连线与该回路面垂直的两个异种电荷（电偶极子）是可以类比的。\n对于一般的情况，推导几乎和电势的多级展开思路相同。 $$ \\begin{align*} \\b A(\\b r)\u0026amp;=\\frac{\\mu_0}{4\\pi}\\iiint_V\\frac{\\b j(\\b r^\\prime)\\d v}{|\\b r-\\b r^\\prime|}\\\\ \u0026amp;\\approx\\frac{\\mu_0}{4\\pi}\\iiint_V\\b j(\\b r^\\prime)\\d v\\left(\\frac1r-\\b r^\\prime\\cdot\\nabla\\frac1r\\right)\\\\ \u0026amp;=\\frac{\\mu_0}{4\\pi}\\left[\\frac1r\\iiint_V\\b j(\\b r^\\prime)\\d v-\\iiint_V\\left(\\nabla\\frac1r\\cdot\\b r^\\prime\\right)\\b j(\\b r^\\prime)\\d v\\right]\\\\ \\end{align*} $$ 为了得到标准形式，我们需要规定 $\\b j$ 在空间中的分布是有限的（要是无限的根本不适合做近似）。先证明一个引理： $$ \\iiint_V\\b j\\cdot\\nabla f\\d v=0 $$ 这是因为 $$ \\text{LHS}=\\iiint_V\\nabla\\cdot(\\b jf)\\d v-\\iiint_Vf\\nabla\\cdot\\b j\\d v=\\oiint_{\\p V}\\b jf\\cdot\\d\\b s=0 $$ 第一项 $$ \\iiint_V\\b j_x\\d v=\\iiint_V\\b j\\cdot\\b{\\hat x}\\d v=\\iiint_V\\b j\\cdot\\nabla x\\d v=0 $$ 第二项，首先我们知道，对任意两维坐标 $\\b x_k,\\b x_l$（这里 $\\b x$ 相当于 $\\b r$，写 $\\b x$ 是为了避免和别的地方混淆）， $$ 0=\\iiint_V\\b j\\cdot\\nabla(\\b x_k\\b x_l)\\d v=\\iiint_V\\b j_k\\b x_l\\d v+\\iiint_V\\b j_l\\b x_k\\d v $$ 然后我们考虑使用 $\\b a\\times(\\b b\\times\\b c)=(\\b a\\cdot\\b c)\\b b-(\\b a\\cdot\\b b)\\b c$ 凑叉乘，记 $\\b d=\\nabla(1/r)$。 $$ \\begin{align*} \u0026amp;\\iiint_V\\left(\\b d\\cdot\\b r^\\prime\\right)\\b j(\\b r^\\prime)\\d v\\\\ ={}\u0026amp;\\iiint_V\\left[\\frac{(\\b d\\cdot\\b r^\\prime)\\b j(\\b r^\\prime)-(\\b d\\cdot\\b j(\\b r^\\prime))\\b r^\\prime}{2}+\\frac{(\\b d\\cdot\\b r^\\prime)\\b j(\\b r^\\prime)+(\\b d\\cdot\\b j(\\b r^\\prime))\\b r^\\prime}{2}\\right]\\d v\\\\ ={}\u0026amp;{-\\frac12}\\iiint_V\\b d\\times(\\b r^\\prime\\times\\b j(\\b r^\\prime))\\d v+\\sum_{k,l}\\b e_l\\iiint_V\\b d_k\\left(\\b r^\\prime_k\\b j(\\b r^\\prime)_l+\\b j(\\b r^\\prime)_k\\b r^\\prime_l\\right)\\d v\\\\ ={}\u0026amp;{-\\frac12}\\b d\\times\\iiint_V\\b r^\\prime\\times\\b j(\\b r^\\prime)\\d v \\end{align*} $$ 于是全部算起来就是 $$ \\b A(\\b r)\\approx\\frac{\\mu_0}{4\\pi}\\b d\\times\\frac12\\iiint_V\\b r^\\prime\\times\\b j(\\b r^\\prime)\\d v $$ 其中后面这一项（含 $1/2$）就是一般意义下的磁偶极矩。这个推导可以作为磁单极子不存在的理论依据。\n对于一个不规则形状但共面的回路， $$ \\b\\mu=\\frac12\\iiint_V\\b r\\times\\b j(\\b r)\\d s\\d l=\\frac12\\oint_L\\b r\\times I\\d\\b r=I\\b n\\oint_Lr^2\\d\\theta=I\\b S $$\n符合常理。\n静磁能 定义静磁能为，将整个体系从相距无穷远且各部分（含自由电荷）静止，控制得到当前状态所作的总功。以下的推导不是特别严谨，你可以假定不考虑相对论效应。同时我们只是举了个特例来说明，随便变一下电偶极子的形状、磁场的分布之类的，体系成员的数量之类的，整个就很难推了。反正我觉得我写得比书里稍微清楚一点点。\n考虑一个磁偶极子在匀强的 $z$ 方向磁场里，与 $x$ 轴有夹角，与 $y$ 轴平行。\n在 1 和 2 上的力虽然相等，但会出现一个力矩，倾向于将整个矩形转成与 $x$ 轴也平行。 $$ \\b\\tau=\\b l\\times\\b F=a\\sin\\theta\\cdot BIb\\cdot(-\\b{\\hat y})=\\b\\mu\\times\\b B $$ 由于我们没学过普物一，所以这里推一下二维的情况： $$ \\d W=\\sum\\d\\b r\\cdot\\b F=\\sum r\\d\\theta F_\\perp=\\sum\\d\\theta(\\b r\\times\\b F)=\\tau\\d\\theta $$ 也就是说，如果我们基于这个匀强磁场造成的“回复力”定义势能，那么现在这个磁偶极子的势能就是 $$ \\int\\tau\\d\\theta^\\prime=\\int\\mu B\\sin\\theta^\\prime\\d\\theta^\\prime=-\\mu B\\cos\\theta+C $$\n为了检验这么搞是否靠谱，现在，我们再考虑两个场景：一个是将 $\\theta=0$ 的这个磁偶极子从无限远处移到原点，一个是将 $\\theta=\\pi/2$ 的移过来。\n由于磁场无法做到无限，我们就想它在某一处有个突变。对于 $\\theta=0$，譬如说从 $x=+\\infty$ 处移过来，然后在某个 $x\\le t$ 开始突然有了磁场。那么在穿越这个边界时，3、4 段力抵消，1 段有力，2 段无力，磁场力做功就是 $Fl=BIb\\cdot a=\\mu B$。\n如果是 $\\theta=\\pi/2$，那么 3、4 段无力，1、2 段力抵消，就是不做功。于是 $E_{\\pi/2}-E_0=\\mu B$，这个和上面的是一致的。\n好，我们现在知道的事情是，将 $\\theta=0$ 情况从无穷远移到原点，所做的功是 $-\\mu B$（和磁场做的功相反）。我们再考察维持电流所需要的功。由于这个是动生电动势，所以我们还是可以用洛伦兹力解释的。当 1 段在内，2 段在外时，且以 $v_0$ 的速度移动时，1 段受到导线方向的力为 $F=Qv_0B$，$Q$ 为 1 段总自由电荷量，为维持电流，做的功率为 $P=Fv$，$v$ 是电流中的电荷速度。总的功就是 $$ W=Pt=Fv\\cdot\\frac{a}{v_0}=QvaB=b\\lambda vaB=ISB=\\mu B $$ 也就是说维持电流做的功与移进去做的功刚好抵消，这很合理，因为磁的洛伦兹力不做功。\n当然同时我们也要考虑产生这个均匀电场的某个神秘角色（比如一个通电螺线管），维持它的电流所用的功。由于力的作用是相互的，因此如果把这个螺线管看作一个整体，它受的力大小就等于电偶极子所受的力（这句话的前提实际上就是，造成电动势的这部分洛伦兹力整体上合力为零），于是再由洛伦兹力不做功，维持电流的功仍然是 $\\mu B$，而这个螺线管是不动的，所以机械上不做功。总体来说做功为 $-\\mu B+\\mu B+\\mu B=\\mu B$。于是，我们可以得到总的静磁能为 $\\mu B$ 加上两个回路各自固有的能量。同样如果有一定夹角，我们可以推出 $U=\\b\\mu\\cdot\\b B$。于是对于一个处于非均匀磁场种的一般回路而言，可以把它拆成小回路 $$ U=\\iiint_V\\b B\\cdot\\d\\b\\mu=I\\iint_S\\b B\\cdot\\d\\b s=I\\oint_{\\p S}\\b A\\cdot\\d\\b l $$ 对于一般的情况，可以用无数回路模拟整个无规则的 $\\b j$ 场。那么这个时候 $I\\d\\b l=\\b j\\d v$。加之我们刚刚考虑的是“螺线管对电偶极子”的能量，反过来还有一倍，所以要除以二，总的就是 $$ U=\\frac12\\iiint_V\\b A\\cdot\\b j\\d v $$\n你可能会想一个问题：既然磁场力不做功，那么为什么磁场会有能量呢？这说明你是在稳恒电流的默认假设下考虑的。变化的情况下还有感生电场。\n法拉第电磁感应定律 对于一个面 $S$，定义磁通量 $$ \\Phi=\\iint_S\\b B\\cdot\\d\\b s $$ 由于 $\\nabla\\cdot\\b B=0$，故这个是良定义的。\n一般来说，之所以能定义电势，就是因为电场做功与路径无关，或者说电场无旋。但是这里我们要给出电动势的定义：将一个电荷 $q$，沿着回路移动一圈，所做的功，除以 $q$。一般符号写成 $\\cal E$。\n那就很奇怪了，这不应该永远是 $0$ 吗？有两种主要情况它会有值。一种是洛伦兹力的分量（洛伦兹力减安培力）形成的动生电动势：当磁场是静的时候， $$ \\mathcal{E}=\\oint_L\\frac{\\b F}q\\cdot\\d\\b l=\\oint_L(\\b v\\times\\b B)\\cdot\\d\\b l=-\\oint_L(\\b v\\times\\d\\b l)\\cdot\\b B=-\\iint_S\\frac{\\d\\b s}{\\d t}\\cdot\\b B=-\\frac{\\d\\Phi}{\\d t} $$ （注：高中课内推导不出这个的原因主要是没学混合积公式，乐）\n这种情况并非“真正有旋”，而只是形式上区分了\u0026quot;mechanical\u0026quot;和\u0026quot;electrical\u0026quot;的力。但是感生电动势就不能这么解释了，我们需要引入法拉第定律：当磁场不是静的时候， $$ \\nabla\\times\\b E=-\\frac{\\p\\b B}{\\p t} $$ 则 $$ \\mathcal{E}=\\oint_L\\b E\\cdot\\d\\b l=\\iint_S(\\nabla\\times\\b E)\\cdot\\d\\b s=-\\iint_S\\frac{\\p\\b B}{\\p t}\\cdot\\d\\b s=-\\frac{\\d\\Phi}{\\d t} $$ 所以两个式子可以联合在一起。可以推出高中特殊情况下的公式 $\\mathcal{E}=Blv$，方向可以归纳为楞次定律。\n自感与互感 自感与互感系数就是回路的电流变化产生的对回路的电动势的比例。例如说，对于一个长度为 $l$，总匝数为 $N$，截面积为 $S$ 的足够长螺线管， $$ \\mathcal{E}=-\\frac{\\d\\Phi}{\\d t}=-\\frac{\\d(\\mu_0\\frac{N}{l}I\\cdot NS)}{\\d t}=-\\mu_0\\frac{N^2S}{l}\\dot I=-\\mu_0n^2lS\\dot I $$\n所以说自感系数为 $L=\\mu_0n^2lS=\\mu_0n^2V$。在高中的时候我们会看到那种直接视作理想情况（$\\mu_0nI$）推互感的方法，然后仔细一推会发现 $M_{12}\\ne M_{21}$，这个东西的原因是两个螺线管之间存在着不可忽略且不可避免的漏磁。如果要写严格的一般的公式，我们可以这样考虑。对于两个回路，记它们的面分别为 $S_1$、$S_2$。 $$ \\begin{align*} \\Phi_{12}=\\iint_{S_2}\\b B_1\\cdot\\d\\b s_2=\\oint_{\\p S_2}\\b A_1\\cdot\\d\\b l_2=\\oint_{\\p S_1}\\oint_{\\p S_2}\\frac{\\mu_0I_1\\d\\b l_1\\cdot\\d\\b l_2}{4\\pi r_{12}} \\end{align*} $$ 注意到 $1$ 和 $2$ 在式子中的地位相同，所以说互感系数 $$ M_{12}=M_{21}=\\frac{\\mu_0}{4\\pi}\\oint_{\\p S_1}\\oint_{\\p S_2}\\frac{\\d\\b l_1\\cdot\\d\\b l_2}{r_{12}} $$ 明确一下，$M_{12}$ 是指 $1$ 的电流变化在 $2$ 中产生的电动势的比例。电动势的正方向与电流正方向相同，所以 $\\mathcal{E}=-L\\dot I$ 定义的 $L$ 一定是正的，而 $\\mathcal{E}_2=-M_{12}\\dot{I}_1$ 定义的 $M_{12}$ 可正可负。比如说如果是两个轴在同一条直线上，绕线方向相同的螺线管，它们之间的 $M$ 就是正的。另外可以根据 $L$ 和 $M$ 反推出磁通量的表达式 $$ \\left\\{\\begin{aligned} \\Phi_1\u0026amp;=L_1I_1+M_{21}I_2\\\\ \\mathcal{E}_1\u0026amp;=-L_1\\dot I_1-M_{21}\\dot I_2\\\\ \\Phi_2\u0026amp;=M_{12}I_1+L_2I_2\\\\ \\mathcal{E}_2\u0026amp;=-M_{12}\\dot I_1-L_2\\dot I_2\\\\ \\end{aligned}\\right. $$ 实际求的时候，这个二重环路积分的式子并不好用。比如一个半径为 $R$ 的大圆线圈，中间有个共面的，面积为 $S$ 的小线圈。那么显然我们更乐意直接用 $\\Phi$ 去算（而且小对大的 $\\Phi$ 也不好算，只有大对小的好算）。根据毕奥—萨伐尔，中心的磁场强度为 $$ B=\\frac{\\mu_0I}{2R} $$ 可以认为中心附近的磁场均匀，所以 $$ M=\\frac{\\mu_0S}{2R} $$ 关于自感系数与互感系数的关系，我感觉就没有一本书讲得是严谨的，这里也只能简单写一下。现在还是考虑两个螺线管，我们不认为它们是理想的。考虑第一个螺线管有电流 $I_1$ 后产生的磁场，设单个截面所能接收到的磁场为 $\\phi_1$。那么 $$ L_1=\\frac{N_1\\phi_1}{I_1},\\,M\\le\\frac{N_2\\phi_1}{I_1} $$ 这里的 $\\le$ 号就是因为可能漏磁。注意由于两个螺线管截面面积可能不同，磁场大小（磁感线密度）可能变化，但总的磁通量（磁感线股数）是不变的。\n同理如果是第二个螺线管通电的话， $$ L_2=\\frac{N_2\\phi_2}{I_2},\\;M\\le\\frac{N_1\\phi_2}{I_2} $$ 于是我们有 $$ M^2\\le\\frac{N_1N_2\\phi_1\\phi_2}{I_1I_2}=L_1L_2 $$ 当且仅当不漏磁时取等。$k=M/\\sqrt{L_1L_2}$ 被称为耦合系数。这个不等式还可以用能量证（见后）。但是我在想的是，你不觉得 $$ \\left(\\oint_{L_1}\\oint_{L_1}\\frac{\\d\\b l_1\\cdot \\d\\b l_1^\\prime}{r}\\right)\\left(\\oint_{L_2}\\oint_{L_2}\\frac{\\d\\b l_2\\cdot \\d\\b l_2^\\prime}{r}\\right)\\ge\\left(\\oint_{L_1}\\oint_{L_2}\\frac{\\d\\b l_1\\cdot \\d\\b l_2}{r}\\right)^2 $$ 长得跟柯西不等式神似吗？能纯从代数上证吗？\n关于自感与互感的应用，最有代表性的电感、LC 震荡电路、变压器，都在高中讲过了，这里略。\n这里我们考虑静磁能。上面我们不得不用动生电动势，借助机械功，间接地求出磁能。现在，有了感生电动势的手段，我们就可以先把没有电流的线路全都摆好，再慢慢加电流。对于一个自感系数为 $L_1$ 的超导线圈，如果它目前电流为 $I$，自感电动势为 $\\mathcal{E}$，那么我们现在考虑一段 $\\d l$ 的线，其处的电场为 $E$，单位时间有 $I$ 的电荷通过，所以这部分的功率是 $EI\\d l$。于是为了维持电流，总的功率就是 $$ \\oint EI\\d l=\\mathcal{E}I $$ 要把电流升到 $I_1$，总的功就是（增大电流无需做功） $$ \\int_0^{I_1}\\mathcal{E}I\\d t=\\int_0^{I_1}L_1I\\d I=\\frac12L_1I_1^2 $$ 这个时候如果再将另一个线圈通电，类似地积一下可以得到互感部分的做功 $MI_1I_2$。所以可以写出总的能量： $$ U=\\frac12\\sum_{i,j}L_{ij}I_iI_j $$ 而我们知道 $\\mathcal{E}=-\\d\\Phi/\\d t=-L\\d I/\\d t$，也就是说 $LI=\\Phi$。于是 $$ \\begin{align*} U\u0026amp;=\\frac12\\sum_i\\sum_j(I_jL_{ji})I_i\\\\ \u0026amp;=\\frac12\\sum_i\\Phi_iI_i\\\\ \u0026amp;=\\frac12\\sum_iI_i\\iint_{S_i}\\b B\\cdot\\d\\b s\\\\ \u0026amp;=\\frac12\\sum_i\\oint_{\\p S_i}\\b A\\cdot I_i\\d\\b l\\\\ \u0026amp;=\\frac12\\iiint\\b A\\cdot\\b j\\d v \\end{align*} $$ 最后一个等号需要考虑一下几何意义。顺便再推一下另一个表达式 $$ \\begin{align*} U\u0026amp;=\\frac12\\iiint\\b A\\cdot\\b j\\d v\\\\ \u0026amp;=\\frac1{2\\mu_0}\\iiint\\b A\\cdot(\\nabla\\times\\b B)\\d v\\\\ \u0026amp;=\\frac1{2\\mu_0}\\left[\\iiint\\b B\\cdot(\\nabla\\times\\b A)\\d v-\\iiint\\nabla\\cdot(\\b A\\times\\b B)\\d v\\right]\\\\ \u0026amp;=\\frac1{2\\mu_0}\\left[\\iiint\\b B^2\\d v-\\iiint_S(\\b A\\times\\b B)\\cdot\\d\\b s\\right] \\end{align*} $$ 当 $S$ 扩大时，$|\\b A|\\propto r^{-1}$，$|\\b B|\\propto r^{-2}$，$S\\propto r^2$，所以后一项就是 $0$。\n最后用能量说明一下互感系数与自感系数的关系。对于两个线圈（注意 $I$ 可以取负，表示电流与规定方向反）， $$ 0\\le U=\\frac12L_1I_1^2+\\frac12L_2I_2^2+MI_1I_2\\xlongequal{x=I_1/I_2}I_1I_2\\left(\\frac{L_1}{2}x+\\frac{L_2}{2}x^{-1}+M\\right) $$ 当 $I_1$ 与 $I_2$ 异号时，我们要保证里面的这个对勾函数最大值 $\\le-M$，即 $$ -2\\sqrt{\\frac{L_1L_2}{4}}\\le-M\\Longrightarrow M\\le\\sqrt{L_1L_2} $$\n例 1 电子感应加速器。\n在高中我们学过运动电荷在匀强电场中做圆周运动，以及两个半圆槽组成的电子加速器。现在的问题是：能否通过改变磁场使得圆周运动轨道保持但不断加快？\n考虑在两个不同半径范围内布置不同强度的匀强垂直磁场。设电子轨道半径为 $r$，轨道所在处的磁场强度为 $B_r$，内部平均电场强度为 $\\bar{B}$。我们有： $$ \\left\\{\\begin{aligned} evB_r\u0026amp;=m\\frac{v^2}r\\\\ \\frac{\\pi r^2}{2\\pi r}\\frac{\\d\\bar B}{\\d t}e\u0026amp;=m\\frac{\\d v}{\\d t} \\end{aligned}\\right. $$ 解得 $\\d\\bar B=2\\d B_r$。\n例 2 一个边长为 $a$ 正方形回路，中间靠右 $1/4$ 处有一个与左右边平行的竖棒。垂直向内的磁场以 $k$ 的速率增加。框架的各部分，单位长度电阻均为 $r$。求竖棒上的电流。\n错误解答：对于左侧 $3/4$ 面积的区域，磁通量的增加速率为 $3a^2k/4$，矩形框架部分电阻为 $7ar/2$，电流为 $3ak/14r$。右侧 $1/4$ 的区域，磁通量增加速率为 $a^2k/4$，电阻为 $5r/2$，电流为 $ak/10r$。电流可以叠加，所以中间这个的电流是 $4ak/35r$。懒得管方向了。\n正确解答：设左 $3/4$ 的外框架部分电动势为 $\\mathcal{E}_1$，右 $1/4$ 是 $\\mathcal{E}_2$，竖棒是 $\\mathcal{E}$，方向都是从上到下。可列方程 $$ \\left\\{\\begin{aligned} \\mathcal{E}_1-\\mathcal{E}\u0026amp;=\\frac{3a^2k}4\\\\ \\mathcal{E}-\\mathcal{E}_2\u0026amp;=\\frac{a^2k}4\\\\ \\frac{\\mathcal{E}_1}{5ar/2}+\\frac{\\mathcal{E}_2}{3ar/2}\u0026amp;=-\\frac{\\mathcal{E}}{ar} \\end{aligned}\\right. $$ 解得电流为 $2ak/31r$。\n例 3 一根无限长导线电流为 $I$，一个圆环半径为 $a$，圆心在距离导线 $b$ 处（$b\u0026gt;a$），圆面与导线形成的磁场垂直。圆环以 $v$ 的速度向远离导线的方向移动，求圆环中的电动势。 $$ \\begin{align*} \\Phi\u0026amp;=\\frac{\\mu_0I}{2\\pi}\\int_{b-a}^{b+a}\\frac{2\\sqrt{a^2-(b-x)^2}\\d x}{x}\\\\ \u0026amp;\\xlongequal{b-x=a\\cos\\theta}\\frac{\\mu_0Ia}\\pi\\int_0^\\pi\\frac{\\sqrt{a^2-a^2\\cos^2\\theta}\\sin\\theta\\d\\theta}{b-a\\cos\\theta}\\\\ \u0026amp;=\\frac{\\mu_0Ia}\\pi\\int_0^\\pi\\frac{\\sin^2\\theta\\d\\theta}{b/a-\\cos\\theta}\\\\ \u0026amp;=\\frac{\\mu_0Ia}\\pi\\int_0^\\pi\\left(\\cos\\theta+\\frac ba+\\frac{1-b^2/a^2}{b/a-\\cos\\theta}\\right)\\d\\theta\\\\ \u0026amp;=\\frac{\\mu_0Ia}\\pi\\left(\\frac ba\\pi+\\left(1-\\frac{b^2}{a^2}\\right)\\int_0^\\pi\\frac{\\d\\theta}{b/a-\\cos\\theta}\\right) \\end{align*} $$ Calculus challenge: $$ \\begin{align*} \\int\\frac{\\d x}{a-\\cos x}\\xlongequal{\\cos x=\\frac{1-t^2}{1+t^2}}2\\int\\frac{\\d t}{(a-1)+(a+1)t^2}=2\\frac{\\arctan\\left(\\sqrt{\\frac{a+1}{a-1}}\\tan\\frac x2\\right)}{\\sqrt{a^2-1}} \\end{align*} $$ 所以原式是 $$ \\frac{\\mu_0Ia}\\pi\\left(\\frac ba\\pi+\\left(1-\\frac{b^2}{a^2}\\right)\\frac\\pi{\\sqrt{b^2/a^2-1}}\\right)=\\mu_0I\\left(b-\\sqrt{b^2-a^2}\\right) $$\n$$ \\mathcal{E}=-\\frac{\\p\\Phi}{\\p b}v=\\mu_0Iv\\left(\\frac b{\\sqrt{b^2-a^2}}-1\\right) $$\n例 4 有一个半径为 $a$，截面半径为 $b$，电阻率为 $\\rho$，密度为 $\\rho_m$ 的金属圆环沿着垂直于匀强磁场 $B$ 的轴以初始为 $\\omega_0$ 的角速度转动（形成一个交流发电机的结构），求速度降低到 $\\omega_0/\\e$ 需要多久，假设 $b\\ll a$，一圈内角速度不会降低太多。\n解 1：作为一个不懂物理思想的人，我就直接硬解。设转的角度为 $\\phi$。为了求出导致速度降低的力矩，需要求出电流： $$ I=\\frac{\\mathcal{E}}{R}=\\frac{-\\d\\Phi/\\d t}{\\rho l/S}=\\frac{\\pi a^2B\\omega\\sin\\phi}{\\rho 2\\pi a/\\pi b^2}=\\frac{\\pi ab^2B\\omega\\sin\\phi}{2\\rho} $$ 对于一段 $\\d\\theta$，其受力平行于转轴方向的分力为 $BIa\\d\\theta\\cdot\\sin\\theta$，力臂为 $a\\sin\\theta\\sin\\phi$。所以 $$ \\tau=-Ia^2B\\sin\\phi\\int_0^{2\\pi}\\sin^2\\theta\\d\\theta=-\\pi Ia^2B\\sin\\phi $$ 而这种结构的转动惯量为 $$ I_r=\\frac{a^2m}2=\\pi^2a^3b^2\\rho_m $$ 因此 $$ \\frac{\\d\\omega}{\\d t}=\\frac\\tau{I_r}=-\\frac{IB\\sin\\phi}{\\pi ab^2\\rho_m}=-\\frac{B^2\\omega\\sin^2\\phi}{2\\rho\\rho_m}\\Longrightarrow\\frac{\\d\\omega}{\\d\\phi}=\\frac{\\dot\\omega}\\omega=-\\frac{B^2}{2\\rho\\rho_m}\\sin^2\\phi $$ 直接两边积分就可以了，代入初始条件得 $$ \\omega=\\frac{B^2}{8\\rho\\rho_m}\\left(\\sin2\\phi-2\\phi\\right)+\\omega_0 $$ 这里 $\\omega(t)$ 和 $\\phi(t)$ 是写不出来的，我就干了一个看起来很诱人的近似：把 $\\sin2\\phi$ 扔了。这样就可以解了： $$ \\dot\\phi=-\\frac{B^2}{4\\rho\\rho_m}\\phi+\\omega_0\\Longrightarrow\\phi=\\frac{4\\omega_0\\rho\\rho_m}{B^2}\\left(1-\\e^{-B^2t/4\\rho\\rho_m}\\right) $$ $\\omega=\\omega_0/\\e$ 时 $\\phi=\\frac{4\\omega_0\\rho\\rho_m}{B^2}(1-\\e^{-1})$，因此 $t=4\\rho\\rho_m/B^2$。\n解 2：从能量角度考虑。这个结构的动能为 $$ E_k=\\frac12I_r\\omega^2=\\frac{\\pi^2a^3b^2\\rho_m}2\\omega^2 $$ 认为一圈内速度不变的情况下，根据焦耳定律，转化为内能的平均功率为 $$ -\\frac{\\d E_k}{\\d t}=P=\\frac1{2\\pi}\\int_0^{2\\pi}I^2R\\d\\phi=\\frac1{2\\pi}\\int_0^{2\\pi}\\frac{\\pi^2a^3b^2B^2\\omega^2\\sin^2\\phi}{2\\rho}\\d\\phi=\\frac{\\pi^2a^3b^2B^2\\omega^2}{4\\rho} $$ 结合以上两式， $$ \\pi^2a^3b^2\\rho_m\\omega\\dot\\omega=-\\frac{\\pi^2a^3b^2B^2\\omega^2}{4\\rho}\\Longrightarrow\\dot\\omega=-\\frac{B^2\\omega}{4\\rho\\rho_m} $$ 从而 $$ t=\\int_{\\omega_0}^{\\omega_0/\\e}\\frac{\\d\\omega}{\\dot\\omega}=\\frac{4\\rho\\rho_m}{B^2}\\int_{\\omega_0/\\e}^{\\omega_0}\\frac{\\d\\omega}{\\omega}=\\frac{4\\rho\\rho_m}{B^2} $$\n位移电流 最后我们需要加上这一项 $$ \\nabla\\times\\b B=\\mu_0\\b j+\\boxed{\\mu_0\\eps_0\\frac{\\p\\b E}{\\p t}} $$ 这一项的来源可以简单地用电荷守恒说明。我们知道旋度的散度为 $0$，如果没有这一项，那么 $$ 0=\\mu_0\\nabla\\cdot\\b j=-\\mu_0\\frac{\\p\\rho}{\\p t} $$ 也就是说只有在电流稳恒的情况下才自洽。加上的一项恰好满足 $$ \\nabla\\cdot\\mu_0\\eps_0\\frac{\\p\\b E}{\\p t}=\\mu_0\\eps_0\\frac{\\p}{\\p t}\\nabla\\cdot\\b E=\\mu_0\\frac{\\p\\rho}{\\p t} $$\n定义位移电流（体密度）为 $$ \\b j_d=\\eps_0\\frac{\\p\\b E}{\\p t} $$\n现在麦克斯韦方程组就蕴含了电荷守恒。我们不需要把 $\\nabla\\cdot\\b j=-\\p\\rho/\\p t$ 单独写出来。\n例 1 考虑一个向外（球面）均匀发出电流的点电荷 $Q$。既然是球面对称，那么如果一个点处的电场或磁场有切向的分量，那么以它和球心为轴旋转，就产生了矛盾。因此场的方向一定是法向的。我们先考虑电场，这个时候， $$ \\nabla\\times\\b E=-\\frac{\\p\\b B}{\\p t} $$ 已经没用了。因为当 $\\b E$ 可以写成 $f(r)\\b r$ 的时候，容易验证旋度必为 $\\b 0$。所以现在我们能简单地说 $\\b E=\\frac{Q\\b{\\hat r}}{4\\pi\\eps_0r^2}$。\n既然 $\\b B$ 也是法向的，$\\nabla\\times\\b B$ 就也应该为 $\\b 0$，进一步地，由于 $\\nabla\\cdot\\b B=0$，就应该没磁场。但是如果没有那一项，就会导致 $$ \\mu_0\\b j=\\mu_0\\frac{\\b{\\hat r}}{4\\pi r^2}\\left(-\\frac{\\p Q}{\\p t}\\right)\\ne 0 $$ 加上那一项就对了。\n例 2 考虑一个正在充电的电容，在其上方去一个圆形安培回路。如果截面只过导线，那么磁场环量 $$ \\Gamma=\\mu_0I $$ 但是我们知道由于磁场无源，故计算环量应当与选择的面无关。如果选择的面是穿过两个极板之间的 $S_1^\\prime$，那么就没有 $\\b j$ 了。这个时候就需要位移电流项了。我们认为极板足够大，所以如果极板的面积为 $S$，$S_1^\\prime$ 的电通量就是 $$ 2\\cdot\\frac{\\sigma}{2\\eps_0}\\cdot S=\\frac{Q}{\\eps_0} $$ 从而 $$ \\Gamma=\\mu_0\\eps_0\\frac{\\p}{\\p t}\\frac{Q}{\\eps_0}=\\mu_0I $$ 自洽了。\n麦克斯韦方程组 现在我们就得正式面对完整的麦克斯韦方程组了。 $$ \\left\\{\\begin{align*} \\nabla\\cdot\\b E\u0026amp;=\\frac{\\rho}{\\eps_0}\\\\ \\nabla\\times\\b E\u0026amp;=-\\frac{\\p\\b B}{\\p t}\\\\ \\nabla\\cdot\\b B\u0026amp;=0\\\\ \\nabla\\times\\b B\u0026amp;=\\mu_0\\b j+\\mu_0\\eps_0\\frac{\\p\\b E}{\\p t} \\end{align*}\\right. $$\n但等一下，在考虑电磁波的传播时我们考虑的是无源的空间。所以 $\\rho$ 和 $\\b j$ 的项就没了。\n我们沿着书里讲解电磁波的思路——首先给一个需要一定假设的，简单直观的方法，然后再推波动方程。\n平面波的初步分析 我们考虑平面波，一切在 $y$、$z$ 方向都是均匀的。在坐标系的 $yz$ 平面上瞬间（可以认为是一个很短的时间内，这个无所谓）通了向 $+z$ 方向的平面电流 $\\b J$，现在我们考虑电磁场在 $x\u0026gt;0$ 部分的传播。\n当然现在我们依照常识知道电磁场不可能瞬间布满整个空间，这也是合理的：通过麦克斯韦方程组，取安培回路，是没法得到极远处瞬间出现磁场的，因为 $\\p\\b E/\\p t\\ne\\b 0$。唯一一种可能瞬间造成场的方式是通过 $\\nabla\\cdot\\b E=\\rho/\\eps_0$，而由于电荷守恒，$\\rho$ 是不可能突变的。\n现在我们需要的假设是，电场和磁场都是先占据 $x$ 小的部分（且占据了就一直存在），再占据 $x$ 大的部分，然后它们的传播速度是相等的。假设某个时刻，它们的波面在 $x_0$。\n由于电磁场均只与 $x$ 有关，故我们发现，$\\b E_z$ 只与 $\\b B_y$ 有关，$\\b E_y$ 只与 $\\b B_z$ 有关。~~没发现也没事，~~我们先分析 $\\b B_y$。取一个 $xy$ 方向的，穿过波面（不穿过 $y$ 轴）的矩形安培回路（$y$ 方向长为 $l$）。$x$ 方向由于平移对称性贡献是 $0$，$y$ 方向，靠内的是 $-l\\b B_y$，靠外的没有磁场。而电通量的变化率是 $lv\\b E_z$。所以 $\\b B_y=-\\mu_0\\eps_0v\\b E_z$；取一个 $xz$ 方向的，穿过波面的矩形高斯（？）回路，$z$ 方向是 $l\\b E_z$，而磁通量的变化率是 $lv\\b B_y$，所以 $\\b E_z=-v\\b B_y$。我们把这两个方程结合起来，就得到 $\\mu_0\\eps_0v^2=1$，也就是说，电磁波传播的速度是 $1/\\sqrt{\\mu_0\\eps_0}$，也就是光速。\n至于 $\\b B_z$ 和 $\\b E_y$，如果假设通电前没有任何电磁场，你会发现它根本没有理由会 $\\ne 0$。$\\b j$ 只会使 $\\b B_y$ 产生变化。\n当然这个推导有很多不严谨的地方，比如你怎么说明 $\\b B_y$ 和 $\\b E_z$ 是均匀的？我的理解是，它本来就只是毛估估看一下，然后可以猜出一个解： $$ \\left\\{\\begin{aligned} \\b B_y(x,t)\u0026amp;=\\frac{\\mu_0J}{2}\\theta(ct-x)\\\\ \\b E_z(x,t)\u0026amp;=-\\frac{\\mu_0cJ}{2}\\delta(ct-x) \\end{aligned}\\right. $$ 然后用类唯一性定理（之类的东西？）。这里 $\\theta$ 是作用类似于 $\\delta$ 的分段函数，满足 $\\theta^\\prime=\\delta$，你可以理解为 $\\max\\{\\operatorname{sgn},0\\}$，或者比如说 $\\lim_{k\\to+\\infty}\\e^{kx}/(\\e^{kx}+1)$。\n解麦克斯韦方程组 怎么严谨地分析上面这玩意呢？说来也简单。一方面， $$ \\nabla\\times(\\nabla\\times\\b B)=\\nabla(\\nabla\\cdot\\b B)-\\nabla^2\\b B=-\\nabla^2\\b B $$ 另一方面（$\\b j=0$）， $$ \\nabla\\times(\\nabla\\times\\b B)=\\mu_0\\nabla\\times\\b j+\\mu_0\\eps_0\\nabla\\times\\frac{\\p\\b E}{\\p t}=-\\mu_0\\eps_0\\frac{\\p^2\\b B}{\\p t^2} $$ 所以 $$ \\nabla^2\\b B=\\mu_0\\eps_0\\frac{\\p^2\\b B}{\\p t^2} $$ $\\b E$ 同理。这是波动方程（后面会讨论）。\n对于一般的情况，完整地过一下推导思路。\n首先，$\\varphi$ 会出一个问题：电场不再保守。但是磁场仍然是无源的，所以我们可以保留 $\\b A$。现在看第二个方程： $$ \\nabla\\times\\b E=-\\frac{\\p\\b B}{\\p t}\\Longleftrightarrow\\nabla\\times\\left(\\b E+\\frac{\\p\\b A}{\\p t}\\right)=0 $$ 所以我们可以让 $\\nabla\\varphi=-\\b E-\\p\\b A/\\p t$，或者说，还是让 $\\varphi$ 表示只考虑电荷导致的势能。这时就有 $$ \\b E=-\\nabla\\varphi-\\frac{\\p\\b A}{\\p t} $$ 所以现在就剩下两个tuó方程 $$ \\left\\{\\begin{aligned} \\nabla\\cdot\\left(\\nabla\\varphi+\\frac{\\p\\b A}{\\p t}\\right)\u0026amp;=-\\frac{\\rho}{\\eps_0}\\\\ \\nabla\\times(\\nabla\\times\\b A)\u0026amp;=\\mu_0\\b j-\\mu_0\\eps_0\\frac{\\p}{\\p t}\\nabla\\varphi-\\mu_0\\eps_0\\frac{\\p^2\\b A}{\\p t^2} \\end{aligned}\\right. $$ 应用库仑规范，发现无法使方程充分简化。\n简化它们的思路是：希望把第二个式子搞成（含源的，数学上叫非齐次）波动方程的样子。其中需要扔掉的两项应当满足 $$ \\nabla(\\nabla\\cdot\\b A)=-\\mu_0\\eps_0\\frac{\\p}{\\p t}\\nabla\\varphi $$ 也就是要求 $$ \\nabla\\cdot\\b A=-\\mu_0\\eps_0\\frac{\\p\\varphi}{\\p t} $$ 把它代回第一个方程，我们就得到（接下来我们就写 $1/c^2$ 不写 $\\mu_0\\eps_0$ 了） $$ \\left\\{\\begin{aligned} \\nabla^2\\varphi-\\frac1{c^2}\\frac{\\p^2\\varphi}{\\p t^2}\u0026amp;=-\\frac{\\rho}{\\eps_0}\\\\ \\nabla^2\\b A-\\frac1{c^2}\\frac{\\p^2\\b A}{\\p t^2}\u0026amp;=-\\mu_0\\b j \\end{aligned}\\right. $$ 这里对 $\\b A$ 与 $\\varphi$ 关系的要求被称为洛伦兹规范。细心的你可能开始怀疑：真能做到这个规范吗？我们假定存在一组任意的解 $(\\varphi,\\b A)$。它可以自由变化的点在于，麦克斯韦方程组只对 $\\b B=\\nabla\\times\\b A$ 有要求，所以如果 $\\b A$ 加上一个任意的无旋场 $\\nabla\\phi$，是不影响的。但是由于有了个额外的方程 $\\b E=-\\nabla\\varphi-\\p\\b A/\\p t$，所以与此同时 $\\varphi$ 要减去 $\\p\\phi/\\p t$。也就是说，如果要把这个任意的解变得符合洛伦兹规范，$\\phi$ 得满足： $$ \\nabla\\cdot(\\b A+\\nabla\\phi)=-\\frac1{c^2}\\left(\\frac{\\p\\varphi}{\\p t}-\\frac{\\p^2\\phi}{\\p t^2}\\right) $$ 即 $$ \\nabla^2\\phi-\\frac1{c^2}\\frac{\\p^2\\phi}{\\p t^2}=-\\nabla\\cdot\\b A-\\frac1{c^2}\\frac{\\p\\varphi}{\\p t} $$ 我们就假定非齐次波动方程一定有解吧，乐。\n这里，我们将关于 $\\b E$ 和 $\\b B$ 的偏微分方程（一共八条）转变为了关于 $\\varphi$ 和 $\\b A$ 的波动方程（四条），方程变得好解许多。实际上 $\\b E$ 和 $\\b B$ 也满足波动方程。容易验证 $$ \\left\\{\\begin{aligned} \\nabla^2\\b E-\\frac1{c^2}\\frac{\\p^2\\b E}{\\p t^2}\u0026amp;=\\frac1{\\eps_0}\\nabla\\rho+\\mu_0\\frac{\\p\\b j}{\\p t}\\\\ \\nabla^2\\b B-\\frac1{c^2}\\frac{\\p^2\\b B}{\\p t^2}\u0026amp;=-\\mu_0\\nabla\\times\\b j \\end{aligned}\\right. $$\n遗憾的是，似乎由于课时不够，后面没讲实际运用 $\\varphi$ 和 $\\b A$ 解方程组的例子，而是直接莫名其妙转向了波导。\n解波动方程 这里我们波动方程其实就是四维矢量的拉普拉斯方程。\n平面波 回到上面的例子，在无场源的空间中，如果 $y$、$z$ 方向是均匀的，那么考虑 $\\b E$ 和 $\\b B$。如果展开麦克斯韦方程组，那么得到 $$ \\left\\{\\begin{aligned} \\frac{\\p\\b E_x}{\\p x}\u0026amp;=0\\\\ 0\u0026amp;=\\frac{\\p\\b B_x}{\\p t}\\\\ \\frac{\\p\\b E_z}{\\p x}\u0026amp;=\\frac{\\p\\b B_y}{\\p t}\\\\ \\frac{\\p\\b E_y}{\\p x}\u0026amp;=-\\frac{\\p\\b B_z}{\\p t}\\\\ \\frac{\\p\\b B_x}{\\p x}\u0026amp;=0\\\\ 0\u0026amp;=\\frac{\\p\\b E_x}{\\p t}\\\\ \\frac{\\p\\b B_z}{\\p x}\u0026amp;=-\\frac1{c^2}\\frac{\\p\\b E_y}{\\p t}\\\\ \\frac{\\p\\b B_y}{\\p x}\u0026amp;=\\frac1{c^2}\\frac{\\p\\b E_z}{\\p t}\\\\ \\end{aligned}\\right. $$ 如果展开刚推得的波动方程，可以得到 $$ \\left\\{\\begin{aligned} \\frac{\\p^2\\b E_y}{\\p x^2}-\\frac1{c^2}\\frac{\\p^2\\b E_y}{\\p t^2}\u0026amp;=0\\\\ \\frac{\\p^2\\b E_z}{\\p x^2}-\\frac1{c^2}\\frac{\\p^2\\b E_z}{\\p t^2}\u0026amp;=0\\\\ \\frac{\\p^2\\b B_y}{\\p x^2}-\\frac1{c^2}\\frac{\\p^2\\b B_y}{\\p t^2}\u0026amp;=0\\\\ \\frac{\\p^2\\b B_z}{\\p x^2}-\\frac1{c^2}\\frac{\\p^2\\b B_z}{\\p t^2}\u0026amp;=0 \\end{aligned}\\right. $$ 可以验证一下，容易从上面那个推得下面这个。为了解 $$ \\frac{\\p^2\\psi}{\\p x^2}-\\frac1{c^2}\\frac{\\p^2\\psi}{\\p t^2}=0 $$ 形式的一维波动方程。根据学微积分时候的经验，对于大于一阶的微分方程，可以考虑“因式分解”（因为微分也是一种线性变换）： $$ \\left(\\frac{\\p}{\\p x}+\\frac1c\\frac{\\p}{\\p t}\\right)\\left(\\frac{\\p}{\\p x}-\\frac1c\\frac{\\p}{\\p t}\\right)\\psi=0 $$ 令 $$ u=\\frac{\\p\\psi}{\\p x}-\\frac1c\\frac{\\p\\psi}{\\p t} $$ 则方程化为 $$ \\frac{\\p u}{\\p x}+\\frac1c\\frac{\\p u}{\\p t}=0 $$ 当然你可以集中注意力，注意到这个式子相当于 $u$ 在 $x+ct=b$（每个 $b$）的直线上不变，从而 $u=f(b)$。But why not learn some PDE?\n解这个玩意的思路是，把 $x$ 视作关于 $t$ 的函数，把方程化作 $u$ 关于 $t$ 的常微分方程。这样，我们就得到了 $tx$ 平面上一条线上的解。然后将这条线平移（之类的），铺满整个平面。这个线叫特征线。当然不是随便选一个 $x=x(t)$ 都可以把方程化过去的。考虑到 $$ \\frac{\\d u}{\\d t}=\\frac{\\p u}{\\p t}+\\frac{\\p u}{\\p x}\\cdot\\frac{\\d x}{\\d t} $$ 所以取 $\\d x/\\d t=c$，即 $x=ct+b$，$b$ 就是可变化的平移量。在这条线上，$\\d u/\\d t=0$，所以解是 $u=C$。当然，这个 $C$ 是与 $b$ 相关的，所以完整的二维的解可以写成（$C$ 太难看了，还是管它叫 $f$）$u=f(b)=f(x-ct)$。\n现在解原来的方程（这边函数写得不是很规范，能懂就行） $$ \\frac{\\p\\psi}{\\p x}-\\frac1c\\frac{\\p\\psi}{\\p t}=u=f(x-ct) $$ 考虑 $x=-ct+b$ 上的解，方程为 $$ \\frac{\\d\\psi}{\\d t}=f(-2ct+b) $$ 令 $F(s)$ 为 $-f(s)/2c$ 的反函数，则 $$ \\psi(t)=C+\\int_0^tf(-2ct^\\prime+b)\\d t^\\prime=C+\\int_b^{-2ct+b}-\\frac{f(s)}{2c}\\d s=C+F(-2ct+b)-F(b)=C+F(x-ct)-F(b) $$ 还是一样，$C$ 是与 $b$ 相关的，另外 $F(b)$ 也可以并到 $C$ 里来，所以最后的解就是 $$ \\psi=F(x-ct)+G(x+ct) $$ 其中 $F$、$G$ 是任意函数，甚至可以不是连续的（用 $\\delta$ 函数模拟）。\n从物理意义上来说，$F$ 是沿 $x$ 轴正方向传播的波，$G$ 是反方向传播的波。如果只取正方向的波，比如我们代回最上面的方程组的 $\\b E_y$，那么 $\\b E_y=F_1(x-ct)$，设 $\\b B_z=F_{*}(x-ct)$，代入其与 $\\b E_y$ 的关系： $$ F_{*}^\\prime\\cdot\\frac{\\p(x-ct)}{\\p x}=-\\frac1{c^2}F_1^\\prime\\cdot\\frac{\\p(x-ct)}{\\p t}=\\frac1c\\b E_y^\\prime $$ 所以 $\\b B_z=F_1(x-ct)/c$（没有加常数是因为假定无穷远处为 $0$）。同理可以得到，$\\b E_z=F_2(x-ct)$ 的话 $\\b B_y=-F_2(x-ct)/c$。加上 $x$ 分量是常数即 $0$，这样一来我们就有 $\\b E\\cdot\\b B=0$。所以说在这种特殊情况下，我们说 $\\b k$、$\\b E$、$\\b B$ 两两垂直，其中 $\\b k$ 是传播方向。一般情况下 $\\b E\\perp\\b B$ 是不成立的。\n球面波 由球面对称性，球面波只有 $\\b{\\hat r}$ 方向分量。由 $\\Delta$ 的球面坐标系表示，波动方程可以写成 $$ \\begin{align*} \\frac{\\p^2\\psi}{\\p r^2}+\\frac2r\\frac{\\p\\psi}{\\p r}-\\frac1{c^2}\\frac{\\p^2\\psi}{\\p t^2}\u0026amp;=0\\\\ \\Longleftrightarrow\\frac{\\p^2(r\\psi)}{\\p r^2}-\\frac1{c^2}\\frac{\\p^2(r\\psi)}{\\p t^2}\u0026amp;=0 \\end{align*} $$ 这个凑换元看起来很牛。这里由于反方向的波不符合实际，所以解就是 $$ \\psi=\\frac{f(r-ct)}{r}\\b{\\hat r} $$\n柱面波 它的方程长这样： $$ \\frac{\\p^2\\psi}{\\p r^2}+\\frac1r\\frac{\\p\\psi}{\\p r}-\\frac1{c^2}\\frac{\\p^2\\psi}{\\p t^2}=0 $$ 不会。\n一般情况 非常不严谨的推导：考虑在原点附近的一堆分布，用点电荷模拟。在远处由于没有电荷，故齐次波动方程仍适用。在近处可以忽略 $c^{-2}\\p^2\\psi/\\p t^2$ 这一项（因为前一项很大），所以近处是，例如说 $\\varphi$，就是和之前静态的公式一样。这样反过来可以推远处的式子： $$ \\varphi(\\b r,t)=\\frac{1}{4\\pi\\eps_0}\\iiint\\frac{\\rho(\\b r^\\prime,t-|\\b r-\\b r^\\prime|/c)\\d v}{|\\b r-\\b r^\\prime|} $$ $\\b A$ 同理。这个玩意叫推迟势。虽然推导的时候用了近似，但代入检验（这里就不写了）一下就会发现这个在一般情况下也是对的。另外 $\\b E$ 和 $\\b B$ 的表达式更加复杂，推导可以看 Griffiths（就是些求导）。这里写一下结论： $$ \\left\\{\\begin{aligned} \\varphi(\\b r,t)\u0026amp;=\\frac{1}{4\\pi\\eps_0}\\iiint\\frac{\\rho(\\b r^\\prime,t-\\mathfrak{\\b r}/c)\\d v}{\\mathfrak{r}}\\\\ \\b A(\\b r,t)\u0026amp;=\\frac{\\mu_0}{4\\pi}\\iiint\\frac{\\b j(\\b r^\\prime,t-\\mathfrak{\\b r}/c)\\d v}{\\mathfrak{r}}\\\\ \\b E(\\b r,t)\u0026amp;=\\frac{1}{4\\pi\\eps_0}\\iiint\\left(\\frac{\\rho(\\b r^\\prime,t-\\mathfrak{\\b r}/c)}{\\mathfrak{r}^2}\\mathfrak{\\b{\\hat r}}+\\frac{\\dot\\rho(\\b r^\\prime,t-\\mathfrak{\\b r}/c)}{c\\mathfrak{r}}\\mathfrak{\\b{\\hat r}}-\\frac{\\dot{\\b j}(\\b r^\\prime,t-\\mathfrak{\\b r}/c)}{c^2\\mathfrak{r}}\\right)\\d v\\\\ \\b B(\\b r,t)\u0026amp;=\\frac{\\mu_0}{4\\pi}\\iiint\\left(\\frac{\\b j(\\b r^\\prime,t-\\mathfrak{\\b r}/c)}{\\mathfrak{r}^2}+\\frac{\\dot{\\b j}(\\b r^\\prime,t-\\mathfrak{\\b r}/c)}{c\\mathfrak{r}}\\right)\\times\\mathfrak{\\b{\\hat r}}\\d v \\end{aligned}\\right. $$ 其中 $\\mathfrak{r}=\\b r-\\b r^\\prime$（我打不出那个玩意！），以及 $\\dot\\rho$ 和 $\\dot{\\b j}$（wtf is this）是关于第二维求偏导。\n解一般的波方程一般考虑复波函数。\n交流电路 不知道为什么突然就开始讲电路了。\n交流电路里到处是三角函数，为了方便运算，我们可以用复数去分析。把电压写成复数 $V=V_0\\e^{\\i\\omega t}$，电流同理。\n注意在交流电路中，要抛弃简单直流电路中“电压产生电流”的因果思维，电压与电流的大小是互相影响的，它们形成平衡就行。\n在交流电路中，电容和电感不再是等效于断路和短路了，它们具有类似电阻的性质。对于电容，如果它两侧的电压为 $U$，那么 $Q=CU$。又 $I=\\d Q/\\d t$，所以 $I$ 和 $U$ 的关系是 $I=C\\d U/\\d t=\\i\\omega CU$，运用欧姆定律，可以“定义”“电阻”（这里管它叫容抗）$z_C=1/\\i\\omega C$。对于电感，我们知道 $\\mathcal{E}=-L\\d I/\\d t$，也就是说如果它是理想（超导）的话，为了平衡，两边需要加上 $-\\cal{E}$ 的电压。所以 $I$ 和 $U$ 的关系是 $U=L\\d I/\\d t=\\i\\omega LI$，感抗 $z_L=\\i\\omega L$。电阻就是 $z_R=R$。所以这里的复数是啥意思呢？就是说它们会使电压和电流之间的相对相位发生变化。这些 $z$ 统称阻抗。\n在交流电路中求解复杂电路中的量，方法（基尔霍夫定律）跟直流是一样的，就是把实数换成复数。具体就不讲了。\n上课也提了一下等效电路相关。任何由线性元件组成的二段电路可以视作一个黑盒，只需要两个参数 $k$、$b$ 刻画：$U=kI+b$。$b=0$ 的称作无源元件，否则是有源元件。$\\arg k$ 就是电压与电流的相位差。无源元件的相位差一定处于 $[-\\pi/2,\\pi/2]$ 内（怎么证？没法归纳（电桥不是串并联））。\n关于有源电路，有两种等效方法：\n（戴维南定理）任何二段有源电路，可以等效为一个理想电压源与一个电阻的串联。电压源的电动势为两端断路时的电压，电阻的大小为电源置为零（电压源短路，电流源断路）后的等效电阻。 （诺顿定理）任何二段有源电路，可以等效为一个。理想电流源与一个电阻的并联。电流源的电流为两端短路时的电压，电阻的大小为电源置为零后的等效电阻。 这里注意，电流源（可以产生任意电压）实际上没法用 $U=kI+b$ 描述，或者其实得用 $I=lU+c$ 这种反过来的，反正就是条直线。\n证明就不写了，看这里。\n电路的能量考虑起来是容易的，就是说如果一段元件两端差了 $U$ 的电压，那么单位时间的电流，你甭管它里面发生了什么，只需要考虑它等效于将这段时间进入的总电荷直接移到出口（电荷守恒），所以功率就是 $UI$。焦耳热 $I^2R$ 是通过能量守恒推导的。\n那么在交流电路里，功率显然不能是虚数。设整个电路等效于电压源 $\\cal E$ 与阻抗 $z=R+\\i X$（$R$ 称为电阻，$X$ 称为电抗）的串联，那么 $$ \\begin{align*} P\u0026amp;=\\frac{\\omega}{2\\pi}\\int_0^{2\\pi/\\omega}\\re\\mathcal{E}\\re I\\d t\\\\ \u0026amp;=\\frac{\\omega}{2\\pi}I_0^2\\int_0^{2\\pi/\\omega}\\left(R\\cos\\omega t-X\\sin\\omega t\\right)\\cos\\omega t\\d t\\\\ \u0026amp;=\\frac12I_0^2R \\end{align*} $$ 这个和直流电路还是不一样的。另外，这说明电抗不对能量产生贡献。\n滤波器 考虑这样的一个结构，设其等效阻抗为 $z_0$，则 $$ z_0=z_1+\\frac{z_0z_2}{z_0+z_2} $$ 解得 $$ z_0=\\frac{z_1}2\\pm\\sqrt{\\frac{z_1^2}4+z_1z_2} $$ 如果取 $z_1=\\i\\omega L$，$z_2=1/\\i\\omega C$，那么（舍掉 $-$ 是因为辐角取值） $$ z_0=\\frac{\\i\\omega L}2+\\sqrt{\\frac LC-\\frac{\\omega^2L^2}{4}} $$ 当 $\\omega\u0026lt;2/\\sqrt{LC}$，实数部分非零，所以这个电路会消耗能量，否则是纯电抗。那么现在问题就来了：为什么电容和电抗两个东西都是纯虚的，但是串并联起来就有电阻了呢？原因是，当你接上电源时，电流会往无穷远处传播，那么从无电流到有电流，这个无论是电阻、电容还是电抗都是要做功的，所以它就一直要做功。那反过来，我们就可以推断，当 $\\omega\\ge 2/\\sqrt{LC}$ 时，电流一定不会往无穷远处传播，或者至少有一个收敛的衰减（当然这个是不严谨的，$\\omega=2/\\sqrt{LC}$ 时是不对的）。\n为了从数学角度验证这个说法，考虑 $a-b$ 和 $c-d$ 的电压差的比。根据分压定律， $$ \\frac{V_{cd}}{V_{ab}}=\\frac{v_0-v_1}{v_0}=\\frac{\\sqrt{4L/C-\\omega^2L^2}-\\i\\omega L}{\\sqrt{4L/C-\\omega^2L^2}+\\i\\omega L} $$ 如果 $\\Delta\\ge 0$，那么比值的模长就 $=1$，否则就 $\u0026lt;1$。因此超过截止频率的信号会指数衰减。\n所以这个结构可以作为一个滤波器。实际情况下，构造足够长的这个结构，$ab$ 头是天线，另一头就只会接受频率 $\\le 2/\\sqrt{LC}$ 的信号。如果再加上一个下面的结构，就可以滤出一个区间内的频率。\n当 $z_1=1/\\i\\omega C$，$z_2=\\i\\omega L$ 时， $$ z_0=\\frac{1}{2\\i\\omega C}+\\sqrt{\\frac LC-\\frac1{4\\omega^2C^2}} $$ 同理可以得到，它是反过来接受 $\\omega\\ge 2/\\sqrt{LC}$ 的信号。\n作业里有些 RC、RL、LC、RLC 电路以及 bandwidth 和 quality factor 相关的东西，如果有时间可以把结论记到 cheat sheet 里。\n传输线 最后考虑一个和下面内容有点联系的东西。我们考虑连续情况下的类比——传输线。费曼那里讲得过于简化了，这里直接按照另一本来。\n考虑两根同轴圆柱空心导体，也就是上面“两个导线”以一平行线为轴旋转一圈。当然我们这里考虑一个截面，反正它是旋转对称的。我们认为上面一条是内层，通了电，下面是接地的。那么导体本身有电阻和自感（什么？为啥没有互感？我不到啊），两个之间可以塞介电质，所以电阻不认为是无穷大，同时还能作为正常的电容看待。现在我们取一小段 $\\Delta z$，设每单位的电阻、自感、电导（电阻 $\\propto$ 面积，所以这里是倒数）、电容分别为 $R$、$L$、$G$、$C$。那么可以列方程 $$ \\left\\{\\begin{aligned} V(z,t)-V(z+\\Delta z,t)\u0026amp;=I(z,t)(R\\Delta z+\\i\\omega L\\Delta z)\\\\ I(z,t)-I(z+\\Delta z,t)\u0026amp;=V(z+\\Delta z,t)(G\\Delta z+\\i\\omega C\\Delta z) \\end{aligned}\\right. $$ $\\Delta z\\to 0$： $$ \\left\\{\\begin{aligned} \\frac{\\p V}{\\p z}\u0026amp;=-(R+\\i\\omega L)I\\\\ \\frac{\\p I}{\\p z}\u0026amp;=-(G+\\i\\omega C)V \\end{aligned}\\right. \\Longrightarrow \\left\\{\\begin{aligned} \\frac{\\p^2V}{\\p z^2}\u0026amp;=(R+\\i\\omega L)(G+\\i\\omega C)V\\\\ \\frac{\\p^2I}{\\p z^2}\u0026amp;=(R+\\i\\omega L)(G+\\i\\omega C)I \\end{aligned}\\right. $$ 所以我们得到了一个“复波速”/复传播常数 $$ \\gamma=\\sqrt{(R+\\i\\omega L)(G+\\i\\omega C)}=\\alpha+\\i\\beta $$ 其中 $\\alpha$ 称为衰减常数，$\\beta$ 称为传播常数。 $$ \\left\\{\\begin{aligned} V\u0026amp;=V_0^+\\e^{-\\gamma z}+V_0^-\\e^{\\gamma z}\\\\ I\u0026amp;=\\sqrt{\\frac{G+\\i\\omega C}{R+\\i\\omega L}}(V_0^+\\e^{-\\gamma z}-V_0^-\\e^{\\gamma z}) \\end{aligned}\\right. $$ 再乘回 $\\e^{\\i\\omega t}$ 就得到 $$ V=V_0^+\\e^{-\\alpha z}\\cos(\\beta z-\\omega t)+V_0^-\\e^{\\alpha z}\\cos(\\beta z+\\omega t) $$ 波长 $\\lambda=2\\pi/\\beta$，波速 $v=\\omega/\\beta$。这就是信号在传输线中的传播。显然只有 $\\alpha=0$ 即 $R=G=0$ 时这东西才能真正有用，这时 $\\beta=\\omega\\sqrt{LC}$，阻抗为 $Z=\\sqrt{L/C}$。\n进一步计算可以得出里面的电磁场，我这边就不写了。它是个 $\\rm TEM$ 波，也就是没有沿线方向的电、磁场。我们会在最后进一步讨论单个导体传输电磁场相关的问题。\n谐振腔 其实建议先看波导再看这个，可能有些东西好理解一点。\n谐振腔说白了就是一个铁皮盒子，电磁场能在其中震荡。这个盒子所起的作用，在数学上，就是给出边界条件。所以我们先明确边界条件的分析方法。\n对于一个面电荷密度为 $\\sigma$，面电流密度为 $\\b J$ 的面，设它左右两边很近处的电磁场为 $\\b E/\\b B_{1/2}$。取穿过该面的，足够扁的高斯面（圆柱，比如），得到 ${\\b E_1}_\\perp-{\\b E_2}_\\perp=\\sigma/\\eps_0$；取足够扁的安培回路，得到 ${\\b E_1}_\\parallel-{\\b E_2}_\\parallel=\\b 0$（因为中间的磁通量正比于长乘宽，除掉环量的长后，宽 $\\to 0$）。同理可得到磁场的式子，最后我们有 $$ \\left\\{\\begin{aligned} \\b n\\cdot(\\b E_1-\\b E_2)\u0026amp;=\\frac{\\sigma}{\\eps_0}\\\\ \\b n\\times(\\b E_1-\\b E_2)\u0026amp;=\\b 0\\\\ \\b n\\cdot(\\b B_1-\\b B_2)\u0026amp;=\\b 0\\\\ \\b n\\times(\\b B_1-\\b B_2)\u0026amp;=\\mu_0\\b J \\end{aligned}\\right. $$\n矩形谐振腔 处理谐振腔问题的思路和前面不太一样，我们是先考虑 free space 里的电磁场的解，然后再代入边界条件，而不是遵循电荷电流 → 电场磁场这个因果关系列麦克斯韦方程组，那样基本解不出来。\n现在考虑一个 $[0,a]\\times[0,b]\\times[0,d]$ 的长方体导体壳（我知道。$c$ 是光速）。设其中的电场为 $\\b E(x,y,z,t)$。我们显然不会觉得把这东西的方程列出来之后能解。所以上课讲了一个粗暴的方法，我这里把它解读为，（我猜）任意（物理上合法的）多元函数都能拆成各个元各自的一元函数的积的无穷和，可以类比一元函数的傅里叶级数来理解，或者一个不严谨的证明就是直接泰勒展开。但是实际上这样理解还是有漏洞，就是说我们这里是要求每个解的边界条件都得满足，但是实际上他们线性组合完了之后满足边界条件就行了，所以我也说不清了。评价为：这就是数理方程。\n考虑 $\\b E_x$，然后通过猜测关于时间震荡（其实是处理波动方程时的常见套路），我们可以把它写成（各维 $\\omega$ 相同） $$ \\b E_x(x,y,z,t)=E_x(x,y,z)\\e^{\\i\\omega t} $$ 同样，实际情况我们就取实部。\n为了避免与磁场扯上关系，我们考虑列波动方程。在空腔内， $$ \\nabla^2\\b E_x-\\frac{1}{c^2}\\frac{\\p^2\\b E_x}{\\p t^2}=0\\Longrightarrow\\nabla^2E_x+\\frac{\\omega^2}{c^2}E_x=0 $$ 右边这个叫亥姆霍兹方程。令 $k=\\omega/c$。\n现在我们把 $E_x(x,y,z)$ 写成 $X(x)Y(y)Z(z)$（分量略 $x$ 下标）。那么方程就变成了 $$ \\frac{\\d^2X}{\\d x^2}YZ+X\\frac{\\d^2Y}{\\d y^2}Z+XY\\frac{\\d^2Z}{\\d z^2}+k^2XYZ=0\\Longrightarrow\\frac{\\d^2 X}{X\\d x^2}+\\frac{\\d^2 Y}{Y\\d y^2}+\\frac{\\d^2 Z}{Z\\d z^2}=-k^2 $$\n对两边分别关于 $x$、$y$、$z$ 求导，就可以得到三个分量都是常数。以 $X$ 分量为例， $$ \\frac{\\d^2X}{\\d x^2}=CX $$ 如果 $C\\ge 0$，会导致 $X$ 向至少一方向增加，无法符合边界条件，肯定不对。所以考虑设 $C=-k_x^2$，这时解得 $$ X=C_1\\cos k_xx+C_2\\sin k_xx $$ 同样写出另外两个部分： $$ \\left\\{\\begin{aligned} X\u0026amp;=C_x\\cos k_xx+D_x\\sin k_xx\\\\ Y\u0026amp;=C_y\\cos k_yy+D_y\\sin k_yy\\\\ Z\u0026amp;=C_z\\cos k_zz+D_z\\sin k_zz\\\\ k^2\u0026amp;=k_x^2+k_y^2+k_z^2 \\end{aligned}\\right. $$ 现在代入边界条件。由于 $y=0/b$、$z=0/d$ 处只能有垂直边界方向的电场，从而无 $x$ 方向分量。故 $$ \\begin{align*} Y(0)=0\u0026amp;\\Longrightarrow C_y=0\\\\ Y(b)=0\u0026amp;\\Longrightarrow D_y=0\\lor k_yb=n\\pi\\,(n\\in\\Z)\\\\ Z(0)=0\u0026amp;\\Longrightarrow C_z=0\\\\ Z(d)=0\u0026amp;\\Longrightarrow D_z=0\\lor k_zd=p\\pi\\,(p\\in\\Z) \\end{align*} $$ $D_y=0$ 和 $D_z=0$ 可以去掉（对应 $n=0$、$p=0$ 情况）。\n$X$ 部分怎么确定呢？别忘了我们还有一个 $\\nabla\\cdot\\b E=0$（因为波动方程的形式前提是把 $\\nabla(\\nabla\\cdot\\b E)$ 去掉）。写开来会长成（这里不省略下标）： $$ \\frac{\\d X_x}{\\d x}Y_xZ_x+X_y\\frac{\\d Y_y}{\\d y}Z_y+X_zY_z\\frac{\\d Z_z}{\\d z}=0 $$ 当 $x$ 接近 $0/a$ 时，根据类似的推导，$X_y=X_z=0$，从而只剩下 $$ \\frac{\\d X_x}{\\d x}Y_xZ_x=0 $$ 所以要么 $Y_x$ 或 $Z_x$ 恒为零，要么就是 $$ \\begin{align*} X^\\prime(0)=0\u0026amp;\\Longrightarrow D_x=0\\\\ X^\\prime(a)=0\u0026amp;\\Longrightarrow C_x=0\\lor k_xa=m\\pi\\,(m\\in\\Z) \\end{align*} $$ 总的来说（$A_x=C_xD_yD_z$）， $$ E_x(x,y,z)=A_x\\cos k_xx\\sin k_yy\\sin k_zz $$ 同理得到其他两维。但注意，我们没说其他两维的 $k_x$、$k_y$、$k_z$ 跟这里一样，所以最后还得依靠 $\\nabla\\cdot\\b E=0$ 来得到额外的结果。最后我们得到的完整的式子与约束为（$\\b B$ 由 $\\nabla\\times\\b E=-\\p\\b B/\\p t=-\\i\\omega\\b B$ 得到） $$ \\left\\{\\begin{aligned} \\b E_x(x,y,z,t)\u0026amp;=A_x\\e^{\\i\\omega t}\\cos k_xx\\sin k_yy\\sin k_zz\\\\ \\b E_y(x,y,z,t)\u0026amp;=A_y\\e^{\\i\\omega t}\\sin k_xx\\cos k_yy\\sin k_zz\\\\ \\b E_z(x,y,z,t)\u0026amp;=A_z\\e^{\\i\\omega t}\\sin k_xx\\sin k_yy\\cos k_zz\\\\ \\b B_x(x,y,z,t)\u0026amp;=(A_zk_y-A_yk_z)\\frac{\\i\\e^{\\i\\omega t}}\\omega\\sin k_xx\\cos k_yy\\cos k_zz\\\\ \\b B_y(x,y,z,t)\u0026amp;=(A_xk_z-A_zk_x)\\frac{\\i\\e^{\\i\\omega t}}\\omega\\cos k_xx\\sin k_yy\\cos k_zz\\\\ \\b B_z(x,y,z,t)\u0026amp;=(A_yk_x-A_xk_y)\\frac{\\i\\e^{\\i\\omega t}}\\omega\\cos k_xx\\cos k_yy\\sin k_zz\\\\ \\frac{\\omega^2}{c^2}\u0026amp;=k_x^2+k_y^2+k_z^2\\\\ 0\u0026amp;=A_xk_x+A_yk_y+A_zk_z\\\\ k_x\u0026amp;=\\frac{m\\pi}{a}\\;(m\\in\\Z)\\\\ k_y\u0026amp;=\\frac{n\\pi}{b}\\;(n\\in\\Z)\\\\ k_z\u0026amp;=\\frac{p\\pi}{d}\\;(p\\in\\Z) \\end{aligned}\\right. $$ 换句话说，要使得这个谐振腔能稳定地振动，初始给的信号必须要是 $\\exists m,n,p\\in\\Z$，使 $$ \\omega=c\\pi\\sqrt{\\left(\\frac ma\\right)^2+\\left(\\frac nb\\right)^2+\\left(\\frac pd\\right)^2} $$ 并且对振幅也有限制。\n对于至少有一个分量为 $0$ 的情况，有一个命名方法——产生对应 $m$、$n$、$p$ 的震荡的信号生成器叫 $\\mathrm{TE}_{mnp}$（如果 $\\b E_z=0$）或 $\\mathrm{TM}_{mnp}$（如果 $\\b B_z=0$）。现在我们来分析一下至少有一个分量为 $0$，会导致哪些情况：\n$\\b E_z=0$，通过 $k_x=0$ 达成。这时 $\\b E_x$、$\\b B_y$、$\\b B_z$ 非零，且无所谓 $A_z$、$A_y$ 是否为零。 $\\b E_z=0$，通过 $A_z=0$ 达成。如果没有别的可变量非零，那么其他五个量均非零。 $A_z=k_z=0$。这种不行，全部都变成零了。 $\\b B_z=0$，通过 $k_z=0$ 达成。这时 $\\b E_z$、$\\b B_x$、$\\b B_y$ 非零。 $\\b B_z=0$，通过 $A_yk_x=A_xk_y$ 达成。这种看起来比较难分析，其实可以根据对称性，得到其他五个量也都非零。 其余情况都只是循环位移一下。总的来说，只有 $0$、$1$、$3$ 个分量为零这三种可能。所以说 $\\rm TE$ 和 $\\rm TM$ 只能表示其中部分情况，但是不会一种非全零的情况是 $\\rm TEM$。另外加一个假设 $b\u0026lt;a\u0026lt;d$。\n我知道你看见这些莫名其妙的说法已经受不了了，TE、TM、TEM 这些东西是波导来的，所以你可以认为这些是“惯例”的问题。\n对于 $\\rm TE$，有 $\\mathrm{TE}_{m0p}$、$\\mathrm{TE}_{0np}$、$\\mathrm{TE}_{mnp}$ 这三种，其中频率最低的是 $\\mathrm{TE}_{101}$。这种情况的场是： $$ \\left\\{\\begin{aligned} \\b E_x\u0026amp;=0\\\\ \\b E_y\u0026amp;=A\\e^{\\i\\omega t}\\sin\\frac{\\pi x}a\\sin\\frac{\\pi z}d\\\\ \\b E_z\u0026amp;=0\\\\ \\b B_x\u0026amp;=-\\frac{A\\pi}d\\frac{\\i\\e^{\\i\\omega t}}\\omega\\sin\\frac{\\pi x}a\\cos\\frac{\\pi z}d\\\\ \\b B_y\u0026amp;=0\\\\ \\b B_z\u0026amp;=\\frac{A\\pi}a\\frac{\\i\\e^{\\i\\omega t}}\\omega\\cos\\frac{\\pi x}a\\sin\\frac{\\pi z}d\\\\ \\omega\u0026amp;=c\\pi\\sqrt{\\frac1{a^2}+\\frac1{d^2}} \\end{aligned}\\right. $$ $\\mathrm{TE}_{111}$ 的场是（注意这里我是把 $A_xk_x+A_yk_y=0$ 的等式解成了 $A_x=Ak_y$，$A_y=-Ak_x$，量纲一塌糊涂，反正能看就行）： $$ \\left\\{\\begin{aligned} \\b E_x\u0026amp;=\\frac{A\\pi}b\\e^{\\i\\omega t}\\cos\\frac{\\pi x}a\\sin\\frac{\\pi y}b\\sin\\frac{\\pi z}d\\\\ \\b E_y\u0026amp;=-\\frac{A\\pi}a\\e^{\\i\\omega t}\\sin\\frac{\\pi x}a\\cos\\frac{\\pi y}b\\sin\\frac{\\pi z}d\\\\ \\b E_z\u0026amp;=0\\\\ \\b B_x\u0026amp;=\\frac{A\\pi^2}{ad}\\frac{\\i\\e^{\\i\\omega t}}\\omega\\sin\\frac{\\pi x}a\\cos\\frac{\\pi y}b\\cos\\frac{\\pi z}d\\\\ \\b B_y\u0026amp;=\\frac{A\\pi^2}{bd}\\frac{\\i\\e^{\\i\\omega t}}\\omega\\cos\\frac{\\pi x}a\\sin\\frac{\\pi y}b\\cos\\frac{\\pi z}d\\\\ \\b B_z\u0026amp;=-A\\pi^2\\left(\\frac1{a^2}+\\frac1{b^2}\\right)\\frac{\\i\\e^{\\i\\omega t}}\\omega\\cos\\frac{\\pi x}a\\cos\\frac{\\pi y}b\\sin\\frac{\\pi z}d\\\\ \\omega\u0026amp;=c\\pi\\sqrt{\\frac1{a^2}+\\frac1{b^2}+\\frac1{d^2}} \\end{aligned}\\right. $$ 对于 $\\rm TM$，只有 $\\mathrm{TM}_{mn0}$、$\\mathrm{TM}_{mnp}$ 这两种，其中频率最低的是 $\\mathrm{TM}_{110}$。对应的场是： $$ \\left\\{\\begin{aligned} \\b E_x\u0026amp;=0\\\\ \\b E_y\u0026amp;=0\\\\ \\b E_z\u0026amp;=A\\e^{\\i\\omega t}\\sin\\frac{\\pi x}a\\sin\\frac{\\pi y}b\\\\ \\b B_x\u0026amp;=\\frac{A\\pi}b\\frac{\\i\\e^{\\i\\omega t}}\\omega\\sin\\frac{\\pi x}a\\cos\\frac{\\pi y}b\\\\ \\b B_y\u0026amp;=-\\frac{A\\pi}a\\frac{\\i\\e^{\\i\\omega t}}\\omega\\cos\\frac{\\pi x}a\\sin\\frac{\\pi y}b\\\\ \\b B_z\u0026amp;=0\\\\ \\omega\u0026amp;=c\\pi\\sqrt{\\frac1{a^2}+\\frac1{b^2}} \\end{aligned}\\right. $$ 我不想再写 $\\mathrm{TM}_{111}$ 啦！\n模式是可以叠加的，另外我想知道，是否存在不能用这些模式线性组合得到的解。\n圆柱形谐振腔 书里有一种很牛的方法，对于接了交流电的平行板电容器，通过反复利用高斯定律和安培定律，可以得到其中电磁场的级数解。然后让边上恒为零，这个时候加上金属侧边（我不知道为啥其中的电流不会影响里面的电磁场），然后就解出来了。\n然后记得还有讲过电磁场在边界处指数衰减的，我也没记。\n将坐标系换为柱坐标系后，套路和上面类似。设 $$ \\b E_z(\\rho,\\phi,z,t)=R(\\rho)P(\\phi)Z(z)\\e^{\\i\\omega t} $$ 在 $\\nabla^2\\b E_z+k^2\\b E_z=0$ 中代入 $$ \\nabla^2=\\frac{\\p^2}{\\p\\rho^2}+\\frac1\\rho\\frac{\\p}{\\p\\rho}+\\frac1{\\rho^2}\\frac{\\p^2}{\\p\\phi^2}+\\frac{\\p^2}{\\p z^2} $$ 得 $$ \\frac{\\d^2R}{\\d\\rho^2}PZ+\\frac1\\rho\\frac{\\d R}{\\d\\rho}PZ+\\frac{R}{\\rho^2}\\frac{\\d^2P}{\\d\\phi^2}Z+RP\\frac{\\d^2Z}{\\d z^2}+k^2RPZ=0 $$ 同除以 $RPZ$： $$ \\frac1R\\frac{\\d^2 R}{\\d\\rho^2}+\\frac1{\\rho R}\\frac{\\d R}{\\d\\rho}+\\frac1{\\rho^2P}\\frac{\\d^2P}{\\d\\phi^2}+\\frac1Z\\frac{\\d^2Z}{\\d z^2}+k^2=0 $$ 整个等式被分成了与 $\\rho$、$\\phi$ 相关的和与 $z$ 相关的部分，所以可设 $$ \\frac1Z\\frac{\\d^2Z}{\\d z^2}=-\\beta^2\\Longrightarrow Z=C_1\\cos\\beta z+C_2\\sin\\beta z $$ 然后这里的话我们把它写成指数的形式，并且只保留 $\\e^{-\\i\\beta z}$ 项。这样做的原因是为了把谐振腔看成波导的变形，然后只保留一个方向传播的波。这个后面会再提。总之 $$ \\b E_z=R(\\rho)P(\\phi)\\e^{\\i(\\omega t-\\beta z)} $$ 这边提一下一个细节，我上课有个疑问：为啥是 $\\e^{\\i\\beta z}$ 而不能是 $\\e^{(\\alpha+\\i\\beta)z}$？一方面如果是 $\\e^{\\alpha z}$，$\\b E_\\rho$、$\\b E_\\phi$ 和 $\\b B_z$ 的边界条件就不可能满足，另一方面如果实部虚部都有，你会发现整个 $\\re Z$ 根本没法满足 $Z^{\\prime\\prime}/Z$ 是个常数。\n再代一遍 $\\Delta$，同除 $RP/\\rho^2$： $$ \\frac{\\d^2R}{\\d\\rho^2}P+\\frac1\\rho\\frac{\\d R}{\\d\\rho}P+\\frac{R}{\\rho^2}\\frac{\\d^2P}{\\d\\phi^2}+(k^2-\\beta^2)RP=0\\Longrightarrow\\frac{\\rho^2}{R}\\frac{\\d^2R}{\\d\\rho^2}+\\frac{\\rho}{R}\\frac{\\d R}{\\d\\rho}+(k^2-\\beta^2)\\rho^2=-\\frac{1}{P}\\frac{\\d^2P}{\\d\\phi^2} $$ 我们又得到了一个等式，两侧分别只与 $\\rho$、$\\phi$ 相关。我们设它为 $n^2$，其中 $n\\in\\N$。只能这么设的原因其实很简单——为了保证 $P$ 以 $2\\pi$ 为周期。右边的解是 $P=C_1\\cos n\\phi+C_2\\sin n\\phi$。左边的方程是 $$ \\rho^2\\frac{\\d^2R}{\\d\\rho^2}+\\rho\\frac{\\d R}{\\d\\rho}+\\left[(k^2-\\beta^2)\\rho^2-n^2\\right]R=0 $$ 令 $k_c^2=k^2-\\beta^2$，$t=k_c\\rho$，则变为 $$ t^2\\frac{\\d^2R}{\\d t^2}+t\\frac{\\d R}{\\d t}+(t^2-n^2)R=0 $$ 这个的解是贝塞尔函数（第一类贝塞尔函数 $J_n$ 和第二类贝塞尔函数 $Y_n$ 的线性组合，但 $Y_n$ 在 $0$ 处发散，舍） $$ R=C_0J_n(t)=C_0J_n(k_c\\rho) $$\n如果 $k\u0026lt;\\beta$ 即 $k_c$ 是虚数，我们会得到 $I_n(\\i k_c\\rho)$，$I$ 是第一类修正贝塞尔函数。这个东西零点只在 $x=0$，所以一定是没法满足边界条件的。所以我们要求 $k\\ge\\beta$。\n$J_0$ 的前两个零点为 $x\\approx 2.405$、$x\\approx 5.520$。\n综上所述，我们的解长成这样 $$ \\b E_z=C\\cdot J_n(k_c\\rho)\\sin(n\\phi+\\phi_0)\\e^{-\\i\\beta z}\\e^{\\i\\omega t} $$ 那实际上 $\\b E_\\rho$ 和 $\\b E_\\phi$ 也肯定是有个 $\\e^{\\i\\beta z}\\e^{\\i\\omega t}$ 的因子在里面的，所以顶底给出了一对边界条件。如果圆柱高为 $d$，那么（实际情况大概会是强制把 $\\sin$ 搞到实部或者改相位之类的） $$ \\beta=\\frac{l\\pi}d\\;(l\\in\\Z) $$ 同时若圆柱半径为 $r$，那么 $J_n(k_cr)=0$。这就是两个边界条件。关于另两个分量和磁场的计算，我们放到下面。有个更简单的方法。\n波导 在研究完两种形状的谐振腔后，我们会想，有没有一般的方法？为什么 $\\rm TEM$ 波不存在？之类的。波导可以理解为没有“底面”的无限长谐振腔，正常谐振腔里的电磁波可以理解为以两个底面为反射面，将波导里的电磁波“折叠起来”。同时，考虑波导可以得到一个更一般的计算方法。\n现在想一个任意形状回路沿 $z$ 轴移动得到的正柱面。设在其中的电磁场为 $$ \\left\\{\\begin{aligned} \\b E\u0026amp;=(\\b{\\hat x}\\b E_x(x,y)+\\b{\\hat y}\\b E_y(x,y)+\\b{\\hat z}\\b E_z(x,y))\\e^{-\\i\\beta z}\\e^{\\i\\omega t}\\\\ \\b B\u0026amp;=(\\b{\\hat x}\\b B_x(x,y)+\\b{\\hat y}\\b B_y(x,y)+\\b{\\hat z}\\b B_z(x,y))\\e^{-\\i\\beta z}\\e^{\\i\\omega t} \\end{aligned}\\right. $$ 现在我们不直接套波动方程，而是代入无源麦克斯韦方程组： $$ \\left\\{\\begin{aligned} \\nabla\\times\\b E\u0026amp;=-\\i\\omega\\b B\\\\ \\nabla\\times\\b B\u0026amp;=\\eps_0\\mu_0\\i\\omega\\b E \\end{aligned}\\right. $$ 展开 $$ \\left\\{\\begin{align*} \\frac{\\p\\b E_z}{\\p y}+\\i\\beta\\b E_y\u0026amp;=-\\i\\omega\\b B_x\u0026amp;\\tag{1}\\\\ -\\i\\beta\\b E_x-\\frac{\\p\\b E_z}{\\p x}\u0026amp;=-\\i\\omega\\b B_y\\\\ \\frac{\\p\\b E_y}{\\p x}-\\frac{\\p\\b E_x}{\\p y}\u0026amp;=-\\i\\omega\\b B_z\\\\ \\frac{\\p\\b B_z}{\\p y}+\\i\\beta\\b B_y\u0026amp;=\\eps_0\\mu_0\\i\\omega\\b E_x\u0026amp;\\tag{2}\\\\ -\\i\\beta\\b B_x-\\frac{\\p\\b B_z}{\\p x}\u0026amp;=\\eps_0\\mu_0\\i\\omega\\b E_y\\\\ \\frac{\\p\\b B_y}{\\p x}-\\frac{\\p\\b B_x}{\\p y}\u0026amp;=\\eps_0\\mu_0\\i\\omega\\b E_z\\\\ \\end{align*}\\right. $$ 结合 $(1)$、$(2)$ 得 $$ (\\eps_0\\mu_0\\omega^2-\\beta^2)\\b E_y=\\i\\left(-\\beta\\frac{\\p\\b E_z}{\\p y}+\\omega\\frac{\\p\\b B_z}{\\p x}\\right) $$ 同理我们可以解得 $\\b E_x$、$\\b B_x$、$\\b B_y$ 关于 $\\b E_z$ 和 $\\b B_z$ 的表达式，这意味着，我们后续只需要解出这两个量就行了。 $$ \\left\\{\\begin{align*} \\b E_x\u0026amp;=\\frac{-\\i}{k_c^2}\\left(\\beta\\frac{\\p\\b E_z}{\\p x}+\\omega\\frac{\\p\\b B_z}{\\p y}\\right)\\\\ \\b E_y\u0026amp;=\\frac{\\i}{k_c^2}\\left(-\\beta\\frac{\\p\\b E_z}{\\p y}+\\omega\\frac{\\p\\b B_z}{\\p x}\\right)\\\\ \\b B_x\u0026amp;=\\frac{\\i}{k_c^2}\\left(\\eps_0\\mu_0\\omega\\frac{\\p\\b E_z}{\\p y}-\\beta\\frac{\\p\\b B_z}{\\p x}\\right)\\\\ \\b B_y\u0026amp;=\\frac{-\\i}{k_c^2}\\left(\\eps_0\\mu_0\\omega\\frac{\\p\\b E_z}{\\p x}+\\beta\\frac{\\p\\b B_z}{\\p y}\\right) \\end{align*}\\right. $$\n别忘了 $k_c^2=k^2-\\beta^2$。\nTEM 波 考虑 $\\b E_z=\\b B_z=0$ 的情况。只有在 $k_c=0$ 即 $k=\\beta$ 时，其他的分量才有可能不是零，这时 $$ \\left\\{\\begin{align*} \\beta\\b E_y\u0026amp;=-\\omega\\b B_x\\\\ \\beta\\b E_x\u0026amp;=\\omega\\b B_y\\\\ \\frac{\\p\\b E_y}{\\p x}\u0026amp;=\\frac{\\p\\b E_x}{\\p y}\\\\ \\beta\\b B_y\u0026amp;=\\eps_0\\mu_0\\omega\\b E_x\\\\ -\\beta\\b B_x\u0026amp;=\\eps_0\\mu_0\\omega\\b E_y\\\\ \\frac{\\p\\b B_y}{\\p x}\u0026amp;=\\frac{\\p\\b B_x}{\\p y}\\\\ \\end{align*}\\right. $$ 这种情况下这堆东西其实没啥用，无非就是还能导出个二维的拉普拉斯方程 $$ \\frac{\\p^2\\b E_x}{\\p x^2}+\\frac{\\p^2\\b E_y}{\\p y^2}=\\frac{\\p^2\\b B_x}{\\p x^2}+\\frac{\\p^2\\b B_y}{\\p y^2}=0 $$ 所以告诉了你真正要解的时候怎么解。但在只有一个导体的情况下，你会发现因为 $\\nabla\\cdot\\b E=0$，所以其实就是一个静电屏蔽的场景，中间无电磁场，因为 $\\nabla^2\\varphi=0$ 且边界等势。所以 $\\rm TEM$ 波其实没什么好说的。\n还有个东西叫波阻抗，其定义为 $$ Z=\\frac{\\b E_x}{\\b H_y}=-\\frac{\\b E_y}{\\b H_x} $$ 其中 $\\b H=\\b B/\\mu_0$。在这里， $$ Z_{\\rm TEM}=\\frac{\\mu_0\\omega}\\beta=\\frac{\\mu_0\\omega}k=\\mu_0c=\\sqrt{\\frac{\\mu_0}{\\eps_0}} $$ $\\eta_0=\\sqrt{\\mu_0/\\eps_0}$ 又被称为真空的固有阻抗。这个跟正常的阻抗肯定是不同的，真空的阻抗显然是 $\\infty$。\n什么？你想知道它的物理意义？我也不知道，但我知道它的计算可能会考。你可以这样记忆：$R=U/I$，$U$ 与电场有关，$I$ 与磁场有关。\nTE 波 $\\b E_z=0$ 而 $\\b B_z\\ne 0$ 时，再考虑 $k=\\beta$ 就没什么意义了（会导致 $\\b B_z$ 是常数）。所以 $$ \\left\\{\\begin{align*} \\b E_x\u0026amp;=\\frac{-\\i\\omega}{k_c^2}\\frac{\\p\\b B_z}{\\p y}\\\\ \\b E_y\u0026amp;=\\frac{\\i\\omega}{k_c^2}\\frac{\\p\\b B_z}{\\p x}\\\\ \\b B_x\u0026amp;=\\frac{-\\i\\beta}{k_c^2}\\frac{\\p\\b B_z}{\\p x}\\\\ \\b B_y\u0026amp;=\\frac{-\\i\\beta}{k_c^2}\\frac{\\p\\b B_z}{\\p y} \\end{align*}\\right. $$ 只需要解磁场的亥姆霍兹方程 $$ \\frac{\\p^2\\b B_z}{\\p x^2}+\\frac{\\p^2\\b B_z}{\\p y^2}+k_c^2\\b B_z=0 $$ 即可。这种情况的波阻抗为 $$ Z_{\\rm TE}=\\frac{\\mu_0\\omega}\\beta=\\frac{k\\eta_0}\\beta $$\nTM 波 $$ \\left\\{\\begin{align*} \\b E_x\u0026amp;=\\frac{-\\i\\beta}{k_c^2}\\frac{\\p\\b E_z}{\\p x}\\\\ \\b E_y\u0026amp;=\\frac{-\\i\\beta}{k_c^2}\\frac{\\p\\b E_z}{\\p y}\\\\ \\b B_x\u0026amp;=\\frac{\\i\\eps_0\\mu_0\\omega}{k_c^2}\\frac{\\p\\b E_z}{\\p y}\\\\ \\b B_y\u0026amp;=\\frac{-\\i\\eps_0\\mu_0\\omega}{k_c^2}\\frac{\\p\\b E_z}{\\p x}\\\\ Z_{\\rm TM}\u0026amp;=\\frac{\\beta}{\\eps_0\\omega}=\\frac{\\beta\\eta_0}k \\end{align*}\\right. $$\n矩形波导 TE 波 $$ \\left(\\frac{\\p^2}{\\p x^2}+\\frac{\\p^2}{\\p y^2}+k_c^2\\right)\\b B_z=0 $$\n设 $$ \\b B_z=X(x)Y(y) $$ 则 $$ \\frac{X^{\\prime\\prime}}{X}+\\frac{Y^{\\prime\\prime}}{Y}+k_c^2=0\\Longrightarrow \\left\\{\\begin{aligned} X\u0026amp;=C_x\\cos k_xx+D_x\\sin k_xx\\\\ Y\u0026amp;=C_y\\cos k_yy+D_y\\sin k_yy\\\\ k_c^2\u0026amp;=k_x^2+k_y^2 \\end{aligned}\\right. $$ 这里 $k_c$ 是实数是比较显然的。然后（$\\b E_x$ 和 $\\b E_y$ 的）边界 $\\Rightarrow D_x=D_y=0$、$k_x=m\\pi/a$、$k_y=n\\pi/b$。从而（必须）有 $$ \\beta=\\sqrt{k^2-\\left(\\frac{m\\pi}a\\right)^2-\\left(\\frac{n\\pi}b\\right)^2} $$ 最后的解是 $$ \\left\\{\\begin{align*} \\b E_x\u0026amp;=\\frac{\\i\\omega n\\pi}{k_c^2b}A\\cos\\frac{m\\pi x}a\\sin\\frac{n\\pi y}b\\e^{-\\i\\beta z}\\\\ \\b E_y\u0026amp;=\\frac{-\\i\\omega m\\pi}{k_c^2a}A\\sin\\frac{m\\pi x}a\\cos\\frac{n\\pi y}b\\e^{-\\i\\beta z}\\\\ \\b E_z\u0026amp;=0\\\\ \\b B_x\u0026amp;=\\frac{\\i\\beta m\\pi}{k_c^2a}A\\sin\\frac{m\\pi x}a\\cos\\frac{n\\pi y}b\\e^{-\\i\\beta z}\\\\ \\b B_y\u0026amp;=\\frac{\\i\\beta n\\pi}{k_c^2b}A\\cos\\frac{m\\pi x}a\\sin\\frac{n\\pi y}b\\e^{-\\i\\beta z}\\\\ \\b B_z\u0026amp;=A\\cos\\frac{m\\pi x}{a}\\cos\\frac{n\\pi y}b\\e^{-\\i\\beta z} \\end{align*}\\right. $$ 这个叫做 $\\mathrm{TE}_{mn}$ 模式。\n最后我们说一下 $k_c$。它称为“截止波数”。想一个波导，它的 $a$、$b$ 都是定的，模式也是定的，所以 $k_c$ 是定的。那么这个时候不定的只有 $\\omega$。如果 $\\omega$ 过小，$k$ 就会过小，$\\beta=\\sqrt{k^2-k_c^2}$ 就变成虚的，信号就无法传播了（会指数衰减）。所以有个对应的截止频率——$\\beta=0$，$k=k_c$ 时 $$ f_{c_{mn}}=\\frac{\\omega_c}{2\\pi}=\\frac{ck}{2\\pi}=\\frac{ck_c}{2\\pi}=\\frac{1}{2\\pi\\sqrt{\\eps_0\\mu_0}}\\sqrt{\\left(\\frac{m\\pi}a\\right)^2+\\left(\\frac{n\\pi}b\\right)^2} $$ 这里讲的这些波导都是高通的。\n同样，如果 $b\u0026lt;a$，最低的截止频率对应的就是 $\\mathrm{TE}_{10}$。对应的 $f_{c_{10}}=1/2a\\sqrt{\\eps_0\\mu_0}$。\n我们再关注有几何意义的几个量：一个是波导波长，即在同一时间，波导中两个波峰的距离。由于 $z$ 方向有个 $\\beta$ 倍，所以这个的值为 $$ \\lambda_g=\\frac{2\\pi}{\\beta}\u0026gt;\\frac{2\\pi}{\\omega}=\\lambda $$ 比正常真空中的波长长。同时，一个波峰的速度为，考虑 $\\e^{\\i(\\omega t-\\beta z)}=C$，也就是 $\\omega t-\\beta z=C$。 $$ v_p=\\frac{\\p z}{\\p t}=\\frac\\omega\\beta=\\frac k\\beta c\u0026gt;c $$ 这个称为相速度。因为波既在正常传播，内部的相位又在变化，所以会造成超光速的错觉。这里的几张图有助于理解。波导里面的信号实际是以群速度传播的： $$ v_g=\\frac{\\p\\omega}{\\p\\beta}=\\frac{\\beta c^2}\\omega=\\frac\\beta kc\u0026lt;c $$ 群速度的公式怎么来的就不讲了。\nTM 波 除了边界条件啥都一样。 $$ \\left\\{\\begin{align*} \\b E_x\u0026amp;=\\frac{-\\i\\beta m\\pi}{k_c^2a}A\\cos\\frac{m\\pi x}a\\sin\\frac{n\\pi y}b\\e^{-\\i\\beta z}\\\\ \\b E_y\u0026amp;=\\frac{-\\i\\beta n\\pi}{k_c^2b}A\\sin\\frac{m\\pi x}a\\cos\\frac{n\\pi y}b\\e^{-\\i\\beta z}\\\\ \\b E_z\u0026amp;=A\\sin\\frac{m\\pi x}a\\sin\\frac{n\\pi y}b\\e^{-\\i\\beta z}\\\\ \\b B_x\u0026amp;=\\frac{\\i\\eps_0\\mu_0\\omega n\\pi}{k_c^2b}A\\sin\\frac{m\\pi x}a\\cos\\frac{n\\pi y}b\\e^{-\\i\\beta z}\\\\ \\b B_y\u0026amp;=\\frac{-\\i\\eps_0\\mu_0\\omega m\\pi}{k_c^2a}A\\cos\\frac{m\\pi x}a\\sin\\frac{n\\pi y}b\\e^{-\\i\\beta z}\\\\ \\b B_z\u0026amp;=0 \\end{align*}\\right. $$ 最低的截止频率对应的是 $\\mathrm{TM}_{11}$。\n","date":"2025-01-22T00:00:00Z","image":"https://littlereuben.github.io/study/course-physics2/cover.jpg","permalink":"https://littlereuben.github.io/study/course-physics2/","title":"普通物理 (2) 笔记"},{"content":"这是一篇学习笔记。\r[PDF file] ","date":"2025-01-22T00:00:00Z","permalink":"https://littlereuben.github.io/study/course-algo-survey/","title":"算设 Survey：一些经典问题的 log 因子优化算法"},{"content":"$\\gdef\\eps{\\varepsilon}\\gdef\\e{\\mathrm{e}}\\gdef\\d{\\mathrm{d}}\\gdef\\i{\\mathrm{i}}\\gdef\\F{\\mathbb{F}}\\gdef\\arcsinh{\\operatorname{arcsinh}}\\gdef\\arccosh{\\operatorname{arccosh}}\\gdef\\arctanh{\\operatorname{arctanh}}\\gdef\\arccoth{\\operatorname{arccoth}}\\gdef\\arcsech{\\operatorname{arcsech}}\\gdef\\arccsch{\\operatorname{arccsch}}\\gdef\\sgn{\\operatorname{sgn}}\\gdef\\sech{\\operatorname{sech}}\\gdef\\csch{\\operatorname{csch}}\\gdef\\arccot{\\operatorname{arccot}}\\gdef\\arcsec{\\operatorname{arcsec}}\\gdef\\arccsc{\\operatorname{arccsc}}\\gdef\\b#1{\\boldsymbol{#1}}\\gdef\\mat#1{\\begin{bmatrix}#1\\end{bmatrix}}\\gdef\\dat#1{\\begin{vmatrix}#1\\end{vmatrix}}\\gdef\\tr{\\operatorname{tr}}\\gdef\\R{\\mathbb{R}}\\gdef\\Q{\\mathbb{Q}}$\n这是一篇学习笔记。\r前言 上半学期没什么东西，就记了一下大纲，然后记了些杂题，一部分放在下面，另一部分可以看期中复习 slide。\n下半学期有比较详尽的内容。\n参照了 wxf 的 ppt 和课。\n理论基础、期中复习。\n上半学期 实分析初步\n基础定义和性质、实数理论（略） 上下界、上下确界 确界的类 $\\eps-\\delta$ 语言 确界原理 初等函数 指数、对数、幂函数的定义 注意只考虑底数 $\u0026gt;0$ 的情况。 有理数指数（开根）、无理数指数都使用上确界定义。 指数、对数、幂函数的单调性。 对数函数在没有连续性理论的情况下，类似于开根，也使用上确界定义。 三角函数、反三角函数的定义与性质 初等函数的定义 注意是有限次的四则运算与复合；注意定义域。 极限与连续性\n$\\eps-\\delta$ 语言\n注意极限和连续性都可以定义在定义域为非区间的函数上，但是考试应该会避免这种事。定义极限时，$x_0$ 必须是定义域的聚点；定义连续性时，$x_0$ 必须在定义域内。 $\\eps-\\delta$ 的证明策略\n基础放缩方法\n上取整 反解不等式 多个条件取最值；分类讨论转求和 三角不等式 阿基米德性、有理数和无理数的稠密性\n黎曼函数、狄利克雷函数 二项式展开 → 伯努利不等式\n条件：$x\u0026gt;-1$\n$a\u0026gt;1$：$(1+x)^a\\ge 1+ax$，在 $x=0$ 处取等\n$a=1$：$(1+x)^a=1+ax$\n$0\u0026lt;a\u0026lt;1$：$(1+x)^a\\le 1+ax$，在 $x=0$ 处取等\n$a=0$：$(1+x)^a=1+ax$\n$a\u0026lt;0$：$(1+x)^a\\ge 1+ax$，在 $x=0$ 处取等\n应用：\n$n^k/a^n$ $\\sqrt[n]a$ $\\sqrt[n]n$ $(1+1/n)^n$ $\\e$ 和 $\\ln$ 相关的不等式\n$\\e^x\\ge 1+x$，在 $x=0$ 处取等（求导证 $(1+x)^{1/x}$ 单降、凸性切线） $\\e^x\\le(1+x)^{1+x}$（$x\u0026gt;-1$），在 $x=0$ 处取等（$(1+x)^{1/x+1}$ 单增） $\\ln(1+x)\\le x\\le(1+x)\\ln(1+x)$（$x\u0026gt;-1$），在 $x=0$ 处取等 $\\e^x\\le1/(1-x)$（$x\u0026lt;1$），1 中 $x$ 换成 $-x$ $\\e^x\u0026lt;(\\e-1)x+1$（$0\u0026lt;x\u0026lt;1$），过 $\\e^x$ 的 $(0,1)-(1,\\e)$ 的割线，凸性 三角函数相关的不等式\n$\\sin x\u0026lt;x\u0026lt;\\tan x$（$0\u0026lt;x\u0026lt;\\pi/2$） 极限的初步性质\n唯一性、有界性 保序性与夹逼定理 取极限后，不含等变含等；极限不等，原邻域也不等。 夹逼定理本身蕴含着极限的存在性。 （连续也有）四则运算 注意分母不能是 $0$。 （连续也有）复合 注意定义域。 初等函数的连续性 数列极限的特有性质\n子列与原列的极限的关系 存在一个下标列同时使两个有界数列收敛 复合函数 单调有界原理 列紧性 柯西列 有界变差数列 闭区间套定理 Stolz 定理 注意使用条件：分母必须单调。 差分后极限存在 $\\Rightarrow$ 原极限存在 数列极限与函数极限的关系\n归结原理与柯西收敛定理 间断点\n可去间断点、跳跃间断点是第一类间断点（左右极限均存在但有至少一个 $\\ne f(x_0)$），其他都是第二类。 $\\e$\n证明数列极限存在 证明函数极限存在 证明数列极限存在的方法\n单调有界定理 $\\e$ $H_n-\\ln n$ 一些可以用 Banach 不动点定理证的东西 保序性、夹逼 阶乘倒数和 $=\\e$ Stolz 平均值的极限 $n!/n^n$ 求极限的方法\n（数列）等式两侧求极限解方程 → 找不动点 数列、函数互相归约 代数变形后利用连续性 换元、取对数 逆天三角换元 等价替换、渐进分析 Stolz、洛 连续性相关定理\n单调函数、反函数的性质 介值定理 有界定理、最值定理 注意必须是闭区间 压缩不动点定理 一致连续性 渐近线\n由定义求：写出曲线上点到直线距离公式，求极限。或者说 $k=\\lim f(x)/x$，$b=\\lim(f(x)-kx)$。 由渐近展开求：通过保留 $x$ 因子，剩下改成 $1/x$，写成 $f(x)/x=1+b/x+\\omicron(x)\\,(x\\to\\infty)$。 无穷和阶\n无穷大小量的表示的定义与初步性质 通过不等式避免除以 $0$。 证明对称性和传递性。 手动展开的方法 $1/(1-x)$：递归 $\\e^x,\\ln(1+x)$ 前几项：直接求极限，利用 $f(2h)-f(h)$ 可以展更多，展到 $x^3$ 项 $(1+x)^{m/n}$：$(1+y)^n=(1+x)^m$，利用 $f+\\omicron(f)=G+\\omicron(g)$ 定理 等价无穷小量替换 注意那个著名反例（$x^2\\sin1/x$） 导数\n导数和微分的定义 注意闭区间上可微，要求端点单侧可导。 导数的运算法则 求导的技巧 对于一些复杂导数的定性分析问题，可以写出“导数一定形如关于某些东西的多项式”，而不求出具体的解析式系数。 导数的应用\n导数在几何与物理中的应用\n切线。注意非正则光滑曲线的切线可能会爆。\n曲率。计算方法 1：求法线交点的极限。计算方法 2：$\\frac{[\\arctan(y/x)]^\\prime}{\\sqrt{{x^\\prime}^2+{y^\\prime}^2}}$ $$ \\kappa=\\left\\lvert\\frac1r\\right\\rvert=\\frac{\\left\\lvert x^\\prime(t)y^{\\prime\\prime}(t)-x^{\\prime\\prime}(t)y^\\prime(t)\\right\\rvert}{\\left[(x^\\prime(t))^2+(y^\\prime(t))^2\\right]^{3/2}} $$ 曲率中心： $$ \\left(x(t)-y^\\prime(t)\\frac{(x^\\prime(t))^2+(y^\\prime(t))^2}{x^\\prime(t)y^{\\prime\\prime}(t)-x^{\\prime\\prime}(t)y^\\prime(t)},y(t)+x^\\prime(t)\\frac{(x^\\prime(t))^2+(y^\\prime(t))^2}{x^\\prime(t)y^{\\prime\\prime}(t)-x^{\\prime\\prime}(t)y^\\prime(t)}\\right) $$\n微分中值定理\n一般的罗尔定理、柯西中值定理、拉格朗日中值定理，注意要在闭区间上连续（左端点右连续，右端点左连续），在开区间上可导，$\\xi\\in$ 开区间。柯西中值定理要求 $g^\\prime\\not\\equiv0$，也就是说 $g$ 严增或严减。\n广义柯西中值定理：$f$、$g$ 在 $(a,b)$ 上可导（$a,b$ 甚至可以是无穷），不要求 $g^\\prime\\ne 0$；$\\exists\\xi\\in(a,b)$ 使得 $$ f^\\prime(\\xi)\\left(\\lim_{x\\to b^-}g(x)-\\lim_{x\\to a^+}g(x)\\right)=g^\\prime(\\xi)\\left(\\lim_{x\\to b^-}f(x)-\\lim_{x\\to a^+}f(x)\\right) $$\n达布定理：导数的介值性。证明考虑利用最值定理找导数为 $0$ 的点（先否定端点是最值点）。也就是说，导数只能有震荡间断点。\n导数与图像的关系\n最值\n极值点处，导数不存在或等于 $0$。反之不一定成立。 如果 $\\exists n\\in\\N_+$，$f$ 在 $x_0$ 处的 $1\\sim 2n-1$ 阶导均为 $0$，且 $2n$ 阶导为正/负，则 $x_0$ 处是严格极小/大值点。证明考虑归纳，利用二阶导是个极值点推回。 有可能无法通过任何阶导判断极值点。 单调性\n开区间还是闭区间无所谓。\n单点的导数不能说明任何单调性，必须是区间。反例：$f(x)=\\begin{cases}x+2x^2\\sin(1/x),\u0026amp;x\\ne0\\\\ 0,\u0026amp;x=0\\end{cases}$\n如果区间上导数恒正，则严格单增；如果恒非负，则单增。严格单增的充要条件是，任意子区间内导数不恒为 $0$。证明，拓展。严格单增并不意味着导数非 $0$，反例：$x^{2n}$。\n如果 $\\exists n\\in\\N_+$，$f$ 在 $x_0$ 处的 $1\\sim 2n$ 阶导均为 $0$，且 $2n+1$ 阶导为正/负，则 $x_0$ 附近严格单增/减，也就是说一阶和三阶及以上在这里是不一样的。证明考虑归纳，用上面那个说明一阶导是极值点。\n高阶导均为 $0$ 不能说明单调性。单调：$f(x)=\\begin{cases}\\e^{-1/x^2},\u0026amp;x\\ne0\\\\ 0,\u0026amp;x=0\\end{cases}$；不单调：$f(x)=\\begin{cases}\\e^{-1/|x|}(0.1+\\sin^2(1/x)),\u0026amp;x\\ne0\\\\ 0,\u0026amp;x=0\\end{cases}$\n连续性\n连续可能处处不可导：Weierstrass 函数。 单点可导要求单点连续。 单点连续不说明邻域连续。$xD(x)$ 单点可导不说明邻域连续。$x^2D(x)$ 区间可导不说明导数连续。$f(x)=\\begin{cases}x^2\\sin(1/x),\u0026amp;x\\ne0\\\\ 0,\u0026amp;x=0\\end{cases}$ 连续且趋近于单点的导数极限存在说明单点导数存在且等于导数极限。 两个达布函数（有介值性的）函数之和不一定是达布函数。$\\pm \\sin(1/x)$，$0$ 处取 $\\pm 1$。 达布函数可能处处不连续：Conway base 13 function。 凸性\n定义：琴森不等式。一阶导（严）单增/减 $\\Leftrightarrow$（严）下/上凸，二阶导非负/正 $\\Leftrightarrow$ 下/上凸。\n不等式语言与导数语言的转化：$f^\\prime_-(x_0)\\le f^\\prime_+(x_0)\\le f^\\prime_-(x\u0026gt;x_0)$。\n一阶导严单当且仅当严凸，二阶导恒正则严凸，但严凸不一定二阶导非零。\n相关不等式：\nJensen Information Hölder Minkowski Young 洛必达法则与泰勒公式\n注意洛必达要求 $g^\\prime(x)\\ne0$。 泰勒公式的皮亚诺余项形式只要求单点 $n$ 阶可导，拉格朗日余项形式必须在 $[x_0,x]$ 连续，$[x_0,x)$ $n+1$ 阶可导。 泰勒多项式唯一。 注意只有在满足可导条件下说泰勒多项式才有意义。 有些情况下在某一阶之后就没法展了，比如 $x^{非整数}$。 不定积分 第二类换元法要保证 $x=u(t)$ 的值域要包含原被积函数的定义域，在 $u(t)$ 整体反函数多值时，要指出 $t$ 的取值。\n分部积分有一个很简单的几何直观。\n特定的积分：\n$$ \\int\\frac{\\d x}{x^2\\pm a^2} $$\n部分分式 $$ \\frac{1}{x^2\\pm a^2}=\\frac{1}{2\\sqrt{\\pm a}}\\left(\\frac{1}{x-\\sqrt{\\pm a}}-\\frac{1}{x+\\sqrt{\\pm a}}\\right) $$ 或换元 $+:a\\tan t$，$-:a\\tanh t,a\\coth t$ $$ \\int\\frac{\\d x}{x^2+a^2}=\\frac1a\\arctan\\frac xa+C $$\n$$ \\int\\frac{\\d x}{a^2-x^2}=\\left\\{\\begin{aligned}\u0026amp;\\frac1a\\arctanh\\frac xa+C,\u0026amp;|x|\u0026lt;a\\\\ \u0026amp;\\frac1a\\arccoth\\frac xa+C,\u0026amp;|x|\u0026gt;a\\end{aligned}\\right.=\\frac1{2a}\\ln\\left\\lvert\\frac{a+x}{a-x}\\right\\rvert+C $$\n$$ \\int\\frac{\\d x}{\\sqrt{\\pm x^2\\pm a^2}} $$\n换元 $+a^2:a\\tan t,a\\sinh t$，$-a^2:a\\sec t,a\\cosh t$，$a^2-:a\\sin t$ $$ \\int\\frac{\\d x}{\\sqrt{x^2+a^2}}=\\arcsinh\\frac xa+C=\\ln\\left(x+\\sqrt{x^2+a^2}\\right)+C $$\n$$ \\int\\frac{\\d x}{\\sqrt{x^2-a^2}}=\\sgn(x)\\arccosh\\left\\lvert\\frac xa\\right\\rvert+C=\\ln\\left\\lvert x+\\sqrt{x^2-a^2}\\right\\rvert+C $$\n$$ \\int\\frac{\\d x}{\\sqrt{a^2-x^2}}=\\arcsin\\frac xa+C $$\n$$ \\int\\frac{\\d x}{x\\sqrt{\\pm x^2\\pm a^2}} $$\n换元 $+a^2:a\\tan t,a\\csch t$，$-a^2:a\\sec t$，$a^2-:a\\sin t$ $$ \\int\\frac{\\d x}{x\\sqrt{x^2+a^2}}=-\\frac1a\\arccsch\\left\\lvert\\frac xa\\right\\rvert+C=-\\frac1a\\ln\\left\\lvert\\frac{a+\\sqrt{x^2+a^2}}{x}\\right\\rvert+C $$\n$$ \\int\\frac{\\d x}{x\\sqrt{x^2-a^2}}=\\frac1a\\arcsec\\left\\lvert\\frac xa\\right\\rvert+C $$\n$$ \\int\\frac{\\d x}{x\\sqrt{a^2-x^2}}=-\\frac1a\\arcsech\\left\\lvert\\frac xa\\right\\rvert+C=-\\frac1a\\ln\\left\\lvert\\frac{a+\\sqrt{x^2-a^2}}{x}\\right\\rvert+C $$\n$$ \\int\\sqrt{\\pm x^2\\pm a^2}\\d x $$\n分部积分 $$ \\int\\sqrt{\\pm x^2\\pm a^2}\\d x=x\\sqrt{\\pm x^2\\pm a^2}-\\int\\frac{\\pm x^2\\d x}{\\sqrt{\\pm x^2\\pm a^2}}=x\\sqrt{\\pm x^2\\pm a^2}-\\int\\sqrt{\\pm x^2\\pm a^2}\\d x\\pm\\int\\frac{a^2\\d x}{\\sqrt{\\pm x^2\\pm a^2}} $$ 或换元 $+a^2:a\\tan t$，$-a^2:a\\sec t$，$a^2-:a\\sin t$ $$ \\int\\sqrt{*}\\d x=\\frac12\\left(x\\sqrt{*}\\pm a^2\\int\\frac{\\d x}{\\sqrt{*}}\\right) $$ 其中 $-a^2$ 取负，其余取正。\n$$ \\int x^n\\e^{kx}\\d x $$\n反复分部积分 $$ \\int x^n\\e^{kx}\\d x=\\e^{kx}\\sum_{i=0}^{n}\\frac{(-1)^in^{\\underline{i}}}{k^{i+1}}x^{n-i}+C $$\n$$ \\int x^n\\ln^kx\\d x $$\n反复分部积分 $$ \\int x^n\\ln^kx\\d x=x^{n+1}\\sum_{i=0}^n\\frac{(-1)^ik^{\\underline{i}}}{(n+1)^{i+1}}\\ln^{k-i}x+C $$\n$$ \\int\\frac{\\d x}{(a^2\\pm x^2)^n} $$\n分部积分递推 $$ \\begin{align*} \\int\\frac{\\d x}{(a^2\\pm x^2)^n}\u0026amp;=\\frac{1}{a^2}\\left[\\int\\frac{(a^2\\pm x^2)\\d x}{(a^2\\pm x^2)^n}\\mp\\int\\frac{x^2\\d x}{(a^2\\pm x^2)^n}\\right]\\\\ \u0026amp;=\\frac{1}{a^2}\\left[\\int\\frac{\\d x}{(a^2\\pm x^2)^{n-1}}+\\frac{1}{2(n-1)}\\int x\\d\\frac{1}{(a^2\\pm x^2)^{n-1}}\\right]\\\\ \u0026amp;=\\frac{1}{a^2}\\left[\\int\\frac{\\d x}{(a^2\\pm x^2)^{n-1}}+\\frac{x}{2(n-1)(a^2\\pm x^2)^{n-1}}-\\frac{1}{2(n-1)}\\int\\frac{\\d x}{(a^2\\pm x^2)^{n-1}}\\right]\\\\ \\Longrightarrow a^2I_n\u0026amp;=\\left[1-\\frac{1}{2(n-1)}\\right]I_{n-1}+\\frac{x}{2(n-1)(a^2\\pm x^2)^{n-1}} \\end{align*} $$ 或部分分式分解 $$ \\frac{1}{(a^2-x^2)^n}=\\sum_{i=1}^n\\frac{\\binom{2n-i-1}{n-1}}{(2a)^{2n-i}}\\left[\\frac{1}{(a+x)^i}+\\frac{1}{(a-x)^i}\\right] $$\n$$ \\int\\frac{\\d x}{(a^2-x^2)^n}=\\frac{\\binom{2n-2}{n-1}}{(2a)^{2n-1}}\\ln\\left\\lvert\\frac{a+x}{a-x}\\right\\rvert+\\sum_{i=1}^{n-1}\\frac{\\binom{2n-i-2}{n-1}}{i(2a)^{2n-i-1}}\\left[\\frac{1}{(a-x)^i}-\\frac{1}{(a+x)^i}\\right]+C $$\n$$ \\int\\sin^nx\\cos^mx\\d x $$\n分部积分递推（点火公式） $$ \\begin{align*} \\int\\sin^nx\\cos^mx\\d x \u0026amp;=\\int\\sin^nx\\cos^{m-1}x\\d\\sin x\\\\ \u0026amp;=\\sin^{n+1}x\\cos^{m-1}x-\\int\\sin x\\left[n\\sin^{n-1}x\\cos^mx-(m-1)\\sin^{n+1}x\\cos^{m-2}x\\right]\\d x\\\\ \u0026amp;=\\sin^{n+1}x\\cos^{m-1}x-(n+m-1)\\int\\sin^nx\\cos^mx\\d x+(m-1)\\int\\sin^nx\\cos^{m-2}x\\d x\\\\ \\Longrightarrow I_{n,m}\u0026amp;=\\frac{1}{n+m}\\left[\\sin^{n+1}x\\cos^{m-1}x+(m-1)I_{n,m-2}\\right] \\end{align*} $$\n当 $n,m$ 有一个是奇数时换元 $$ \\int\\sin^nx\\cos^mx\\d x=\\int\\sin^nx\\left(1-\\sin^2x\\right)^{(m-1)/2}\\d\\sin x=\\int t^n\\left(1-t^2\\right)^{(m-1)/2}\\d t $$ 都是偶数时只能用二倍角公式归约为 $\\cos 2x$ 的多项式。\n欧拉公式秒了！\n$$ \\int\\tan^nx\\d x $$\n凑换元递推 $$ \\int\\tan^nx\\d x=\\int\\tan^{n-2}\\sec^2x\\d x-\\int\\tan^{n-2}x\\d x=\\frac{\\tan^{n-1}x}{n-1}-\\int\\tan^{n-2}x\\d x $$ 或直接换元 $$ \\int\\tan^nx\\d x\\xlongequal{t=\\tan x}\\int\\frac{t^n\\d t}{1+t^2}= \\sum_{i=1}^{n/2}\\frac{(-1)^{i-1}\\tan^{n-2i+1}x}{n-2i+1}+ \\left\\{\\begin{aligned} \u0026amp;x,\u0026amp;2\\mid n\\\\ \u0026amp;\\ln\\lvert\\sec x\\rvert,\u0026amp;2\\nmid n \\end{aligned}\\right. +C $$\n$$ \\int\\sec^nx\\d x $$\n分部积分递推 $$ \\int\\sec^nx\\d x=\\int\\sec^{n-2}x\\d\\tan x=\\sec^{n-2}x\\tan x-\\int(n-2)\\sec^{n-2}x(\\sec^2x-1)\\d x $$ 或直接换元 $$ \\int\\sec^{2n}x\\d x=\\int\\sec^{2n-2}x\\d\\tan x=\\int(1+t^2)^{n-1}\\d t $$\n$$ \\int\\sec^{2n-1}x\\d x=\\int\\frac{\\d\\sin x}{\\cos^{2n}x}=\\int\\frac{\\d t}{(1-t^2)^n} $$\n$$ \\int\\e^x\\sin^nx\\d x $$\n有理函数（参考），复数法的本质是扩展变成复变解析函数，相关的求导公式形式与实变函数类似。\n首先把复根全部搞出来，分母不要留二次项。考虑确定以下系数： $$ f(x)=\\frac{P(x)}{(x-x_0)^kQ(x)}=\\sum_{i=1}^k\\frac{A_i}{(x-x_0)^i}+R(x) $$ 其中 $(x-x_0)\\nmid Q(x)$。\n两边同乘 $(x-x_0)^k$，然后不断求导，代入 $x=x_0$，可得 $$ A_i=\\frac{1}{(k-i)!}\\left.\\left[\\frac{P(x)}{Q(x)}\\right]^{k-i}\\right|_{x=x_0} $$ 如果有复根，我们知道它们一定是一对对的。容易证明在 $f$ 的系数是实数时，$(x-z_0)^{-i}$ 与 $(x-\\overline{z_0})^{-i}$ 的系数是共轭的。\n对于 $i=1$ 的部分，积出 $$ \\begin{align*} \u0026amp;(c+\\i d)\\ln(x-a-\\i b)+(c-\\i d)\\ln(x-a+\\i b)\\\\ ={}\u0026amp;(c+\\i d)\\left[\\ln\\sqrt{(x-a)^2+b^2}+\\i\\arg(x-a-\\i b)\\right]+(c-\\i d)\\left[\\ln\\sqrt{(x-a)^2+b^2}+\\i\\arg(x-a+\\i b)\\right]+C\\\\ ={}\u0026amp;c\\ln\\left(x^2-2ax+a^2+b^2\\right)+2d\\arctan\\frac{b}{x-a}+C \\end{align*} $$ 注意到 $\\arctan t=\\arctan(-1/t)+C$。\n对于 $i\u0026gt;1$ 的部分，就全是分式了 $$ \\begin{align*} \u0026amp;-\\frac{1}{i-1}\\left[\\frac{c+\\i d}{(x-a-\\i b)^{i-1}}+\\frac{c-\\i d}{(x-a+\\i b)^{i-1}}\\right]\\\\ ={}\u0026amp;-\\frac{2}{(i-1)(x^2-2ax+a^2+b^2)^{i-1}}\\left[c\\sum_{j=0}^{\\lceil i/2\\rceil-1}\\binom{i-1}{2j}(-1)^jb^{2j}(x-a)^{i-1-2j}-d\\sum_{j=0}^{\\lfloor i/2\\rfloor-1}\\binom{i-1}{2j+1}(-1)^jb^{2j+1}(x-a)^{i-2-2j}\\right] \\end{align*} $$\n$$ \\int\\frac{\\d x}{x^n+1} $$\n直接部分分式分解。取 $\\omega$ 为 $2n$ 次单位根 $\\e^{\\i\\pi/n}$。 $$ \\begin{align*} \u0026amp;\\int\\frac{\\d x}{x^n+1}\\\\ ={}\u0026amp;\\int\\frac{\\d x}{\\displaystyle\\prod_{k=0}^{n-1}\\left(x-\\omega^{2k+1}\\right)}\\\\ ={}\u0026amp;\\int\\d x\\sum_{k=0}^{n-1}\\frac{\\displaystyle\\lim_{x\\to\\omega^{2k+1}}\\frac{x-\\omega^{2k+1}}{x^n+1}}{x-\\omega^{2k+1}}\\\\ \\xlongequal{\\rm l\u0026rsquo;H}{}\u0026amp;\\int\\d x\\sum_{k=0}^{n-1}\\frac{\\displaystyle\\frac{1}{n\\omega^{(n-1)(2k+1)}}}{x-\\omega^{2k+1}}\\\\ ={}\u0026amp;-\\frac1n\\int\\d x\\sum_{k=0}^{n-1}\\frac{\\omega^{2k+1}}{x-\\omega^{2k+1}}\\\\ ={}\u0026amp;-\\frac1n\\sum_{k=0}^{n-1}\\omega^{2k+1}\\ln(x-\\omega^{2k+1})+C\\\\ ={}\u0026amp;-\\frac1n\\sum_{k=0}^{n-1}\\left(\\cos\\frac{(2k+1)\\pi}{n}+\\i\\sin\\frac{(2k+1)\\pi}{n}\\right)\\left(\\ln\\sqrt{x^2-2x\\cos\\frac{(2k+1)\\pi}{n}+1}+\\i\\arg\\left(x-\\cos\\frac{(2k+1)\\pi}{n}-\\i\\sin\\frac{(2k+1)\\pi}{n}\\right)\\right)+C\\\\ ={}\u0026amp;-\\frac1n\\sum_{k=0}^{n-1}\\left[\\frac12\\cos\\frac{(2k+1)\\pi}{n}\\ln\\left(x^2-2x\\cos\\frac{(2k+1)\\pi}{n}+1\\right)+\\sin\\frac{(2k+1)\\pi}{n}\\arctan\\frac{\\displaystyle\\cos\\frac{(2k+1)\\pi}{n}-x}{\\displaystyle\\sin\\frac{(2k+1)\\pi}{n}}\\right]+C \\end{align*} $$\n二项式微分的积分（$m,n,p\\in\\mathbb Q$） $$ \\int x^m(a+bx^n)^p\\d x $$ 有初等表示当且仅当 $p$、$(m+1)/n$、$p+(m+1)/n$ 中有一个是整数。\n$p$ 为负整数的情况，取 $l$ 为 $m$、$n$ 分母的 $\\operatorname{lcm}$： $$ \\int x^m(a+bx^n)^p\\d x\\xlongequal{x=t^l}k\\int t^{ml+k-1}(a+bt^{nl})^p\\d t $$ $(m+1)/n$ 为整数的情况： $$ \\int x^m(a+bx^n)^p\\d x\\xlongequal{t=a+bx^n}\\frac1n\\int t^p\\left(\\frac{t-a}{b}\\right)^{\\frac{m+1}{n}-1}\\d t $$ $p+(m+1)/n$ 为整数的情况： $$ \\int x^m(a+bx^n)^p\\d x=\\int x^{m+np}(ax^{-n}+b)^p\\d x $$\n$$ \\int\\frac{\\d x}{\\sqrt[n]{1+x^n}} $$\n这个复合上面第三种形式，但是如果直接换元 $t^n=x^{-n}+1$，会要开 $n$ 次根导致一些正负号很烦的问题。所以这里有个换元（来源）： $$ \\int\\frac{\\d x}{\\sqrt[n]{1+x^n}}\\xlongequal[\\d t=\\frac{t-t^{n-1}}{x}\\d x]{t=\\frac{x}{\\sqrt[n]{1+x^n}}}\\int\\frac{\\d t}{1-t^n} $$\n复杂根分式积分：https://zhuanlan.zhihu.com/p/559773120\n$$ \\int\\sqrt{\\tan x}\\d x $$ 直接换元，剩下的分式有比直接部分分式分解简单点的方法。 $$ \\begin{align*} \\int\\sqrt{\\tan x}\\d x \u0026amp;\\xlongequal{t=\\sqrt{\\tan x}}\\int\\frac{2t^2}{1+t^4}\\d t\\\\ \u0026amp;=2\\int\\frac{\\d t}{t^2+t^{-2}}\\\\ \u0026amp;=\\int\\frac{1-t^{-2}+1+t^{-2}}{t^2+t^{-2}}\\d t\\\\ \u0026amp;=\\int\\frac{1-t^{-2}}{(t+t^{-1})^2-2}\\d t+\\int\\frac{1+t^{-2}}{(t-t^{-1})^2+2}\\d t\\\\ \u0026amp;\\xlongequal[v=t-t^{-1}]{u=t+t^{-1}}\\int\\frac{\\d u}{u^2-2}+\\int\\frac{\\d v}{v^2+2}\\\\ \u0026amp;=\\frac1{2\\sqrt2}\\ln\\frac{u-\\sqrt2}{u+\\sqrt2}+\\frac1{\\sqrt2}\\arctan\\frac v{\\sqrt2}+C\\\\ \u0026amp;=\\frac1{2\\sqrt2}\\ln\\frac{t^2-\\sqrt2t+1}{t^2+\\sqrt2t+1}+\\frac1{\\sqrt2}\\arctan\\frac{t^2-1}{\\sqrt2t}+C\\\\ \u0026amp;=\\frac1{2\\sqrt2}\\ln\\frac{\\tan x-\\sqrt{2\\tan x}+1}{\\tan x+\\sqrt{2\\tan x}+1}+\\frac1{\\sqrt2}\\arctan\\frac{\\tan x-1}{\\sqrt{2\\tan x}}+C \\end{align*} $$ 注意 $\\sqrt{\\sin x}$ 是积不了的。\n定积分 点火公式用的很多，这里先写一下。 $$ \\int_0^{\\pi/2}\\sin^n x\\d x=\\left.-\\sin^{n-1}x\\cos x\\right|_0^{\\pi/2}+(n-1)\\int_0^{\\pi/2}\\cos^2x\\sin^{n-2}x\\d x=(n-1)\\int_0^{\\pi/2}\\sin^{n-2}x\\d x-(n-1)\\int_0^{\\pi/2}\\sin^nx\\d x $$ 于是 $I_n=\\frac{n-1}{n}I_{n-2}$，然后 $I_0=\\pi/2$，$I_1=1$。$I_2=\\frac12\\frac\\pi2=\\frac\\pi4$，$I_3=\\frac23$，$I_4=\\frac34\\frac\\pi4=\\frac{3\\pi}{16}$，$I_5=\\frac45\\frac23=\\frac8{15}$。$I_{2n}=\\frac{(2n-1)!!}{(2n)!!}\\frac\\pi2$，$I_{2n+1}=\\frac{(2n)!!}{(2n+1)!!}$。同理可以得出 $$ \\int_0^{\\pi/2}\\sin^nx\\cos^mx\\d x=\\frac{(n-1)!!(m-1)!!}{(n+m)!!}\\cdot\\left\\{\\begin{aligned}\u0026amp;\\frac\\pi2,\u0026amp;2\\mid n\\land 2\\mid m\\\\ \u0026amp;1,\u0026amp;\\text{otherwise}\\end{aligned}\\right. $$\n定积分的基本性质：拼区间、反向、线性性、保序性。\n微积分基本定理。\n内容： 若被积函数可积，则积分上限函数连续。 若被积函数连续，则积分上限函数可导且导数对应相等。于是就是原函数，从而原函数两点的差就是被积函数两点间的积分。 若原函数的导数可积，则原函数两点的差就是导数两点间的积分。 注意：$\\int_a^bf(x)\\d x=F(b)-F(a)$ 仅在 $\\forall x\\in[a,b]$，$F^\\prime(x)=f(x)$ 时可以用，但凡有一个间断点就不行。 证明 1：考虑 $g(t)=\\int_a^tf(x)\\d x-(F(t)-F(a))$，这个函数连续（因为它可导且导数处处为零）。如果它不是处处为零，就能找到导数非零的点。\n证明 2：$F(b)-F(a)=\\sum(F(x_i)-F(x_{i-1}))=\\sum F^\\prime(\\xi_i)(x_i-x_{i-1})=S(F^\\prime,P,\\xi)\\to\\int_a^bF^\\prime(x)\\d x$。 注意：积分上限函数的导数不一定是被积函数（可去间断点消失、跳跃间断点不可导、震荡间断点不确定）；一个函数的导数不一定可积，反例：https://en.wikipedia.org/wiki/Volterra%27s_function。 定积分换元，课内的使用条件是被积函数连续，换元函数的导数可积。如果换元函数的导数连续只需对换元前后的积分上限函数求导即可，如果导数不连续要一板一眼地用牛—莱证。课外（Kestelman）最松的条件是被积函数可积，换元函数是积分上限函数。\n积分第一中值定理。使用条件：$f$ 在闭区间上连续，$g$（权重函数）可积且恒非负。$\\xi$ 可以 $\\in(a,b)$，需要讨论一下边界。\n记忆方法： $$ \\begin{align*} \u0026amp;f(\\xi)=\\frac{\\int_a^bf(x)g(x)\\d x}{\\int_a^bg(x)\\d x}\\\\ \u0026amp;\\frac{F^\\prime(\\xi)}{G^\\prime(\\xi)}=\\frac{F(b)-F(a)}{G(b)-G(a)}\\\\ \u0026amp;F\\leftrightarrow f\\cdot g,\\,G\\leftrightarrow g \\end{align*} $$\n积分余项泰勒公式，证明思路反复分部积分。这里可以进行对比记忆：\n皮亚诺余项，只需单点 $n$ 阶可导，余项给得最不精确； 拉格朗日余项，需要区间 $n+1$ 阶可导，余项给得精确些，但 $\\xi$ 未知； 积分余项，需要区间 $n+1$ 阶导数可积，给出确定可以计算的余项。 积分余项与拉格朗日余项的关系可以根据积分中值定理得出： $$ \\int_{x_0}^x\\frac{f^{(n+1)}(t)}{n!}(x-t)^n\\d t=\\frac{f^{(n+1)}(\\xi)}{n!}\\int_{x_0}^x(x-t)^n\\d t=\\frac{f^{(n+1)}(\\xi)}{(n+1)!}(x-x_0)^{n+1} $$ 关于这个有一个很有意思的关系，就是当你试图求一个函数的 $n$ 阶原函数时，你求的是 $$ \\begin{align*} F(x)\u0026amp;=\\int_a^x\\d x_1\\left(\\int_a^{x_1}\\d x_2\\left(\\int_a^{x_2}\\d x_3\\left(\\cdots\\left(\\int_a^{x_{n-1}}f(x_n)\\d x_n+C_n\\right)\\cdots\\right)+C_3\\right)+C_2\\right)+C_1\\\\ \u0026amp;=\\int_a^x\\d x_1\\int_a^{x_1}\\d x_2\\int_a^{x_2}\\d x_3\\cdots\\int_a^{x_{n-1}}f(x_n)\\d x_n+C_n^\\prime x^{n-1}+\\cdots+C_3^\\prime x^2+C_2^\\prime x+C_1 \\end{align*} $$ 而 $$ \\begin{align*} \u0026amp;\\int_a^x\\d x_1\\int_a^{x_1}\\d x_2\\int_a^{x_2}\\d x_3\\cdots\\int_a^{x_{n-2}}\\d x_{n-1}\\int_a^{x_{n-1}}f(x_n)\\d x_n\\\\ ={}\u0026amp;\\left.\\left(x_1\\int_a^{x_1}\\d x_2\\int_a^{x_2}\\d x_3\\cdot\\int_a^{x_{n-1}}f(x_n)\\d x_n\\right)\\right|_a^x-\\int_a^xx_1\\d x_1\\int_a^{x_1}\\d x_3\\cdots\\int_a^{x_{n-1}}f(x_n)\\d x_n\\\\ ={}\u0026amp;\\int_a^x(x-x_1)\\d x_1\\int_a^{x_1}\\d x_3\\cdots\\int_a^{x_{n-1}}f(x_n)\\d x_n\\\\ ={}\u0026amp;{-\\frac12}\\int_a^x\\d(x-x_1)^2\\int_a^{x_1}\\d x_3\\cdots\\int_a^{x_{n-1}}f(x_n)\\d x_n\\\\ ={}\u0026amp;{-\\frac12}\\left.\\left[(x-x_1)^2\\int_a^{x_1}\\d x_3\\cdots\\int_a^{x_{n-1}}f(x_n)\\d x_n\\right]\\right|_a^x+\\frac12\\int_a^x(x-x_1)^2\\d x_1\\int_a^{x_1}\\d x_4\\cdots\\int_a^{x_{n-1}}f(x_n)\\d x_n\\\\ ={}\u0026amp;\\frac12\\int_a^x(x-x_1)^2\\d x_1\\int_a^{x_1}\\d x_4\\cdots\\int_a^{x_{n-1}}f(x_n)\\d x_n\\\\ ={}\u0026amp;{-\\frac16}\\int_a^x\\d(x-x_1)^3\\int_a^{x_1}\\d x_4\\cdots\\int_a^{x_{n-1}}f(x_n)\\d x_n\\\\ ={}\u0026amp;\\frac16\\int_a^x(x-x_1)^3\\d x_1\\int_a^{x_1}\\d x_5\\cdots\\int_a^{x_{n-1}}f(x_n)\\d x_n\\\\ ={}\u0026amp;\\cdots\\ \\cdots\\\\ ={}\u0026amp;\\frac{1}{(n-1)!}\\int_a^x(x-x_1)^{n-1}f(x_1)\\d x_1 \\end{align*} $$ 也就是说你得到了一个将 $n$ 个积分号缩成一个积分号的方法，而且为啥最后的结果跟柯西余项这么像呢？你考虑在 $x=a$ 处展开这个 $F$（忽略尾部多项式），你发现，刚好它 $0\\sim n-1$ 阶导都是 $0$。\n误差估计。对于取平均长的小段并进行左/右/中端高矩形、梯形、二次函数拟合的方法，分析误差的思路是泰勒展开。辛普森公式。推广情况：Newton-Cotes 公式。\nCauchy-Schwartz 不等式。一个与用 $\\Delta$ 等价的方法是，（配方）找到取最低点的 $t$。\n定积分求面积。课上讲了一些和拓扑相关的简单东西，略。主要提两点：\n将曲线（参数方程）分段成函数的方法：取所有竖切线。\n参数方程定义的曲线（自然正向）的面积： $$ S=-\\int y\\d x=\\int x\\d y=\\frac12\\int(x\\d y-y\\d x)=\\frac12\\int\\b r\\times\\d\\b r=\\frac12\\int r^2\\d\\theta $$ 前两个的思路就是用横/竖切线把区间分段函数化套用正常的定积分，叉乘这个相信会计算凸包面积的小朋友们一定不陌生。\n我们可以证明积分式与参数的选择、与坐标系的选择无关，即在平移、旋转变换下为不变量。\n定积分求长度啥的。就是说，你在近似 + 无限小划分的过程中，关键的一点是，你取的端点必须在线上，不然就会导致 $\\sqrt 2=2$、$\\pi=4$、球表面积算错等情况。至于勾股定理，实际上它是个公理。\n另外讲了个重参数化，大概就是将自变量从任意的 $t$ 变成弧长 $t^\\prime=l$，让 $|\\d\\b x/\\d t^\\prime|=1$。这个鬼玩意可以用来定义三角函数。于是现在我们有三种严格定义三角函数的方法：公理法、弧长法和无穷级数法。\n曲线相关（拓展），细节太多了，略。\n一些应用的公式：\n曲率，弧长参数下表达式很简单，$\\kappa(l)=|\\widetilde{\\b x}^{\\prime\\prime}(l)|$。一般参数可以通过链式求导法则： $$ \\widetilde{\\b x}^{\\prime\\prime}(l)=[\\b x(t)]^{\\prime\\prime}_l=[\\b x^\\prime(t)t^\\prime(l)]^\\prime_l=\\left[\\frac{\\b x^\\prime(t)}{|\\b x^\\prime(t)|}\\right]^\\prime_l=\\frac{\\b x^{\\prime\\prime}(t)}{|\\b x^\\prime(t)|^2}-\\b x^\\prime(t)\\frac{[|\\b x^\\prime(t)|]^\\prime}{|\\b x^\\prime(t)|^3}=\\frac{\\b x^{\\prime\\prime}(t)}{|\\b x^\\prime(t)|^2}-\\b x^\\prime(t)\\frac{\\b x^\\prime(t)\\cdot\\b x^{\\prime\\prime}(t)}{|\\b x^\\prime(t)|^4} $$ 极坐标 $$ \\kappa=\\frac{\\left\\lvert 2{r^\\prime}^2-rr^{\\prime\\prime}+r^2\\right\\rvert}{\\left({r^\\prime}^2+r^2\\right)^{3/2}} $$\n弧长：\n正常函数 $$ \\int\\sqrt{1+\\left(\\frac{\\d y}{\\d x}\\right)^2}\\d x $$\n参数方程 $$ \\int\\sqrt{\\left(\\frac{\\d x}{\\d t}\\right)^2+\\left(\\frac{\\d y}{\\d t}\\right)^2}\\d t $$\n极坐标 $$ \\int\\sqrt{(\\d r)^2+(r\\d\\theta)^2} $$\n旋转体体积（绕 $x$ 轴）：\n正常函数 $$ \\pi\\int y^2\\d x $$\n参数方程（自然正向，即使有凹陷也行） $$ -\\pi\\int y^2\\frac{\\d x}{\\d t}\\d t=\\pi\\int x^2\\frac{\\d y}{\\d t}\\d t $$\n极坐标 $$ \\pi\\int y^2\\d x=\\pi\\int r^2\\sin^2\\theta(r\\sin\\theta\\d\\theta-\\cos\\theta\\d r) $$ 或（考虑用球近似每一个 $\\d\\theta$ 对应的体积贡献） $$ \\int_0^{\\pi}\\int_0^r2\\pi r\\sin\\theta\\cdot r\\d\\theta\\d r=\\frac{2\\pi}{3}\\int r^3\\sin\\theta\\d\\theta $$\n高维球的体积。设为 $V_n(r)=C_nr^n$。 $$ \\begin{align*} V_n(r)\u0026amp;=\\int_{-\\pi/2}^{\\pi/2} V_{n-1}(r\\cos\\theta)\\d(r\\sin\\theta)\\\\ \u0026amp;=C_{n-1}r^n\\int_{-\\pi/2}^{\\pi/2}\\cos^n\\theta\\d\\theta\\\\ \u0026amp;=(2+[2\\mid n](\\pi-2))\\frac{(n-1)!!}{n!!}C_{n-1}r^n\\\\ \u0026amp;=\\frac{2^{\\lceil n/2\\rceil}\\pi^{\\lfloor n/2\\rfloor}}{n!!}r^n \\end{align*} $$\n旋转体表面积（绕 $x$ 轴）（注意题目可能会要加上底面积！）：\n正常函数 $$ 2\\pi\\int y\\sqrt{1+\\left(\\frac{\\d y}{\\d x}\\right)^2}\\d x $$\n参数方程 $$ 2\\pi\\int y\\sqrt{\\left(\\frac{\\d x}{\\d t}\\right)^2+\\left(\\frac{\\d y}{\\d t}\\right)^2}\\d t $$\n极坐标 $$ 2\\pi\\int y\\sqrt{(\\d x)^2+(\\d y)^2}=2\\pi\\int r\\sin\\theta\\sqrt{(\\d r)^2+(r\\d\\theta)^2} $$\nPappus-Guldin 定理其实就是质心的定义。在线密度均匀时，质心为 $$ \\overline{y}=\\frac{\\int y\\d l}{\\int\\d l} $$ 而旋转体表面积为 $$ 2\\pi\\int y\\d l $$ 在面密度均匀时，质心的 $y$ 为 $$ \\overline{y}=\\frac{\\int y^2/2\\d x}{\\int y\\d x} $$ 而旋转体体积为 $$ \\pi\\int y^2\\d x $$\n注意一般而言，体积的导数不等于表面积，面积的导数不等于周长！\n有空补一下 $2t/(1+t^2)$ 的换元。\n广义积分 分析敛散性的手段：\n所有一般的定积分可用的处理手段都可以，包括四则运算、换元、分部积分、牛—莱（注意是单侧极限）。\n柯西\n比较，两种用法\n比较（极限形式）：$f=\\Omicron(g)$，\n如果 $g$ 绝对收敛，则 $f$ 绝对收敛；\n如果 $g$ 条件收敛，则得不出任何结论，如果 $g$ 恒非负，那就回到上一条。\n反例：$\\int_0^{+\\infty}\\frac{\\sin x}{\\sqrt x}\\d x$ 根据狄收敛，但 $\\int_0^{+\\infty}\\frac{\\sin x}{\\sqrt x+\\sin x}\\d x$ 不收敛。因为 $$ \\frac{\\sin x}{\\sqrt x}-\\frac{\\sin x}{\\sqrt{x}+\\sin x}=\\frac{\\sin^2x}{x+\\sqrt x\\sin x}\u0026gt;\\frac{\\sin^2x}{2x} $$ 而后者发散。但是这两个东西在 $x\\to+\\infty$ 时是等价无穷小。\n狄利克雷：$f$ 的积分上限函数有界，$g$ 单调且 $\\to 0$。如果不单调，反例就在楼上。证明（假定 $f$ 连续，$g$ 导数连续）： $$ \\int_a^{+\\infty}f(x)g(x)\\d x=\\lim_{x\\to+\\infty}F(x)g(x)-F(a)g(a)-\\int_a^{+\\infty}F(x)g^\\prime(x)\\d x $$ 其中 $F(x)g(x)\\to 0$，$\\int_a^{+\\infty}|F(x)g^\\prime(x)|\\d x\\le M\\int_a^{+\\infty}|g^\\prime(x)|\\d x=Mg(a)$。\n一般的证明见理论基础。\n阿贝尔：$f$ 的积分收敛（更强），$g$ 单调且有界（更弱）。证明就直接把 $\\lim g$ 拎出来就行。\n不单调的反例：$\\int_0^{+\\infty}\\left(\\frac{\\sin x}{\\sqrt x}\\right)^2$，单个这个玩意既是 $\\to 0$，又是积分收敛，但是 $\\int_0^{+\\infty}\\frac{\\sin^2x}{x}$ 用二倍角公式得是发散的。\n注意：无穷限积分收敛并不代表被积函数趋近于 $0$。\n特定的例子：\n$$ \\int_0^{+\\infty}\\frac{\\d x}{x^a\\ln^bx} $$\n首先注意一下定义域，下面就不提定义域的问题了。\n$x\\to+\\infty$：$a\u0026gt;1$ 时与 $x^{-(a+1)/2}$ 比较以去掉 $\\ln$，收敛；$a\u0026lt;1$ 时与 $x^{-1}$ 比较，发散。\n$x\\to 1$：比较去掉 $x^a$，比较把 $\\ln^bx$ 变成 $(x-1)^b$。$b\\ge 1$ 时发散，$b\u0026lt;1$ 时收敛。\n$x\\to 0^+$：关键是 $\\forall\\epsilon\u0026gt;0$，$\\lim_{x\\to0^+}x^\\epsilon\\ln^bx=0$。$a\u0026lt;1$ 时与 $x^{-(a+1)/2}$ 比较，收敛；$a\u0026gt;1$ 时与 $x^{-1}$ 比较，发散。这种情况还可以换元 $1/x$ 归约到 $x\\to+\\infty$。\n$a=1$：换元，$b\\ne 1$ 时不定积分为 $1/(b-1)\\ln^{b-1}x$，$b\u0026gt;1$ 时 $x\\to+\\infty$ 和 $x\\to 0^+$ 收敛，$x\\to 1$ 发散；$b\u0026lt;1$ 时 $x\\to 1$ 收敛，其余发散；$b=1$ 时是 $\\ln|\\ln x|$，全部发散。\n$a\u0026gt;1$ $a=1,b\u0026gt;1$ $a=1,b=1$ $a=1,b\u0026lt;1$ $a\u0026lt;1$ $x\\to+\\infty$ 收敛 收敛 发散 发散 发散 $x\\to1$ $\\rightarrow$ 发散 发散 收敛 $\\leftarrow$ $x\\to0^+$ 发散 收敛 发散 发散 收敛 记忆方法：$a=1$ 换元，$a\\ne 1$ 时 $x$ 是主要项。 $$ \\int_M^{+\\infty}\\frac{\\d x}{x^a\\cdot\\ln^bx\\cdot\\ln^c\\ln\\ln x\\cdot\\ln^d\\ln\\ln\\ln x\\cdot\\cdots} $$ 这样的情况就依次看，不断换元。\n$$ \\int_0^{+\\infty}\\frac{\\sin x}{x^a}\\d x $$\n$x\\to+\\infty$：$a\\le 0$ 用柯西，发散。$a\u0026gt;1$ 时放缩至 $x^{-a}$，绝对收敛；$0\u0026lt;a\\le 1$ 时， $$ \\int_1^{+\\infty}\\frac{\\sin x}{x^a}\\d x=\\left.-\\frac{\\cos x}{x^a}\\right|_1^{+\\infty}-a\\int_1^{+\\infty}\\frac{\\cos x}{x^{a+1}}\\d x $$ 两项都收敛。但是 $$ \\int_1^{+\\infty}\\left\\lvert\\frac{\\sin x}{x^a}\\right\\rvert\\d x\\ge\\int_1^{+\\infty}\\frac{\\sin^2x}{x^a}\\d x=\\int_1^{+\\infty}\\frac{1-\\cos 2x}{2x^a}\\d x=\\left.-\\frac{1}{2(a-1)}\\frac{1}{x^{a-1}}\\right|_1^{+\\infty}-\\frac12\\int_1^{+\\infty}\\frac{\\cos 2x}{x^a}\\d x $$ 前一项（$a=1$ 时是 $\\ln$）发散，后一项收敛，所以不绝对收敛。注意在实际考试时为保险起见，无论是四则运算还是分部积分，最好用柯西收敛准则的方式去说明。\n另一种证明思路是直接用狄利克雷说明 $a\u0026gt;0$ 时相对收敛。如果对于 $a\\le 0$ 收敛，那么由 $$ \\int_1^{+\\infty}\\sin x\\d x=\\int_1^{+\\infty}\\frac{\\sin x}{x^a}x^a\\d x $$ 由阿贝尔知 $\\sin x$ 的积分收敛，矛盾。说明 $a\u0026gt;0$ 时的绝对收敛性还有一种神奇的方法，考虑取 $|\\sin x|$ 的平均值 $2/\\pi$。由于 $$ \\left\\lvert\\int_0^A(|\\sin x|-2/\\pi)\\d x\\right\\rvert=\\left\\lvert\\int_0^{A\\bmod\\pi}(|\\sin x|-2/\\pi)\\d x\\right\\rvert\u0026lt;2 $$ 故由狄利克雷， $$ \\int_1^{+\\infty}\\frac{|\\sin x|-2/\\pi}{x^a}\\d x $$ 收敛。而 $\\int_1^{+\\infty}2\\d x/\\pi x^a$仅在 $a\u0026gt;1$ 时收敛。\n$x\\to0^+$：$\\sin x\\sim x$，所以 $a\\ge 2$ 时发散。\n$$ \\int_0^{+\\infty}\\frac{\\ln(1+x)}{x^a}\\d x $$\n$x\\to+\\infty$：$a\\le 1$ 时显然发散，$a\u0026gt;1$ 时与 $x^{-(1+a)/2}$ 比较，收敛。\n$x\\to 0^+$：$\\ln(1+x)\\sim x$，$a\\ge 2$ 时发散。\n因此 $a\\in(1,2)$ 时收敛。\n$$ \\int_0^{+\\infty}\\frac{\\sin x}{x^a+\\sin x}\\d x $$\n$x\\to+\\infty$：$a\u0026lt;0$ 时有无穷个间断点，但由于 $x^a$ 不是主项，故直接用柯即可，发散。$a=0$ 同。$a\u0026gt;0$ 时考虑依赖已知的结果： $$ \\frac{\\sin x}{x^a+\\sin x}=\\frac{\\sin x}{x^a}-\\frac{\\sin^2x}{x^a(x^a+\\sin x)} $$ 由于后面一项恒非负，故可以用比较的极限形式，$\\sim \\sin^2x/x^{2a}$。根据之前的分析，$a\\le 1/2$ 时发散，$a\u0026gt;1/2$ 时收敛。\n因此 $a\u0026gt;1$ 时绝对收敛，$1/2\u0026lt;a\\le 1$ 是前一项相对收敛，后一项绝对收敛，所以是相对收敛；$0\u0026lt;a\\le 1/2$ 时前一项相对收敛，后一项发散，所以是发散；$a\\le 0$ 时发散。\n$x\\to 0^+$：$a\u0026gt;1$ 时 $\\to 1$，$a=1$ 时 $\\to1/2$，$a\u0026lt;1$ 时 $\\to 0$，故不用管。\n超纲不定积分无初等表示积分：\n$$ \\int_0^{+\\infty}x^{a-1}\\e^{-x}\\d x $$\n$x\\to+\\infty$：与 $-\\e^{x/2}$ 比较，去掉 $x^{a-1}$，收敛。$x\\to 0$：$a\\le0$ 时发散。\n$\\Gamma$ 函数。递推公式： $$ \\Gamma(n)=\\int_0^{+\\infty}x^{n-1}\\e^{-x}\\d x=\\left.-x^{n-1}\\e^{-x}\\right|_0^{+\\infty}+(n-1)\\int_0^{+\\infty}x^{n-2}\\e^{-x}\\d x=(n-1)\\Gamma(n-1) $$ 余元公式：$\\frac{1}{\\Gamma(n)\\Gamma(1-n)}=\\frac{\\sin\\pi n}{\\pi}$。证明思路：写成 $\\Beta$ 函数后级数展开。\n推论：$\\Gamma\\big(\\frac12\\big)=\\sqrt\\pi$，也可以用高斯积分得到。\n$$ \\int_0^1x^{a-1}(1-x)^{b-1}\\d x $$\n$x\\to1^-$：$b\\le 0$ 时发散。$x\\to0^+$：$a\\le 0$ 时发散。\n$\\Beta$ 函数。递推公式：$\\Beta(n,m)=\\frac{m-1}{n+m-1}\\Beta(n,m-1)$。\n与 $\\Gamma$ 函数的关系：$\\Beta(n,m)=\\frac{\\Gamma(n)\\Gamma(m)}{\\Gamma(n+m)}$。证明思路：二重积分的换元。\n与三角函数的关系： $$ \\begin{align*} \\int_0^{\\pi/2}\\sin^nx\\cos^mx\\d x\u0026amp;\\xlongequal{t=\\sin^2x}\\int_0^1\\frac{t^{n/2}(1-t)^{m/2}}{2\\sin x\\cos x}\\d t\\\\ \u0026amp;=\\frac12\\int_0^1t^{(n-1)/2}(1-t)^{(m-1)/2}\\d t\\\\ \u0026amp;=\\frac12\\Beta\\left(\\frac{n+1}2,\\frac{m+1}2\\right) \\end{align*} $$ 所以我们又得到了一种神秘的说明 $\\Gamma(1/2)=\\sqrt{\\pi/2}$ 的方法。\n一个奇妙的关系： $$ \\begin{align*} \\int_0^{+\\infty}\\frac{\\d x}{1+x^n}\u0026amp;\\xlongequal{t=x^n}\\frac1n\\int_0^{+\\infty}\\frac{\\d t}{t^{1-\\frac1n}(1+t)}\\\\ \u0026amp;\\xlongequal{u=\\frac1{1+t}}\\frac1n\\int_0^1u^{-\\frac1n}(1-u)^{\\frac1n-1}\\d u\\\\ \u0026amp;=\\frac1n\\Beta\\left(1-\\frac1n,\\frac1n\\right)\\\\ \u0026amp;=\\frac1n\\Gamma\\left(1-\\frac1n\\right)\\Gamma\\left(\\frac1n\\right)\\\\ \u0026amp;=\\frac{\\pi}{n\\sin\\pi n} \\end{align*} $$\n$$ \\int_0^{+\\infty}\\frac{\\sin x}x\\d x $$\nDirichlet 积分，用费曼积分法。\n$$ \\int_0^{+\\infty}\\sin x^2\\d x $$\nFresnel 积分。收敛：换元 $t=x^2$ 变成 $\\sin t/2\\sqrt t$，套上面的。求的话要 Laplace 变换或转极坐标或留数。\n$$ \\int_0^{+\\infty}\\e^{-x^2}\\d x $$\nGauss 积分。收敛：同样换元。求可以用极坐标或其他二重积分方法。wxf 写了个不超纲的，借助点火公式的复杂方法，非常牛。\n不超纲不定积分无初等表示积分：\n$$ \\int_0^{+\\infty}\\frac{f(ax)-f(bx)}{x}\\d x $$\nFroullani 积分（$f$ 连续），考虑拆开定义证。 $$ \\begin{align*} \u0026amp;\\int_0^{+\\infty}\\frac{f(ax)-f(bx)}x\\d x\\\\ ={}\u0026amp;\\lim_{l\\to 0}\\lim_{r\\to+\\infty}\\int_l^r\\frac{f(ax)-f(bx)}x\\d x\\\\ ={}\u0026amp;\\lim_{l\\to 0}\\lim_{r\\to+\\infty}\\left(\\int_l^r\\frac{f(ax)}x\\d x-\\int_l^r\\frac{f(bx)}x\\d x\\right)\\\\ ={}\u0026amp;\\lim_{l\\to 0}\\lim_{r\\to+\\infty}\\left(\\int_{la}^{ra}\\frac{f(t)}t\\d t-\\int_{lb}^{rb}\\frac{f(t)}t\\d t\\right)\\\\ ={}\u0026amp;\\lim_{l\\to 0}\\lim_{r\\to+\\infty}\\left(\\int_{la}^{lb}\\frac{f(t)}t\\d t-\\int_{ra}^{rb}\\frac{f(t)}t\\d t\\right)\\\\ ={}\u0026amp;\\lim_{l\\to 0}\\lim_{r\\to+\\infty}\\left(f(\\xi_l)\\ln\\frac ba-f(\\xi_r)\\ln\\frac ba\\right)\\\\ ={}\u0026amp;\\left(\\lim_{x\\to0^+}f(x)-\\lim_{x\\to+\\infty}f(x)\\right)\\ln\\frac ba \\end{align*} $$\n$$ \\int_0^{\\pi/2}\\ln\\sin x\\d x $$\n区间再现法的例题 $$ \\begin{align*} \\int_0^{\\pi/2}\\ln\\sin x\\d x\u0026amp;=\\int_0^{\\pi/2}\\ln\\cos x\\d x\\\\ \u0026amp;=\\frac12\\left(\\int_0^{\\pi/2}\\ln(\\sin x\\cos x)\\d x\\right)\\\\ \u0026amp;=\\frac12\\left(\\int_0^{\\pi/2}(\\ln\\sin 2x-\\ln 2)\\d x\\right)\\\\ \u0026amp;=\\frac14\\int_0^\\pi\\ln\\sin t\\d t-\\frac{\\pi\\ln2}4\\\\ \u0026amp;=\\frac12\\int_0^{\\pi/2}\\ln\\sin t\\d t-\\frac{\\pi\\ln2}4\\\\ \\Longrightarrow\\int_0^{\\pi/2}\\ln\\sin x\\d x\u0026amp;=-\\frac{\\pi\\ln2}2 \\end{align*} $$\n$$ \\int_0^1\\frac{\\ln(1+x)}{1+x^2}\\d x $$\n神秘的区间再现法 $$ \\begin{align*} \\int_0^1\\frac{\\ln(1+x)}{1+x^2}\\d x\u0026amp;=\\left.\\ln(1+x)\\arctan x\\right|_0^1-\\int_0^1\\frac{\\arctan x}{1+x}\\d x\\\\ \u0026amp;\\xlongequal{x=\\tan t}\\frac{\\pi\\ln 2}4-\\int_0^{\\pi/4}\\frac{t}{1+\\tan t}\\sec^2 t\\d t\\\\ I=\\int_0^{\\pi/4}\\frac{t}{1+\\tan t}\\sec^2 t\\d t\u0026amp;=\\int_0^{\\pi/4}\\frac{t\\d t}{(\\sin t+\\cos t)\\cos t}\\\\ \u0026amp;=\\int_0^{\\pi/4}\\frac{t\\d t}{\\sqrt2\\sin(t+\\pi/4)\\cos t}\\\\ \u0026amp;\\xlongequal{u=\\pi/4-t}\\int_0^{\\pi/4}\\frac{(\\pi/4-u)\\d u}{\\sqrt2\\cos u\\cos(\\pi/4-u)}\\\\ \u0026amp;=\\frac\\pi4\\int_0^{\\pi/4}\\frac{\\sec^2u\\d u}{1+\\tan u}-I\\\\ \u0026amp;=\\frac{\\pi\\ln2}4-I\\\\ \u0026amp;=\\frac{\\pi\\ln2}8 \\end{align*} $$ 神秘的换元法 from https://www.zhihu.com/question/512255255/answer/2355309447：$x=\\frac{1-t}{1+t}$。\n$$ \\int_0^\\pi\\frac{x\\sin x}{1+\\cos^2x}\\d x $$\n无聊的区间再现法，答案是 $\\pi^2/4$。感兴趣可以看这个。\n$$ \\int_0^\\pi\\frac{\\sin nx}{\\sin x}\\d x $$\n赖皮方法：三角函数展开成 $\\e$。正常方法： $$ \\begin{align*} I_n=\\int_0^\\pi\\frac{\\sin nx}{\\sin x}\\d x\u0026amp;=\\int_0^\\pi\\frac{\\sin(n-1)x\\cos x+\\sin x\\cos(n-1)x}{\\sin x}\\d x\\\\ \u0026amp;=\\int_0^\\pi\\frac{\\sin nx+\\sin(n-2)x}{2\\sin x}\\d x\\\\ \u0026amp;=\\frac12\\left(I_n+I_{n-2}\\right)\\\\ \u0026amp;=I_{n-2}\\\\ \u0026amp;=(n\\bmod 2)\\pi \\end{align*} $$\n微分方程 如果遇到没法用下面方法解的微分方程，尝试两边同时求导！如果带积分还可以设 $g(x)=\\int_0^xf(t)\\d t$ 这种。\n$y^\\prime=f(x)$。最基本，直接不定积分。\n$y^\\prime=f(y)$。将 $x$ 和 $y$ 的地位互换，得到 $x^\\prime_y=1/f(y)$，归为 1。\n$y^\\prime=f(x)g(y)$。分离变量型，把 $g$ 除过去，两边积分。这应该是唯一一个不能归约基本型的方程，几何意义也不是特别容易理解，硬要理解可以用下面这种方法：\n考虑 $f(x,y)\\d x+g(x,y)\\d y=0$ 形式的微分方程，它的解是以 $(f,g)$ 为梯度场的二元函数的等高线。设原函数为 $\\varphi(x,y)$，那么要求 $$ \\varphi(x,y)=\\int f(x,y)\\d x+C_y(y)=\\int g(x,y)\\d y+C_x(x) $$ 这个连等要求了一个事，就是 $\\int f(x,y)\\d x-\\int g(x,y)\\d y$ 中不能有同时跟 $x$ 和 $y$ 有关的项，也就是 $$ \\frac{\\partial f}{\\partial y}=\\frac{\\partial g}{\\partial x} $$ 解为 $$ \\int f(x,y)\\d x+\\int\\left(g(x,y)-\\frac{\\partial}{\\partial y}\\int f(x,y)\\d x\\right)\\d y=0 $$\n$y^\\prime=f(y/x)$。这说明 $x$ 和 $y$ 的同步伸缩不改变向量场。而 1 容易解是因为 $y$ 的上下移动不改变向量场，也就是走向只与 $x$ 有关。如果能把这个方程的伸缩不变性也变成 1 中的这个性质就好做的。所以可以换元$p=y/x$，$z=\\ln|x|$，得到 $z^\\prime_p=\\frac{1}{f(p)-p}$，或者换元 $x=\\e^{u}\\cos\\theta$，$y=\\e^u\\sin\\theta$，得到 $$ \\frac{u^\\prime_\\theta\\tan\\theta+1}{u^\\prime_\\theta-\\tan\\theta}=f(\\tan\\theta)\\Longleftrightarrow u^\\prime_\\theta=\\frac{f(\\tan\\theta)\\tan\\theta+1}{f(\\tan\\theta)-\\tan\\theta} $$ 为什么要换 $\\ln$ 不直接换 $r$ 或 $x$？因为要求换元后是平移不变，而如果直接用 $(r,\\theta)$ 去表示的话，其实是不满足的——因为在用极坐标表示位置的同时，也要用它表示向量场，而极坐标的切向基向量（未经单位化）$\\b e_\\theta=r\\b{\\hat\\theta}$ 它的长度不是 $1$，就会导致原来看起来相等的向量在极坐标里不等。而如果改成换 $u=\\ln r$ 的话，就利用对数把伸缩变成了平移，$\\b e_\\theta=\\e^u\\b{\\hat\\theta}$，而 $\\b e_u=\\e^u\\b{\\hat u}$，向量场在 $u$ 平移是两维同时伸缩的，由于我们只关心方向，故相当于不变。\n$$ y^\\prime=f\\left(\\frac{a_1x+b_1y+c_1}{a_2x+b_2y+c_2}\\right) $$\n分平行和非平行考虑。平行换元分母转分离变量，非平行平移交点到原点后变为齐次。\n不含 $y$ 和不含 $x$，两种降阶方法。核心思想是增加未知函数，增加方程数，减少求导阶数。\n$y^\\prime=a(x)y+f(x)$。非齐次一阶，用常数变易法：先求出无 $f(x)$ 时的解 $y=\\e^{\\int a(x)\\d x}$，然后设解为 $y=C(x)\\e^{\\int a(x)\\d x}$（由于 $\\e^*$ 恒非零故不会漏解），展开得 $C(x)=\\int f(x)\\e^{-\\int a(x)\\d x}$。\n$\\b y^\\prime=A\\b y$。常系数一阶线性方程组。求出 $A$ 的 Jordan 标准型 $P^{-1}AP=J$，方程变为 $\\b y^\\prime=PJP^{-1}\\b y$ 即 $(P^{-1}\\b y)^\\prime=J(P^{-1}\\b y)$，然后直接解，再乘回来。对于可对角化的情况，有一个很优美的写法： $$ \\b y=P\\mat{C_1\\e^{\\lambda_1x}\\\\ \\vdots\\\\ C_n\\e^{\\lambda_nx}}=\\sum_{i=1}^nC_iv_i\\e^{\\lambda_ix}=\\mat{\\e^{\\lambda_1x}\u0026amp;\\cdots\u0026amp;0\\\\ \\vdots\u0026amp;\\ddots\u0026amp;\\vdots\\\\ 0\u0026amp;\\cdots\u0026amp;\\e^{\\lambda_nx}}\\b y(0)=\\e^\\Lambda\\b y(0) $$ 对于 Jordan 块 $$ \\b u^\\prime=\\mat{\\lambda\u0026amp;1\u0026amp;0\u0026amp;\\cdots\u0026amp;0\\\\ 0\u0026amp;\\lambda\u0026amp;1\u0026amp;\\cdots\u0026amp;0\\\\ \\vdots\u0026amp;\\vdots\u0026amp;\\vdots\u0026amp;\\ddots\u0026amp;\\vdots\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;\\cdots\u0026amp;1\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;\\cdots\u0026amp;\\lambda}_{k\\times k}\\b u $$ 容易解得 $$ \\b u=\\mat{(C_kx^{k-1}+\\cdots+C_1)\\e^{\\lambda x}\\\\ (C_kx^{k-2}+\\cdots+C_2)\\e^{\\lambda x}\\\\ \\vdots\\\\ (C_kx+C_{k-1})\\e^{\\lambda x}\\\\ C_k\\e^{\\lambda x}} $$\n$$ y^{(n)}+\\sum_{i=0}^{n-1}a_iy^{(i)}=0 $$ 常系数高阶线性。核心思想是导数也是线性变换。求出左边对应多项式的根 $\\lambda_1\\sim\\lambda_n$。于是整个可以写成 $$ \\left[\\prod_{i=1}^n\\left(\\frac{\\d}{\\d x}-\\lambda_i\\right)\\right]y=0 $$ 于是可以逐一求解。实际上不用暴力求——如果去重后根为 $\\lambda_1\\sim\\lambda_k$ 且重数分别为 $m_1\\sim m_k$，容易代入验证 $y$ 可以写成以下函数的线性组合： $$ \\e^{\\lambda_1},x\\e^{\\lambda_1},\\cdots,x^{m_1-1}\\e^{\\lambda_1},\\cdots $$ 对于有非齐次项的情况，可以用常数变易法，更一般的方法见后。\n$$ x^ny^{(n)}+\\sum_{i=0}^{n-1}a_ix^iy^{(i)}=0 $$ Euler 方程。同样可以待定系数 $$ \\left[\\prod_{i=1}^n\\left(\\frac{x\\d}{\\d x}-\\lambda_i\\right)\\right]y=0 $$ 然后暴解。注意到 $x\\d/\\d x=\\d/\\d\\ln|x|$，于是考虑直接把自变量换成 $t=\\ln|x|$。于是 $$ \\frac{x^i\\d^i}{\\d x^i}=\\frac{x\\d}{\\d x}\\left(\\frac{x^{i-1}\\d^{i-1}}{\\d x^{i-1}}\\right)-(i-1)\\frac{x^{i-1}\\d^{i-1}}{\\d x^{i-1}}=\\cdots=\\prod_{j=0}^{i-1}\\left(\\frac{\\d}{\\d t}-j\\right) $$ 于是原方程变为上一种类型 $$ \\sum_{j=0}^ny^{(j)}_t\\sum_{i=j}^n(-1)^{i-j}\\begin{bmatrix}i\\\\ j\\end{bmatrix}a_i=0 $$ 其中 $\\begin{bmatrix}i\\\\ j\\end{bmatrix}$ 是第一类斯特林数。\n一些特殊的因式分解。例如： $$ x\\frac{\\d^2}{\\d x^2}-(x+1)\\frac{\\d}{\\d x}+1=\\left(x\\frac{\\d}{\\d x}-1\\right)\\left(\\frac{\\d}{\\d x}-1\\right) $$\n$$ x(x+1)\\frac{\\d^2}{\\d x^2}-(4x+2)\\frac{\\d}{\\d x}+6=\\left(x\\frac{\\d}{\\d x}-2\\right)\\left((x+1)\\frac{\\d}{\\d x}-3\\right) $$\n$$ y^{(n)}+\\sum_{i=0}^{n-1}a_i(x)y^{(i)}=f(x) $$\n高阶非齐次线性。我们写成矩阵的形式： $$ \\mat{y\\\\ y^\\prime\\\\ \\vdots\\\\ y^{(n-1)}}^\\prime=\\mat{0\u0026amp;1\u0026amp;0\u0026amp;\\cdots\u0026amp;0\u0026amp;0\\\\ 0\u0026amp;0\u0026amp;1\u0026amp;\\cdots\u0026amp;0\u0026amp;0\\\\ \\vdots\u0026amp;\\vdots\u0026amp;\\vdots\u0026amp;\\ddots\u0026amp;\\vdots\u0026amp;\\vdots\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;\\cdots\u0026amp;0\u0026amp;1\\\\ -a_0(x)\u0026amp;-a_1(x)\u0026amp;-a_2(x)\u0026amp;\\cdots\u0026amp;-a_{n-2}(x)\u0026amp;-a_{n-1}(x)}\\mat{y\\\\ y^\\prime\\\\ \\vdots\\\\ y^{(n-1)}}+\\mat{0\\\\ 0\\\\ \\vdots\\\\ f(x)} $$\n$$ \\b y^\\prime=A\\b y+\\b f $$\n假设在齐次的情况下，解得了 $n$ 个线性无关解 $y_1,\\cdots,y_n$，把它们的 $0\\sim n-1$ 阶导写成列向量，排起来成为 $U_{n\\times n}$。使用常数变易法，考虑 $$ \\b C=\\mat{C_1(x)\\\\ C_2(x)\\\\ \\vdots\\\\ C_n(x)},\\;\\b y=U\\b C $$ 那么 $$ U^\\prime\\b C+U\\b C^\\prime=\\b y^\\prime=A\\b y+\\b f $$ 而 $$ U^\\prime\\b C=AU\\b C=A\\b y $$ 因此要解的就是 $$ U\\b C^\\prime=\\b f\\Longrightarrow\\b C=\\int U^{-1}\\b f\\d x $$ 以 $n=2$ 为例，最后要解的就是 $$ \\left\\{\\begin{aligned} y_1C_1^\\prime(x)+y_2C_2^\\prime(x)\u0026amp;=0\\\\ y_1^\\prime C_1^\\prime(x)+y_2^\\prime C_2^\\prime(x)\u0026amp;=f(x) \\end{aligned}\\right. $$ 这个矩阵方法很自然地加入了额外的 $n-1$ 条限制，其本质是在设 $\\b y=U\\b C$ 时默认了通解 $y$ 的高阶导由基础解系线性组合的系数与零阶组合的系数相同。这个其实是“冒险”的，但下面对解的性质的分析保证了这个是对的。\n如果方程有个两个解 $\\b y_1$，$\\b y_2$，$\\b y_1|_{x=x_0}=\\b y_2|_{x=x_0}$，则 $\\b y_1=\\b y_2$。\n证：$\\b y_1-\\b y_2$ 是 $\\b y^\\prime=A\\b y$ 的解，从而可以写成 $U\\b C$ 的形式，其中 $\\b C$ 与 $x$ 无关。而 $(U\\b C)|_{x=x_0}=\\b 0$，从而 $\\b C=U^{-1}|_{x=x_0}\\b 0=\\b 0$。\n当我们说“$n$ 个线性无关的解”时，我们不需要明确是在哪个 $x$ 处线性无关。$\\set{\\b y_1,\\cdots,\\b y_n}$ 线性无关，当且仅当对于某个 $x_0$，这组函数向量在 $x_0$ 处的实数向量线性无关。\n引理（Liouville）：对于齐次情况（不要求 $\\b y_i$ 形如一个 $y$ 的 $0\\sim n-1$ 阶导），$\\dat{U}^\\prime=\\tr A\\dat{U}$。$\\dat{U}$ 称为 $n$ 个解的 Wronsky 行列式。\n证：根据乘积的导数 → $\\b y$ 满足的等式 → 行列式的性质，（$y_{j,k}$ 表示第 $j$ 个解的第 $k$ 项） $$ \\dat{U}^\\prime=\\sum_{r=1}^n\\dat{\\Set{y_{j,i}^{([i=r])}}_{n\\times n}}=\\sum_{r=1}^n\\dat{\\Set{\\begin{cases}y_{j,i},\u0026amp;i\\ne r\\\\ \\sum_{k=1}^nA_{i,k}y_{j,k},\u0026amp;i=r\\end{cases}}_{n\\times n}}=\\sum_{r=1}^nA_{r,r}\\dat{U}=\\tr A\\dat{U} $$ 而 $\\dat{U}^\\prime=\\tr A\\dat{U}$ 是一个一阶齐次线性的方程，直接解得 $\\dat{U}=\\e^{\\int\\tr A\\d x}$，代入初始条件得 $\\dat{U}=\\dat{U}|_{x=x_0}\\e^{\\int_{x_0}^x\\tr A|_{x=t}\\d t}$。由于 $\\e^*$ 恒正，故只要某个 $x_0$ 处线性无关，就处处线性无关。\n当 $A$ 的各项都是连续函数时，$\\b y^\\prime=A\\b y$ 对于任何初始条件都存在解。\n证明见理论基础（咕）。\n$$ y^{\\prime\\prime}+a_1(x)y^\\prime+a_0(x)y=0 $$\n假定已经知道了一个解 $y_1$，求另一个线性无关的解 $y_2$。设 $y_2=C(x)y_1$。代入可得： $$ C^\\prime(x)=\\frac{C}{y_1^2\\e^{\\int_{x_0}^xa_1(t)\\d t}} $$ 再积回去即可，取 $C\\ne 0$ 容易验证可以得到一个线性无关的解。\n$$ y^\\prime+a(x)y=b(x)y^n\\;(n\\ne 0,1) $$\nBernoulli 方程。换元 $z=y^{1-n}$，等式两边同除以 $y^n$： $$ \\frac{y^\\prime}{y^n}+\\frac{a(x)}{y^{n-1}}=b(x)\\Longleftrightarrow\\frac{z^\\prime}{1-n}+a(x)z=b(x) $$\n杂题 证明 $\\R$ 是唯一的完备序域。\n答案见理论基础。\nLagrange 恒等式的几何意义？\n能否构造在 $\\Q$ 处间断，$\\R\\setminus\\Q$ 处连续的单增函数？能否构造在 $\\Q$ 处连续，$\\R\\setminus\\Q$ 处间断的单增函数？\n如果不要求单增，那就用黎曼函数。要求单增也不难，构造奇函数 $f$： $$ f(x\u0026gt;0)=\\sum_{0\u0026lt;p/q\\le x}2^{-q} $$ 容易知道这玩意是收敛的，但是我们发现一个新的有趣的问题：求 $$ \\sum_{i\\ge 1}\\mu(i)2^{-i} $$\n不能。增函数的间断点都是跳跃间断点，这个跳跃处一定包含有理数，因此间断点是至多可数的。\n证明 $\\N$ 和 $\\R$、$\\N$ 和 $\\mathcal{P}(\\N)$ 不等势。\n对角线法；或考虑 $\\set{i\\mid i\\notin A_i}$，这个集合不能是某个 $A_j$，否则 $j$ 既不能 $\\in A_j$，又不能 $\\notin A_j$。\n证明 Stolz 定理：\n$\\set{b_n}$ 严增，$\\lim b_n=+\\infty$，$\\lim\\Delta a_n/\\Delta b_n\\in\\R\\cup\\set{\\pm\\infty}$，则 $\\lim a_n/b_n=\\lim\\Delta a_n/\\Delta b_n$。 $\\set{b_n}$ 严降，$\\lim b_n=\\lim a_n=0$，$\\lim\\Delta a_n/\\Delta b_n\\in\\R\\cup\\set{\\pm\\infty}$，则 $\\lim a_n/b_n=\\lim\\Delta a_n/\\Delta b_n$。 设 $\\lim\\Delta a_n/\\Delta b_n=L$，$\\forall\\varepsilon\u0026gt;0$，$\\exists N$，$\\forall n\u0026gt;N$， $$ (L-\\varepsilon)(b_{n+1}-b_n)\u0026lt;a_{n+1}-a_n\u0026lt;(L+\\varepsilon)(b_{n+1}-b_n) $$ 于是 $$ (L-\\varepsilon)(b_{n+1}-b_{N+1})\u0026lt;a_{n+1}-a_{N+1}\u0026lt;(L+\\varepsilon)(b_{n+1}-b_{N+1}) $$ 即（容易取到 $b$ 为正） $$ \\left\\lvert\\frac{a_{n+1}}{b_{n+1}}-\\frac{a_{N+1}}{b_{n+1}}-L+L\\frac{b_{N+1}}{b_{n+1}}\\right\\rvert\u0026lt;\\left(1-\\frac{b_{N+1}}{b_{n+1}}\\right)\\varepsilon\u0026lt;\\varepsilon $$ 取足够大的 $n$，即可 $$ \\left\\lvert\\frac{a_{n+1}}{b_{n+1}}-L\\right\\rvert\\le\\left\\lvert\\frac{a_{n+1}}{b_{n+1}}-\\frac{a_{N+1}}{b_{n+1}}-L+L\\frac{b_{N+1}}{b_{n+1}}\\right\\rvert+\\left\\lvert\\frac{a_{N+1}}{b_{n+1}}-L\\frac{b_{N+1}}{b_{n+1}}\\right\\rvert\u0026lt;2\\varepsilon $$ Remark. 这里主要是考虑去除 $a_N$ 和 $b_N$ 的“垃圾”影响。如果硬处理的话，可以直接比对已知不等式和目标不等式，硬解出 $n$ 的范围，但这样会麻烦。这个证法主要是通过保留 $1-b_{N+1}/b_{n+1}$ 因子的方式，减少了讨论的复杂程度。\n设 $\\lim\\Delta a_n/\\Delta b_n=L$，$\\forall\\varepsilon\u0026gt;0$，$\\exists N$，$\\forall n\u0026gt;N$， $$ (L-\\varepsilon)(b_{n+1}-b_n)\u0026lt;a_{n+1}-a_n\u0026lt;(L+\\varepsilon)(b_{n+1}-b_n) $$ 于是 $\\forall n^\\prime \u0026gt;n$， $$ (L-\\varepsilon)(b_{n^\\prime+1}-b_n)\u0026lt;a_{n^\\prime+1}-a_n\u0026lt;(L+\\varepsilon)(b_{n^\\prime+1}-b_n) $$ 即 $$ \\left\\lvert\\frac{a_n}{b_n}-\\frac{a_{n^\\prime+1}}{b_n}-L+L\\frac{b_{n^\\prime+1}}{b_n}\\right\\rvert\u0026lt;\\left(1-\\frac{b_{n^\\prime+1}}{b_n}\\right)\\varepsilon\u0026lt;\\varepsilon $$ 取足够大的 $n^\\prime$，即可 $$ \\left\\lvert\\frac{a_n}{b_n}-L\\right\\rvert\\le\\left\\lvert\\frac{a_n}{b_n}-\\frac{a_{n^\\prime+1}}{b_n}-L+L\\frac{b_{n^\\prime+1}}{b_n}\\right\\rvert+\\left\\lvert\\frac{a_{n^\\prime+1}}{b_n}-L\\frac{b_{n^\\prime+1}}{b_n}\\right\\rvert\u0026lt;2\\varepsilon $$ Remark. 这种情况奇怪的点在于，不能扔前缀的部分了，因为越前反而越大。所以要找到影响够小的部分，只能到后面去找，再减回来。洛必达法则的 $0/0$ 形式的思路也是类似。\n$$ \\lim_{n\\to\\infty}\\frac{n^k}{a^n} $$\n解 1： $$ *=\\lim_{n\\to\\infty}\\left(\\frac{n}{a^{n/k}}\\right)^k=k^k\\left(\\lim_{t\\to\\infty}\\frac{t}{a^t}\\right)^k=0 $$ 因为 $$ \\frac{t}{a^t}=\\frac{t}{(1+a-1)^t}\\le\\frac{t}{\\binom t2(a-1)^2}=\\frac{2}{(t-1)(a-1)^2}\\to 0 $$ 解 2：当 $n\u0026gt;1/(1-a^{-1/k})$ 时， $$ \\frac{n^k/a^n}{(n+1)^k/a^{n+1}}=a\\left(1-\\frac1{n+1}\\right)^k\u0026gt;1 $$ 即递减，故极限存在。对 $$ \\frac{n^k}{a^n}=a\\left(\\frac{n}{n+1}\\right)^k\\frac{(n+1)^k}{a^{n+1}} $$ 两边取极限得 $$ \\lim_{n\\to\\infty}\\frac{n^k}{a^n}=a\\lim_{n\\to\\infty}\\frac{n^k}{a^n}\\Longrightarrow\\lim_{n\\to\\infty}\\frac{n^k}{a^n}=0 $$ 解 3：取对数硬证。\n解 4：用 Stolz 定理 + 归纳证。\n不用洛必达，证明 $$ \\lim_{x\\to0^+}x\\ln x=0 $$\n$$ \\lim_{x\\to 0^+}x\\ln x=\\lim_{x\\to 0^+}\\e^{\\ln x}\\ln x\\xlongequal{y=-\\ln x}-\\lim_{y\\to+\\infty}\\frac{y}{\\e^y}=0 $$\n$$ \\lim_{x\\to 0}\\frac{(1+nx)^{1/m}-(1+mx)^{1/n}}{x} $$\n$$ \\begin{align*} \u0026amp;\\lim_{x\\to 0}\\frac{(1+nx)^{1/m}-(1+mx)^{1/n}}{x}\\\\ ={}\u0026amp;\\lim_{x\\to 0}\\frac{(1+nx)^{1/m}-1}{x}-\\lim_{x\\to 0}\\frac{(1+mx)^{1/n}-1}{x}\\\\ \\xlongequal{t=(1+nx)^{1/m},u=(1+mx)^{1/n}}{}\u0026amp;\\lim_{t\\to 1}\\frac{n(t-1)}{t^m-1}-\\lim_{u\\to 1}\\frac{m(u-1)}{u^n-1}\\\\ ={}\u0026amp;\\lim_{t\\to 1}\\frac{n}{t^{m-1}+\\cdots+1}-\\lim_{u\\to 1}\\frac{m}{u^{n-1}+\\cdots+1}\\\\ ={}\u0026amp;\\frac{n}{m}-\\frac{m}{n} \\end{align*} $$\n另一种麻烦些的处理方法是考虑 $$ \\begin{align*} \u0026amp;\\lim_{x\\to 0}\\frac{(1+x)^p-1}{x}\\\\ ={}\u0026amp;\\lim_{x\\to 0}\\frac{\\e^{p\\ln(1+x)}-1}{x}\\\\ ={}\u0026amp;\\lim_{x\\to 0}\\frac{\\e^{p\\ln(1+x)}-1}{\\ln(1+x)}\\\\ \\xlongequal{t=p\\ln(1+x)}{}\u0026amp;p\\lim_{t\\to 0}\\frac{\\e^t-1}{t}\\\\ \\xlongequal{u=\\e^t-1}{}\u0026amp;p\\lim_{u\\to 0}\\frac{u}{\\ln(1+u)}\\\\ ={}\u0026amp;p \\end{align*} $$\n$\\e$ 相关：\n证明 $(1+1/n)^n$ 单增且有界，$(1+1/n)^{n+1}$ 单减且有界，从而两者极限存在且相等。 证明 $(1+1/x)^x$ 在 $\\R^\\pm$ 上分别单增，$\\lim_{x\\to\\infty}(1+1/x)^x=\\e$。 证明 $\\sum_{i=0}^{+\\infty}1/i!=\\e$。 证明 $\\e\\notin\\Q$。 证 1（比值比较法）： $$ \\begin{align*} \u0026amp;\\frac{\\left(1+\\frac1{n+1}\\right)^{n+1}}{\\left(1+\\frac1n\\right)^n}\\\\ ={}\u0026amp;\\left(\\frac{1+\\frac1{n+1}}{1+\\frac1n}\\right)^n\\frac{n+2}{n+1}\\\\ ={}\u0026amp;\\left(1-\\frac{1}{(n+1)^2}\\right)^n\\frac{n+2}{n+1}\\\\ \u0026gt;{}\u0026amp;\\left(1-\\frac{n}{(n+1)^2}\\right)\\frac{n+2}{n+1}\\\\ ={}\u0026amp;\\frac{n^3+3n^2+3n+2}{n^3+3n^2+3n+1}\\\\ \u0026gt;{}\u0026amp;1 \\end{align*} $$\n其中第一个 $\u0026gt;$ 是（归纳法可以证的）伯努利不等式。\n证 2（均值不等式）： $$ \\left(1+\\frac1n\\right)^n=1\\cdot\\left(1+\\frac1n\\right)^n\\le\\left(\\frac{1+n+1}{n+1}\\right)^{n+1}=\\left(1+\\frac1{n+1}\\right)^{n+1} $$ 证 3（二项式展开）： $$ \\begin{align*} \\left(1+\\frac1n\\right)^n \u0026amp;=\\sum_{i=0}^n\\frac{n^{\\underline{i}}}{i!}n^{-i}\\\\ \u0026amp;=\\sum_{i=0}^n\\frac1{i!}\\prod_{j=0}^{i-1}\\left(1-\\frac jn\\right)\\\\ \u0026amp;\u0026lt;\\sum_{i=0}^{n+1}\\frac1{i!}\\prod_{j=0}^{i-1}\\left(1-\\frac j{n+1}\\right)=\\left(1+\\frac1{n+1}\\right)^{n+1} \\end{align*} $$ 另一个： $$ \\begin{align*} \u0026amp;\\frac{\\left(1+\\frac1n\\right)^{n+1}}{\\left(1+\\frac1{n+1}\\right)^{n+2}}\\\\ ={}\u0026amp;\\left(\\frac{1+\\frac1n}{1+\\frac1{n+1}}\\right)^{n+1}\\frac{n+1}{n+2}\\\\ ={}\u0026amp;\\left(1+\\frac{1}{n(n+2)}\\right)^{n+1}\\frac{n+1}{n+2}\\\\ \u0026gt;{}\u0026amp;\\left(1+\\frac{n+1}{n(n+2)}\\right)\\frac{n+1}{n+2}\\\\ ={}\u0026amp;\\frac{n^2+4n^2+4n+1}{n^3+4n^2+4n}\\\\ \u0026gt;{}\u0026amp;1 \\end{align*} $$\n$\u0026gt;0$ 的情况： $$ \\left(1+\\frac1{\\lfloor x\\rfloor+1}\\right)^{\\lfloor x\\rfloor}\\le\\left(1+\\frac1x\\right)^x\\le\\left(1+\\frac1{\\lfloor x\\rfloor}\\right)^{\\lfloor x\\rfloor+1} $$\n夹逼即可。$\u0026lt;0$ 时： $$ \\lim_{x\\to-\\infty}\\left(1+\\frac1x\\right)^x=\\lim_{x\\to-\\infty}\\left(\\frac{x}{x+1}\\right)^{-x}=\\lim_{t\\to+\\infty}\\left(1+\\frac{1}{t+1}\\right)^t=\\e $$ 似乎没有简单的方法证明其本身的单调性。\n一方面， $$ \\left(1+\\frac1n\\right)^n=\\sum_{i=0}^n\\frac1{i!}\\prod_{j=0}^{i-1}\\left(1-\\frac jn\\right)\\le\\sum_{i=0}^n\\frac1{i!} $$ 另一方面， $$ \\lim_{n\\to\\infty}\\left(1+\\frac1n\\right)^n\\ge\\lim_{n\\to\\infty}\\sum_{i=0}^k\\frac1{i!}\\prod_{j=0}^{i-1}\\left(1-\\frac jn\\right)=\\sum_{i=0}^k\\frac1{i!} $$ 或者也可以利用伯努利不等式（from https://www.zhihu.com/question/427108293/answer/3227359998） $$ \\left(1+\\frac1n\\right)^n=\\sum_{i=0}^n\\frac1{i!}\\prod_{j=0}^{i-1}\\left(1-\\frac jn\\right)\\ge\\sum_{i=0}^n\\frac1{i!}\\left(1-\\frac{i(i-1)}{n}\\right)=\\left(1-\\frac1n\\right)\\sum_{i=0}^n\\frac1{i!} $$\n（from https://www.zhihu.com/question/341220643/answer/868684204）\n若 $$ \\sum_{i=0}^{+\\infty}\\frac{1}{i!}=\\e=\\frac qp\\Longrightarrow\\sum_{i=0}^pp^{\\underline{p-i}}+\\sum_{i=p+1}^{+\\infty}\\frac1{i^{\\underline{i-p}}}=q(p-1)! $$ 则 $$ \\sum_{i=p+1}^{+\\infty}\\frac1{i^{\\underline{i-p}}}\u0026lt;\\sum_{i=1}^{\\infty}\\frac1{(p+1)^i}=\\frac1p\\le 1 $$ 是整数，矛盾。\n$$ \\lim_{x\\to 0}\\frac{\\sin(x^2\\sin(1/x))}{x} $$\n错误解法： $$ \\lim_{x\\to 0}\\frac{\\sin(x^2\\sin(1/x))}{x}=\\lim_{x\\to 0}\\frac{x^2\\sin(1/x)}{x}=\\lim_{x\\to 0}x\\sin\\frac{1}{x}=0 $$ 错误之处：当我们说 $\\sin(x^2\\sin(1/x))\\sim x^2\\sin(1/x)$ 时，我们实际上在说 $$ \\lim_{x\\to 0}\\frac{\\sin(x^2\\sin(1/x))}{x^2\\sin(1/x)}=1 $$ 这个极限是在 $\\R\\setminus\\set{0}\\setminus\\set{1/k\\pi\\mid k\\in\\Z\\setminus\\set{0}}$ 上说的，但是原极限并没有去掉这些点，而等价无穷小替换的原理是“硬拆出一个分式”方法，所以这样不行。\n正确解法 1：夹逼。\n正确解法 2： $$ \\lim_{x\\to 0}\\frac{\\sin(x^2\\sin(1/x))}{x}=\\lim_{x\\to 0}\\frac{x^2\\sin(1/x)}{x}=\\lim_{x\\to 0}x\\sin\\frac{1}{x}=0 $$ 欸欸欸，不是，怎么跟上面的错误解法一样啊？\n别急，我们这里用的是 wxf 的等价无穷小定义：$f\\sim g$ 定义为 $f=g+\\omicron(g)$，或者说 $\\forall\\varepsilon\u0026gt;0$，$\\exists\\delta\u0026gt;0$，$\\forall|x-x_0|\u0026lt;\\delta$，$|f(x)-g(x)|\\le\\varepsilon|g(x)|$（注意这里必须是 $\\le$，不然 $0$ 就爆了）。容易验证还是有 $\\sin(x^2\\sin(1/x))\\sim x^2\\sin(1/x)$，于是 $$ \\lim_{x\\to 0}\\frac{\\sin(x^2\\sin(1/x))}{x}=\\lim_{x\\to 0}\\frac{x^2\\sin(1/x)+\\omicron(x^2\\sin(1/x))}{x}=\\lim_{x\\to 0}\\left(x\\sin\\frac 1x+\\omicron\\left(x\\sin\\frac 1x\\right)\\right)=0 $$\n这个定义在保证应用时可以替换的情况下，避免了除法。\n说到这个定义，我们就不禁会关心一个东西：\n证明：$x\\to x_0$，$f=g+\\omicron(g)\\Leftrightarrow g=f+\\omicron(f)$。\n设 $f-g=\\omicron(g)$。$\\forall\\varepsilon\\in(0,1)$，已知 $\\exists\\delta\u0026gt;0$，$\\forall|x-x_0|\u0026lt;\\delta$， $$ \\begin{align*} |f(x)-g(x)|\u0026amp;\\le\\frac{\\varepsilon}{1+\\varepsilon}|g(x)|\\\\ \u0026amp;=\\frac{\\varepsilon}{1+\\varepsilon}|g(x)-f(x)+f(x)|\\\\ \u0026amp;\\le\\frac{\\varepsilon}{1+\\varepsilon}|f(x)-g(x)|+\\frac{\\varepsilon}{1+\\varepsilon}|f(x)|\\\\ \\Longrightarrow\\frac{1}{1+\\varepsilon}|f(x)-g(x)|\u0026amp;\\le\\frac{\\varepsilon}{1+\\varepsilon}|f(x)|\\\\ \\Longrightarrow|f(x)-g(x)|\u0026amp;\\le\\varepsilon|f(x)| \\end{align*} $$\n$y_n=2y_{n-1}^2-1, |y_0|\\le 1$， 分析 $\\set{y_n}$ 的敛散性。\n设 $y_n=\\cos\\theta_n$, 则 $y_n=\\cos(2^n\\theta_0)$.\n对于 $\\theta_0$ 是 $\\pi$ 的有理数倍的情况, 设 $\\theta_0=q\\pi/p$, 其中 $p,q$ 互质, $p\u0026gt;0$. 如果 $p=2^k$, 那么 ${y_n}$ 收敛至 $1$; 如果 $p=3\\cdot 2^k$, 那么 ${y_n}$ 收敛至 $-1/2$; 否则 ${y_n}$ 震荡不收敛.\n对于 $\\theta_0$ 是 $\\pi$ 的无理数倍的情况, $y_n\\ne 1$. 如果 $\\lim_{n\\to\\infty}y_n=1$, 那么 $\\exists N$, $\\forall n\\ge N$, $1-y_n\u0026lt;1/2$. 设 $d_n=1-y_n$. 有 $d_n=2(1+y_{n-1})d_n$. 那么当 $n\u0026gt;N$ 时, $d_n\u0026gt;3d_{n-1}\u0026gt;\\cdots\u0026gt;3^{n-N}d_N$. 取 $n=N-\\lceil\\log_3d_N\\rceil$, 则 $d_n\u0026gt;1/2$, 矛盾.\n同样, $y_n\\ne-1/2$. 如果 $\\lim_{n\\to\\infty}y_n=-1/2$, 那么 $\\exists N$, $\\forall n\\ge N$, $|y_n+1/2|\u0026lt;1/4$. 设 $c_n=|y_n+1/2|$, 有 $c_n=2|y_n-1/2|c_{n-1}$. 那么当 $n\u0026gt;N$ 时, $c_n\u0026gt;(3/2)c_{n-1}\u0026gt;\\cdots\u0026gt;(3/2)^{n-N}c_N$. 取 $n=N-\\lceil\\log_{3/2}c_N\\rceil$, 则 $c_n\u0026gt;1/4$, 矛盾. 故 ${y_n}$ 不收敛.\n综上所述, ${y_n}$ 收敛的充要条件是 $\\arccos y_0\\in{q\\pi/2^k,q\\pi/(3\\cdot 2^k)\\mid q,k\\in\\N}$.\n$x_1=a$，$y_1=b$，$x_{n+1}=(x_n+y_n)/2$，$y_{n+1}=\\sqrt{x_ny_n}$。分析两个数列收敛到的同一个值。\nhttps://en.wikipedia.org/wiki/Arithmetic%E2%80%93geometric_mean\n$x_1=1$，$x_{n+1}=x_n+1/S_n$。分析 $\\lim_{n\\to\\infty}\\e^{x_n^2}/S_n$ 是否收敛。\n求教教/kel\n不用微分中值定理证明洛必达定理。\n$0/0$：已知存在 $x_0$ 的一个邻域，使得邻域内 $|f^\\prime(x)/g^\\prime(x)-A|\u0026lt;\\varepsilon$。由于导数的介值性，可以假定 $g^\\prime(x)$ 恒 $\u0026gt;0$。所以 $f^\\prime(x)-(A-\\varepsilon)g^\\prime(x)\u0026gt;0$，$f^\\prime(x)-(A+\\varepsilon)g^\\prime(x)\u0026lt;0$，所以 $f(x)-(A-\\varepsilon)g(x)$ 严格单增，$f(x)-(A+\\varepsilon)g(x)$ 严格单减。又由于在 $x_0$ 处这两者都等于 $0$，故 $x\u0026lt;x_0$ 时 $f(x)-(A-\\varepsilon)g(x)\u0026lt;0$，同时 $g(x)\u0026lt;0$，故 $A-\\varepsilon\u0026lt;f(x)/g(x)$。同理讨论其他三种情况，得 $A-\\varepsilon\u0026lt;f(x)/g(x)\u0026lt;A+\\varepsilon$。\n这种情况因为要处理 $0^\\pm$ 的情况所以用上了达布，不好看。下面这种情况会看起来比较牛：\n$*/\\infty$：只考虑左侧。设 $\\lim_{x\\to x_0^-}g(x)=+\\infty$，从而 $g^\\prime(x)\u0026gt;0$。同理我们会得到在 $x\\in(x_1,x_0)$ 内 $f(x)-(A-\\varepsilon)g(x)$ 严格单增。现在取 $x_0$ 的另一个左邻域 $(x_2,x_0)\\subset(x_1,x_0)$ 使得 $\\forall x\\in(x_2,x_0)$，$-\\varepsilon g(x)\u0026lt;f(x_1)-(A-\\varepsilon)g(x_1)$，因为 $g(x)\\to+\\infty$ 所以这是可以的。这时对于其中的 $x$， $$ f(x)-(A-\\varepsilon)g(x)\u0026gt;f(x_1)-(A-\\varepsilon)g(x_1)\u0026gt;-\\varepsilon g(x)\\Longrightarrow\\frac{f(x)}{g(x)}\u0026gt;A-2\\varepsilon $$ 其余情况同理。\n$f(x)\\in\\mathscr{C}[0,1]$ 满足 $|f(x)|\\le 1+\\int_0^x|f(t)|\\d t$。证明 $|f(x)|\\le\\e^x$。\n这个题的非积分形式在教积分之前也出现过（5.1.13）。\n证 1：令 $g(x)=|f(x)|-\\e^x$，则 $|g(x)|-\\int_0^xg(x)\\d x\\le 0$。如果 $g(x)$ 出现了正的，取 $x_0=\\operatorname{argmax}g(x)$。由中值定理， $$ g(x_0)\\le\\int_0^{x_0}g(t)\\d t=x_0g(\\xi)\\;(\\xi\\in(0,x_0)) $$ 如果 $x_0=1$，让 $x_0=\\xi$ 后再做一遍。现在 $g(\\xi)\\ge g(x_0)/x_0\u0026gt;g(x_0)$，与 $g(x_0)$ 最大矛盾。\n证 2：令 $g(x)=\\int_0^x|f(t)|\\d t$。则 $$ g^\\prime(x)\\le 1+g(x)\\Longrightarrow\\frac{g^\\prime(x)}{1+g(x)}\\le 1\\Longrightarrow\\ln(1+g(x))\\le x\\Longrightarrow1+g(x)\\le\\e^x\\Longrightarrow|f(x)|\\le\\e^x $$ 这种方法更通用。\n对于 $[0,1]$ 上的连续函数 $f$ 与以 $1$ 为周期的非负可积函数 $g$，证明 $$ \\lim_{n\\to\\infty}\\int_0^1f(x)g(nx)\\d x=\\int_0^1f(x)\\d x\\int_0^1g(x)\\d x $$\n$$ \\begin{align*} \u0026amp;\\lim_{n\\to\\infty}\\int_0^1f(x)g(nx)\\d x\\\\ ={}\u0026amp;\\lim_{n\\to\\infty}\\sum_{i=0}^{n-1}\\int_{i/n}^{(i+1)/n}f(x)g(nx\\bmod 1)\\d x\\\\ ={}\u0026amp;\\lim_{n\\to\\infty}\\frac1n\\sum_{i=0}^{n-1}f(\\xi_{n,i})\\int_0^1g(x)\\d x\\\\ ={}\u0026amp;\\int_0^1f(x)\\d x\\int_0^1g(x)\\d x \\end{align*} $$\n设 $f(x)=\\int_x^{x+1}\\sin(t^2)\\d t$。证明 $\\forall x\u0026gt;0$，$|f(x)|\\le 1/x$。\n既然不能直接用 Dirichlet 判别法，就考虑其原理，试图魔改其证明的过程。 $$ \\begin{align*} \\left|\\int_{x^2}^{(x+1)^2}\\frac{\\sin u}{2\\sqrt u}\\d u\\right|\u0026amp;=\\left|-\\left.\\frac{\\cos u}{2\\sqrt u}\\right|_{x^2}^{(x+1)^2}-\\int_{x^2}^{(x+1)^2}\\frac{\\cos u}{4u^{3/2}}\\d u\\right|\\\\ \u0026amp;\\le\\frac{1}{2(x+1)}+\\frac{1}{2x}+\\int_{x^2}^{(x+1)^2}\\frac{\\d u}{4u^{3/2}}\\\\ \u0026amp;=\\frac{1}{2(x+1)}+\\frac{1}{2x}-\\frac{1}{2(x+1)}+\\frac{1}{2x}\\\\ \u0026amp;=\\frac1x \\end{align*} $$\n","date":"2025-01-22T00:00:00Z","image":"https://littlereuben.github.io/study/course-calculus-1-2/cover.jpg","permalink":"https://littlereuben.github.io/study/course-calculus-1-2/","title":"微积分 A(1) 复习及一些题"},{"content":"$\\gdef\\s{\\operatorname{S}}\\gdef\\F{\\mathbb{F}}\\gdef\\d{\\mathrm{d}}\\gdef\\Q{\\mathbb{Q}}$\n这是一篇学习笔记。\r实数理论 参考：chenxia25 与我的讨论、https://zhuanlan.zhihu.com/p/48859870\n所有 $\\forall/\\exists a$ 形式的东西，$a$ 默认属于当前讨论的集合。当你看见 $\\Rightarrow$ 时，就说明不是形式语言。\nDefinition 1. 自然数集，利用 Peano 公理定义：\nAxiom 1.0. 等价关系的确立\nP.S. 这里我们默认了等价关系满足 $m=n\\Rightarrow \\s(m)=\\s(n)$ 及其推论，也就是说“等价关系”在保证不产生矛盾的情况下被内化为了可替换关系。这是需要区分的，后面关于减法的定义就需要验证其良定义性。\nAxiom 1.1. $0\\in\\N$\nAxiom 1.2. $\\forall i(i\\in\\N\\rightarrow \\s(i)\\in\\N)$\nAxiom 1.3. $\\forall i\\forall j(\\s(i)=\\s(j)\\rightarrow i=j)$（$\\s$ 是单射）\nAxiom 1.4. $\\forall i(\\s(i)\\ne 0)$\nAxiom 1.5. $\\forall A((0\\in A\\land \\forall n(n\\in A\\rightarrow \\s(n)\\in A))\\rightarrow \\N\\subseteq A)$（数学归纳法原理）\nProperty 1.1. $\\N=\\set{0}\\cup \\s(\\N)$，或者说 $\\s$ 是到 $\\N\\setminus\\set{0}$ 的满射（从而是双射）。\nProof. 3 和 6 保证了两个方向。\nDefinition 1.1. 加法，利用逐点归纳定义，$m+\\s(n)=\\s(m+n)$。我们将 $m+1$ 与 $\\s(m)$ 划等号。\nDefinition 1.2. 乘法，利用逐行归纳定义，$m\\cdot \\s(n)=m\\cdot n+m$。\n下文中的归纳，均依赖于 Axiom 1.5。\nProperty 1.2. $\\forall a(0+a=a+0=a)$（加法幺元）\nProof. $0+a=a$ 只需对 $a$ 归纳。\nProperty 1.3. $\\forall a\\forall b(a+b=b+a)$（加法交换律）\nProof. 对 $b$ 归纳。一种方法是，只需证明 $\\s(b)+a=\\s(b+a)$，对 $a$ 归纳，命题为 $\\s(b)+\\s(a)=\\s(b+\\s(a))$，由 $\\s(b)+\\s(a)\\xlongequal{\\text{def}}\\s(\\s(b)+a)\\xlongequal{\\text{ind}}\\s(\\s(b+a))\\xlongequal{\\text{def}}\\s(b+\\s(a))$ 得。另一种方法是，借助结合律，先证 $a+1=1+a$，再得 $a+\\s(b)=a+(b+1)=(a+b)+1=(b+a)+1=b+(a+1)=b+(1+a)=(b+1)+a=\\s(b)+a$。\nProperty 1.4. $\\forall a\\forall b\\forall c((a+b)+c=a+(b+c))$（加法结合律）\nProof. 对 $c$ 归纳，不用 Property 1.3。可能需要单独证 $c=1$ 情况。\nProperty 1.5. $\\forall a\\forall b\\forall c(a+c=b+c\\rightarrow a=b)$（加法消去律）\nProperty 1.6. $\\forall a(1\\cdot a=a\\cdot 1=a)$（乘法幺元）\nProperty 1.7. $\\forall a\\forall b(a\\cdot b=b\\cdot a)$（乘法交换律）\nProof. 同样首先证明 $\\s(b)\\cdot a=b\\cdot a+a$，对 $a$ 归纳，命题为 $\\s(b)\\cdot\\s(a)=b\\cdot\\s(a)+\\s(a)$，由 $\\s(b)\\cdot\\s(a)\\xlongequal{\\text{def}}\\s(b)\\cdot a+\\s(b)\\xlongequal{\\text{ind}}b\\cdot a+a+\\s(b)\\xlongequal{\\text{def}}b\\cdot a+\\s(a+b)\\xlongequal{\\text{P1.3}}b\\cdot a+\\s(a)+b\\xlongequal{\\text{com}}b\\cdot a+b+\\s(a)\\xlongequal{\\text{def}}b\\cdot\\s(a)+\\s(a)$ 得。于是原命题对 $b$ 归纳，$a\\cdot\\s(b)=a\\cdot b+a=b\\cdot a+a=\\s(b)+a$。\nProperty 1.8. $\\forall a\\forall b\\forall c((a\\cdot b)\\cdot c=a\\cdot(b\\cdot c))$（乘法结合律）\nProof. 对 $c$ 归纳，利用 Property 1.9。\nProperty 1.9. $\\forall a\\forall b\\forall c((a+b)\\cdot c=a\\cdot c+b\\cdot c)$（乘法对加法的分配律）\nProof. 对 $c$ 归纳。\nProperty 1.10 $\\forall a\\forall b\\forall c((c\\ne 0\\land a\\cdot c=b\\cdot c)\\rightarrow a=b)$（乘法消去律）\nDefinition 2. 整数集，以“减法字符串”定义其中的元素，同时定义了①相等的判断、②元素的加法、③元素的乘法。同时证明了加法和乘法是良定义的。同时定义了 $\\Z_+$ 是 $\\N\\setminus\\set{0}$ 对应的部分。\nP.S. 我们常用的整数集实际上是书里这个整数集关于等价关系 $m+q=p+n\\Leftrightarrow m-n=p-q$ 的商集。\n下文的 $0$ 代指 $0-0$。\nProperty 2.1\u0026amp;2\u0026amp;3. 加法幺元、交换律、结合律\nProperty 2.4 $\\forall a\\exists b(a+b=b+a=0)$ 且 $b=-a$ 唯一（加法逆元）\nProof. 构造容易，证唯一性可以不用抽象代数的方法：设 $a+b=a+c=0$，即 $(a_1+b_1)-(a_2+b_2)=(a_1+c_1)-(a_2+c_2)$，即 $a_1+b_1+a_2+c_2=a_1+c_1+a_2+b_2$，利用 Property 1.5 得 $b_1+c_2=c_1+b_2$ 即 $b=c$。\nProperty 2.5\u0026amp;6\u0026amp;7\u0026amp;8. 乘法幺元、交换律、结合律、分配律\nProperty 2.9. $\\forall a([a\\in\\Z_+]+[a=0]+[-a\\in\\Z_+])=1$\nProof. $\\ge 1$ 好证，$\\le 1$ 的证明方法是，如果 $a\\in\\Z_+\\land-a\\in\\Z_+$，则设 $a_1-a_2=\\s(k)-0$，$a_2-a_1=\\s(l)-0$，两式相加得 $0-0=(\\s(k)+\\s(l))-0=\\s(\\s(k)+l)-0$ 与 $\\s(\\cdot)\\not\\equiv 0$ 矛盾。\nP.S. 再次注意，这里“两式相加”的操作基于的是等号和加号的良定义性。\nP.S. 环，自动有加法幺元等于乘法零元（$a\\cdot 0=a\\cdot (0+0)=a\\cdot 0+a\\cdot 0$ 两边消去）\nCorollary 2.1. $\\forall a(-(-a)=a)$\nCorollary 2.2. $\\forall a(a=-a\\leftrightarrow a=0)$\nCorollary 2.3. $\\forall a\\forall b(a,b\\in\\N\\rightarrow a+(-b)=a-b)$\nCorollary 2.4. $\\forall a\\forall b(a\\cdot(-b)=(-a)\\cdot b=-(a\\cdot b))$\nDefinition 3. 有理数集，以“分数字符串”定义其中的元素，同时定义了①相等的判断、②元素的加法、③元素的乘法。同时证明了加法和乘法是良定义的。同时定义了 $\\Q_+$ 是分子分母均为正整数对应的部分。\n下文的 $0,1$ 分别代指 $0/1,1/1$。\nProperty 3.1\u0026amp;2\u0026amp;3\u0026amp;4 加法幺元、交换律、结合律、逆元\nProperty 3.5\u0026amp;6\u0026amp;7\u0026amp;8. 乘法幺元、交换律、结合律、分配律\nProperty 3.9. $\\forall a(a\\ne 0\\rightarrow\\exists b(a\\cdot b=b\\cdot a=1))$ 且 $b=a^{-1}$ 唯一（乘法逆元）\nCorollary 3.1\u0026amp;2\u0026amp;3\u0026amp;4. 同上\nCorollary 3.5. $\\forall a(a\\ne 0\\rightarrow(a^{-1})^{-1}=a)$\nCorollary 3.6. $\\forall a(a=a^{-1}\\leftrightarrow a=1)$\nCorollary 3.7. $\\forall a(a\\ne 0\\rightarrow(-a)^{-1}=-(a^{-1}))$\nCorollary 3.8. $\\forall a\\forall b(a,b\\ne 0\\rightarrow (ab)^{-1}=a^{-1}b^{-1})$\nCorollary 3.9. $\\forall a\\forall b((a,b\\in\\Z\\land b\\ne 0)\\rightarrow a\\cdot b^{-1}=a/b)$\nCorollary 3.10. $\\forall a\\forall b((a,b\\in\\Z\\land b\\ne 0)\\rightarrow a/(-b)=(-a)/b=-(a/b))$\nCorollary 3.11. $\\forall a\\forall b((a,b\\in\\Z\\land a,b\\ne 0)\\rightarrow (a/b)^{-1}=b/a)$\nDefinition 4. 序关系，利用减法与 $\\Q_+$ 定义；序域。\nCorollary 4.1. $\\forall a\\forall b([a\u0026lt;b]+[a=b]+[a\u0026gt;b]=1)$（三分律）\nCorollary 4.2. $\\forall a\\forall b\\forall c(a\u0026lt;b\\rightarrow a+c\u0026lt;b+c)$\nCorollary 4.3. $\\forall a\\forall b\\forall c((a\u0026gt;0\\land b\u0026gt;0\\land c\u0026gt;0)\\rightarrow(a\u0026lt;b\\rightarrow a\\cdot c\u0026lt;b\\cdot c))$\nCorollary 4.4. $\\forall a(a\\le a)$（自反性）\nCorollary 4.5. $\\forall a\\forall b((a\\le b\\land b\\le a)\\rightarrow(a=b))$（反对称性）\nCorollary 4.6. $\\forall a\\forall b\\forall c((a\\le b\\land b\\le c)\\rightarrow(a\\le c))$（传递性）\nCorollary 4.7. $\\forall a\\forall b\\forall c\\forall d((a\\le b\\land c\\le d)\\rightarrow a+c\\le b+d)$\nCorollary 4.8. $\\forall a\\forall b\\forall c\\forall d((0\\le a\\le b\\land 0\\le c\\le d)\\rightarrow a\\cdot c\\le b\\cdot d)$\nCorollary 4.1\u0026amp;2\u0026amp;3 说明 $\\Q$ 是一个序域。显然序域一定是无限的，且一定构成全序集。Corollary 4.4\u0026amp;5\u0026amp;6 是全序集的定义，从而是序域的性质。\nTheorem 4.1. $\\Q$ 是最小的序域，这个“最小”的意义在证明中给出。\nProof. 考虑域 $\\F$。考虑其乘法幺元，它可以通过加法得到 $\\Z$（它在加法群里的生成子群必须是无限的，否则无序），再通过乘法得到 $\\Q$。\nDefinition 5. 实数集，以 Dedekind 分割定义。上面的 Definition 1\u0026amp;2\u0026amp;3\u0026amp;4 都没写明定义，这里很重要，所以写一下。\n实数的四则运算和全序的性质略。\n（from ycx）当我们定义一个结构的时候，有两种方法——一种是把它直接构造出来，一种是用一些不自相矛盾的公理声明这个结构所满足的性质，并“声称它存在”。例如 $\\N$，第一种定义方法是用 ZFC 的无穷公理加 $\\sup$ 构造 $M=\\set{\\varnothing,\\set{\\varnothing},\\set{\\varnothing,\\set{\\varnothing}},\\cdots}$，一种就是用 Peano 公理。给出了存在性，然后容易验证其唯一性（唯一用同构映射定义）。\n那么 $\\R$ 也是一样的。我们先给出它的构造性定义。\n（Dedekind 分割）实数 $A$ 是一个集合，它满足：\n$A\\subset\\Q$ $A$ 存在上界 $\\forall x\\forall y((x\\in A\\land y\u0026lt;x)\\rightarrow y\\in A)$ 若 $A$ 存在上确界，则 $A$ 的上确界 $\\in A$。 $\\R$ 就是所有这样的 $A$。\n定义实数的 $\\le$ 就是 $\\subseteq$。定义 $A+B=\\set{x+y\\mid x\\in A,y\\in B}$。定义 $A\\cdot B=\\overline{\\set{xy\\mid x\\in\\overline{A},y\\in\\overline{B}}}$。\n解释：在 $\\Q$ 上，不是所有有上界的集合都有上确界。\n4 不成立的话就会出现 $\\set{x\\mid x\u0026lt;1}$ 的东西，或者说可以理解为造成 $0.999\\cdots\\ne 1$。\n我们再给出公理法定义。\n（Dedekind 原理，$1$）$\\R$ 满足： $$ \\forall A\\forall B((A\\subseteq\\R\\land B\\subseteq\\R\\land A\\ne\\varnothing\\land B\\ne\\varnothing\\land\\forall a\\forall b((a\\in A\\land b\\in B)\\rightarrow a\\le b))\\rightarrow\\exists c\\forall a\\forall b((a\\in A\\land b\\in B)\\rightarrow a\\le c\\le b)) $$ 后面我们就尽量不用反人类语言了。\n说的是，任何非空集 $A$，$B\\subset\\R$，$A$ 中元素全部 $\\le$ $B$ 中元素，那么存在一个 $c$ 夹在 $A$，$B$ 之间。\n我们给出一些等价的公理：\n（确界原理，$2$）$\\R$ 满足：\n$\\forall A\\subseteq\\R$，$A\\ne\\varnothing$，$A$ 有上界 $\\Rightarrow$ $A$ 有上确界。\n$1\\Rightarrow 2$：对于 $A$，取 $B=\\set{b\\mid\\forall a,a\\le b}$。由于 $A$ 有上界，故 $B\\ne\\varnothing$。由 1，得到一个 $c$，这个 $c$ 是 $A$ 的上界，接下来说明是上确界。如果有更小的上界 $c^\\prime\u0026lt;c$，那么 $c^\\prime\\in B$，与 $c$ 是 $B$ 的下界矛盾。\n$2\\Rightarrow 1$：在 1 的 $\\exists c$ 中，取 $c=\\sup A$。既然 $\\forall a\\in A$，$b\\in B$，都有 $a\\le b$，那么 $B$ 中的元素都是 $A$ 的上界，于是 $c$ 不可能大于 $B$ 中的元素，于是 $c$ 满足条件。\n（单调有界定理，$3$）$\\R$ 上的数列 $a$ 如果单调有界，则必收敛（$\\exists A\\forall\\varepsilon\\exist N\\forall n(n\u0026gt;N\\rightarrow |a_n-A|\u0026lt;\\varepsilon)$）。\n$2\\Rightarrow 3$：直接用确界就行。\n$3\\Rightarrow 2$：构造数列 $\\set{a_n}$：$a_1$ 为 $A$ 中任一数（不妨设 $a_1$ 不是上界，否则就证完了），$a_{n+1}$ 通过 $a_n+d$ 得到，$d$ 这样确定：一开始考虑 $d=1$，如果 $a_n+d$ 成为上界了，就将 $d$ 除以 $2$。我们首先证明 $d$ 一定能取到——如果取不到，就意味着，$\\forall k\\ge 0$，$a_n+2^{-k}\\ge\\forall a\\in A$，（$\\Alpha^\\prime$）故 $a_n\\ge\\forall a\\in A$，也就是说 $a_n$ 就是上界了，这与构造 $d$ 的方式矛盾。\n然后我们证明 $l=\\lim_{n\\to\\infty}a_n$ 是上确界。如果 $l$ 不是上界，设 $A\\ni a\u0026gt;l$，取 $\\varepsilon=a-l$，那么有 $l-\\varepsilon\u0026lt;a_n\\le a$。如果 $a_{n+1}\\ne a_n$，那么 $d$ 可以大一倍；如果 $a_{n+1}=a_n$，那由（$\\Alpha^\\prime$）也是不对的。如果 $l$ 不是确界，设 $l^\\prime\u0026lt;l$ 也是上界，取 $\\varepsilon=l-l^\\prime$，那就有 $A\\ni a\u0026gt;l^\\prime$ 了，矛盾。\n最后证 $\\Alpha^\\prime$：$\\lim_{n\\to\\infty}2^{-n}=0$（与阿基米德性等价）。首先它一定有极限，然后如果它 $\u0026gt;0$，设为 $L$，取 $\\varepsilon=L$，那么有 $2^{-n}\u0026lt;2L$，那么 $2^{-(n+1)}\u0026lt;L$，矛盾。\n既然提到了，那也顺便讲好吧。\n（Archimedes 性，$\\Alpha$）任意实数都不是 $\\N$ 的上界。\n$2\\Rightarrow\\Alpha$：设有，那一定有上确界 $s$，那么 $\\exists n\\in\\N$，$n\u0026gt;s-1$，故 $n+1\u0026gt;s$，矛盾。\n（致密性定理，$4$）有界实数列必有收敛子列。\n$2+3\\Rightarrow 4$：构造子列 $\\set{b_n}$：如果 $\\set{a_n}$ 的上确界包含其中，为 $a_s$，那么取 $b_1=a_s$，接着看 $\\set{a_{n+s}}$ 的上确界，以此类推。如果一直有，那么构造出单调不升的有界数列 $b$，收敛；如果某次发现上确界不包含其中了，那可以构造 $b_1=$ 此后随便一个数，然后 $b_{n+1}$ 为 $b_n$ 之后随便一个 $\u0026gt;b_n$ 的数（不可能不存在，否则由有限情况 $\\sup=\\max$ 就存在确界了），这样构造出单调不降的有界数列 $b$，收敛。\n$3\\Rightarrow 4$：设 $\\set{a_n}$ 界为 $[l,r]$，取 $[l,(l+r)/2]$ 和 $[(l+r)/2,r]$ 之中，包含 $\\set{a_n}$ 中无限项的一个区间，不断推下去。取 $b_i$ 为第 $i$ 次区间中对应的任意元素，只需保证 $b$ 取的下标递增即可（由于无限项，故一定可以取到）。$3$ 可得区间左右端点都收敛，由夹逼定理，$\\set{b_n}$ 收敛。注意夹逼定理是不需要任何公理就可以证明的。\n$2\\Rightarrow 4$ 直接把 $3\\Rightarrow 4$ 里的单调有界换成确界即可。\n$4\\Rightarrow 3$：取这个单调有界数列 $\\set{a_n}$ 的收敛子列 $\\set{b_n}$，$\\forall\\varepsilon\u0026gt;0$，$\\set{b_n}$ 中有一项及之后都与极限值差少于 $\\varepsilon$，取 $b$ 中这项对应 $a$ 中位置及之后即可。\n（聚点定理，$5$）$\\R$ 的有界无限子集 $S$ 必有聚点。\n$4\\Rightarrow 5$：构造 $\\set{a_n}$，$a_{n+1}$ 取 $S\\setminus\\set{a_{1\\sim n}}$ 中任一点，于是我们找到一个收敛点列，它收敛到的点就是聚点。\n$5\\Rightarrow 4$：将有界数列视作有界无限集，取一聚点 $A$，取数列 $\\set{b_n}$，$b_i$ 为 $\\mathring{U}(A,1/i)$ 内的一个点，同时保证 $b$ 对应在 $a$ 中的位置递增（这是可以做到的，因为 $\\mathring{U}(A,1/i)$ 里有无限个点）。由 $\\Alpha^{\\prime\\prime}$，$\\set{b_n}$ 收敛到 $A$。\n$\\Alpha^{\\prime\\prime}$：$\\lim_{n\\to\\infty}1/n=0$。这个也和 $\\Alpha$ 等价，可以直接用 $5$ 导出。\n（有限覆盖定理，$6$）如果开区间 $\\cal I$ 构成了闭区间 $[a,b]$ 的覆盖，则它有一个有限子集也是 $[a,b]$ 的覆盖。\nRemark. 这个对 $\\Q$ 不成立的原因是，在 $\\Q$ 上 $[-\\sqrt2,+\\sqrt2]\\cap\\Q$ 是闭集（同时也是开集），只需搞一列不跨 $\\sqrt2$ 的区间覆盖它就是反例。\n$2\\Rightarrow 6$：设 $S=\\set{x\\le b\\mid [a,x]\\,可以被有限覆盖}$，$S$ 有上确界 $s$。找 $\\cal I$ 中包含 $s$ 的开区间 $(l,r)$，显然 $l\\in S$，因此 $(s+r)/2\\in S$，与 $\\sup S=s$ 矛盾。\nRemark. 如果 $b$ 开，那么 $\\cal I$ 中可能找不到包含 $s$ 的区间。\n$6\\Rightarrow 2$：假设有界集合 $A\\subseteq[a,b]$ 无上确界。现在我们考虑构造一些覆盖 $[a,b]$ 开区间。对于 $x$，如果 $x$ 不是 $A$ 的上界，即 $\\exists A\\ni y\u0026gt;x$，则取 $(2x-y,y)$；如果 $x$ 是 $A$ 的上界，即 $\\exists y\u0026lt;x$ 也是 $A$ 的上界，则取 $(y,2x-y)$。每个 $x$ 搞出一个开区间，这些区间形成一个覆盖，必有有限子集也是覆盖。但这些区间的每个，要么在某个 $a\\in A$ 左侧，要么在所有 $a\\in A$ 右侧，因此必存在一个 $a$ 处于这两类区间之间，没被覆盖到，矛盾。\n$6\\Rightarrow 5$：假设 $S\\subseteq[a,b]$ 无聚点，那么每个点都存在一个开邻域只包含它本身一个 $S$ 中的点。取 $[a,b]$ 的每个点的这样的开邻域，它们的一个有限子集同样形成 $[a,b]$ 的覆盖，与 $S$ 无限矛盾。\n（柯西收敛定理，$\\text{C}$）数列 $a$ 收敛，当且仅当 $\\forall\\varepsilon\\exists N\\forall m\\forall n(m,n\u0026gt;N\\rightarrow|a_m-a_n|\u0026lt;\\varepsilon)$。\n$4\\Rightarrow\\text{C}$：一个方向是显然的，也不需完备性。另一个方向：显然 $a$ 有界。找到其一个收敛子列，容易利用柯西列性质证明整个序列也收敛到这个值。\n（闭区间套定理，$\\text{N}$）对于不降数列 $\\set{a_n}$ 和不增数列 $\\set{b_n}$，如果 $a_n\\le b_n$，且 $\\lim_{n\\to\\infty}(b_n-a_n)=0$，那么存在 $c$，$\\lim_{n\\to\\infty}a_n=\\lim_{n\\to\\infty}b_n=c$ 且 $c$ 是满足 $\\forall n$，$a_n\\le c\\le b_n$ 的唯一数。\n$1/2/3\\Rightarrow\\text{N}$：证明至多一个不需要完备性，只需用极限的定义；证明存在一个，可以构造 $A=\\set{a\\mid\\exists a_n\\ge a}$ 和 $B=\\set{b\\mid\\exists b_n\\le b}$ 后用 $1$，也可以直接对 $\\set{a_n}$ 用 $2/3$。\n$\\text{C}\\Rightarrow\\text{N}$： $$ \\begin{align*} \\lim_{n\\to\\infty}(b_n-a_n)=0\u0026amp;\\Rightarrow\\fbox{blabla}(n\u0026gt;m\u0026gt;N\\rightarrow|b_m-a_m-b_n+a_n|\u0026lt;\\varepsilon)\\\\ \u0026amp;\\Rightarrow\\fbox{blabla}(n\u0026gt;m\u0026gt;N\\rightarrow a_n-a_m\u0026lt;\\varepsilon\\land b_m-b_n\u0026lt;\\varepsilon)\\\\ \u0026amp;\\Rightarrow\\lim_{n\\to\\infty}a_n=A\\land\\lim_{n\\to\\infty}b_n=B \\end{align*} $$ 然后就是证明 $\\forall a_n\\le A,B\\le\\forall b_n$，再说明 $A=B$ 即可。\n$\\text{N}\\Rightarrow\\text{C}$：对于一个柯西列，构造一列不断缩紧的区间，我们的想法是，考虑一个收敛于 $0$ 的正数列 $\\set{d_n}$。根据柯西列的性质，每个 $d_n$ 都可以找到一个 $N_n$，使 $\\forall m\u0026gt;N_n$，$|a_m-a_{N_n}|\u0026lt;d_n$。这样，取 $[l_n,r_n]=[a_{N_n}-d_n,a_{N_n}+d_n]\\cap[l_{n-1},r_{n-1}]$，这样就得到了一个符合条件的闭区间列，于是就搞出了极限 $c$。要证明 $\\set{a_n}$ 极限为 $c$，$\\forall\\varepsilon\u0026gt;0$，找到 $d_m\u0026lt;\\varepsilon/2$，于是 $c$ 和 $\\set{a_{n+N_m}}$ 的所有元素都在这个长度 $\u0026lt;\\varepsilon$ 的区间 $[l_m,r_m]$ 中。\n但是怎么找 $\\set{d_n}$ 呢？你发现没了 $\\Alpha$，啥都干不成。但是这里摆着一个几乎能用的序列——$\\Delta\\set{a_n}$，但是要去掉里面为 $0$ 的项。因此要特殊讨论一下 $\\Delta\\set{a_n}$ 只有有限项非零的情况。\n$\\text{N}+\\Alpha\\Rightarrow 2$：对于有上界的集合 $A$，取区间 $[a,s]$，其中 $a\\in A$（可以假设 $a$ 不是上界），$s$ 是 $A$ 的上界。每次取区间中点，如果中点是上界，那么往左半缩小，否则往右半缩小。根据 $\\Alpha$，区间长度 $\\to 0$。根据保序性，极限是上界。如果不是上确界，容易得到某个区间的左端点也不是上界，从而与构造矛盾。\n$\\text{N}+\\Alpha\\Rightarrow 3/4$ 都很简单。\n实际上，连续函数的一些性质也可以作为实数公理，但这里就略去了。\n容易验证 Dedekind 分割构造的集合满足公理，那么现在考虑唯一性。\nTheorem 5.1. $\\R$ 是唯一的完备序域。\nProof. 设这样的序域为 $\\F$。首先 $\\F$ 一定包含 $\\Q$，设 $\\varphi$ 是自然嵌入，我们考虑扩展 $\\varphi$。$\\forall A\\in\\R$，$\\sup\\varphi(A)$（显然上界存在，又由确界原理）在 $\\F$ 中找到了 $A$ 对应的元素，同时上确界的唯一性很重要。如果 $\\F$ 中还有别的元素 $x$，拿出 $\\set{y\\mid y\\le x}\\cap\\varphi(\\Q)=X$，由阿基米德性，$\\varphi(\\Q)$ 中有 $\u0026gt;x$ 的元素，因此 $\\varphi^{-1}(X)$ 的上界存在，从而 $x=\\varphi\\left[\\sup{\\varphi^{-1}(X)}\\right]$。于是就双射了。\nTheorem 5.2. $\\R$ 中有理数和无理数都是稠密的。\nProof. $\\forall a,b\\in\\R$，$a\u0026lt;b$，由阿基米德性，$\\exist n\\in\\N_+$，$1/n\u0026lt;b-a$。取 $c=\\sup\\set{k/n\\mid k\\in\\Z}\\cap(-\\infty,b)$，同理可证这个交非空，然后 $c$ 就是 $\\in(a,b)$ 的有理数。找到 $\\left(a-\\sqrt 2,b-\\sqrt 2\\right)$ 中的一个有理数 $c^\\prime$，$c\u0026rsquo;+\\sqrt{2}$ 就是 $\\in(a,b)$ 的无理数。\nP.S. 尽管 $(a,b)$ 尚未定义，但这里可以不用这个语言，所以只是为了方便才这么写。\nExample 5.1. $\\set{x\\mid x\u0026lt;0\\lor x^2\u0026lt;2}$ 对应的实数不是有理数。\nTheorem 5.3. 定义区间 $I$ 为满足 $\\forall x\u0026lt;y\\in I,\\forall x\u0026lt;z\u0026lt;y,z\\in I$ 的集合。则 $I$ 只可能是 $[a,b]$、$[a,b)$、$(a,b]$、$(a,b)$、$(-\\infty,b]$、$(-\\infty,b)$、$[a,+\\infty)$、$(a,+\\infty)$、$(-\\infty,+\\infty)$ 中的一类。\nTheorem 5.4. $y=x^n\\,(n\\in\\N_+)$ 在 $[0,+\\infty)$ 上严格单调递增；对于 $y\\ge 0$，对应的 $x$ 唯一存在。\nProof. 考虑归纳。由 Corollary 4.8，对于 $0\\le x_1\u0026lt;x_2$，$x_1^n\u0026lt;x_2^n\\rightarrow x_1^{n+1}\u0026lt;x_2^{n+1}$。\n考虑解 $x_0=\\sup\\set{x\\mid x^n\u0026lt;y}$。由于 $\\max\\set{y,1}^n\\ge y$ 故上界存在。\n如果 $x_0^n\u0026lt;y$，那么考虑构造 $[x_0(1+\\varepsilon)]^n\u0026lt;y$ 即 $(1+\\varepsilon)^n\u0026lt;y/x_0^n$，这个构造可考虑放缩 $$ (1+\\varepsilon)^n=\\frac{1}{\\left(\\frac{1}{1+\\varepsilon}\\right)^n}=\\frac{1}{\\left(1-\\frac{\\varepsilon}{1+\\varepsilon}\\right)^n}\u0026lt;\\frac{1}{1-\\frac{n\\varepsilon}{1+\\varepsilon}}\u0026lt;\\frac{y}{x_0^n}\\Rightarrow\\frac{n\\varepsilon}{1+\\varepsilon}\u0026lt;1-\\frac{x_0^n}{y} $$ 解一下可以解出合适的 $\\varepsilon\u0026gt;0$，于是与 $x_0$ 是上界矛盾；如果 $x_0^n\u0026gt;y$，那么考虑构造 $(1-\\varepsilon)^n\u0026gt;1-n\\varepsilon\u0026gt;y/x_0^n$，与 $x_0$ 是确界矛盾。\nDefinition 6.1. 对于 $y\\ge 0$，$\\sqrt[n]{y}$ 为使得 $x^n=y$ 的唯一的 $x$。\nP.S. 这类定义问题可以利用连续性和介值定理作为通法证明存在性，但这里就不讲这种方法了。\nDefinition 6.2. 对于 $y\u0026gt;0$，$y^{m/n}=\\left(\\sqrt[n]{y}\\right)^m$。\nDefinition 6.3. 对于 $y\\ge 1$，$y^\\alpha=\\sup_{a\\in(-\\infty,\\alpha]\\cap\\Q}\\set{y^a}$；对于 $0\u0026lt;y\u0026lt;1$，$y^\\alpha=(1/y)^{-\\alpha}$。\nP.S. 这里我们只考虑 $y\\ge 0$ 的情况。$y\u0026lt;0$ 属于复变函数的内容。\nCorollary 6.1. 指数函数和幂函数的运算法则和单调性等。略。\nTheorem 5.5. 对于 $a\u0026gt;1$，$y=a^x$ 在 $\\R$ 上严格单调递增；对于 $y\u0026gt;0$，对应的 $x$ 唯一存在。\nLemma. $\\inf_{n\\in\\N_+}\\set{a^{1/n}}=1$。\nProof. $a^{1/n}\u0026gt;1$ 故下界存在且 $\\ge 1$。如果下界为 $b\u0026gt;1$ 则 $\\forall n$，$a^{1/n}\\ge b\\Rightarrow a\\ge b^n\u0026gt;1+n(b-1)$ 即 $n\u0026lt;(a-1)/(b-1)$，与 $\\Alpha$ 矛盾。\nProof. 我们可以不依赖 Corollary 6.1 证明单调性。对于 $x_1\u0026lt;x_2$，由 Theorem 5.2，$\\exists q_1/p_1\u0026lt;q_2/p_2\\in(x_1,x_2)\\cap\\Q$。我们知道 $a^{q_2/p_2}/a^{q_1/p_1}=\\left(\\sqrt[p_1p_2]{a}\\right)^{q_2p_1-q_1p_2}\\ge\\sqrt[p_1p_2]{a}\u0026gt;\\sqrt[p_1p_2]{1}=1$。于是 $a^{x_1}\\le x^{q_1/p_1}\u0026lt;x^{q_2/p_2}\\le a^{x_2}$。\n考虑解 $x_0=\\sup\\set{x\\mid a^x\u0026lt;y}$。由于 $a^{\\lceil(y-1)/(a-1)\\rceil}\u0026gt;y$（根据伯努利不等式）故上界存在。\n如果 $a^{x_0}\u0026lt;y$，则 $\\exists n$，$a^{1/n}\u0026lt;y/a^{x_0}$，故 $a^{x_0+1/n}\u0026lt;y$，与 $x_0$ 是上界矛盾；如果 $a^{x_0}\u0026gt;y$ 也是类似的。\nDefinition 6.4. 对于 $y\u0026gt;0$，$a\u0026gt;1$，$\\log_ay$ 为使得 $a^x=y$ 的唯一的 $x$；对于 $0\u0026lt;a\u0026lt;1$，$\\log_ay=-\\log_{1/a}y$。\nCorollary 6.2. 对数函数的运算法则和单调性等。略。\nP.S. 我们可以用 $x^\\alpha=\\mathrm{e}^{\\alpha\\ln x}$ 来定义幂函数，但我看不出有什么必要。\nDefinition 6.5. 定义 $\\sin x$ 和 $\\cos x$ 为满足以下公理的两个 $\\R\\to\\R$ 的函数（可以说明它们是唯一的）：\n$\\cos 0=\\sin\\pi/2=1$，$\\cos\\pi=-1$。 $\\cos(x-y)=\\cos x\\cos y+\\sin x\\sin y$。 $\\forall x\\in(0,\\pi/2)$，$0\u0026lt;\\cos x\u0026lt;\\sin x/x\u0026lt;1/\\cos x$。 定积分理论 Definition 0. 一个区间 $[a,b]$ 的划分 $P$ 为一个有限的严格递增列 $a=x_0\u0026lt;x_1\u0026lt;\\cdots\u0026lt;x_n=b$。定义其范数 $\\lVert P\\rVert=\\max{x_{i}-x_{i-1}}$。\nDefinition 1. 对于定义在 $[a,b]$ 上的有界函数 $f$，与一个 $[a,b]$ 的划分 $P$，定义 $f$ 关于 $P$ 的 Darboux 上和为 $$ \\overline{S}(f,P)=\\sum_{i=1}^n(x_i-x_{i-1})\\cdot\\sup_{x\\in[x_{i-1},x_i]}f(x) $$ 下和同理。\nDefinition 2. （语境略）定义 Darboux 上积分为 $$ \\overline{S}(f)=\\overline{\\int_a^b}f(x)\\d x=\\inf_P\\overline{S}(f,P) $$ 下积分同理。如果上下积分存在且相等，就定义 Darboux 积分为这个相等的值，称 $f$ 在 $[a,b]$ 上 Darboux 可积。\nProperty 1. 对于两个划分 $P$，$Q$，$\\underline{S}(f,P)\\le\\underline{S}(f,P\\cup Q)\\le\\overline{S}(f,P\\cup Q)\\le\\overline{S}(f,Q)$。\nProof. 直接使用 $\\inf$ 和 $\\sup$ 的性质。\nTheorem 1. $$ \\underline{S}(f)=\\overline{S}(f) \\Longleftrightarrow\\forall\\varepsilon\u0026gt;0,\\exists P,\\overline{S}(f,P)-\\underline{S}(f,P)\u0026lt;\\varepsilon \\Longleftrightarrow\\exists I,\\forall\\varepsilon\u0026gt;0,I-\\varepsilon\u0026lt;\\underline{S}(f,P)\\le I\\le\\overline{S}(f,P)\u0026lt;I+\\varepsilon $$ Proof. 只证 $2\\Rightarrow 3$。取 $I=\\underline{S}(f)$。$\\forall\\varepsilon\u0026gt;0$，$\\exists P$，$\\underline{S}(f,P)\\le I\\le\\overline{S}(f)\\le\\overline{S}(f,P)\u0026lt;\\underline{S}(f,P)+\\varepsilon\\le\\underline{S}(f)+\\varepsilon$。\nProperty 2. （大前提有界）递增函数、连续函数、间断点有限函数均 Darboux 可积。\nProof. 递增函数：$\\overline{S}(f,P)-\\underline{S}(f,P)\\le(f(b)-f(a))\\lVert P\\rVert$。连续函数：利用一致连续性。间断点有限函数：在各间断点处搞个足够小的区间。\nProperty 3. $(a,b)$ 上连续的函数也 Darboux 可积。\nProof. 设极差为 $M$。对于 $\\varepsilon$，考虑左右两端取短段 $\\delta$ 以排除端点处震荡间断的影响，于是 $[a+\\delta,b-\\delta]$ 上一致连续。对于中间，如果对于 $\\varepsilon^\\prime$ 来说，一致连续保证 $\\delta^\\prime$ 内震荡 $\u0026lt;\\varepsilon^\\prime$，则总的就是 $$ \\overline{S}(f,P)-\\underline{S}(f,P)\\le2\\delta M+(b-a-2\\delta)\\varepsilon^\\prime $$ 取要求 $\\varepsilon^\\prime=\\varepsilon/2(b-a)$，以及 $\\delta=\\min{\\delta^\\prime,\\varepsilon/4M}$ 即可。\nDefinition 3. 在 $P$ 的基础上额外加一组表示点 $\\xi_{1\\sim n}$，$\\xi_i\\in[x_{i-1},x_i]$。定义对应的 Riemann 和 $$ S(f,P,\\xi)=\\sum_{i=1}^n(x_i-x_{i-1})f(\\xi_i) $$ 如果 $\\exists I$，$\\forall\\varepsilon\u0026gt;0$，$\\exists\\delta\u0026gt;0$，$\\forall P:\\lVert P\\rVert\u0026lt;\\delta$，$\\forall\\xi$，$|S(f,P,\\xi)-I|\u0026lt;\\varepsilon$，则称 $I$ 为 $f$ 在 $[a,b]$ 上的 Riemann 积分，$f\\in\\mathscr{R}[a,b]$。 $$ I=\\int_a^bf(x)\\d x $$ Remark. Darboux 定义的是无向的积分，更容易高维推广；Riemann 定义的是有向积分，处理正负更方便。\nDefinition 4. 一个点集为零测度集，定义为，$\\forall\\varepsilon\u0026gt;0$，存在一列开区间覆盖所有点，且长度和 $\u0026lt;\\varepsilon$。\nProperty 4. 可数集为零测度集。\nP.S. 零测度集可能不可数，如康托集。\nTheorem 2.（Darboux 定理）若 $\\overline{S}(f)$ 存在，则 $\\displaystyle\\lim_{\\lVert P\\rVert\\to 0}\\overline{S}(f,P)=\\overline{S}(f)$。（不明确写这个 $\\lim$ 的定义了，容易脑补）\nProof. 设极差为 $M$。$\\forall\\varepsilon\u0026gt;0$，由 $\\inf$ 的定义，$\\exists P$，$\\overline{S}(f,P)\u0026lt;\\overline{S}(f)+\\varepsilon^\\prime$。$\\forall P^\\prime:\\lVert P^\\prime\\rVert\u0026lt;\\delta$，考虑 $\\overline{S}(f,P)$、$\\overline{S}(f,P^\\prime)$ 与 $\\overline{S}(f,P\\cup P^\\prime)$ 的关系：当划分从 $P^\\prime$ 变成 $P\\cup P^\\prime$ 时，至多 $|P|$ 个 $P^\\prime$ 中的区间被细分了，假设这些细分的区间的贡献都变化极大，也就只有 $\\overline{S}(f,P^\\prime)-\\overline{S}(f,P\\cup P^\\prime)\\le|P|\\delta M$。于是 $\\overline{S}(f,P^\\prime)\\le\\overline{S}(f,P\\cup P^\\prime)+|P|\\delta M\\le\\overline{S}(f,P)+|P|\\delta M\u0026lt;\\overline{S}(f)+\\varepsilon^\\prime+|P|\\delta M$。取 $\\delta=\\varepsilon/2|P|M$，$\\varepsilon^\\prime=\\varepsilon/2$ 即可。\nTheorem 3.（Lebesgue 可积性定理）$f$ 在 $[a,b]$ 上 Riemann 可积 $\\Longleftrightarrow$ $f$ 在 $[a,b]$ 上有界且 Darboux 可积 $\\Longleftrightarrow$ $f$ 在 $[a,b]$ 上的间断点为零测度集。\nProof. $1\\Rightarrow 2$ 易（需先证有界）。$2\\Rightarrow 1$ 用 Theorem 2。\n定义 $f$ 在点 $x$ 处的振幅为 $$ \\omega(x)=\\lim_{\\delta\\to 0}\\left(\\sup_{x^\\prime\\in U(x,\\delta)}f(x^\\prime)-\\inf_{x^\\prime\\in U(x,\\delta)}f(x^\\prime)\\right) $$ 那么不连续点即为 $\\omega\u0026gt;0$ 的点。\n$2\\Rightarrow 3$：由于存在划分 $P$ 使得 $\\overline{S}(f,P)-\\underline{S}(f,P)\u0026lt;\\varepsilon/2k$，故所有 $\\omega\\ge1/k$ 的间断点形成的集合 $D_{1/k}$，一定能被长度 $\u0026lt;\\varepsilon$ 的区间覆盖。这是因为，所有处于 $P$ 中非分割端点的 $D_{1/k}$ 中元素，它们对应的总段长至多 $\\varepsilon/2$，在端点处的随意处理。从而 $D_{1/k}$ 是零测度集。现在，所有间断点的集合 $D=\\bigcup_{k=1}^{\\infty}D_{1/k}$，而可数个零测度集的并仍为零测度集。\n$3\\Rightarrow 2$：$\\forall\\varepsilon\u0026gt;0$，我们知道 $D_{\\varepsilon/2(b-a)}$ 可以被一族长度和 $\u0026lt;\\varepsilon/2M$ 的开区间覆盖，对于 $\\omega\u0026lt;\\varepsilon/2(b-a)$ 的每一点，都可以找到其一邻域，该邻域的振幅 $\u0026lt;[\\omega+\\varepsilon/2(b-a)]/2\u0026lt;\\varepsilon/2(b-a)$。于是我们现在得到 $[a,b]$ 的一组开覆盖，从而有有限开覆盖 $C$。将该开覆盖的各端点作为划分点，得到的上下和之差必不超过各开区间振幅乘长度之和，而后者小于 $M\\cdot\\varepsilon/2M+(b-a)\\cdot\\varepsilon/2(b-a)=\\varepsilon$。\n参考：https://zhuanlan.zhihu.com/p/450983357\n狄利克雷判别法 Theorem 1.（微分中值定理）对于 $g\\in\\mathscr{R}[a,b]$，$f$ 在 $[a,b]$ 上单调不增，$\\exists\\xi\\in[a,b]$， $$ \\int_a^bf(x)g(x)\\d x=f(a)\\int_a^\\xi g(x)\\d x+f(b)\\int_\\xi^bg(x)\\d x $$ Proof. 我们先考虑 $f(b)=0$ 的情况。令 $G$ 为 $g$ 的积分上限函数（以 $a$ 为下限），$M$ 为 $g$ 的界。第一步我们希望把乘积的积分的一半拆成和式：对于 $[a,b]$ 的一个划分 $P$， $$ \\begin{align*} \u0026amp;\\left\\lvert\\sum_{i=1}^nf(x_{i-1})\\int_{x_{i-1}}^{x_i}g(x)\\d x-\\int_a^bf(x)g(x)\\d x\\right\\rvert\\\\ ={}\u0026amp;\\left\\lvert\\sum_{i=1}^n\\int_{x_{i-1}}^{x_i}(f(x_{i-1})-f(x))g(x)\\d x\\right\\rvert\\\\ \\le{}\u0026amp;M\\sum_{i=1}^n\\int_{x_{i-1}}^{x_i}(f(x_{i-1})-f(x))\\d x\\\\ \\le{}\u0026amp;M\\sum_{i=1}^n(f(x_{i-1})-f(x_i))(x_i-x_{i-1})\\\\ \\le{}\u0026amp;M|P|\\sum_{i=1}^n(f(x_{i-1})-f(x_i))\\\\ ={}\u0026amp;M|P|f(a)\\to 0\\;(|P|\\to 0) \\end{align*} $$ 从而（$\\in$ 号用了 $f$ 单调的性质） $$ \\begin{align*} \u0026amp;\\int_a^bf(x)g(x)\\d x\\\\ ={}\u0026amp;\\lim_{|P|\\to 0}\\sum_{i=1}^nf(x_{i-1})(G(x_i)-G({x_{i-1}}))\\\\ ={}\u0026amp;\\lim_{|P|\\to 0}\\left(\\sum_{i=0}^{n-1}f(x_i)G(x_{i+1})-\\sum_{i=0}^nf(x_i)G(x_i)\\right)\\\\ ={}\u0026amp;\\lim_{|P|\\to 0}\\left(\\sum_{i=1}^nf(x_{i-1})G(x_i)-\\sum_{i=1}^nf(x_i)G(x_i)\\right)\\\\ ={}\u0026amp;\\lim_{|P|\\to 0}\\sum_{i=1}^n(f(x_{i-1})-f(x_i))G(x_i)\\\\ \\in{}\u0026amp;\\left[\\lim_{|P|\\to 0}\\sum_{i=1}^n(f(x_{i-1})-f(x_i))\\cdot\\min_{x\\in[a,b]}G(x),\\lim_{|P|\\to 0}\\sum_{i=1}^n(f(x_{i-1})-f(x_i))\\cdot\\max_{x\\in[a,b]}G(x)\\right]\\\\ ={}\u0026amp;f(a)\\left[\\min_{x\\in[a,b]}G(x),\\max_{x\\in[a,b]}G(x)\\right] \\end{align*} $$ 由于 $G$ 连续，故存在 $\\xi$ 使 $$ \\int_a^bf(x)g(x)\\d x=f(a)\\int_a^\\xi g(x)\\d x $$ 对于 $f(b)\\ne 0$ 的情况，我们知道存在 $\\xi$ 使 $$ \\int_a^b(f(x)-f(b))g(x)\\d x=(f(a)-f(b))\\int_a^\\xi g(x)\\d x $$ 移项即可。\n参考：https://www.zhihu.com/question/596132013/answer/3487524727\nTheorem 2.（狄利克雷判别法）对于 $g\\in\\mathscr{R}[a,\\forall b]$，$f$ 在 $[a,+\\infty)$ 上单调不增，若 $G$ 有界，$f$ 趋近于 $0$，则 $$ \\int_a^{+\\infty}f(x)g(x)\\d x $$ 存在。\nProof. 考虑使用柯西来判。考虑到 $\\exists\\xi\\in[l,r]$， $$ \\int_l^rf(x)g(x)\\d x=f(l)\\int_l^\\xi g(x)\\d x+f(r)\\int_\\xi^rg(x)\\d x=f(l)(G(\\xi)-G(l))+f(r)(G(r)-G(\\xi)) $$ 由于 $G$ 有界，故只需取足够大的 $l$ 使 $f$ 足够小即可。\n高阶线性微分方程解的存在性 比较复杂（Picard-Lindelöf 定理），先咕了。\n","date":"2025-01-22T00:00:00Z","permalink":"https://littlereuben.github.io/study/course-calculus-0/","title":"微积分的理论基础"},{"content":"$\\gdef\\ker{\\mathop{\\mathrm{Ker}}}\\gdef\\im{\\mathop{\\mathrm{Im}}}\\gdef\\e{\\mathrm{e}}\\gdef\\d{\\mathrm{d}}\\gdef\\F{\\mathbb{F}}\\gdef\\r{\\operatorname{rank}}\\gdef\\L{\\mathsf{L}}\\gdef\\mat#1{\\begin{bmatrix}#1\\end{bmatrix}}\\gdef\\dat#1{\\begin{vmatrix}#1\\end{vmatrix}}\\gdef\\T{\\mathsf{T}}\\gdef\\U{\\mathsf{U}}\\gdef\\E{\\mathsf{E}}$\n这是一篇学习笔记。\r前言 完全从线性变换角度去讲线性代数，主要就是六个递进的难点：秩—零化度定理、行列秩相等、Cayley–Hamilton 定理、对偶、内积空间下的对偶、正交相关定理。反而行列式、SVD、Jordan 之类的没有那么难理解，只是麻烦罢了。\n线性变换最难解释的是转置，转置没有一个直观的意义，例如转置的行列式等于原行列式这种东西。无论是否在内积空间下，转置只能用范畴论去理解，画出对偶的交换图，它其实也是很自然的，但再往后，到了复正规矩阵和实对称矩阵可以正规对角化这里，就完全不懂了，只能背证明。\n但总的来说我线性代数没记特别多东西，Cayley–Hamilton 定理和对偶相关的理解就咕掉了。\n题 只使用线性变换的知识（不使用初等行变换）证明 $\\dim\\ker f+\\dim\\im f=\\dim V$。\n$\\ker f$ 是 $V$ 的一个子空间。取出它的一组基 $\\set{v_{1\\sim n}}$，并将它扩展成 $V$ 的基 $\\set{v_{1\\sim n},v_{n+1\\sim m}}$。现在 $f(v_{1\\sim n})=0$，而我们要证的是，$\\set{f(v_{n+1\\sim m})}$ 线性无关，从而它是 $\\im f$ 的基。 $$ \\sum c_if(v_i)=0\\Longleftrightarrow f\\left(\\sum c_iv_i\\right)=0\\Longleftrightarrow \\sum c_iv_i\\in\\ker f $$ 这里 $\\sum$ 是 $\\sum_{i=n+1}^m$。要么 $c$ 全都是 $0$，要么 $\\set{v_{1\\sim m}}$ 不是基。\n只使用线性变换的知识（不使用初等行变换）证明行秩等于列秩。\n考虑 $A_{n\\times m}$ 的行空间的对偶空间，这个空间就是 $\\F^m/\\ker A$，于是 $$ 行秩=m-\\dim\\ker A=m-(m-\\dim\\im A)=列秩 $$ 这里的核心思路是说，将 $A$ 以两种方式看成同一个线性变换：一种是将 $A$ 视作某个对偶空间（对偶空间的对偶空间与原空间间存在自然映射，在这个问题里更简单，就是个点乘）——这个是行的，一种是直接考虑 $A$ 的线性变换——这个是列的。那么剩下的问题其实是证明原空间和对偶空间的维数相等，这个是用基来证的。\n$f:V\\to V$。证明 $\\exists k$，$V=\\ker f^k\\oplus\\im f^k$。\n我们知道 $\\im f^{k+1}\\subseteq\\im f^k$，于是 $\\exists k$，$\\dim V\u0026gt;\\dim\\im f\u0026gt;\\dim\\im f^2\u0026gt;\\cdots\u0026gt;\\dim\\im f^k=\\dim\\im f^{k+1}=\\dim\\im f^{k+2}=\\cdots$。如果 $\\ker f^k\\cap\\im f^k\\supseteq\\set{0,v}$，则 $f^{2k}(v)=0$，矛盾。\n这个命题在抽代里也有一个对应的版本。\n$A_{n\\times m}$，$B_{m\\times l}$。证明 $\\r(A)+\\r(B)-m\\le\\r(AB)$。\n首先，我们有，对于 $f:U\\to V$，$g:V\\to W$， $$ \\dim\\ker f+\\dim\\ker g\\ge\\dim\\ker(g\\circ f) $$ 直观上很好理解，证明： $$ \\dim\\ker(g\\circ f)=\\dim(\\ker f\\oplus\\ker g|_{\\im f})=\\dim\\ker f+\\dim\\ker g|_{\\im f}\\le\\dim\\ker f+\\dim\\ker g $$\n于是 $$ \\begin{align*} \\r(AB)\u0026amp;=\\dim\\im\\L_{AB}\\\\ \u0026amp;=\\dim\\im(\\L_A\\circ\\L_B)\\\\ \u0026amp;=l-\\dim\\ker(\\L_A\\circ\\L_B)\\\\ \u0026amp;\\ge l-\\dim\\ker\\L_A-\\dim\\ker\\L_B\\\\ \u0026amp;=l-m+\\dim\\im\\L_A-l+\\dim\\im\\L_v\\\\ \u0026amp;=\\r(A)+\\r(B)-m \\end{align*} $$ 可选的一种类似的思路：先证 $\\dim\\im(g\\circ f)\\ge\\dim\\im f-\\dim\\ker g$：$\\dim\\im f=\\dim\\ker g|_{\\im f}+\\dim\\im g|_{\\im f}$。\n$A_{n\\times n}$，$B_{n\\times n}$，$AB=BA=O$，$\\r(A^2)=\\r(A)$。证明 $\\r(A+B)=\\r(A)+\\r(B)$。\n思路 1：证明 $\\ker\\L_{A+B}=\\ker\\L_A\\cap\\ker\\L_B$ 与 $\\ker\\L_A+\\ker\\L_B=\\R^n$。\n$(A+B)x=0\\Rightarrow Ax=A(A+B)x=0$，$(A+B)x=0\\Rightarrow Bx=-Ax=0\\Rightarrow\\ker\\L_{A+B}\\subseteq\\ker\\L_A\\cap\\ker\\L_B$。 $\\r(A^2)=\\r(A)\\Rightarrow\\ker\\L_A\\oplus\\im\\L_A=\\R^n$，$BA=0\\Rightarrow\\im\\L_A\\subseteq\\ker\\L_B\\Rightarrow\\ker\\L_A+\\ker\\L_B=\\R^n$。 思路 2：证明 $\\im\\L_{A+B}=\\im\\L_A+\\im\\L_B$ 与 $\\im\\L_A\\cap\\im\\L_B=\\set{0}$。\n$\\im\\L_A=\\im\\L_{A^2+BA}=\\im\\L_{(A+B)A}\\subseteq\\im\\L_{A+B}$；$\\im\\L_B=\\im\\L_{A+B-A}\\subseteq\\im\\L_{A+B}+\\im\\L_A=\\im\\L_{A+B}$。 $\\r(A^2)=\\r(A)\\Rightarrow\\ker\\L_A\\oplus\\im\\L_A=\\R^n$，$AB=O\\Rightarrow\\im\\L_B\\subseteq\\ker\\L_A$。 $A_{m\\times n}$，$B_{n\\times m}$，证明 $\\r(AB)=\\r(A)\\Rightarrow\\exists C_{m\\times n},A=ABC$。\n设 $A=[\\alpha_i]$。$Ae_i=\\alpha_i$，而 $\\ker\\L_{AB}=\\ker\\L_A$ 故 $\\exists\\gamma_i$，$AB\\gamma_i=\\alpha_i$。令 $C=[\\gamma_i]$。\n$A_{n\\times n}$。证明若 $\\forall x\\in\\R^n$，$x\\ne 0$，$|x^\\top Ax|\u0026lt;|x^\\top x|$，则 $I-A^2$ 可逆。\n$|x^\\top Ax|\u0026lt;|x^\\top x|$ 展开： $$ -\\sum x_i^2\u0026lt;\\sum\\sum x_ix_ja_{ij}\u0026lt;+\\sum x_i^2\\\\ \\Longrightarrow \\left\\{ \\begin{aligned} x^\\top(I-A)x=\\sum\\sum x_ix_j(\\delta_{ij}-a_{ij})\u0026gt;0\\\\ x^\\top(I+A)x=\\sum\\sum x_ix_j(\\delta_{ij}+a_{ij})\u0026gt;0 \\end{aligned} \\right. $$ 如果 $I-A$ 不可逆，则 $\\exists x\\ne 0$，$(I-A)x=0$，那么 $x^{\\top}(I-A)x=0$，矛盾。\n同理 $I+A$ 可逆，于是 $I-A^2$ 可逆。\n$A_{m\\times n}$，$B_{n\\times m}$，证明 $\\r(I_m+AB)-\\r(I_n+BA)=m-n$。\n$$ \\begin{bmatrix}I_m+AB\u0026amp;O\\\\ O\u0026amp;I_n\\end{bmatrix}\\sim\\begin{bmatrix}I_m+AB\u0026amp;A\\\\ O\u0026amp;I_n\\end{bmatrix}\\sim\\begin{bmatrix}I_m\u0026amp;A\\\\ -B\u0026amp;I_n\\end{bmatrix}\\sim\\begin{bmatrix}I_m\u0026amp;A\\\\ O\u0026amp;I_n+BA\\end{bmatrix}\\sim\\begin{bmatrix}I_m\u0026amp;O\\\\ O\u0026amp;I_n+BA\\end{bmatrix} $$\nhttps://zhuanlan.zhihu.com/p/473406438\nTMD 为什么我记了这个期末考却没想起来？？\n$A_{l\\times m}$，$B_{n\\times p}$，$C_{l\\times p}$。证明：\n$W_{p\\times n}$，$BWB=B$ 总是有解。 $X_{m\\times n}$，$AXB=C$ 有解 $\\Leftrightarrow \\r(A)=\\r(\\begin{bmatrix}A\u0026amp;C\\end{bmatrix})\\land\\r\\left(\\begin{bmatrix}B\\\\ C\\end{bmatrix}\\right)$ 设 $\\r(B)=r$。通过消成相抵标准形，可以得到 $B=PQ$ 满秩分解，其中 $P_{n\\times r}$ 是列满秩，$Q_{r\\times p}$ 是行满秩。构造 $W=B^+=Q^\\top(QQ^\\top)^{-1}(P^\\top P)^{-1}P^\\top$。只需证明 $\\r(QQ^\\top)=\\r(P^\\top P)=r$ 即可，这个直接用一般的公式（同解证）。\n$\\Leftarrow$：构造 $X=A^+CB^+$。根据条件，$AY=C$、$ZB=C$ 均有解，故 $$ AXB=AA^+CB^+B=AA^+AYB^+B=AYB^+B=CB^+B=ZBB^+B=ZB=C $$\n$a\\in\\R^n$，求 $\\dat{I+aa^\\top}$。\n思路 1：根据行列式的拆分公式，可以把 $\\dat{I+aa^\\top}$ 拆成 $2^n$ 个行列式的和，其中如果有两行都取自 $aa^\\top$ 就是 $0$，剩下的就是 $1+\\sum a_i^2$。\n思路 2：考虑 $(I+aa^\\top)v=\\lambda v\\Leftrightarrow aa^\\top v=(\\lambda-1)v$。我们知道 $a\\ne 0$ 时 $\\dim aa^\\top=1$，故有 $n-1$ 重 $\\lambda-1=0$。另一重怎么考虑呢？代入 $v=a$ 得 $aa^\\top v=a(a^\\top v)=\\braket{a,a}a$。\n$$ \\dat{\\lambda\u0026amp;1\u0026amp;0\u0026amp;\\cdots\u0026amp;0\u0026amp;0\\\\ n\u0026amp;\\lambda\u0026amp;2\u0026amp;\\cdots\u0026amp;0\u0026amp;0\\\\ 0\u0026amp;n-1\u0026amp;\\lambda\u0026amp;\\cdots\u0026amp;0\u0026amp;0\\\\ \\vdots\u0026amp;\\vdots\u0026amp;\\vdots\u0026amp;\\ddots\u0026amp;\\vdots\u0026amp;\\vdots\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;\\cdots\u0026amp;\\lambda\u0026amp;n\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;\\cdots\u0026amp;1\u0026amp;\\lambda} $$\n思路 1：令原式为 $D_n(\\lambda)$。 $$ \\begin{align*} D_n(\\lambda)={}\u0026amp;\\dat{\\lambda\u0026amp;1\u0026amp;0\u0026amp;0\u0026amp;\\cdots\u0026amp;0\u0026amp;0\u0026amp;0\\\\ n\u0026amp;\\lambda\u0026amp;2\u0026amp;0\u0026amp;\\cdots\u0026amp;0\u0026amp;0\u0026amp;0\\\\ 0\u0026amp;n-1\u0026amp;\\lambda\u0026amp;3\u0026amp;\\cdots\u0026amp;0\u0026amp;0\u0026amp;0\\\\ 0\u0026amp;0\u0026amp;n-2\u0026amp;\\lambda\u0026amp;\\cdots\u0026amp;0\u0026amp;0\u0026amp;0\\\\ \\vdots\u0026amp;\\vdots\u0026amp;\\vdots\u0026amp;\\vdots\u0026amp;\\ddots\u0026amp;\\vdots\u0026amp;\\vdots\u0026amp;\\vdots\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;0\u0026amp;\\cdots\u0026amp;\\lambda\u0026amp;n-1\u0026amp;0\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;0\u0026amp;\\cdots\u0026amp;2\u0026amp;\\lambda\u0026amp;n\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;0\u0026amp;\\cdots\u0026amp;0\u0026amp;1\u0026amp;\\lambda}\\\\ \\xlongequal{r_1\\xleftarrow{+}r_2+\\cdots+r_{n+1}}{}\u0026amp;\\dat{\\lambda+n\u0026amp;\\lambda+n\u0026amp;\\lambda+n\u0026amp;\\lambda+n\u0026amp;\\cdots\u0026amp;\\lambda+n\u0026amp;\\lambda+n\u0026amp;\\lambda+n\\\\ n\u0026amp;\\lambda\u0026amp;2\u0026amp;0\u0026amp;\\cdots\u0026amp;0\u0026amp;0\u0026amp;0\\\\ 0\u0026amp;n-1\u0026amp;\\lambda\u0026amp;3\u0026amp;\\cdots\u0026amp;0\u0026amp;0\u0026amp;0\\\\ 0\u0026amp;0\u0026amp;n-2\u0026amp;\\lambda\u0026amp;\\cdots\u0026amp;0\u0026amp;0\u0026amp;0\\\\ \\vdots\u0026amp;\\vdots\u0026amp;\\vdots\u0026amp;\\vdots\u0026amp;\\ddots\u0026amp;\\vdots\u0026amp;\\vdots\u0026amp;\\vdots\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;0\u0026amp;\\cdots\u0026amp;\\lambda\u0026amp;n-1\u0026amp;0\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;0\u0026amp;\\cdots\u0026amp;2\u0026amp;\\lambda\u0026amp;n\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;0\u0026amp;\\cdots\u0026amp;0\u0026amp;1\u0026amp;\\lambda}\\\\ \\xlongequal{c_2,\\cdots,c_{n+1}\\xleftarrow{-}c_1}{}\u0026amp;\\dat{\\lambda+n\u0026amp;0\u0026amp;0\u0026amp;0\u0026amp;\\cdots\u0026amp;0\u0026amp;0\u0026amp;0\\\\ n\u0026amp;\\lambda-n\u0026amp;2-n\u0026amp;-n\u0026amp;\\cdots\u0026amp;-n\u0026amp;-n\u0026amp;-n\\\\ 0\u0026amp;n-1\u0026amp;\\lambda\u0026amp;3\u0026amp;\\cdots\u0026amp;0\u0026amp;0\u0026amp;0\\\\ 0\u0026amp;0\u0026amp;n-2\u0026amp;\\lambda\u0026amp;\\cdots\u0026amp;0\u0026amp;0\u0026amp;0\\\\ \\vdots\u0026amp;\\vdots\u0026amp;\\vdots\u0026amp;\\vdots\u0026amp;\\ddots\u0026amp;\\vdots\u0026amp;\\vdots\u0026amp;\\vdots\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;0\u0026amp;\\cdots\u0026amp;\\lambda\u0026amp;n-1\u0026amp;0\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;0\u0026amp;\\cdots\u0026amp;2\u0026amp;\\lambda\u0026amp;n\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;0\u0026amp;\\cdots\u0026amp;0\u0026amp;1\u0026amp;\\lambda}\\\\ \\xlongequal{r_1}{}\u0026amp;\\dat{\\lambda-n\u0026amp;2-n\u0026amp;-n\u0026amp;\\cdots\u0026amp;-n\u0026amp;-n\u0026amp;-n\\\\ n-1\u0026amp;\\lambda\u0026amp;3\u0026amp;\\cdots\u0026amp;0\u0026amp;0\u0026amp;0\\\\ 0\u0026amp;n-2\u0026amp;\\lambda\u0026amp;\\cdots\u0026amp;0\u0026amp;0\u0026amp;0\\\\ \\vdots\u0026amp;\\vdots\u0026amp;\\vdots\u0026amp;\\ddots\u0026amp;\\vdots\u0026amp;\\vdots\u0026amp;\\vdots\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;\\cdots\u0026amp;\\lambda\u0026amp;n-1\u0026amp;0\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;\\cdots\u0026amp;2\u0026amp;\\lambda\u0026amp;n\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;\\cdots\u0026amp;0\u0026amp;1\u0026amp;\\lambda}\\cdot(\\lambda+n)\\\\ \\xlongequal{r_1\\xleftarrow{+}r_2+\\cdots+r_n}{}\u0026amp;\\dat{\\lambda-1\u0026amp;\\lambda\u0026amp;\\lambda\u0026amp;\\cdots\u0026amp;\\lambda\u0026amp;\\lambda\u0026amp;\\lambda\\\\ n-1\u0026amp;\\lambda\u0026amp;3\u0026amp;\\cdots\u0026amp;0\u0026amp;0\u0026amp;0\\\\ 0\u0026amp;n-2\u0026amp;\\lambda\u0026amp;\\cdots\u0026amp;0\u0026amp;0\u0026amp;0\\\\ \\vdots\u0026amp;\\vdots\u0026amp;\\vdots\u0026amp;\\ddots\u0026amp;\\vdots\u0026amp;\\vdots\u0026amp;\\vdots\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;\\cdots\u0026amp;\\lambda\u0026amp;n-1\u0026amp;0\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;\\cdots\u0026amp;2\u0026amp;\\lambda\u0026amp;n\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;\\cdots\u0026amp;0\u0026amp;1\u0026amp;\\lambda}\\cdot(\\lambda+n)\\\\ \\xlongequal{r_2\\xleftarrow{+}r_3+\\cdots+r_n}{}\u0026amp;\\cdots\\cdots\\\\ \\xlongequal{r_{n-1}\\xleftarrow{+}r_n}{}\u0026amp;\\dat{\\lambda-1\u0026amp;\\lambda\u0026amp;\\lambda\u0026amp;\\cdots\u0026amp;\\lambda\u0026amp;\\lambda\u0026amp;\\lambda\\\\ n-1\u0026amp;\\lambda+n-2\u0026amp;\\lambda+n\u0026amp;\\cdots\u0026amp;\\lambda+n\u0026amp;\\lambda+n\u0026amp;\\lambda+n\\\\ 0\u0026amp;n-2\u0026amp;\\lambda+n-3\u0026amp;\\cdots\u0026amp;\\lambda+n\u0026amp;\\lambda+n\u0026amp;\\lambda+n\\\\ \\vdots\u0026amp;\\vdots\u0026amp;\\vdots\u0026amp;\\ddots\u0026amp;\\vdots\u0026amp;\\vdots\u0026amp;\\vdots\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;\\cdots\u0026amp;\\lambda+2\u0026amp;\\lambda+n\u0026amp;\\lambda+n\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;\\cdots\u0026amp;2\u0026amp;\\lambda+1\u0026amp;\\lambda+n\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;\\cdots\u0026amp;0\u0026amp;1\u0026amp;\\lambda}\\cdot(\\lambda+n)\\\\ \\xlongequal{c_n\\xleftarrow{-}c_{n-1}}{}\u0026amp;\\dat{\\lambda-1\u0026amp;\\lambda\u0026amp;\\lambda\u0026amp;\\cdots\u0026amp;\\lambda\u0026amp;\\lambda\u0026amp;0\\\\ n-1\u0026amp;\\lambda+n-2\u0026amp;\\lambda+n\u0026amp;\\cdots\u0026amp;\\lambda+n\u0026amp;\\lambda+n\u0026amp;0\\\\ 0\u0026amp;n-2\u0026amp;\\lambda+n-3\u0026amp;\\cdots\u0026amp;\\lambda+n\u0026amp;\\lambda+n\u0026amp;0\\\\ \\vdots\u0026amp;\\vdots\u0026amp;\\vdots\u0026amp;\\ddots\u0026amp;\\vdots\u0026amp;\\vdots\u0026amp;\\vdots\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;\\cdots\u0026amp;\\lambda+2\u0026amp;\\lambda+n\u0026amp;0\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;\\cdots\u0026amp;2\u0026amp;\\lambda+1\u0026amp;n-1\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;\\cdots\u0026amp;0\u0026amp;1\u0026amp;\\lambda-1}\\cdot(\\lambda+n)\\\\ \\xlongequal{c_{n-1}\\xleftarrow{-}c_{n-2}}{}\u0026amp;\\cdots\\cdots\\\\ \\xlongequal{c_2\\xleftarrow{-}c_1}{}\u0026amp;\\dat{\\lambda-1\u0026amp;1\u0026amp;0\u0026amp;\\cdots\u0026amp;0\u0026amp;0\u0026amp;0\\\\ n-1\u0026amp;\\lambda-1\u0026amp;2\u0026amp;\\cdots\u0026amp;0\u0026amp;0\u0026amp;0\\\\ 0\u0026amp;n-2\u0026amp;\\lambda-1\u0026amp;\\cdots\u0026amp;0\u0026amp;0\u0026amp;0\\\\ \\vdots\u0026amp;\\vdots\u0026amp;\\vdots\u0026amp;\\ddots\u0026amp;\\vdots\u0026amp;\\vdots\u0026amp;\\vdots\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;\\cdots\u0026amp;\\lambda-1\u0026amp;n-2\u0026amp;0\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;\\cdots\u0026amp;2\u0026amp;\\lambda-1\u0026amp;n-1\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;\\cdots\u0026amp;0\u0026amp;1\u0026amp;\\lambda-1}\\cdot(\\lambda+n)\\\\ ={}\u0026amp;(\\lambda+n)D_{n-1}(\\lambda-1)\\\\ ={}\u0026amp;(\\lambda+n)(\\lambda+n-2)D_{n-2}(\\lambda-2)\\\\ ={}\u0026amp;\\cdots\\cdots\\\\ ={}\u0026amp;\\prod_{i=0}^n(\\lambda+n-2i) \\end{align*} $$ 思路 2：https://math.stackexchange.com/a/340611\n思路 3：记 $$ A=\\mat{0\u0026amp;1\u0026amp;0\u0026amp;\\cdots\u0026amp;0\u0026amp;0\\\\ n\u0026amp;0\u0026amp;2\u0026amp;\\cdots\u0026amp;0\u0026amp;0\\\\ 0\u0026amp;n-1\u0026amp;0\u0026amp;\\cdots\u0026amp;0\u0026amp;0\\\\ \\vdots\u0026amp;\\vdots\u0026amp;\\vdots\u0026amp;\\ddots\u0026amp;\\vdots\u0026amp;\\vdots\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;\\cdots\u0026amp;0\u0026amp;n\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;\\cdots\u0026amp;1\u0026amp;0} $$ （该矩阵被称为 Kac matrix）\n考虑 $Ax=\\lambda x$，其中 $x=\\mat{x_0\u0026amp;\\cdots\u0026amp;x_n}^\\top$。具体写成： $$ \\left\\{\\begin{align*} x_1\u0026amp;=\\lambda x_0\\\\ nx_0+2x_2\u0026amp;=\\lambda x_1\\\\ (n-1)x_1+3x_3\u0026amp;=\\lambda x_2\\\\ \\cdots\u0026amp;\\cdots\\\\ x_{n-1}\u0026amp;=\\lambda x_n \\end{align*}\\right. $$ 令 $f(t)=\\sum x_it^i$，可以写成 $t(nf-tf^\\prime)+f^\\prime=\\lambda f$ 即 $$ \\frac{f^\\prime(t)}{f(t)}=\\frac{nt-\\lambda}{t^2-1}=\\frac{n+\\lambda}{2(t+1)}+\\frac{n-\\lambda}{2(t-1)} $$ 两端同时积分得 $$ f(t)=C(t+1)^{(n+\\lambda)/2}(t-1)^{(n-\\lambda)/2} $$ 也就是说，仅有这些 $f$ 展开可以作为 $x$，且这样的 $f$ 还需满足没有超过 $x^n$ 的项，因此只能有 $|\\lambda|\\le n$ 且 $\\lambda$ 为与 $n$ 奇偶的整数。\n证明：如果一个方阵 $A$ 只有行列异奇偶的位置非零，则其特征值一定正负成对出现。\n考虑 $D=\\operatorname{diag}(1,-1,1,-1,\\cdots)$。注意到 $D^{-1}AD=-A$。因此，若 $Av=\\lambda v$，则 $$ A(Dv)=(AD)v=-(DA)v=-D(Av)=-D\\lambda v=-\\lambda(Dv) $$\n求 $$ A=\\mat{b\u0026amp;c\u0026amp;0\u0026amp;\\cdots\u0026amp;0\u0026amp;0\\\\ a\u0026amp;b\u0026amp;c\u0026amp;\\cdots\u0026amp;0\u0026amp;0\\\\ 0\u0026amp;a\u0026amp;b\u0026amp;\\cdots\u0026amp;0\u0026amp;0\\\\ \\vdots\u0026amp;\\vdots\u0026amp;\\vdots\u0026amp;\\ddots\u0026amp;\\vdots\u0026amp;\\vdots\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;\\cdots\u0026amp;b\u0026amp;c\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;\\cdots\u0026amp;a\u0026amp;b} $$ 的特征值与特征向量。\n我们知道， $$ \\dat{A}=\\left\\{\\begin{aligned}\u0026amp;\\frac1{\\sqrt\\Delta}\\left[\\left(\\frac{b+\\sqrt\\Delta}2\\right)^{n+1}-\\left(\\frac{b-\\sqrt\\Delta}2\\right)^{n+1}\\right],\u0026amp;\\Delta\\ne0\\\\ \u0026amp;(n+1)\\left(\\frac b2\\right)^n,\u0026amp;\\Delta=0\\end{aligned}\\right. $$ 如果 $ac=0$，那么唯一的特征值为 $b$，否则 $$ \\lambda=b-2\\sqrt{ac}\\cos\\frac{k\\pi}{n+1}\\;(k=1,\\cdots,n) $$ 特征向量似乎有点难。我们来看一下 deepseek 怎么说，这边它先通过相似变换（$D=\\operatorname{diag}((a/c)^{i/2})$）把矩阵变成对称的。\n对于对称三对角矩阵的特征向量问题，我们可以通过以下步骤详细推导：\n步骤1：建立特征方程\n设对称三对角矩阵为： $$ S = \\begin{bmatrix} b \u0026amp; \\sqrt{ac} \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\\\ \\sqrt{ac} \u0026amp; b \u0026amp; \\sqrt{ac} \u0026amp; \\cdots \u0026amp; 0 \\\\ 0 \u0026amp; \\sqrt{ac} \u0026amp; b \u0026amp; \\cdots \u0026amp; 0 \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\sqrt{ac} \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; \\sqrt{ac} \u0026amp; b \\end{bmatrix}, $$ 其特征方程为 $S \\mathbf{v} = \\lambda \\mathbf{v}$。假设特征向量为 $\\mathbf{v} = [v_1, v_2, \\dots, v_n]^T$，则分量满足递推关系：\n$$ \\sqrt{ac} \\cdot v_{k-1} + b \\cdot v_k + \\sqrt{ac} \\cdot v_{k+1} = \\lambda v_k, \\quad k = 1, 2, \\dots, n, $$ 其中约定 $v_0 = v_{n+1} = 0$。\n步骤2：引入正弦函数试探解\n观察到边界条件 $v_0 = v_{n+1} = 0$，尝试用正弦函数作为解：\n$$ v_k = \\sin\\left(\\theta k\\right), $$\n代入递推方程：\n$$ \\sqrt{ac} \\cdot \\sin\\left(\\theta (k-1)\\right) + b \\cdot \\sin\\left(\\theta k\\right) + \\sqrt{ac} \\cdot \\sin\\left(\\theta (k+1)\\right) = \\lambda \\sin\\left(\\theta k\\right). $$\n步骤3：利用三角恒等式化简\n利用正弦函数的和差公式：\n$$ \\sin\\left(\\theta (k-1)\\right) + \\sin\\left(\\theta (k+1)\\right) = 2 \\sin\\left(\\theta k\\right) \\cos\\theta, $$\n方程简化为：\n$$ \\sqrt{ac} \\cdot 2 \\sin\\left(\\theta k\\right) \\cos\\theta + b \\cdot \\sin\\left(\\theta k\\right) = \\lambda \\sin\\left(\\theta k\\right). $$\n消去 $\\sin\\left(\\theta k\\right)$（非零解要求）后得到：\n$$ \\lambda = b + 2\\sqrt{ac} \\cos\\theta. $$\n步骤4：应用边界条件\n由 $v_{n+1} = 0$，即： $$ \\sin\\left(\\theta (n+1)\\right) = 0 \\implies \\theta (n+1) = m\\pi \\implies \\theta = \\frac{m\\pi}{n+1}, \\quad m = 1, 2, \\dots, n. $$\n因此，特征值为：\n$$ \\lambda_m = b + 2\\sqrt{ac} \\cos\\left(\\frac{m\\pi}{n+1}\\right), $$\n对应特征向量分量为：\n$$ v^{(m)}_k = \\sin\\left(\\frac{mk\\pi}{n+1}\\right). $$\n步骤5：正交归一性验证\n通过计算内积 $ \\sum_{k=1}^n v^{(m)}_k v^{(p)}_k$，可验证不同特征向量正交，且归一化常数为 $\\sqrt{\\frac{2}{n+1}}$。\n总结\n对称三对角矩阵的特征向量由正弦函数构成，其形式为：\n$$ \\mathbf{v}^{(m)} = \\left[ \\sin\\left(\\frac{m\\pi}{n+1}\\right), \\sin\\left(\\frac{2m\\pi}{n+1}\\right), \\dots, \\sin\\left(\\frac{nm\\pi}{n+1}\\right) \\right]^T, $$\n满足正交性和完备性，构成一组基底。\n求循环矩阵 $\\Set{a_{(n-i+j)\\bmod n}}$ 的特征值与特征向量。\n这个反倒很简单，既然知道求行列式的套路是 $$ \\mat{a_0\u0026amp;a_1\u0026amp;\\cdots\u0026amp;a_{n-1}\\\\ a_{n-1}\u0026amp;a_0\u0026amp;\\cdots\u0026amp;a_1\\\\ \\vdots\u0026amp;\\vdots\u0026amp;\\ddots\u0026amp;\\vdots\\\\ a_1\u0026amp;a_2\u0026amp;\\cdots\u0026amp;a_0}\\mat{\\omega^{0\\cdot0}\u0026amp;\\omega^{1\\cdot0}\u0026amp;\\cdots\u0026amp;\\omega^{(n-1)\\cdot0}\\\\ \\omega^{0\\cdot1}\u0026amp;\\omega^{1\\cdot1}\u0026amp;\\cdots\u0026amp;\\omega^{(n-1)\\cdot1}\\\\ \\vdots\u0026amp;\\vdots\u0026amp;\\ddots\u0026amp;\\vdots\\\\ \\omega^{0\\cdot(n-1)}\u0026amp;\\omega^{1\\cdot(n-1)}\u0026amp;\\cdots\u0026amp;\\omega^{(n-1)\\cdot(n-1)}}=\\mat{\\omega^{0\\cdot0}f(\\omega^0)\u0026amp;\\omega^{1\\cdot0}f(\\omega^1)\u0026amp;\\cdots\u0026amp;\\omega^{(n-1)\\cdot0}f(\\omega^{n-1})\\\\ \\omega^{0\\cdot1}f(\\omega^0)\u0026amp;\\omega^{1\\cdot1}f(\\omega^1)\u0026amp;\\cdots\u0026amp;\\omega^{(n-1)\\cdot1}f(\\omega^{n-1})\\\\ \\vdots\u0026amp;\\vdots\u0026amp;\\ddots\u0026amp;\\vdots\\\\ \\omega^{0\\cdot(n-1)}f(\\omega^0)\u0026amp;\\omega^{1\\cdot(n-1)}f(\\omega^1)\u0026amp;\\cdots\u0026amp;\\omega^{(n-1)\\cdot(n-1)}f(\\omega^{n-1})} $$ 那就知道特征值和特征向量分别是 $$ f(\\omega^k),\\,\\mat{\\omega^{k\\cdot0}\\\\ \\omega^{k\\cdot1}\\\\ \\vdots\\\\ \\omega^{k\\cdot(n-1)}}\\;(k=0,\\cdots,n-1) $$ 其中 $f(x)=\\sum a_ix^i$，$\\omega=\\e^{2\\pi\\mathrm{i}/n}$。\n对于 $A_{m\\times n}$，$B_{n\\times m}$，证明 $I_m-AB$ 可逆 $\\Leftrightarrow$ $I_n-BA$ 可逆。\n证 1：若 $(I-AB)C=I$，则 $(I-BA)(BC)=BC-B(C-I)=B$，故 $(I-BA)(BCA)=BA=I-(I-BA)$，故 $(I-BA)(BCA+I)=I$。\n证 2：若对于某个 $x\\ne 0$，$(I-AB)x=0$，则 $(I-BA)Bx=Bx-BABx=Bx-Bx=0$，其中 $Bx\\ne 0$ 因为否则 $(I-AB)x=x\\ne 0$。\n证 3： $$ \\mat{I-AB\u0026amp;O\\\\ B\u0026amp;I}\\sim\\mat{I\u0026amp;A\\\\ B\u0026amp;I}\\sim\\mat{I\u0026amp;A\\\\ O\u0026amp;I-BA} $$\n$A^2=I$，证明 $A$ 可对角化。\n$$ \\begin{align*} \u0026amp;(A+I)(A-I)=0\\\\ \\Longrightarrow{}\u0026amp;\\im\\L_{A-I}\\subseteq\\ker\\L_{A+I}\\\\ \\Longrightarrow{}\u0026amp;n-\\dim\\ker\\L_{A-I}=\\dim\\im\\L_{A-I}\\le\\dim\\ker\\L_{A+I}\\\\ \\Longrightarrow{}\u0026amp;\\dim\\ker\\L_{A-I}+\\dim\\ker\\L_{A+I}\\ge n \\end{align*} $$\n又知道特征空间的维数和不能超过 $n$，故 $\\dim\\ker\\L_{A-I}+\\dim\\ker\\L_{A+I}=n$。\n这类问题可以扩展到最小多项式相关的定理：如果一个矩阵/线性变换的最小多项式为 $\\prod(t-\\lambda_i)^{m_i}$，那它的 Jordan 标准型中 $\\lambda_i$ 对应的 Jordan 块的最大大小就是 $m_i$。\n对于 Jordan 块 $J_{n\\times n}$，求 $J^k$。\n众所周知矩阵的幂次有一个组合意义：$A_{i,j}$ 表示 $i$ 到 $j$ 的边权，$(A^k)_{i,j}$ 表示 $i$ 到 $j$ 恰好走 $k$ 步，所有可能路径的边权之积的和。所以 $(J^k)_{i,j}$ 就是走 $j-i$，每次走 $0$ 或 $1$ 步，这个显然是 $$ \\binom{k}{j-i}\\lambda^{k-j+i} $$\n证明对于可对角化的 $\\T$ 和 $\\U$，$\\T$ 和 $\\U$ 可同时对角化当且仅当 $\\T\\U=\\U\\T$。如果 $\\T$ 和 $\\U$ 可正交对角化，类似的结论也成立。\n对于 $\\T$ 的特征向量 $v\\in\\E_\\lambda$，$\\T\\U(v)=\\U\\T(v)=\\lambda\\U(v)$ 从而 $\\E_\\lambda$ 是 $\\U$ 的不变子空间。取 $\\U$ 在其上的对角化即可。需要证明可对角化 $\\Rightarrow$ 在不变子空间内可对角化，略。\n正交对角化的情况，考虑 $\\mathbb{C}$。还是随便取一个 $\\E_\\lambda$，只需证明 $\\E_\\lambda^\\perp$ 也是 $\\T$ 和 $\\U$ 的不变子空间即可。首先由内积的操作知道 $\\E_\\lambda^\\perp$ 是 $\\T^*$ 的不变子空间，其次 $\\T^*$ 的特征向量都是 $\\T$ 的特征向量，从而 $\\E_\\lambda^\\perp$ 也是 $\\T$ 的不变子空间。\n","date":"2025-01-22T00:00:00Z","permalink":"https://littlereuben.github.io/study/course-linear-algebra/","title":"线代的一些题"},{"content":"这是一篇学习笔记。\r[PDF file] ","date":"2024-11-03T00:00:00Z","permalink":"https://littlereuben.github.io/study/course-calculus-1-1/","title":"微积分 A(1) 期中复习会—一些有意思的难题"},{"content":"这是一篇想法。\r[PDF file] 相关阅读材料\n对应中文版也可以在 zlib 找到。\n","date":"2024-10-04T00:00:00Z","permalink":"https://littlereuben.github.io/theory/sol-ling/","title":"Solvay Presentation —— Linguistics"},{"content":"$\\gdef\\d{\\mathrm{d}}\\gdef\\sgn{\\operatorname{sgn}}\\gdef\\e{\\mathrm{e}}\\gdef\\bm#1{\\boldsymbol{#1}}$\n这是一篇学习笔记。\r这些内容主要写于 2024 年上半年我自学高中物理时想到的一些问题。实际上是 2025.2.23 upload 这个文章的，现在看起来很幼稚了，就只是当作记录吧。\n小球上半圆弧模型 众所周知，上到一半是 $\\sqrt{2gr}$，从顶上飞出去是 $\\sqrt{5gr}$。那斜抛刚好落到圆弧与水平面连接处呢？\n设斜抛起始点与圆心连线与水平夹角为 $\\theta$，高度为 $h$。 $$ \\left\\{\\begin{align*} h\u0026amp;=r(1+\\sin\\theta)\\\\ \\dfrac 12mv_0^2\u0026amp;=\\dfrac 12mv^2+mgh\\\\ m\\dfrac{v^2}r\u0026amp;=mg\\sin\\theta\\\\ h\u0026amp;=\\dfrac 12gt^2-vt\\cos\\theta\\\\ r\\cos\\theta\u0026amp;=vt\\sin\\theta \\end{align*}\\right. $$ 解得 $\\sin\\theta=\\frac 12,v_0=\\sqrt{3.5gr}$。\n恒定功率加速问题 考虑机车从静止开始以恒定功率 $P$ 加速，阻力为 $f$，希望求出 $v$ 关于 $t$ 的表达式。根据牛二， $$ \\frac Pv-f=m\\dot v $$ 即 $$ \\dfrac{mv}{P-fv}\\d v=\\d t $$\n两边积分然后根据 $v|_{t=0}=0$ 即可解得 $C$。\n当 $f=0$ 时，解得 $$ v=\\sqrt{\\frac{2Pt}m} $$ 其余情况下有 $$ \\frac mf\\left(\\frac Pf\\ln\\frac P{P-fv}-v\\right)=t $$ 当 $t\\to+\\infin$ 时 $v\\to P/f$。$v$ 关于 $t$ 不存在初等表达式，需借助 Lambert W 函数。\n如果阻力正比于 $v$ 即 $f(v)=kv$，则 $$ v=\\sqrt{\\frac{P(1-\\e^{-\\frac{2k}mt})}k} $$\n真正的自由落体运动 method from zby（的同学）.\n视星体为质量为 $M$ 的质点，记 $y$ 为轻物体（如果是两个星体，以其中一个为参考系即可）距质点的距离。初始 $y|_{t=0}=d$，速度为 $0$。\n然后会得到这样一个微分方程： $$ \\ddot yy=GM $$ 不会解……\n换一个思路，由能量守恒， $$ -{GM}d=-{GM}y+\\frac12{\\dot y}^2 $$ 即 $$ \\dot y=\\sqrt{2GM\\left(\\frac 1y-\\frac 1d\\right)} $$ 那就是（我们来详细推导一下） $$ \\begin{align*} t={}\u0026amp;\\int_{y}^d\\frac{\\d x}{\\sqrt{2GM\\left(\\frac 1x-\\frac 1d\\right)}}\\\\ \\xlongequal{z=\\sqrt{\\frac 1x-\\frac 1d}}{}\u0026amp;\\sqrt{\\frac{2}{GM}}\\int_{0}^{\\sqrt{\\frac 1y-\\frac 1d}}\\frac{\\d z}{\\left(z^2+\\frac 1d\\right)^2}\\\\ \\xlongequal{\\tan\\alpha=\\sqrt dz}{}\u0026amp;\\sqrt{\\frac{2d^3}{GM}}\\int_0^{\\arctan\\sqrt{\\frac dy-1}}\\cos^2\\alpha\\d\\alpha\\\\ ={}\u0026amp;\\sqrt{\\frac{2d^3}{GM}}\\left.\\left(\\frac{\\sin2\\alpha}{4}+\\frac\\alpha2\\right)\\right|_0^{\\arctan\\sqrt{\\frac dy-1}}\\\\ ={}\u0026amp;\\sqrt{\\frac{d}{2GM}}\\left(y\\sqrt{\\frac dy-1}+d\\arctan\\sqrt{\\frac dy-1}\\right) \\end{align*} $$ 因此，相撞时刻为 $$ t|_{y\\to 0}=\\frac\\pi2d\\sqrt\\frac d{2GM} $$\n开普勒推万有引力 开普勒第一定律 所有行星绕恒星运动的轨道都是椭圆，且恒星处在椭圆的某个焦点上。\n以 $F_1$ 为极点，$F_1F_2$ 为极轴建立极坐标系，行星轨迹为\n$$ r=\\frac{ep}{1-e\\cos\\theta} $$\n开普勒第二定律 一对特定恒星与行星的连线在相等时间内所扫过的面积相等。\n设 $S$ 为单位时间内扫过的面积，则 $$ 2S=r^2\\dot\\theta $$\n开普勒第三定律 对于一个恒星，其所有行星轨道半长轴的立方与公转周期的平方成正比。\n设该比例为 $k$，即 $$ \\frac{a^3}{T^2}=k $$ 又 $$ T\\cdot S=\\pi ab $$ 故 $$ S^2=\\frac{\\pi^2kb^2}{a} $$\n极坐标下的加速度 将极坐标下的加速度正交分解成径向加速度 $a_r$ 与切向加速度 $a_\\theta$。\n极坐标下有径向基矢 $\\hat r=\\hat x\\cos\\theta+\\hat y\\sin\\theta$ 和 切向基矢 $\\hat\\theta=-\\hat x\\sin\\theta+\\hat y\\cos\\theta$。\n首先有 $$ \\begin{align*} \\d\\hat r\u0026amp;=\\hat\\theta\\d\\theta\\\\ \\d\\hat\\theta\u0026amp;=-\\hat r\\d r \\end{align*} $$ 故 $$ \\begin{align*} \\frac{\\d(r\\hat r)}{\\d t}\u0026amp;=\\dot r\\hat r+r\\hat\\theta\\\\ \\frac{\\d^2(r\\hat r)}{\\d t^2}\u0026amp;=\\left(\\ddot r-r\\dot\\theta^2\\right)\\hat r+\\left(2\\dot r\\dot\\theta+r\\ddot\\theta\\right)\\hat\\theta\\\\ \\end{align*} $$ 即 $$ \\begin{align*} a_r\u0026amp;=\\ddot r-r\\dot\\theta^2\\\\ a_\\theta\u0026amp;=2\\dot r\\dot\\theta+r\\ddot\\theta \\end{align*} $$\n推导 综合上述公式， $$ \\begin{align*} \\dot r\u0026amp;=-\\frac{e^2p\\sin\\theta}{(1-e\\cos\\theta)^2}\\dot\\theta\\\\ \u0026amp;=-\\frac{r^2\\dot\\theta}{p}\\sin\\theta\\\\ \u0026amp;=-\\frac{2S}{p}\\sin\\theta\\\\ \\ddot r\u0026amp;=-\\frac{2S}{p}\\dot\\theta\\cos\\theta\\\\ \u0026amp;=-\\frac{2S}{p}\\left(\\frac 1e-\\frac pr\\right)\\dot\\theta\\\\ a_r\u0026amp;=\\ddot r-r\\dot\\theta^2\\\\ \u0026amp;=-\\frac{2S}{ep}\\dot\\theta+\\frac{2S}{r}\\dot\\theta-\\frac{2S}{r}\\dot\\theta\\\\ \u0026amp;=-\\frac{2S}{ep}\\cdot\\frac{2S}{r^2}\\\\ \u0026amp;=-\\frac{4\\pi^2kb^2}{aepr^2}\\\\ \u0026amp;=-\\frac{4\\pi^2k}{r^2}\\\\ a_\\theta\u0026amp;=2\\dot r\\dot\\theta+r\\ddot\\theta\\\\ \u0026amp;=\\frac{\\d(r^2\\theta)}{r\\d t}\\\\ \u0026amp;=0 \\end{align*} $$ 由牛二，引力方向为两星球连线，大小为 $$ F=\\frac{4\\pi^2km}{r^2} $$ 设恒星与行星质量分别为 $m_1,m_2$，对应常数分别为 $k_1,k_2$，由牛三， $$ \\frac{4\\pi^2k_1m_2}{r^2}=\\frac{4\\pi^2k_2m_1}{r^2} $$ 即 $$ \\frac{k_1}{m_1}=\\frac{k_2}{m_2} $$ 由此可见，存在一常数，所有物体的 $k$ 比 $m$ 均为该常数，设其为 $\\frac{G}{4\\pi^2}$，则 $$ F=\\frac{Gm_1m_2}{r^2} $$\n非质点的库仑力计算 对于一个半径为 $R$，均匀带电 $Q$ 的圆环，与圆心连线垂直于圆面且长为 $D$ 的点处的电场大小为（相似三角形分解力） $$ \\frac{kQD}{(R^2+D^2)^{\\frac 32}} $$ 对于一个半径为 $R$，均匀带电 $Q$ 的球壳，与球心距离为 $D$ 处的电场大小为 $$ \\begin{align*} \u0026amp;\\int_{-\\frac\\pi 2}^{\\frac\\pi 2}\\frac{k\\left(\\frac{2\\pi R^2\\cos\\theta\\d\\theta}{4\\pi R^2}Q\\right)(D-R\\sin\\theta)}{\\left[R^2\\cos^2\\theta+(D-R\\sin\\theta)^2\\right]^{\\frac 32}}\\\\ ={}\u0026amp;\\frac{kQ}{2}\\int_{-\\frac\\pi 2}^{\\frac\\pi 2}\\frac{\\cos\\theta\\d\\theta(D-R\\sin\\theta)}{\\left(R^2+D^2-2RD\\sin\\theta\\right)^{\\frac 32}}\\\\ ={}\u0026amp;\\frac{kQ}{2}\\left.\\frac{D\\sin\\theta-R}{D^2\\sqrt{R^2+D^2-2RD\\sin\\theta}}\\right|_{-\\frac\\pi 2}^{\\frac\\pi 2}\\\\ ={}\u0026amp;\\frac{kQ}{2D^2}(1+\\sgn(D-R)) \\end{align*} $$ 于是一个半径为 $R$，均匀带电 $Q$ 的实心球，与球心距离为 $D$ 处的电场大小为 $$ \\left\\{\\begin{align*} \u0026amp;\\dfrac{kQD}{R^3},\u0026amp;D\u0026lt;R\\\\ \u0026amp;\\dfrac{kQ}{D^2},\u0026amp;D\\ge R \\end{align*}\\right. $$ 因此均匀带电的球对于某点的电场，等效于去除在该点外围的球的部分后，球心对其的电场。\n对于一个半径为 $R$，均匀带电 $Q$ 的圆板，与圆心连线垂直于圆面且长为 $D$ 的点处的电场大小为 $$ \\begin{align*} \u0026amp;\\int_0^R\\frac{k\\left(\\frac{2\\pi r\\d r}{\\pi R^2}Q\\right)D}{\\left(r^2+D^2\\right)^{\\frac 32}}\\\\ ={}\u0026amp;\\frac{2kQD}{R^2}\\int_0^R\\frac{r\\d r}{(r^2+D^2)^{\\frac 32}}\\\\ ={}\u0026amp;\\frac{2kQD}{R^2}\\left(\\left.-\\frac{1}{\\sqrt{R^2+D^2}}\\right|_0^R\\right)\\\\ ={}\u0026amp;\\frac{2kQ}{R^2}\\left(1-\\frac{D}{\\sqrt{R^2+D^2}}\\right) \\end{align*} $$ $R\\to+\\infty$ 可导出电荷面密度为 $\\sigma$ 的无限大均匀带电平面的电场大小为 $2\\pi k\\sigma$（与距离无关），同时可以导出电容的决定式 $$ C=\\frac QU=\\frac Q{Ed}=\\frac Q{2\\cdot 2\\pi k\\sigma\\cdot d}=\\frac S{4\\pi kd} $$ 对于一个电荷线密度为 $\\lambda$ 的无限长均匀带电导线，与它距离为 $D$ 处的电场大小为 $$ \\int_{-\\infty}^{\\infty}\\frac{k(\\lambda\\d x)D}{(x^2+D^2)^{\\frac 32}}=\\frac{2k\\lambda}{D} $$\n对于一个半径为 $R$，均匀带电，电荷线密度为 $\\lambda$ 的圆环，在圆所在平面内，与圆心距离为 $D$ 处的电场大小为 $$ \\int_0^{2\\pi}\\frac{k(R\\d\\theta\\cdot\\lambda)(D-R\\sin\\theta)}{(R^2+D^2-2RD\\sin\\theta)^{\\frac32}} $$ 然后这个玩意 TM 积不出来！是个椭圆积分。反而下面这个是可以积的：\n对于一个半径为 $R$，均匀带电，电荷面密度为 $\\sigma$ 的无限长圆筒，与轴心距离为 $D$ 处的电场大小为 $$ \\int_0^{2\\pi}\\frac{2k(R\\d\\theta\\cdot\\sigma)(D-R\\sin\\theta)}{R^2+D^2-2RD\\sin\\theta}=\\frac{2\\pi k\\sigma R}D(1+\\sgn(D-R)) $$ 于是一个半径为 $R$，均匀带电，电荷体密度为 $\\rho$ 的无限长圆柱，与轴心距离为 $D$ 处的电场大小为 $$ \\left\\{\\begin{align*} \u0026amp;2\\pi k\\rho D,\u0026amp;D\u0026lt;R\\\\ \u0026amp;\\dfrac{2\\pi k\\rho R^2}{D},\u0026amp;D\\ge R \\end{align*}\\right. $$ 因此均匀带电的圆柱对于某点的电场，等效于去除在该点外围的圆柱的部分后，轴心对其的电场。\n通电导线的磁场 直导线的磁场分布和带电导线的电场分布是类似的，都是与距离成反比，只是方向不同。\n对于一个半径为 $R$，电流为 $I$ 的圆导线，与圆心距离为 $D$ 处的磁感应强度大小为 $$ \\int_0^{2\\pi}这部分咕了 $$\n通电螺线管的磁场 对于一个半径为 $R$，面电流密度为 $\\sigma$（$\\sigma$ 在数值上等于 $nI$，$n$ 为单位宽度上的匝数。电流为逆时针方向）的无限长通电螺线管，与轴心距离为 $D$ 处的磁感应强度大小为：\n假设螺线管轴心与 $z$ 轴重合，现拿出一段宽为 $\\d l$，与 $z$ 轴平行的无限长条，设它的电流方向为 $(d_x,d_y,0)$（模长为 $1$）。若将它平移到 $z$ 轴处，它对 $(x,y,0)$ 处的磁感应强度为 $$ \\begin{align*} \u0026amp;\\d l\\int_{-\\infty}^{+\\infty}\\frac{k\\sigma\\d z\\cdot(d_x,d_y,0)\\times(x,y,-z)}{\\left(x^2+y^2+z^2\\right)^{\\frac32}}\\\\ ={}\u0026amp;k\\sigma\\d l\\cdot(d_x,d_y,0)\\times\\left(\\frac{2x}{x^2+y^2},\\frac{2y}{x^2+y^2},0\\right)\\\\ ={}\u0026amp;2k\\sigma\\d l\\frac{d_xy-d_yx}{x^2+y^2}\\cdot\\vec k \\end{align*} $$ 回到原问题 $$ \\int_0^{2\\pi}2k\\sigma R\\d\\theta\\frac{-\\sin\\theta(D-R\\sin\\theta)-\\cos\\theta(-R\\cos\\theta)}{R^2+D^2-2RD\\sin\\theta}=2\\pi k\\sigma(1-\\sgn(D-R)) $$ 因此理想的通电螺线管，管内为强度为 $\\mu_0\\sigma$ 的匀强磁场，管上的强度为管内的一半，管外无磁场。\n电容充放电过程 充电过程中，设电源电压为 $E$，电容电压为 $U$，整个电路的电阻为 $R$。 $$ C\\dot U=\\dot Q=I=\\frac{E-U}{R} $$ 解得 $$ U=E(1-\\e^{-\\frac t{CR}}) $$ 同理可得到放电过程（这里的 $E$ 指电容的初始电压） $$ U=E\\e^{-\\frac t{CR}} $$ 无论哪种情况，都有 $$ I=\\frac{\\e^{-\\frac t{CR}}}{R} $$\n碰撞问题的理解 关于非弹性碰撞时的能量损耗，可以理解为两者相对于质心的速度的减小，详见这个回答。在这个回答中提到说，一个系统的动能等于其质心动能加上各部分相对于质心的动能，这是一个有趣的结论： $$ \\sum m_i\\bm{v_i}^2=M\\bm{V}^2+\\sum m_i(\\bm{v_i}-\\bm{V})^2\\\\ \\text{which }M=\\sum m_i,\\bm{V}=\\sum\\bm{v_i} $$ 直接展开即证。\n关于完全非弹性碰撞必定共速的原因，可以从两个角度理解。\n第一个角度就是直接求最值： $$ \\max;\\frac12m_1v_1^2+\\frac12m_2v_2^2-\\frac12m_1{v_1\u0026rsquo;}^2-\\frac12m_2{v_2\u0026rsquo;}^2\\\\ \\text{s.t.};m_1v_1+m_2v_2=m_1v_1\u0026rsquo;+m_2v_2\u0026rsquo; $$ 建立一个坐标系，横轴是 $\\sqrt{m_1}v_1$，纵轴是 $\\sqrt{m_2}v_2$。那么所有合法的情况都处于一条斜率为 $-\\sqrt{m_1/m_2}$ 的直线上。完全非弹性碰撞就是其上与原点距离最近的点，也就是原点到该直线的垂足，而这条垂线的斜率为 $\\sqrt{m_2/m_1}$，其上面的点就是 $v_1=v_2$。弹性碰撞可以视作关于这条垂线对称。\n第二个角度就是假想两球之间连了一个轻弹簧。那么弹簧长度最小或最大时，两球相对静止，这时弹簧的弹性势能最大，动能减少量最大。\n对了，考虑求一下弹簧的长度关于时间的函数？设伸长量为 $x$，初始为 $0$。 $$ \\left\\{\\begin{align*} \\dot{v_1}\u0026amp;=\\frac{kx}{m_1}\\\\ \\dot{v_2}\u0026amp;=-\\frac{kx}{m_2}\\\\ \\dot{x}\u0026amp;=v_2-v_1 \\end{align*}\\right.\\Rightarrow \\ddot{x}=-k\\left(\\frac1{m_1}+\\frac1{m_2}\\right)x $$ 解得 $x=\\dfrac{v\\sin\\sqrt cx}{\\sqrt c}$，其中 $c=k\\left(\\dfrac1{m_1}+\\dfrac1{m_2}\\right)$，$v$ 为初始的相对速度。\n因此这时实际上做的是类似简谐运动。同时可以轻松求出能量损耗最大值为 $$ \\frac 12kx_{\\max}^2=\\frac{m_1m_2v^2}{2(m_1+m_2)} $$\n单摆相关 考察一个初始时轻绳与竖直方向夹角为 $\\theta_0$ 且初速度为 $0$ 的摆的周期。\n夹角到 $\\theta$ 时，速度满足 $$ \\frac12mv^2=mgl(\\cos\\theta-\\cos\\theta_0) $$ 故周期为 $$ \\begin{align*} T(\\theta_0)={}\u0026amp;4\\int_0^{\\theta_0}\\frac{l\\d\\theta}{\\sqrt{2gl(\\cos\\theta-\\cos\\theta_0)}}\\\\ ={}\u0026amp;2\\sqrt{\\frac lg}\\int_0^{\\theta_0}\\frac{\\d\\theta}{\\sqrt{\\sin^2\\frac{\\theta_0}{2}-\\sin^2\\frac{\\theta}{2}}}\\\\ \\xlongequal{\\sin\\alpha=\\frac{\\sin\\frac{\\theta}{2}}{\\sin\\frac{\\theta_0}{2}}}{}\u0026amp;4\\sqrt{\\frac lg}\\int_0^{\\frac\\pi2}\\frac{\\d\\alpha}{\\sqrt{1-\\sin^2\\frac{\\theta_0}{2}\\sin^2\\alpha}}\\\\ ={}\u0026amp;4\\sqrt{\\frac lg}\\cdot K\\left(\\sin\\frac{\\theta_0}{2}\\right) \\end{align*} $$ 其中 $K(a)$ 为第一类完全椭圆积分。推导中最难的一步是换元，我也是从知乎上看来的（几篇都是这么搞的）。\n从而也可以验证书中的公式 $\\lim_{\\theta_0\\to 0}T(\\theta_0)=2\\pi\\sqrt{l/g}$。另外 $T(\\pi/2)\\approx 7.4163\\sqrt{l/g}$。\n如果换成轻杆也是一样的。对于能绕一整周的情况，设在顶部时速度为 $v_0$，那么周期为 $$ 2\\int_0^\\pi\\frac{l\\d\\theta}{\\sqrt{2gl(1+\\cos\\theta)+v_0^2}}=\\frac{4l}{\\sqrt{4gl+v_0^2}}K\\left(\\sqrt\\frac{4gl}{4gl+v_0^2}\\right) $$\n可以将上面的两种情况统一一下。如果能量等效高度为 $h$，令 $r=h/2l$， $$ T\u0026rsquo;(r)=\\left\\{\\begin{align*}\u0026amp;2\\sqrt{\\dfrac lg}K\\left(\\sqrt r\\right),\\quad\u0026amp;r\u0026lt;1\\\\ \u0026amp;2\\sqrt{\\dfrac l{gr}}K\\left(\\frac 1{\\sqrt r}\\right),\\quad\u0026amp;r\u0026gt;1\\end{align*}\\right. $$ 为了整齐起见，$r\u0026lt;1$ 时 $T\u0026rsquo;(r)$ 表示半周期。\n悬链线 设曲线的函数为 $y=f(x)$，其中最低点在 $y$ 轴上，两头在 $(\\pm d,0)$。\n首先，由于悬空部分只受重力作用，故绳每一点的张力横向分力均相等，设为 $T$。则点 $x$ 处的张力纵向分力大小为 $T\\cdot\\lvert f\u0026rsquo;(x)\\rvert$。\n取绳上小段 $x$ 到 $x+\\d x$，由受力平衡， $$ T(f\u0026rsquo;(x+\\d x)-f\u0026rsquo;(x))=\\rho g\\sqrt{1+f\u0026rsquo;(x)^2}\\d x $$ 即 $$ y\u0026rsquo;\u0026rsquo;=\\frac{\\rho g}T\\sqrt{1+{y\u0026rsquo;}^2} $$ 记 $k=\\rho g/T$，解得 $$ y=\\frac{\\cosh kx-\\cosh kd}{k} $$ 其中 $T$ 一般由绳长 $l$ 确定，满足 $$ l=\\frac{2\\sinh kd}{k} $$\n机械振动 简谐振动 简谐振动满足方程 $$ \\ddot x=-\\frac kmx $$ 有通解 $$ x=A\\sin(\\omega t+\\varphi) $$ 其中 $A,\\omega,\\varphi$ 可以由系统已知量和初始情况 $x_0,v_0$ 确定（记 $\\alpha=k/m$）： $$ \\begin{align*} \\omega\u0026amp;=\\sqrt\\alpha\\\\ A\u0026amp;=\\sqrt{x_0^2+\\frac{v_0^2}\\alpha}\\\\ \\varphi\u0026amp;=\\mathrm{atan2}\\left(x_0,\\frac{v_0}{\\sqrt\\alpha}\\right) \\end{align*} $$\n阻尼振动 阻尼振动满足方程（阻力正比于速度） $$ \\ddot x=-\\alpha x-\\beta\\dot x $$ 根据微分方程相关理论，要讨论 $\\Delta=\\beta^2-4\\alpha$ 的正负。\n临界阻尼 当 $\\Delta=0$ 时 $$ x=\\e^{-\\frac\\beta2t}\\left(x_0+\\frac\\beta2x_0t+v_0t\\right) $$\n临界阻尼是收敛最快的。\n过阻尼 当 $\\Delta\u0026gt;0$ 时 $$ x=\\e^{-\\frac\\beta2t}\\left(x_0\\cosh\\frac{\\sqrt\\Delta}2t+\\frac{\\beta x_0+2v_0}{\\sqrt\\Delta}\\sinh\\frac{\\sqrt\\Delta}2t\\right) $$\n欠阻尼 当 $\\Delta\u0026lt;0$ 时 $$ x=\\e^{-\\frac\\beta2t}A\\sin(\\omega t+\\varphi) $$ 其中 $$ \\begin{align*} \\omega\u0026amp;=\\frac{\\sqrt{-\\Delta}}2\\\\ A\u0026amp;=\\sqrt{x_0^2-\\frac{(\\beta x_0+2v_0)^2}\\Delta}\\\\ \\varphi\u0026amp;=\\mathrm{atan2}\\left(\\frac{x_0}A,\\frac{\\beta x_0+2v_0}{\\sqrt{-\\Delta}A}\\right) \\end{align*} $$ 由此可知欠阻尼振动的周期为 $$ T=\\frac{4\\pi}{\\sqrt{4\\alpha-\\beta^2}} $$\n对比图 令 $\\alpha=1,x_0=1,v_0=0$。\n（有没有人能告诉我 Mathematica 里 Plot Legended 的图例的线长怎么改啊）\n受迫振动 受迫振动满足方程 $$ \\ddot x=-\\alpha x-\\beta\\dot x+\\gamma\\cos\\omega t $$ 解微分方程过程中，可以发现它能被拆分成无策动力的阻尼振动和频率为策动力频率的简谐振动。\n对于 $\\beta\\ne 0$ 的情况，前者趋近于 $0$，后者振幅为（完整表达式这里就不算了） $$ A=\\frac\\gamma{\\sqrt{(\\alpha-\\omega^2)^2+(\\beta\\omega)^2}} $$ 如果 $\\beta^2\u0026lt;2\\alpha$，则取到最大值时 $$ \\omega=\\sqrt{\\alpha-\\frac{\\beta^2}2},A=\\frac\\gamma{\\beta\\sqrt{\\alpha-\\dfrac{\\beta^2}4}} $$ 否则 $\\omega\\to 0$ 时，$A\\to A_{\\max}=\\gamma/\\alpha$。\n对于 $\\beta=0$ 的情况，假设初始 $x|_{t=0}=\\dot x|_{t=0}=0$。如果 $\\omega^2\\ne \\alpha$，则 $$ x=\\frac\\gamma{\\alpha-\\omega^2}\\left(\\cos\\omega t-\\cos\\sqrt\\alpha t\\right) $$ 在 $\\omega/\\sqrt\\alpha\\in\\R\\setminus\\mathbb{Q}$ 时，$\\sup\\lvert x\\rvert=2\\gamma/\\lvert\\alpha-\\omega^2\\rvert$，其余情况下 $x_{\\max}$ 或 $x_{\\min}$ 会很难求。实际分析时，我们会认为 $\\beta$ 较小但不为 $0$，这样 $A\\approx\\gamma/\\lvert\\alpha-\\omega^2\\rvert$。\n如果 $\\omega^2=\\alpha$，则 $$ x=\\frac{\\gamma t\\sin\\omega t}{2\\omega} $$ 综上，$A$ 的公式可以推广到任意 $\\alpha,\\omega\u0026gt;0,\\beta\\ge 0$。\n对比图 令 $\\alpha=\\gamma=1$。蓝色虚线表示最优顶点。由此可见，当 $\\beta\\ll\\alpha$ 时，$\\omega=\\sqrt\\alpha$ 会导致共振。\n粒子在磁场中的运动轨迹 一个质量为 $m$，电荷量为 $+q$ 的带电粒子在磁感应强度为 $B$ 的匀强磁场中静止释放，考虑重力。取垂直于磁场的面作平面直角坐标系，磁场向内，原点为初始位置，向右为 $x$ 轴正方向，向下为 $y$ 轴正方向。 $$ \\left\\{\\begin{align*} qB\\dot y\u0026amp;=m\\ddot x\\\\ -qB\\dot x+mg\u0026amp;=m\\ddot y \\end{align*}\\right. $$ 令 $k=qB/m$。两式分别求导代入另一式，结合初始条件解得 $$ \\left\\{\\begin{align*} x\u0026amp;=\\frac g{k^2}(kt-\\sin kt)\\\\ y\u0026amp;=\\frac g{k^2}(1-\\cos kt) \\end{align*}\\right. $$ 这是摆线。\n章动 以陀螺脚为参考点。考虑质心在圆盘中心，设质量为 $m$，质心为 $\\vec{l}$，转动惯量为 $I$，角动量为 $\\vec{L}$。\n陀螺在一个瞬间的运动可以用两个量描述：自转的角速度 $\\omega$，公转的速度 $\\vec{v}$。 $$ \\left\\{\\begin{align*} \\vec{l}\\cdot\\vec{v}\u0026amp;=\\vec{0}\\\\ m\\vec{l}\\times\\vec{v}+I\\omega\\cdot\\frac{\\vec{l}}{\\lvert\\vec{l}\\rvert}\u0026amp;=\\vec{L} \\end{align*}\\right. $$ 解得 $$ \\left\\{\\begin{align*} \\omega\u0026amp;=\\frac{\\vec{L}\\cdot\\vec{l}}{I\\lvert\\vec{l}\\rvert}\\\\ m\\vec{l}\\times\\vec{v}\u0026amp;=\\vec{L}-\\frac{\\vec{L}\\cdot\\vec{l}}{\\vec{l}\\cdot\\vec{l}}\\cdot\\vec{l} \\end{align*}\\right. $$ 另有 $$ \\dot{\\vec{L}}=\\vec{l}\\times\\vec{G} $$ 不会解。猜想：$\\vec{l}$ 是关于时间的三角函数。\n","date":"2024-08-30T00:00:00Z","image":"https://littlereuben.github.io/study/physics0/cover.jpg","permalink":"https://littlereuben.github.io/study/physics0/","title":"高中物理中的拓展问题"},{"content":"这是一篇摘抄笔记。\r《汉字与东亚文化》[韩] 金文京\n如果有觉得内容有问题或者我概括得有问题的请纠错。\n下文年份略，可以自行看书。\n引入 这里先为书纠个错：阿尔泰语系已经被否定了；语系与语言类型没有必然联系。\n东亚各国的人民在民族、宗教、语言、世界观、政治立场上都有很大差别或分歧，为了概括他们的文化共同点，就不能用这些方面的要素。日本学者首先提出“汉字文化圈”的概念，然而，尽管汉字确实成为东亚各国的文化的一个纽带，但若考虑与文字相关的其他语言学概念，包括读音和语法，还有汉字在文章中的应用，这些在各国就有很大不同了。这本书要讨论东亚各国是如何引进汉字并对其加以改造与吸收的，就要同时分析汉字背后更深层的文化和历史因素。\n汉字和各国本土语言之间的纽带，除了本土语言直接模仿汉字读音，吸收为“外来语”以外，就是训读。“训”即为“训诂”。\n日语训读 概况与发源 日语的训读分为两类：くんよみ和くんどく。くんよみ就是用汉字意义对应固有词来读汉字，くんどく则是通过改变整句汉文中的语序使其符合本土语言语序。在解汉文时，日本人会加上返点（返り点）、振假名（振り仮名）和送假名（送り仮名），然后用日语的方式读，这就是書き下し文。\nくんよみ直接用日语读汉字，而不是以注解形式出现，作者认为这是因为缺乏交谈机会，没必要练好发音，翻译可以代替本音。\n日本训读的源头是模仿中国古代的佛经汉译和训诂。佛经汉译时，先用汉语音译再意译，日语也可以这么搞（只不过是反过来用汉语音译日语）；同时也把梵语的 SOV 变成 SVO，日语就再返回来。 $$ \\begin{matrix} \u0026amp;用汉字表记\u0026amp;\u0026amp;用汉字表记\u0026amp;\\\\ 梵语\u0026amp;\\longrightarrow\u0026amp;汉语\u0026amp;\\longleftarrow\u0026amp;日语\\\\ 多音节\u0026amp;\u0026amp;单音节\u0026amp;\u0026amp;多音节\\\\ \\rm SOV\u0026amp;\u0026amp;\\rm SVO\u0026amp;\u0026amp;\\rm SOV\\\\ 屈折\u0026amp;\u0026amp;孤立\u0026amp;\u0026amp;黏着 \\end{matrix} $$ 语言特征上的对称性给人一种梵语和日语的对应感，造成了翻译、文本表记方式的对称性。在意识层面的影响后面再提。\n这里的模仿还可以具体到符号。返点包括レ・一・二・三・上・中・下，其中レ点源于中国古代用于订正笔误颠倒所用的“乙”符号，这个符号也演化成现在修改文章用的对调符号。一二三也在陀罗尼中有见到。\n佛经汉译日译的过程中产生的另一个研究是悉昙学——研究字母的学问，这导致了五十音图的产生。作者认为，佛经汉译时的标准固定音译汉字，是假名的来源。\n从意识层面讲，首先，佛经里说，佛可以用各种语言讲法，正本以外的文章也算佛说，这保证了梵汉和汉和翻译的基础，也同时造成了伪经的泛滥。其次，梵语和日语（在表征上的）相似性，使古代日本人产生了梵和同类说、本地垂迹说和反本地垂迹说，用汉字表记日语对应成了陀罗尼。日语用汉字和假名的标记方式的意识根源也在于——与梵文产生对应。这个意识的背后，根源是古代日本大量学习中国文化，但为了保留自己的本土文化，需要与中国文化有一定抗衡的思想，这就要借以印度的佛教这一较远的文化。\n日语训读的演变 汉字的くんよみ，以及汉文的くんどく，都是日本人学习并吸收汉字文化，再将其变为自身文化的方式。它们逐渐从理解汉文的工具，转变为独立的文体。\n日语训读的演变：口头训读→包含语顺符（数字、句读点）和送假名（万叶假名）的早期训读体系→ヲコト点→角笔→接近现代的汉文训读\nヲコト点源于中国的用于标注破音字声调的圈发，利用不太占空间的点符号在字周围的不同位置和形状，区分不同的助词。不同宗派的点图是不同的，是保密的。而新佛教的兴起、武士阶级掌权导致的知识掌握格局的变化、木版印刷的使用，导致ヲコト点的衰落，变为类似现在的训读。另外，大量禅僧留学导致了直读思路的产生。直读的一个论点是助词也有重要的语义语感作用，以及为了“复文”。推崇直读在客观条件上是由于与中国人交流变频繁，在意识上也是受到了朱子学的影响。\n到后面到了训读废止论、训读无用论的地步。要么直读，要么完全译成日语。当然训读的影响还在，实践上总是无法完全摒除（一斋点）。\n开放与外国交流后，训读被用于其他语言间的转换。同时直读指向了将汉语作为外国语学习。而军国主义则推崇汉文训读。\n五最后一段总结还是挺全面的。\n朝鲜语训读 概况 古代朝鲜半岛也有汉字训读，经典的《千字文》音训并读流传至今。关于句子的训读，新罗时期的训读也是用汉字省笔和倒读符号，还有一种是角笔写的训点。根据史料史实的一种推测是，训读是从新罗通过佛经传给日本的。朝鲜王朝时期也是有类似的训读。发明谚文后，有一类对汉文的《谚解》，是用悬吐（也叫口诀，句末加吐即助词）加朝鲜语翻译（也是汉谚混写）。训读到谚解主要是对佛教的抑制。\n近代由于日本的占领，朝鲜使用汉谚混写，甚至出现汉字训读的提议。\n日朝训读的对比 日本 朝鲜 佛经 训读 训读 儒学与朱子学 直读与日译 汉字音与谚解 早期诗歌的记录方式：\n日本 朝鲜 越南 和歌 乡歌 诀 用万叶假名表记日语 用汉字表记朝鲜语；试图译成汉诗 用喃字表记越南语；从汉文翻译而来 日本和朝鲜的训读后期发展不同，有与中国交流程度不同、佛教兴衰程度不同等客观原因，也有由地理、政治等原因导致的国家意识的原因。日本主打一个“对等”，把天竺、震旦、日本对等起来，把汉文和训读体对等起来。而朝鲜无法这样，则是“自居中华”（至于这个意识如何和废直读联系起来，书中没给出答案，这个有待进一步研究）。\n其他语言 契丹语有训读现象，无书面训读符号。回鹘语有训读现象，以及汉字音加翻译的解汉文形式，但无训读符号。越南语有训读现象，用喃字表记固有词，有汉字音加翻译的解汉文形式，无训读符号。\n汉语也处在变化之中（除了本身的变化，主要还有是北方游牧民族语言的干扰），不仅是语音、词汇，也包括语法，因此不同时期的人们都会用当时的词汇、语法去翻译更早期的文章，叫做“直解”。尽管不至于训读，但人们在脑中已出现间接的“翻译”过程。\n与汉字相关的文学 汉字在书面上连接了东亚各国。尽管发音、解汉文的方法各异，但书面汉文（以及汉诗）在各国都是一致的，这也为“笔谈”提供条件。从另一角度来说，从语音出发的汉诗的格律要求就变成了人为规定。\n古代汉文本身也有很多种类，包括骈文、散文、吏文、尺牍文、佛教汉文、诗、词、曲、白话文学等等。那这些不同的文体对其他各语言也产生了不同的影响。\n介于正规汉文和其他本土语言之间的，是变体汉文。主要包含受水平所限夹杂不正确用法、本土词汇（汉字写法），影响质量的不成熟的汉文，以及刻意使用本土语言语法词汇的拟汉文。\n比较正规的变体汉文有：日本的宣命体、候そうろう文、書き下し文、漢文訓読体，朝鲜的吏讀文，蒙文硬译体和汉儿言语。\n其他用汉字表记的本土语言的文体就不记了。\n日本的初高中教育里国文会学汉文，也会单独学汉文。韩国在高中，汉文和中文并列为外国语。越南不学。\n附：东亚各语言历史表记方法 日语 日语最早是直接假借汉字表音，即万葉仮名（实际上万叶假名里也包含少量训读的情况，例如女め、止と、部へ）。\n平安时代开始使用假名，平片假名分别由万叶假名的草书和部分演化而得。一开始没有统一规范，所以一音有多种表记，相对于现在非标准的假名被称为変体仮名。同时尽管当时语音上已有浊音、拨音、促音、拗音，但表记上没有，浊点是几百年后才有的。\n从那时开始，除了部分纯平假名文章，日语大部分由汉字假名混写文（漢字かな交じり文）记录。\n由于语音变化，战后政府发布了現代仮名遣い，调整了正字法（拨音小っ、拗音小ゃ行、四つ仮名、废ゐゑ、非开头は行、助词はを、长元音）。\n战前后政府发布了《当用漢字表》《常用漢字表》，规定新字体。\n朝鲜语 朝鲜语最早也是一样，即吏리讀두（名称有很多，比如吏書、吏吐、鄉札等）。不同的是，这个吏读不仅包含用汉字表记助词和固有词，也包含对汉字的训读，而且在谚文发明后仍在使用。\n14 世纪世宗发布《训民正音》后开始用谚文（一开始就叫언문，한글这个名字是 20 世纪才有的），用谚文给汉字注音，也有汉谚混写（國국漢한文문混혼用용），类似日本，也有妇女儿童写的纯谚文文章。\n然后说日据时期的汉谚混写主要是日语的影响，这个我不是很懂。战后，民族主义就推崇废除汉字（韓한㐎글專전用용）。朝鲜在金的指示下马上废除了汉字，但保留汉字教育；韩国朴实行了韩文专用政策，70 年至今汉字使用基本是递减趋势（有起伏）。谚文方面政府也颁布了正字法，相对于古代主要是去掉了ㅿㆁㆆㆍ等已合并的发音表记（不过这个其实是先前已逐渐消失的），规定紧音的写法、收音双收音，还有隔写等。\n越南语 越南古代的官方长期都是用汉文，而民间有假借汉字，并创造喃字。十七世纪西方传教士创造了越南语拉丁字（𡨸chữ國Quốc語ngữ），后续法国殖民政府推行之，并禁用汉文和汉喃文。我看到过一个比较有意思的是胡志明的汉字和国语字混写。现在越南不用汉字和喃字，也基本没人认识了。\n例 日语 朝鲜语 越南语 音读 漢かん 文문 國quốc 假借 安あ 隱을 沒một 训读 山やま 桑뽕 国字 凪なぎ 乭둘 𡗶trời 其他与汉字相关的文字包括契丹大小字、西夏文、女真字、女书。\n值得注意的是，关于日朝的训读、汉和/谚混写的问题，假名/谚文的问题，知乎上有不少以语言特征对应表记可行性为理由的分析，这是倒置了因果，是很片面的，应当排除。\n附：东亚各语言之间人、地名互译方式 取自知乎的某个帖子，但是原作者我目前找不到了。\n音译目前对方语言的发音的，叫“现地音”。韩国主张用现地音（例如베이징、도쿄），反正我感觉很难看。\n延伸阅读 日语历史（宝藏）\n古日语 up 主\n古朝鲜语 up 主\n金文京教授的讲座（直接 b 站搜也行）\n汉字古今中外读音查询（王赟 maigo 有许多关于汉字文化圈语言的回答）\n中古朝鲜语汉字音表\n中古朝鲜语汉字音研究\n日语古代汉字音随便哪里都能查到，无非就是用历史假名遣。越南汉越音和喃字字典也容易查到。\n思考 在上面的分析中我们会发现，除了佛教、儒学、朱子学、和古代中国的交流这些文化交流以外，还有一个很大的因素就是各自的民族意识。各国面对汉字的态度，其实就是在学习中国文化与保留本族文化之间不断摇摆，达到一个变化中的平衡。尽管当今，社会上的、国家间的问题其主要因素是利益，但政治、文化、历史因素也是不可忽视且融为一体的。所以我觉得，这本书的分析其实可以启发我们对这些问题的思考，思考我们对一些事情定性的判断标准是什么。当然不能完全类比汉字（汉字的属性比较单一），但至少能提供一个角度。\n思考会持续更新。\n","date":"2024-08-24T00:00:00Z","image":"https://littlereuben.github.io/theory/book-hanzi-yu-dongya-wenhua/cover.png","permalink":"https://littlereuben.github.io/theory/book-hanzi-yu-dongya-wenhua/","title":"《汉字与东亚文化》阅读笔记"},{"content":"这是一篇摘抄笔记。\r在提起某個漢語方言時，人們的第一反應大部分是發音、比較特色的一些實詞，抑或是語序，而對於虛詞，尤其是副詞以外的虛詞，則很少有人注意。這種現象不僅發生在不瞭解該方言的人身上，母語者也是如此。作為學校去方言化的一代人，我覺得我們對於自己的方言主要有兩點缺乏認識：一是較少用但地道的實詞。因為我們學方言只能聽長輩講，而現在長輩講方言一般都是日常生活，柴米油鹽相關的場景，很多詞，包括一些有典故的成語、歇後語都用不上，或者有多種表示同一意思的詞長輩習慣於用其中一種，或者根據地區有些詞少用，那我們就接觸不到。二就是語法。至少對我來説，小時候很少用方言說長句。而到小學高年級或中學以後再練習，已經過了最佳習得期，多有語法錯誤或不豐富。這樣一來，我們說的就是不正宗的“普通話式方言”。而漢語作為孤立語，虛詞起到的很重要的語法作用。我作以下的總結，就是想引起大家對方言語法的關注，順帶還有方言的正字。\n以下詞僅包括我知道的詞，如果有補充可以評論。\n注：\n非官話我想還是用繁體字吧。所以為什麽上面這些也用 拼音使用吳語學堂的拼音方案，非單字不標調。資料參考吳語學堂和甬江小片方言資料整理。説是參考，其實基本完全就是看這兩個。 在等號或約等號后，帶引號的是普通話，加粗的是寧波話。 義項帶星號的是實義。如果實詞義不是特有（普通話裏沒有）的義，就省略。 如果一個詞的意義與普通話裏完全相同，就不記錄了。 aq 往往在口語中發音并非 /ɐʔ/，而是 /əʔ/ 甚至 /ɪʔ/。 句首語氣詞可以在句中單用。 漢字 拼音 釋義 備注 個 ghoq8/goq8 ①=助詞“的”“地”；②=句末語氣詞“的”； 嗬 ghou5 =個； 應該是音變，意思完全相同。 噢 ghau2 ①句末語氣詞，表提示； 詞典裏說表示這個義項的是嗬，但音不對。 哎 ei1/ghei2 ①句首語氣詞，表應答；②句首、末語氣詞，表强調、提示； ei1 只用於①；ghei2 用於句首時微微有不耐煩之感。 嗐 ghe6 ①句首語氣詞，表驚訝或贊嘆； 誒 e1 ①句首語氣詞，表同意或接收信息； 詞典裏沒有。 呐 naq8/nha1 ①句首語氣詞，表祈使或同意；②句首語氣詞，表讓人注意； 了 laq8 ①=助詞“了”； 不能用於句末。我感覺與勒區分沒必要，但詞典裏列了這條。 𡀂/了 lei2 ①=助詞“了”；②句末語氣詞，表感嘆、誇張、催促、勸阻等； 僅用於句末。 勒 laq8 ①=了；②=用於伴隨狀語的“着”；③=助詞“得”；④=表示所有格的“的”；⑤=介詞“到”；⑥=介詞“在”； 勒其、勒眼 laq ji、laq ngae =勒②； 來 le2 ①=表示時間或地點的“在”；②=“正在”； 口語上可讀 liq。 來勒、來的、來該 le laq、le tiq、le ke =來； 來的用於近指，來該用於遠指。來和來勒不能單用，來的和來該可以單用，但調不同。 的 tiq7 ①表示動作或狀態的持續，近指；②很； ②用於一些固定搭配。 東 ton1 ①=的①（語氣更强）；②句末語氣詞，表强調； 該 ke1/kiq7 ①表示動作或狀態的持續，遠指；*②代詞，這、那； ①讀 ke1，②讀 kiq7。 仔、的仔 tsy3、tiq tsy ①表示完成或假設完成，≈“了之後”；②表示動作的持續或動作的伴隨；③句末語氣詞，表祈使； 啦 la6/laq8 ①特殊疑問句的疑問詞；②=用於列舉的“啊”；③語氣詞，表强調； 勿/弗 vaq8/faq7 ①=“不”； 城區應該都是讀 vaq8 的。不能單用。 勿啦 vaq laq/vaq la ①一般疑問句的疑問詞；②句末語氣詞，表揣測； 口語上可讀 vəq la/vla/vaq/va，其中後兩者可合寫作𠲎。 𣍐 vei2 ①=表示沒能力的“不會”；②表示不願意的“不會”；③=勿啦； ①可以拆成勿會。 𣍐好 vei hau ①=“非常”；*②形容數量多、程度深等，≈“不得了”； 覅 fe1 ①=“不要”； 後面必須接其或動詞。 甮 ven2 ①=“不用”； 後面必須接代詞或動詞。 甮派 ven pha ①=“非常”“甭提有多麽……”； 好甮 hau ven ①=“不用”； 後面可以不接。 莫 mhau1 ①=“別”；②表示希望不要但實際有可能發生，≈“別是”； 嘸 mh5 ①=“沒有”； 用於一些固定搭配。 嘸沒 mhiq7 ①=“不”；②=“沒”； ①僅接形容詞，也可以單用。 沒 maq8 ①滿，整； 咋 dza6 ①=“咋”；②=“什麽”；③表示程度深；④表示程度，與否定詞連用； ④例：莫咋、𣍐咋、覅咋、呒没咋。 撥/畀 paq8 ①=介詞“給”；②=“被”；*③=動詞“給”；*④=表示“使”的動詞“讓”； 可與我、阿拉、儂、渠等代詞合音成 po、paq laq、pen、pi。 搭 taq7 ①=介詞“跟”；②=表示“幫”的“給”；③=介詞“對”；④=“把”； 可與我、阿拉、儂、渠等代詞合音成 to、taq laq、ten、ti。 搭仔 taq tsy =搭①； 格 kaq7 ①=表順接的“那”；②句中語氣助詞，無實義； 格貌格 kaq mau kaq ①=“這樣子”； 口語上可讀 kaq maq kaq。 格貌 kaq mau ①=格①；②=格貌格； 口語上可讀 kaq maq。 介 ka5 ①=“這樣”；②=表示程度深的“這麽”；③=“似的”；④=助詞“地”； 格貌的格就是其的音轉。①與格貌格語感上差別大。③④都可以讀作 kaq7 從而和格互通。 純 zyun2 ①=“全都”； 頂 tin3 ①=“最”；②=“上面”；③實詞； 煞 saq7 ①=“很”；②=表示程度深的“死”；*③=實詞用於補語的“死”； 侅 khi1/khe1 ①=“很”；*②=“很多”； 侅煞 khi saq =侅①； 眼 ngae6 ①=表示數量少的“點”； 少數搭配中不明確表示數量少，如勒眼、該眼。 扣 kheu5 ①=“恰”；②=“偏偏”； 凑 tshei5 ①=“跟（一起）”； 口語上可讀作 tshae5。我不確定別樣凑的凑怎麽解釋。tsheu5 是實詞義。 不 paq7 ①用於AB不B結構，表示“AB之類”“AB什麽的”； 不剌 paq laq ①=“的樣子”，多貶義； 裏 li6 ①形容詞和副詞後綴，≈“的樣子”；②用於A裏AB結構； ②的準確含義我也搞不清。 西 shi1 ①用於亂A西A結構； 記 ci5 ①用於A記A記結構，表示動作的重複或某種情態； 三千 sae chi ①用於亂A三千結構，表示胡亂做； 生 san1 ①用於數量詞后，表示關於數量的狀態； 式 soq7 ①用於形容詞后，表示情態或程度；②用於動詞后，表示動作的方式； 法 faq7 =式； 相 shian5 ①用於各種詞后表示對應的樣子或感覺； 是話 zy wo ①=“如果”；*②=表肯定“是這樣說”； 单超 tae chiau ①=表條件關係的“只要”； 東西 ton shi ①句末語氣詞，表肯定或强調； 聲響、一聲響 shin shian、iq shin shian ①=“之後”； 語感上强調“一做前面說的事之後馬上有某種反應”，或也常表示假設。 只只、是只 ciq ciq、zy ciq ①=“只（是、有）” 總只 tson ciq ①=只只、是只；②=“只能”“只好”； 和總 ghou tson ①=“都”； 聚頭 zyu deu ①=“一起”； 躉注 ten tsyu ①=“一并”； 交關 ciau kuae ①=“很”；*②=“很多”； 犯關 vae kuae ①=交關①；*②糟糕，不妙； 和個 ghou kou ①=“完全”； 藍扮 lae pae ①=“偶爾”； 候着 gheu zyuq ①=“有時候”“有機會”；*②抓到機會，剛好碰到；*③沒準，以後什麽時候有機會不確定了； 老老 lau lau ①=“經常”； 時格 zy kaq ①=“老是”； 退過 thei kou ①=句末語氣詞“算了”；*②糟糕，完蛋； 還只 wa ciq ①=“才”；②=“剛剛”； 怕、怕其 pho、pho ji ①=“難道”； 派派 pha pha ①=“按理説”； 限板 ghae pae ①=“肯定”； 好壞 hau ua =限板； 真到話、正式 cin tau wo、cin shiq ①=“確實”；*②真的； 真到話有額外的語感，表示聽到消息的人感到不可思議。 是會 zy wei ①=“果然”“真”； 是介 zy ka ①≈“又很”；*②=表示求情、妥協的“算了”；*③=表示勉强接受的“罷了”“由它了”；*④=“是這樣”； 眼眼叫 ngae ngae ciau ①=“恰巧”； 虧煞 chiu saq ①=“幸虧”； 横𠡒 uan tei ①=“硬是”；*②偏執的； 偏生 phi san ①=“偏偏”； 順埭 zyun da ①=“順便”； 仍規 jin kuei ①=“依舊”； 能可、能使 nen khou、nen sy ①=“寧可”； 反使、反向 fae sy、fae shian ①=“反而”； 如話、是話 syu wo、sy wo ①=“如果”； 是話呐的是話=是介話。 省勒 sae laq ①=“省得”； ","date":"2024-08-24T00:00:00Z","permalink":"https://littlereuben.github.io/theory/ningbonese-function-word/","title":"宁波话中的虚词"},{"content":"这是一篇收集。\r第三列是样例输出一的第一个字符串，可用于校验。\nadhoc 包括分析性质结论、线性扫描、推式子，还有一些基础算法（二分、倍增等）和数据结构（队列、栈等）。\n难度为预估 CF 评分除以 100。\n以下不含原题，但有可能考后被发现恰巧是已有类似的题。\n中文名 英文名 SO1 类型 难度 备注 挑战群同构 npc 1 数论 32 配对 pair 5 ds 33 天桥 bridge 3 ds 33 \u0026gt;1 被爆标了 连连看 game 332748215 poly 35+ 23 互测 原子 atom 2 构造 20 旅行计划 plan 3 图论 24 禁止套娃 nest 23 dp 27 \u0026gt;1 简单题 easy 1 数论 34 \u0026gt;1 染色数组 color 2 adhoc 21 博弈 game 5 博弈\u0026amp;dp 33 消消乐 bubbles 2 adhoc 34 土豆田 potato 4 adhoc 25 CF627E 弱 像素原神 mc 5 dp 32 区间操作 oper 2 ds 35 猜排列 interact 2 adhoc 16 异或 xor 24 adhoc 25 机器车路径规划问题 path FAIL 构造 26 × 猴子排序 sort 1 dp 31 最简洁的题面 simple 2 数论 35+ × ","date":"2024-08-08T00:00:00Z","permalink":"https://littlereuben.github.io/study/problemsetting/","title":"OI 出题列表"},{"content":"这是一篇记事。\n本文记录的内容并非完全准确，观点仅供参考。\r背景：小 Y 与小 Z 互相分享学习经历。小 Y 向小 Z 介绍了 OI 的考察内容。\n小 Z：所以说，OI 的出题范围其实很有限，做得多了也没什么新的花样。你们训练的时间越长，其实只是在这里面钻牛角尖钻得越来越深罢了，而且越来越脱离实际。\n小 Y：我觉得不是这样的，在做 OI 时，我们都感觉自己是在研究这个世界最底层的东西，因为随着我们不断优化这些算法，我们就不断接近这些问题解的复杂度下界，这就像数学和物理中的那些常数一样，对应着宇宙中一些最基本的关系，例如带修区间查询的下界是 $q\\log n$，静态区间半群信息查询的下界是 $(n+q)\\alpha(n)$，还有现在学术界取得进步的负权最短路、网络流等等，这些结果都是很吸引我的。\n这就像什么呢？我想到《三体》里，有讲到，人类跟四维生物的机器对话，就通过互相发送质数（$2,3,5,7,\\cdots$）来表明自己是智慧生物。算法也是这样的一种东西。\n小 Z：你如何理解质数？\n小 Y：（疑惑）你想让我回答什么？定义吗？那不就是不存在非平凡因子的 $1$ 以外的正整数吗？\n小 Z：从抽象代数的角度。\n小 Y：（略作思考）我知道高斯质数，就是复数上的。也可以是环上的，域上的，比如不可约多项式。\n小 Z：很好，我在你这个年纪的时候也是大概接触并想到了这些东西。所以，你觉得如果真的出现了科幻小说中的场景，人类把质数发过去，外星人会不会更可能只是不屑一顾？\n小 Y：（恍然大悟）你的意思是不是说，OI 研究的是在图灵机模型下的算法，而这可能只是某个“抽象计算模型”的特例？而量子计算是一个不同的特例？所以你说，OI 只是在钻牛角尖。\n小 Z：是的。我觉得，既然你喜欢计算机，希望探寻这个世界的本质，那么在未来，你更应当做的，是开创新的计算模型和计算工具，那才是真正的创新。你不要因为擅长解算法题，因为自己这之前的成就，就认为自己最喜欢的是算法理论，把自己困在传统模型的领域内。\n","date":"2024-07-30T00:00:00Z","permalink":"https://littlereuben.github.io/theory/conversation1/","title":"一段对话"},{"content":"$\\gdef\\rank{\\operatorname{rank}}\\gdef\\nul{\\operatorname{Nul}}$\n这是一篇学习笔记。\r书是丘维生的《高等代数（上册）》。由于自己以前学过一些线代，所以这里列出的都是一些细节。\n所有矩阵默认 $n$ 行 $m$ 列，秩为 $r$。\n1.1：这里证明以下最简行阶梯形唯一。第一步是证明主元位置相同。假设 $A$ 化为了 $B=\\begin{bmatrix}\\beta_1\u0026amp;\\cdots\u0026amp;\\beta_n\\end{bmatrix}^\\top$ 与 $C=\\begin{bmatrix}\\gamma_1\u0026amp;\\cdots\u0026amp;\\gamma_n\\end{bmatrix}^\\top$，已知 $\\set{\\beta_i}\\cong\\set{\\gamma_i}$。如果它们在第 $k$ 行第一次出现了主元不同，不妨设 $B$ 的这行主元在前，就会发现 $\\set{\\gamma_i}$ 无法表出 $\\beta_k$，因为 $\\gamma_{1\\sim k-1}$ 的系数必须是 $0$，而 $\\gamma_{k\\sim n}$ 又无能为力。第二步是证明 $\\beta_i=\\gamma_i$，同样是线性表出，其他向量的系数都必须是 $0$。\n另外再证明非主元列是左侧主元列的线性组合。首先阶梯型矩阵中，左侧主元列形成上三角，必满秩，即证。如果要证明原矩阵也符合该性质，只需利用行变换不改变列向量之间关系的性质即可。\n2.4 \u0026amp; 2.6：展开的证明。核心：行列地位相等，$\\tau(p)=\\tau(q)+\\tau(p\u0026rsquo;)$，其中 $\\set{(i,p_i)}=\\set{(q_i,p\u0026rsquo;_i)}$。\n2.4：范德蒙德行列式的证明。要避免 $a_i^k-a_1^k$ 就需要差分，倒过来减。\n2.7.例5：三对角行列式，结论可以记一下。\n2.*：循环矩阵行列式的处理思路。先乘个 $F$，最后可以除掉，或者我的思路是直接单位根反演。另外，计算 $|F|$ 如果只是平方一下，会遇到正负无法确定的问题，处理方法详见 https://zhuanlan.zhihu.com/p/507677010。\n2.5：Cramer 法则。理解：考虑魔改高斯消元的过程：第 $j$ 列当作不存在，$j-1$ 列主元出来了之后直接搞 $j+1$ 列。这样最后一行只有 $a_j$ 和 $b$。这个时候 $|A|$ 就是所有主元再乘上 $a_{n,j}$，$|B_j|$ 就是所有主元乘上 $b_n$，因此除一下就是 $x_j$。\n2.4.例3：加边法。有点神秘。\n2.4.定理4：mark.\n3：线性无关性、极大线性无关组的大小、秩、行列式、线性空间维数（及基大小）、方程解数、可逆性，这么几个角度。\n3.5：行秩等于列秩。无论是行、列秩，行列式，它们的性质都是通过初等变换下的不变性来证的。\n3.7.例3：理解：$k$ 行这个方程没用，$x_l$ 是自由元，取它为 $A_{kl}$，所以它可以移到右边。然后用 Cramer 解。$B_j$ 和 $A_{kj}$ 之间首先差了个负号，然后 $x_l$ 对应列对齐要交换 $|j-l|-1$ 次，还有就是代数余子式的负号。因此\n$$ (-1)^{k+j}B_j=(-1)^{|j-l|}A_{kj}\\\\ \\eta_j=\\frac{B_j}{M_{kl}}A_{kl}=(-1)^{k+l}B_j=(-1)^{k+l+k+j+j+l}A_{kj}=A_{kj} $$ 3.7.习8：他乡遇故知。太逆天了。\n3.9：应用大天地，值得一看。\n4.3：关于 $|A||B|=|AB|$ 的证明思路，一个是分块，一个是拆成初等矩阵（也是相当常见的证明思路，书里没写是因为依赖于 4.4.性质6）。Cauchy-Binet 证明图：\n4.4：证明左逆等于右逆的三个思路。与抽代不同的是这里要给出逆元存在的构造性证明，所以书里是第三种。\n设左逆为 $B$，则 $AB=AIB=ABAB\\Rightarrow I=(AB)^{-1}AB=(AB)^{-1}ABAB=AB$。 设左逆为 $B$，右逆为 $C$，则 $B=BI=BAC=IC=C$。 先证明存在 $B$ 既是左逆也是右逆，再同 2 证没别的逆。 4.4.性质4\u0026amp;例4：mark.\n4.5：分块矩阵初等变换。注意行变换只能左乘（且行列数分别为 to、from 行数），列变换只能右乘（且行列数分别为 from、to 列数），哪怕所有块都是方阵。另外分块初等矩阵只适用于对角是方阵的情况。\n4.9.例17：注意 $A$ 的零空间是与其行空间互为正交补，而不是列空间。因此 $Ax=0$ 的那些 $x$ 并不与 $\\operatorname{Im}\\mathcal{A}$ 垂直，注意几何直观别搞错了。\n5：关于矩阵秩的若干等式、不等式，不是很熟，记一下。\n$\\dim W=m-\\rank(A)$。构造证。\n$\\rank(AB)\\le\\min(\\rank(A),\\rank(B))$。线性表出证。\n$\\rank(A+B),\\rank[A,B]\\le\\rank(A)+\\rank(B)$。线性表出证。\n$\\rank(AA^\\top)=\\rank(A^\\top A)=\\rank(A)$。同解或行列式证（复矩阵不成立）。\n$\\rank(A^m)=\\rank(A^{m+1})\\Rightarrow\\forall k,\\rank(A^m)=\\rank(A^{m+k})$。同解证。\n$\\rank\\begin{bmatrix}A\u0026amp;0\\\\ 0\u0026amp;B\\end{bmatrix}=\\rank(A)+\\rank(B)$、$\\rank\\begin{bmatrix}A\u0026amp;C\\\\ 0\u0026amp;B\\end{bmatrix}\\ge\\rank(A)+\\rank(B)$。线性表出或行列式证。\n$AB=0\\Rightarrow\\rank(A)+\\rank(B)\\le m$。从齐次方程组解角度证。\n$\\rank(AB)\\ge\\rank(A)+\\rank(B)-m$。分块证，也可以用线性变换证。\n左乘列满秩、右乘行满秩，秩不变。同解或用 8 证。\n幂等 $\\Leftrightarrow \\rank(A)+\\rank(I-A)=n$，对合 $\\Leftrightarrow \\rank(I+A)+\\rank(I-A)=n$。分块或 2+3 证。\n补充：我想到 $\\Leftarrow$ 的一个比较妙的证明：$\\rank(A)+\\rank(I-A)=n$，由于 $\\rank+\\dim\\nul=n$，故 $\\dim\\nul A+\\dim\\nul(I-A)=n$，又 $\\nul A\\cap\\nul(I-A)=0$，故 $\\nul A\\times\\nul(I-A)=\\R^n$。于是任意 $x$，$Ax=0$ 或 $x$，于是 $Ax=A^2x\\Rightarrow (A^2-A)x=0$ 对于所有 $x$ 成立，即 $A^2-A=0$。\n$\\rank(A)=r\\Leftrightarrow\\exists B_{n\\times r},C_{r\\times m},\\rank(B)=\\rank(C)=r,A=BC$。分别用相抵、9 或 2+3 证。\n4.6：看着看着发现上三角矩阵的几个性质不是很清楚，记一下。\n上三角矩阵之积还是上三角，上三角矩阵的逆还是上三角。直观或代数证。 上三角矩阵的伴随矩阵还是上三角。 若上三角矩阵 $A$ 满足 $AA^\\top=A^\\top A$，则它为对角矩阵。若 $A$ 是正交矩阵，则 $A$ 的对角全是 $\\pm1$。 LU 分解 LU 分解用于避开逆矩阵求解线性方程组。$L$ 是 $n\\times n$，$U$ 是 $n\\times m$。\n一般的 LU 分解要求可以不用交换行将 $A$ 化简为行阶梯形（注意“各阶顺序主子式非 $0$”仅适用于满秩方阵）。\n求 $L$ 可以理解为：① 对 $L$ 做同样的事情可以变成 $I$；② $L$ 作用于 $U$ 可以变回 $A$（我感觉这种好理解，就是 $L$ 是所有变换顺序倒过来，然后正负互换）。这就是为什么 $L$ 可以由每次行变换乘的系数得出。注意就算目前行对应（下一个主元）位置为 $0$ 也不一定会出事，如果该列下面全 $0$，那就直接往后找。同时允许 $U$ 最后几行全零。\n出现主元问题时用 LUP 分解。通过 $PA=LU$（直接在 $A$ 中剩余行中对换，作用效果与 $U$ 中对换相同，又不会破坏 $L$ 的下三角性质），可以避免一堆奇怪的讨论。看一个例子（注意，当交换两行时，$L$ 中对应行除对角 $1$ 外也要交换）：\n$P$ $L$ $U$ $\\begin{bmatrix}1\u0026amp;0\u0026amp;0\u0026amp;0\\\\ 0\u0026amp;1\u0026amp;0\u0026amp;0\\\\ 0\u0026amp;0\u0026amp;1\u0026amp;0\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;1\\end{bmatrix}$ $\\begin{bmatrix}1\u0026amp;0\u0026amp;0\u0026amp;0\\\\ 0\u0026amp;1\u0026amp;0\u0026amp;0\\\\ 0\u0026amp;0\u0026amp;1\u0026amp;0\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;1\\end{bmatrix}$ $\\begin{bmatrix}0\u0026amp;2\u0026amp;1\u0026amp;0\\\\ 4\u0026amp;2\u0026amp;13\u0026amp;2\\\\ 2\u0026amp;2\u0026amp;7\u0026amp;1\\\\ 2\u0026amp;3\u0026amp;7.5\u0026amp;.5\\end{bmatrix}$ $\\begin{bmatrix}0\u0026amp;1\u0026amp;0\u0026amp;0\\\\ 1\u0026amp;0\u0026amp;0\u0026amp;0\\\\ 0\u0026amp;0\u0026amp;1\u0026amp;0\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;1\\end{bmatrix}$ $\\begin{bmatrix}1\u0026amp;0\u0026amp;0\u0026amp;0\\\\ 0\u0026amp;1\u0026amp;0\u0026amp;0\\\\ 0\u0026amp;0\u0026amp;1\u0026amp;0\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;1\\end{bmatrix}$ $\\begin{bmatrix}4\u0026amp;2\u0026amp;13\u0026amp;2\\\\ 0\u0026amp;2\u0026amp;1\u0026amp;0\\\\ 2\u0026amp;2\u0026amp;7\u0026amp;1\\\\ 2\u0026amp;3\u0026amp;7.5\u0026amp;.5\\end{bmatrix}$ $\\begin{bmatrix}0\u0026amp;1\u0026amp;0\u0026amp;0\\\\ 1\u0026amp;0\u0026amp;0\u0026amp;0\\\\ 0\u0026amp;0\u0026amp;1\u0026amp;0\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;1\\end{bmatrix}$ $\\begin{bmatrix}1\u0026amp;0\u0026amp;0\u0026amp;0\\\\ 0\u0026amp;1\u0026amp;0\u0026amp;0\\\\ .5\u0026amp;0\u0026amp;1\u0026amp;0\\\\ .5\u0026amp;0\u0026amp;0\u0026amp;1\\end{bmatrix}$ $\\begin{bmatrix}4\u0026amp;2\u0026amp;13\u0026amp;2\\\\ 0\u0026amp;2\u0026amp;1\u0026amp;0\\\\ 0\u0026amp;1\u0026amp;.5\u0026amp;0\\\\ 0\u0026amp;2\u0026amp;1\u0026amp;-.5\\end{bmatrix}$ $\\begin{bmatrix}0\u0026amp;1\u0026amp;0\u0026amp;0\\\\ 1\u0026amp;0\u0026amp;0\u0026amp;0\\\\ 0\u0026amp;0\u0026amp;1\u0026amp;0\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;1\\end{bmatrix}$ $\\begin{bmatrix}1\u0026amp;0\u0026amp;0\u0026amp;0\\\\ 0\u0026amp;1\u0026amp;0\u0026amp;0\\\\ .5\u0026amp;.5\u0026amp;1\u0026amp;0\\\\ .5\u0026amp;1\u0026amp;0\u0026amp;1\\end{bmatrix}$ $\\begin{bmatrix}4\u0026amp;2\u0026amp;13\u0026amp;2\\\\ 0\u0026amp;2\u0026amp;1\u0026amp;0\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;0\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;-.5\\end{bmatrix}$ $\\begin{bmatrix}0\u0026amp;1\u0026amp;0\u0026amp;0\\\\ 1\u0026amp;0\u0026amp;0\u0026amp;0\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;1\\\\ 0\u0026amp;0\u0026amp;1\u0026amp;0\\end{bmatrix}$ $\\begin{bmatrix}1\u0026amp;0\u0026amp;0\u0026amp;0\\\\ 0\u0026amp;1\u0026amp;0\u0026amp;0\\\\ .5\u0026amp;1\u0026amp;1\u0026amp;0\\\\ .5\u0026amp;.5\u0026amp;0\u0026amp;1\\end{bmatrix}$ $\\begin{bmatrix}4\u0026amp;2\u0026amp;13\u0026amp;2\\\\ 0\u0026amp;2\u0026amp;1\u0026amp;0\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;-.5\\\\ 0\u0026amp;0\u0026amp;0\u0026amp;0\\end{bmatrix}$ 在解具体方程时，只需解 $Ly=Pb$ 与 $Ux=y$ 即可。注意不要搞错成 $P^{-1}b$。\nLDU 分解只是对满秩方阵而言，就是简单地把 $U$ 的对角元变成 $1$。\n正交相关 根据点乘的几何意义，可得在单个向量上的投影。\n一般的正交投影，我们从两个角度理解。\n代数角度：希望写成 $y=\\hat y+z$ 的形式，其中 $\\hat y=\\sum c_iu_i$，$z\\cdot u_i=0$。后一个式子可以写成 $$ 0=(y-\\hat y)\\cdot u_i=(y-\\sum c_iu_i)\\cdot u_i=y\\cdot u_i-c_iu_i^2\\Rightarrow c_i=\\frac{y\\cdot u_i}{u_i\\cdot u_i} $$ 几何角度就是若干个“分量投影”的和。\n而最佳逼近定理就是由 $z\\perp W$ 加上勾股定理，勾股定理的本质就是正交向量的点积为 $0$。正交相关的一切内容都是围绕这一性质展开的。\n如果 $y\\in W$，那正交投影的公式就给出的线性表出的构造。\n注意如果不是正交方阵，而是若干正交单位向量组成的矩阵 $U=\\begin{bmatrix}u_1\u0026amp;\\cdots\u0026amp;u_n\\end{bmatrix}$，那么 $U^\\top U=I$，但 $UU^\\top\\ne I$——而且 $UU^\\top y$ 给出了 $y$ 在 $W$ 上的投影。\nQR 分解 QR 分解就是用矩阵表示出了 Gram-Schmidt 正交化的过程。\n使用条件：$A$ 列向量线性无关。\n推导很简单，就是记住是正交矩阵在左即可。 $$ \\begin{bmatrix}\\alpha_1\u0026amp;\\cdots\u0026amp;\\alpha_m\\end{bmatrix}=\\begin{bmatrix}u_1\u0026amp;\\cdots\u0026amp;u_m\\end{bmatrix}\\begin{bmatrix}\\alpha_1\\cdot u_1\u0026amp;\\alpha_2\\cdot u_1\u0026amp;\\cdots\u0026amp;\\alpha_m\\cdot u_1\\\\ 0\u0026amp;\\alpha_2\\cdot u_2\u0026amp;\\cdots\u0026amp;\\alpha_m\\cdot u_2\\\\ \\vdots\u0026amp;\\vdots\u0026amp;\\ddots\u0026amp;\\vdots\\\\ 0\u0026amp;0\u0026amp;\\cdots\u0026amp;\\alpha_m\\cdot u_m\\end{bmatrix} $$ 这里对矩阵作了一点简化，其思路是 $$ \\alpha_i=\\sum_{j\\le i}\\frac{\\alpha_i\\cdot v_j}{v_j\\cdot v_j}v_j=\\sum_{j\\le i}\\frac{\\alpha_i\\cdot(|v_j|u_j)}{|v_j|^2}(|v_j|u_j)=\\sum_{j\\le i}(\\alpha_i\\cdot u_j)u_j $$ 如果觉得别扭也可以把 $v_i$ 拿出来单独讨论。\n实操方法 1：在 Gram-Schmidt 正交化的时候写清楚那个下三角形的公式，写成矩阵，最后第 $i$ 行乘 $|v_i|$ 即可。\n实操方法 2：直接求出单位正交基 $Q$，然后由 $Q^\\top A=R$ 算出 $R$。\n唯一性见 4.6.例5。\n最小二乘法 理解角度 1：在不求出正交基的情况下求投影，即利用垂直的性质。$\\alpha_i\\cdot(Ax-b)=0$。\n理解角度 2：要最小化 $|Ax-b|$，也就是最小化 $(Ax-b)\\cdot(Ax-b)$。 $$ 0=\\frac{\\partial(\\sum\\alpha_jx_j-b)^2}{\\partial x_i}=2\\sum \\alpha_i\\cdot\\alpha_jx_j-2\\alpha_i\\cdot b $$ 这里 $\\sum \\alpha_jx_j=Ax$，于是式子就变成 $A^\\top Ax=A^\\top b$。\n从代数角度证明必有解：一方面，$[A^\\top A,A^\\top b]$ 的列向量都是 $A^\\top$ 之列向量的线性组合，故秩不超过 $\\rank(A)$。另一方面 $\\rank(A^\\top A)=\\rank(A)$。\n当 $A$ 列满秩时，$A^\\top A$ 满秩，即有唯一解。\n另外，如果想把 $A$ 正交分解了再 $b$ 去投影，也没问题。设 $A=QR$，$b$ 的正交投影为 $QQ^\\top b$。如果要转成用 $A$ 列向量的线性组合来表示，那就是 $Ax=QQ^\\top b\\Rightarrow QRx=QQ^\\top b\\Rightarrow Rx=Q^\\top b\\Rightarrow x=R^{-1}Q^\\top b$（其实都是 $\\Leftrightarrow$）\n应用理解：有若干样本点 $(a_i,b_i)$，考虑用一个函数 $y=\\sum c_if_i(x)$ 去拟合（$c_i$ 未知，$f_i$ 已知。例如直线就取 $f_1(x)=1,f_2(x)=x$），误差就是 $y$ 与对应 $b_i$ 的差的平方和。那这时其实就是求以下方程的最小二乘解： $$ \\begin{bmatrix}f_1(a_1)\u0026amp;\\cdots\u0026amp;f_m(a_1)\\\\ \\vdots\u0026amp;\\ddots\u0026amp;\\vdots\\\\ f_1(a_n)\u0026amp;\\cdots\u0026amp;f_m(a_n)\\end{bmatrix}\\begin{bmatrix}c_1\\\\ \\vdots\\\\ c_m\\end{bmatrix}=\\begin{bmatrix}b_1\\\\ \\vdots\\\\ b_n\\end{bmatrix} $$ 这里的函数可以是多自变量函数。\n矩阵的相抵与相似 相抵矩阵秩相同。将矩阵转换成相抵标准型的过程，类比将满秩方阵拆分成初等矩阵的过程。其最大作用就是拆矩阵简化证明。非满秩的矩阵在推式子时会出现类似“丢失信息”的现象。\n广义逆矩阵是不易直观理解的部分，几个性质的证明动机也不清晰，我只能记下书里基础的东西，其实都是些废话：\n处理广义逆矩阵相关问题的基本方式是将 $A$ 写成 $PIQ$。 广义逆矩阵的阶为 $m\\times n$。形式为 $A^-=Q^{-1}\\begin{bmatrix}I_r\u0026amp;B\\\\ C\u0026amp;D\\end{bmatrix}P^{-1}$。$Q$ 为 $m\\times m$，$P$ 为 $n\\times n$，中间为 $m\\times n$。 $Ax=b$ 有解当且仅当 $b=AA^-b$。直接用定义+后面的构造证。解为所有 $A^-b$。证明所有解都可以表示为这种形式的方式的思路是，先把 $A$ 拆开，然后 $P,Q$ 就出来了，分析一下构造 $B,C,D$ 即可（这里 $b\\ne 0$，不然构造会找不到非 $0$ 元）。 $Ax=0$ 的解为 $(I_m-A^-A)\\gamma$（$A^-$ 随便固定一个，$\\gamma$ 取所有）。一个解直接对应 $\\gamma=x$。 后面 $A^+$ 我直接投降。其应用就是，$A$ 列满秩时，$Ax=b$ 的最小二乘解就是 $A^+b$。另外，列满秩矩阵满足 $A^-A=I$，其中一个特殊的 $A^-$ 是 $(A^\\top A)^{-1}A^\\top$；行满秩矩阵满足 $AA^-=I$，其中一个特殊的 $A^-$ 是 $A^\\top(AA^\\top)^{-1}$。无论是否列/行满秩，$A^-$ 都不是唯一的，只有满秩方阵才有 $A^-=A^{-1}$。 矩阵的相似可以从线性变换的角度来理解。想象一个线性变换，它将自然基下的向量 $x$ 映射到 $Ax$。现在我们想知道，在另一个基下这样的变换该如何描述。假设另一个基为 $P$（$P$ 的列向量为所有基向量），根据基变换相关的内容我们知道：在这个基的表示下的向量 $x$，在自然基下的表示为 $Px$；反之在自然基表示下的向量 $x$，在这个基的表示为 $P^{-1}x$（空间和向量永远不动，只是表出会变）。\n对于这个基下的向量 $x$，先将它用自然基表出，然后 $A$ 作用，再变回去。这就是 $P^{-1}APx$。$B=P^{-1}AP$ 就是在这个基下的变换矩阵。正如 3b1b 所说，基变换和相似就是一个“语言翻译”的过程。\n所以说，两个矩阵相似，就说明可以通过选取合适的基，使它们对应的线性变换看起来相同。这里我们可以联系抽代里半直积本质相同的判别方式（第 12 章性质 2）来理解——如果自同构是共轭的，就说明可以选取不同的元素作为生成元，使得这两个自同构分别在两种生成元下形式完全相同，那就说明这两个半直积同构。\n对角化的几何解释见 https://www.bilibili.com/video/BV1TH4y1L7PV/。简而言之就是把基变成那些特征向量，然后线性变换就变成简单的各维分别缩放了。这其实让我想到了卷积定理。\n关于特征值和特征向量。首先要明确，相似变换下，行列式、秩、迹、特征值都不变，但特征向量会变。\n无论是否满秩，特征值数量（算上重数）总为 $n$，但特征子空间的维数和就不一定了。如果满秩，则特征值全部非零，但是不满秩时，特征值 $0$ 的重数并不等于 $n-r$，而是大于等于，例如 $\\begin{bmatrix}0\u0026amp;1\\\\ 0\u0026amp;0\\end{bmatrix}$。相关证明见 https://www.zhihu.com/question/297458474/answer/1362625976。\n几何重数小于等于代数重数的证明直观是很好理解的，你都构造出那几个线性无关的特征向量了，那不得至少有这几个嘛。证明的思路就是基变换，把这几个特征向量作为基，别的任选，然后 $|\\lambda I-A^\\prime|=0$ 就行。\n不同特征值对应的特征向量不同，这个只需看一个简单情况就可以理解证明思路：如果 $A\\alpha_1=\\lambda_1\\alpha_1,A\\alpha_2=\\lambda_2\\alpha_2,c\\alpha_1=\\alpha_2$，那么 $\\lambda_1c\\alpha_1=Ac\\alpha_1=A\\alpha_2=\\lambda_2\\alpha_2=\\lambda_2c\\alpha_1\\Rightarrow\\lambda_1=\\lambda_2$。后面的东西都是比较显然的。\n一些特殊矩阵的特征值。幂等矩阵有 $\\rank(A)$ 重特征值 $1$，$n-\\rank(A)$ 重特征值 $0$。证明这个的步骤是，首先说明特征值只能是 $0$ 或 $1$，然后利用几何重数说明代数重数。对合矩阵也是类似。幂零矩阵与它们的不同点仅在于不能对角化。注意不能从特征值判断特殊矩阵。注意可对角化和满秩之间没有关系。\n现在距离抽代里那个自同构的分析，我们还有两个障碍：一个是 Jordan 标准型还没学，一个是不允许复数。\n简单提一下 Cayley-Hamilton 定理的证明：对角阵易证，因为相当于每个特征值代进特征多项式。从而可对角化的情况易证，因为 $f(P^{-1}AP)=P^{-1}f(A)P$，然后可以用 https://www.zhihu.com/question/31557902/answer/1636767376 这种来理解。另一个证明思路是，先通过证明乘每个 $\\varepsilon_i$ 均为 $0$ 来证明上三角矩阵满足，然后再把任意一个矩阵相似化为上三角：https://zhuanlan.zhihu.com/p/657653840。最后，书里的证明思路是，通过比对 $(\\lambda I-A)(\\lambda I-A)^\\star=|\\lambda I-A|I$ 两侧的系数证明。\n它的一个重要作用是给出了 $A^n$ 关于 $A^{0\\sim n-1}$ 的表达式，从而可以递推（P4723）。\n","date":"2024-07-26T00:00:00Z","image":"https://littlereuben.github.io/study/linear-algebra-1/cover.png","permalink":"https://littlereuben.github.io/study/linear-algebra-1/","title":"线代（上）自学笔记"},{"content":"这是一篇摘抄笔记。\n本文适合不了解 html 和 scc 但想自己建博客的读者看。\r本地初始操作 下载 git，更新用户名和邮箱信息。 下载 hugo，选 extended。 建文件夹，里面存所有网站的文件夹。 hugo new site 名字，会出现一个子文件夹（下称为主文件夹），对应一个网站。 进入，找想要的主题，通过 git clone 或直接复制粘贴的方式放到 themes 文件夹中，最好只有一个主题（实际是可以在配置的 theme 改），然后主题的文件夹名别动。 把主题对应的 exampleSite 内文件复制到主文件夹。 hugo 可以编译（生成 public/ 内的网页文件），hugo server 在 hugo 的基础上开了个 localhost 网页以供实时预览，每次运行即可查看效果，随时改（保存）随时更新，不需要“编译”。Ctrl+C 停止。注意，有的时候改风格或页面布局时出现语法问题，就算改回来也会没反应（停留在一个编译错误页面或没有改动效果），这时应当停止再运行。 主题相关（stack） 如果遇到其他主题需求，一个通用方法是，如果想改某些样式或大小或长宽，则找 assets 里 scss 文件；如果想改页面布局，则找 layouts 里 html 文件。具体可以按文件名实际意思找，也可以 F12 出调试工具后找对应的项名字或数值，然后用查找文件内容在主题文件夹里直接暴力找。\n注意主题对浏览器页面不同大小的时候做了适配，所以会发现有 respond(…) 这种东西，阈值参见 breakpoint.scss。一般建议改参数（某些距离之类）的时候，顺带各种尺寸情况都改了，然后最后拿手机、平板之类的访问一下看看是否合适。\n配置文件应当放在主文件夹中，名字为 hugo.*，后缀可以是 yaml，toml 或 json。建议直接按上面第 6 点，把 exampleSite 的配置文件复制过来，删掉原来的 hugo.toml。下文简称该文件为“配置”。\n把配置里的 baseurl 改一下。\n多语言选项直接关了完事，配置里 DefaultContentLanguage 改 zh-cn，hasCJKLanguage 改 false，language 删了。\n网站图标：配置里 params.favicon。.ico 文件放到 static/ 里。\n头像放 assets/img/。\n左右边栏最大宽度：grid.css 里 .container\u0026amp;.extended 的 respond(xl) 内。会相应改变中间主题的宽度。\n左右边栏与页面左右边缘距离：grid.css 里 .main-container 的 respond(md) 内。\n头像大小，头像、博客标题、博客描述居中：sidebar.scss 里 .left-sidebar 的 \u0026ndash;sidebar-avatar-size，.sidebar header 的 .site-avatar（其实不改就行）、.site-name、.site-description 内加 text-align: center;。\n左右边栏额外两侧空白：sidebar.scss 里 .left-sidebar、.right-sidebar 内额外加 padding-left: ?px; 和 padding-right: ?px; 即可。\n左右边栏和中间主体的间距：variables.scss 里 :root 的 \u0026ndash;section-separation。\n所以，如果你想真的让左边栏内容完美居中，所要做的就是：把 4 和 7 调成相等，6 的 left、right 不要不相等。\n左侧边栏之页面 second method 的高亮：主题文件夹/layouts/partials/sidebar/left.html 里找到这段：\n{{ $currentPage := . }} {{ range .Site.Menus.main }} {{ $active := or (eq $currentPage.Title .Name) (or ($currentPage.HasMenuCurrent \u0026#34;main\u0026#34; .) ($currentPage.IsMenuCurrent \u0026#34;main\u0026#34; .)) }} 删掉改成：\n{{ $currentPage := . }} {{ $siteTitle := .Site.Title }} {{ range .Site.Menus.main }} {{ $active := or (eq $currentPage.Title .Name) (or ($currentPage.HasMenuCurrent \u0026#34;main\u0026#34; .) ($currentPage.IsMenuCurrent \u0026#34;main\u0026#34; .)) }} {{ $active := or ($active) (and (eq $currentPage.Title $siteTitle ) (eq .Identifier \u0026#34;home\u0026#34;)) }} 目录的行间距：layout/article.scss 里 .widget\u0026ndash;toc#TableOfContents 里面有个 margin 后面带四个数的，分别是上边缘、右边缘、每行下方、左边缘。\n左侧边栏图标与文字的距离：variables.scss 里 :root 的 \u0026ndash;menu-icon-separation。\n最后修改时间：https://shitao5.org/posts/hugo-stack/\nbranch 页面的标题形式：在 layout/_default/list.html 里，我是直接把 section-title 注释掉的（因为无论如何它都只会显示章节两字），希望这个自定义的话我也不大会，但是网上好像可以查到？https://discourse.gohugo.io/t/how-can-i-get-a-user-friendly-section-name-title/10880/3\n段内行距：variables.scss 里 :root 的 \u0026ndash;article-line-height。段间行距：layout/article.scss 里 .article-content 里有个 margin: 1.5em 0;\n关于段首缩进：爆了，下面这个方法会导致列表的编号和内容间有过大的距离，应该无解。\n在 layout/article.scss 里 .article-content 里加一句 text-indent: 2em; 这样会发现它缩进过度了。在 variables.scss 里改 \u0026ndash;card-padding。\n这里有两个注意点，一个是你发现 F12 之后两侧 padding 变了，这个在不是 layout 里的 article.scss 里 .article-list\u0026ndash;tile 的 .article-details 的 padding 改。\n一个是注意到包括标题、图片在内的东西都会被缩进，标题我觉得这样挺好看的，图片的话会导致右侧被遮，这里我的解决方法是用 html 格式的图片，还可以调大小，更好用，唯一可惜的是用不上 stack 自带的图片文字描述下方显示，不过这个也可以写一段 html。\n大标题大小：不是 layout 里的 article.scss 里 .article-title 的 font-size。\nF12 时头像不居中问题：sidebar.scss 里 .sidebar header 的 .site-avatar 的 margin 改成 auto（注意这类 margin 的东西如果不填 0 或 auto，则必须填四个数，分别代表上右下左）。\n网站名称颜色：光把 sidebar.scss 里 .site-name 的 color 改掉没用，还要把 left.html 里 site-name 的链接去掉。\n文章主题图片的高度：layout/article.scss 里 .article-page 的 .article-header 的 .article-image 的 img 的 max-height。\n回到顶部：https://www.blain.top/p/renovation/#%E8%BF%94%E5%9B%9E%E9%A1%B6%E9%83%A8%E6%8C%89%E9%92%AE 配合 https://yelleis.top/p/61fdb627/#%E8%BF%94%E5%9B%9E%E9%A1%B6%E9%83%A8。可以平滑的。\n左边栏项过多但不想滚轮：sidebar.scss 里 .left-sidebar 的 max-height。左边栏各项间距：menu.scss 里 #main-menu 的 gap。\n归档里 CATEGORIES 不是中文：archives.html 里改 \u0026lt;h2 class=\u0026quot;section-title\u0026quot;\u0026gt;{{ $taxonomy.Title }}\u0026lt;/h2\u0026gt;。\n归档的分类卡片大小：list.scss 里 .subsection-list 的 .article-list\u0026ndash;tile 的 article 的 width、height。\n文章先后（默认按时间）、左侧栏、归档分类等都可以用 md 开头 yaml 里 weight 调优先级。\n左侧栏“个性签名”换行：不知为何 \\n 会被空格代替，\u0026lt;br/\u0026gt; 没用。我找遍了整个 theme 文件夹只找到一处把换行替换为空格的代码，去掉之后还是没用。所以只能在 left.html 里硬编码了。\n归档分类卡片渐变颜色：main.ts 里 articleDetails.style.background。我觉得不改也挺好看。\n归档多栏：https://blog.grew.cc/posts/stack#%E5%BD%92%E6%A1%A3%E9%A1%B5%E5%8F%8C%E6%A0%8F。\n图标可以在 https://tablericons.com/ 找，放在主题的 assets/icons 里。\n关闭 toc 的编号：layout/article.scss 里 li a:first-of-type::before 部分注释掉。\n代码行号：配置里 markup:highlight:lineNos。\n“评论”标题：在 layouts/partials/comments/include.html 的第一二行间加 \u0026lt;h2 style=\u0026quot;color: var(--card-text-color-main)\u0026quot;\u0026gt;评论\u0026lt;/h2\u0026gt;。这样暗色模式不会还是黑的。\n如果觉得 ![]() 图片和封面图片糊得不正常且难看，可以把配置里的 imageProcessing 下面两个改成 false。\n阅读量：https://hyrtee.github.io/2023/start-blog/#%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90。这里有个问题就是首页的每篇文章的阅读量是无法正常显示的，这个我也不会解决，只能只在具体文章页面显示该阅读量。但是问题在于首页的卡片的 details 和文章的 details 是共用 layout/partials/article/components/details.html 的，就无法区别处理。我的处理方法是复制一份 header.html 和 details.html 然后改一份有统计量的。显然这并不是个简介的解决方案，主要我不会 html 里 partial 情况下的传参。\n内嵌 pdf：https://github.com/anvithks/hugo-embed-pdf-shortcode。Better choice：https://bugdrivendevelopment.net/pdf-reader-hugo-sites/，如果希望像我一样在 pdf 下面再显示一个原文件的链接，可以加一行 \u0026lt;a href=\u0026quot;{{ .Get 0 }}\u0026quot; style=\u0026quot;display:block;text-align:center;\u0026quot;\u0026gt;\u0026lt;b\u0026gt;[PDF file]\u0026lt;/b\u0026gt;\u0026lt;/a\u0026gt;。\ncontent 目录结构 博客里的页面分为 branch 和 leaf 两类，branch 就是下面还有子页面的页面。\ncontent 文件夹对应 home 页面，是 branch 类型。home 就是主页。\ncontent 的文件夹结构与网站链接结构完全对应，一个文件夹一个页面，branch 对应的文件夹下如果有其他 md 或含 index.md 的子文件夹，就会在对应页面也显示出来。\ncontent 内所有想要能显示出来的页面，必须要包含 index.md 或 _index.md 文件，前者是给 leaf 用的，后者是给 branch 用的。这个 md 的开头应当有一段 yaml（或其他格式）给出其相关信息。对于 branch，就不用写别的东西了（写了也没用）；对于 leaf，yaml 之后就是正文。\n实际上 leaf 页面可以在 post 或对应的 branch 文件夹里直接放 md，但是最好还是按照上面的习惯来。\n这样的一段 yaml 应当符合 https://stack.jimmycai.com/writing/frontmatter 的格式（有漏，可以看 https://zhuanlan.zhihu.com/p/688275787 里“我的模板”，注意冒号之后必须加空格！复杂字符串如果出问题需要两边打引号！）。特殊地，有几类特殊的布局，可以加上 layout 信息，参见 exampleSite 的 page/。\n建议建文件夹 content/page/ 以存放所有出现在左边栏内的页面。所有希望出现在左边栏中的页面（包括 home 的 _index.md 以及 page 的 index.md），它们开头的 yaml 需要额外以 https://stack.jimmycai.com/config/menu 里 first method 的方法写一下。second method 是直接写在配置里的，配合上面第 10 点。\n主页的中间，会显示所有属于 content/post/ 里的内容——这是由配置里 params.mainSection 决定的。\n除了按上述方式配置的 content/_index.md、post（mainSection 的条目）、page 内 md 外，其余东西一律没有导航界面（包括别的 branch），只能在浏览器上改链接来访问，因此其实可以在博客里“藏”东西。\n然后还有一个特殊的文件夹 content/categories，这里面放的东西会和每个文章的分类联系在一起，参见 exampleSite。如果不用这个文件夹，直接写每篇文章的 categories 也是没问题的，就是归档里会没图片。如果用这个文件夹，可以设置 categories 的标签颜色、图片等，而且可以将一个类别的 id 和名称分开来，文件夹名、slug、调用时用 id，title 写名称。\nMarkdown、KaTeX 相关 这部分很重要，请务必注意！\r无论如何要当心任何位置出现的特殊字符，尤其是 Typora 里没出问题的 \\。\n支持内嵌 html。 同普通 Markdown，如果两段间不留空行且第一段末尾没有俩空格，则渲染出来是不换行的。 关于列表的分段，Typora 是显示出来一律是分段的行距，但对于从未在标号（或项目点）前退格的列表，源码会不留空行，在网页里是不分段的行距（对比本列表和上一个列表）。这个可能会有点难看，如果介意的话，要手动改一下。另外列表内分段是按照缩进来的。 公式支持 KaTeX 功能（如果没渲染检查一下配置和 frontmatter 里有没有开 math），行间公式上下不留空行也没事。 如果要利用全局 \\def，必须使用 \\gdef。这个和 Typora 是不一样的，Typora 不识别 \\gdef 但 \\def 是全局的。 矩阵等多行的东西，需要打三个 \\ 后再来个空格，以换行。这个很奇怪。 \\,、\\; 之类的小空格必须改成 \\\\,、\\\\;。这个也很奇怪。 表格里公式偷懒不用 \\lvert\\rvert 直接打 | 时会出现与表格边界混淆的情况（Typora 会自动正确处理），这时要加转义 \\。\\set 里第一个 | 会被识别为“满足”符号，自动适应左右高度。 公式内星号 *、百分号 % 要加转义 \\（Typora 会自动正确处理）。 还有很多不加 \\ 就会爆的情况。我遇到最诡异的是 ${a}_{b}{c}_{d}$ 无法渲染。这种是因为垃圾 Markdown 渲染器把公式内外搞混了（两个下划线之间被识别为斜体，一般会出现在 |_（代入值）和 }_ 这种地方）。遇到这种情况反正就在各个特殊字符前试着加 \\ 就行。甚至多行推不等式出现多个 \u0026gt; 会识别成引用，无语。 连接自动识别在遇到标点时会有问题，建议还是用 \u0026lt;\u0026gt; 括起来。 撇号如果直接用 ' 会很丑（$\u0026rsquo;$），必须用 ^\\prime。 html 格式的图片要居中必须单独写 center。 如果希望强制调整表格列宽，可以用 \u0026lt;div style=\u0026quot;width: 宽度\u0026quot;\u0026gt;\u0026lt;/div\u0026gt;。注意其副作用是在不同宽度的屏幕上可能会显示得不好看。 我在写域论笔记时试图 \\def\\char{\\operatorname{char}}，然后 \\ne 就没法用了，也不知道为什么…… Github 部署 Github 部署的思路如下：\nGithub 上一个公开的 repo 放网页文件。 每次 hugo 完，把 public/ 内东西放到 repo 里。 如果不想手动操作，可以再建一个（可以私有）放整个博客的 repo，每次 push 之后用 github action 自动编译、更新到网页 repo 里。 由于我想经常调试博客的 theme，而且第三步略麻烦，所以我就是手动更新。\n总的操作方法见 https://zhuanlan.zhihu.com/p/568470172（有三篇）。\n注意：\n网址只能是 github用户id.github.io，github settings pages 里改域名的选项是得自己先买域名的。 hugo 编译后，public 里老的文件是会留着的（例如你反复给一篇文章换主题图片，它都会留着）。如果你不希望别人来翻你的 github repo 看到这些，得每次手动删除。 每次把网页复制到本地仓库前，最好先删光（别手动删！git 会自动追踪仓库里的文件，可能会出问题。具体处理方法见下文）。 评论 disqus 有广告。 giscus 必须登录 github 才能评论。 twikoo 似乎有审查。 cusdis 万岁！\n免费版 cusdis 一个月 10 条 quick approve 和 100 条需要 approve 的评论（大概就是你得在邮箱的评论通知里点一下），完全够。\nupd：但是有个缺点，就是选填的 Email 谁也看不到，而且 reply 也不会通知评论者，相当于没用。\nupd：似乎 quick approve 界面可以看到。\n操作非常简单：\n注册个账号。输入博客网址与 notification 邮箱。 配置里 params 的 comments 的 provider 改成 cusdis，下面 cusdis 里 host 和 id 改一下，具体改的内容看 cusdis 里你的 dashboard 上方的 Embeded Code。 如果想改中文，在 layout/partial/comments/provider/cusdis.html 里 \u0026lt;script async defer src=\u0026quot;{{ $host }}/js/cusdis.es.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; 的上面加一句 \u0026lt;script async defer src=\u0026quot;https://cusdis.com/js/widget/lang/zh-cn.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt;。 Cusdis 的块非常矮，目前我没有找到一个能使块长随着评论数量变化的方法，一个差一点的解决方法见 https://barthpaleologue.github.io/Blog/posts/add-and-customize-cusdis-hugo/。upd：问题已解决，见该博客评论。问题是滚动条还在，这个似乎没法解决。\n日常维护 我一般习惯这样：\n在另外的文件夹里写博客。\n每次手动新建文章文件夹，md 复制过去改名成 index.md，开头加上那段 yaml（我不习惯 hugo new）。yaml 我用的模板：\ntitle: description: date: slug: image: categories: toc: true math: true comments: true 更新到 github。我写了以下脚本（须在 git bash 下运行，我的博客文件夹和 repo 文件夹并列）：\ncd blog/ rm public/* -r hugo cd ../LittleReuben.github.io/ git rm * -r cd ../ cp -rf blog/public/* LittleReuben.github.io/ cd LittleReuben.github.io/ git add --all git commit -m \u0026#34;upd\u0026#34; git push -u origin main 注意博客网页更新较慢，大概要等个 2min。\n我这边发现一个问题：一旦 commit 了过大的文件并 push 失败，这个文件就会永远存在历史记录 .git/object/ 里，导致后续就算删了也无法 push。其实博客这种东西本身没必要记录每次 commit 的 history，但是 git 要删 history 很麻烦，所以我的思路是，直接把整个 *.github.io/ 文件夹删空（包括 .git/），然后重新远程 clone 过来上一个正常的版本。\n如果想搭博客也可以直接问我要魔改的 theme。\n参考链接 https://thirdshire.com/hugo-stack-renovation-part-two/\nhttps://xrg.fj.cn/p/hugo-stack%E4%B8%BB%E9%A2%98%E6%9B%B4%E6%96%B0%E5%B0%8F%E8%AE%B0/\nhttps://munlelee.github.io/post/hugo%E5%8D%9A%E5%AE%A2-stack%E4%B8%BB%E9%A2%98%E4%BF%AE%E6%94%B9%E7%AC%AC%E4%B8%80%E7%AB%99/\nhttps://zhixuan2333.github.io/posts/ac760353/\nhttps://blog.linsnow.cn/p/modify-hugo/\nhttps://zhuanlan.zhihu.com/p/685991593\nhttps://yelleis.top/p/61fdb627/\n","date":"2024-07-25T00:00:00Z","image":"https://littlereuben.github.io/study/blog-tutorial/logo.png","permalink":"https://littlereuben.github.io/study/blog-tutorial/","title":"Hugo 博客搭建经验"},{"content":"$\\gdef\\lcm{\\operatorname{lcm}}\\gdef\\ker{\\operatorname{Ker}}\\gdef\\im{\\operatorname{Im}}\\gdef\\syl{\\operatorname{Syl}}\\gdef\\or{\\operatorname{or}}\\gdef\\aut{\\operatorname{Aut}}\\gdef\\norm{\\vartriangleleft}\\gdef\\inn{\\operatorname{Inn}}\\gdef\\out{\\operatorname{Out}}\\gdef\\F{\\mathbb{F}}$\n这是一篇学习笔记。\n本文仅供参考，学习顺序是不合理的。如果希望深入研究有限群分类，请先学完环和域。\r原来是为了醋包的饺子。不想看无聊细节的可以直奔第 12 节。\nGTM73 之 我只来得及看完群论了 这本教材内容是比较全的，对初学者不友好的点就是解说较少，就是大量的定理—证明，很多证明能看懂它是对的，但是无法理解它的思路是怎么想到的。\n1. 三个代数结构 大纲 半群、幺半群、群的定义，能导出它们的性质以及它们能导出的性质。 构建新群的方法：直积、用等价类划分。 笔记 幺元的定义是对每个元素都有一个同样的元素与它运算后不变，幺元的唯一性也是指在刚才这个定义中的唯一。对于半群与幺半群，对某个特定的 $a$，$ab=a$ 的 $b$ 可能有多个，例如含不互质元素的乘法半群，按位与、或的半群。\n由半群到群的判定：\n存在左幺元与左逆元的半群是群。\n存在左幺元与右逆元的半群不一定是群（$xy=y$）。\n存在左幺元与唯一右逆元的半群不一定是群（$xy=y$）。\n存在唯一左幺元与右逆元的半群一定是群。\n证：$e=a^{-1}(a^{-1})^{-1}=a^{-1}e(a^{-1})^{-1}=a^{-1}aa^{-1}(a^{-1})^{-1}=a^{-1}ae$，因此 $a^{-1}a$ 也是逆元，$a^{-1}a=e$。\n感觉这个证明没那么自然，可能是为了硬凑 $a^{-1}a$ 形式。能否给出更自然的证明？\n存在左逆元与右逆元的半群一定是群（这里没有定义幺元，所以左右逆元可以定义为 $ax=b$ 与 $ya=b$ 均有解）。\n证：$(\\exists x,ax=a)\\land(\\forall b,\\exists y,ya=b)\\Rightarrow\\forall b,bx=b$，因此存在右幺元。\n具有左右消去律的有限半群一定是群。\n证：由消去律 $aG=G$（双射），可以得到幺元以及逆元。\n具有左右消去律的无限半群不一定是群。（$\\N$）\n存在左逆元的幺半群一定是群。\n证：$xa=e\\land yx=e\\Rightarrow y=yxa=a$ 于是右逆元存在。$xa=ya\\Rightarrow x=xaa^{-1}=yaa^{-1}=y$。\n一般的幺半群中不一定有左逆元等于右逆元。（https://math.stackexchange.com/questions/655186/in-a-non-commutative-monoid-is-the-left-inverse-of-an-element-also-the-right-in）\n2. 同构、同态、子群、+循环群 大纲 同态、单同态、满同态、同构、自同态、自同构的定义。 核、像的定义。 子群、生成子群、循环群的定义。 以上概念相关性质（仅限群）： 单位元、逆元与子群在映射下的对应性，核、像也是子群，子群的交也是子群； 核大小为 $1$ 则为单同态； 子群的判定、生成子群的结构（最小）； 笔记 几个书里的理解问题： 单同态：$G$ 与 $H$ 的子群同构；满同态：$G$ 的商类与 $H$ 同构。 幺半群同态，幺元可能不对应，是因为可以找 $H$ 中某个平方等于自身的非幺元，把 $G$ 中所有元素都映射到它。然而群中是找不到这样的元素的。如果是满同态就对应了。 群同态中，每个有原像的元素，它们的原像集合大小相等。 群中一个元素不断自乘，是不可能形成 ρ 形的。于是有限子群的判定只需要看封闭性即可。 无限群一定有无限个子群，这是因为取出其每个元素的循环子群，如果只有有限个，那么必定有一个子群为无限的，那取其的子群即可。 循环群基本上讲的是废话，但是有个性质还是挺重要的，在数论中用得很多。对于阿贝尔群： $|a|\\perp|b|\\Rightarrow|ab|=|a||b|$。证明思路有两个：① 如果 $a^t=b^{-t}=x\\ne e$，那么 $|x|\\mid|a|\\land|x|\\mid|b|$，故 $|x|=1$，矛盾；② 如果 $(ab)^t=e$，那么 $a^{t|b|}=(ab)^{t|b|}=e=(ab)^{t|a|}=b^{t|a|}$，故 $|a|\\mid t\\land|b|\\mid t$。 $\\exists c,|c|=\\lcm(|a|,|b|)$。设 $|a|=xy^\\prime$，$|b|=x^\\prime y$，设所有在 $|a|$ 中次数 $\\ge$ 在 $|b|$ 的质因子乘积为 $X$，其余为 $Y$，$x=\\gcd(|a|,X^\\infin)$，其余同理。取 $c=a^yb^x$，由于 $|a^y|=x\\perp|b^x|=y$，故 $|c|=xy=\\lcm(|a|,|b|)$。 $|a|=p^x,|b|=p^y,x\u0026lt;y\\Rightarrow|ab|=p^y$。若有 $z\u0026lt;x$ 使 $(ab)^{p^z}=1$，则 $p^{x-z}=|a^{p^z}|=|b^{p^z}|=p^{y-z}$。 2 的形式对于（不一定循环）子群也成立。这个学了后面的知识就显然了，阿贝尔是个很强的性质。 3. Lagrange 定理相关 大纲 群中左/右同余、左/右陪集、左/右商集的定义及性质。 指标、子群乘积的定义及相关性质： （拉格朗日定理）$[G:H]=|G|/|H|$ $[G:K]=[G:H][H:K]$ $|HK|=|H||K|/|H\\cap K|$ $[H:H\\cap K]\\le [G:K]$，取等 $\\Leftrightarrow G=HK$ 笔记 关键抓住两句话：\n同一陪集内的元素对应的陪集仍为该陪集。 陪集形成等大的划分。 阶为质数的群一定与 $\\Z_p$ 同构，可以取 $\\set e$ 以外的循环子群，利用拉格朗日定理。\n另外，拉格朗日定理本质上就是 Burnside 引理的引理 $|E||Z|=|G|$，这个后面会详细讲。\n4. 正规子群与商群 大纲 正规子群的定义、等价表述、相关性质。 由正规子群的陪集构成的商群，其性质。 群的三个同构定理： $G$ 关于其同态核的商群，同构于同态映射的像。 某一子群关于一正规子群（与其交）的商群，同构于两者的积关于该正规子群的商群。 两个具有包含关系的正规子群，原群关于小者的商群与大者关于小者的商群，同样构成正规子群关系，且原群关于大者的商群，同构于两者分别关于小者取商群后再取的商群。 满同态下子群、正规子群、商群的一一对应性（当然，得是符合某些简单条件的）。 下文所有“正规子群”都默认为除 $\\set{e}$ 与本身外的正规子群。\n笔记 正规子群的核心是可以将群拆成“两层子群”，原理是左右幺元的同一。只有正规子群能生成商群（证明：https://www.zhihu.com/question/525584612/answer/2419749410）。\n一个群可能有多个同样大小的正规子群。\n$K\\norm H\\norm G\\nRightarrow K\\norm G$。而 $K\\norm G,K\\sub H\\sub G\\Rightarrow K\\norm H$，因为子群与正规子群的交是子群的正规子群。另外 $H,K\\norm G\\Rightarrow H\\cap K,HK\\norm G$。另外直积因子的直积因子是正规的。另外若 $K$ 是 $H$ 的正规 Sylow 子群且 $H\\norm G$，则 $K\\norm G$。\n关于群的三个同构定理的理解：\n（5.6）一个同态在缩了核之正规子群后，可以认为啥也没变，只是原像“类型转换”了一下。 （一）从同态在 $H$ 中的行为可看出，$a\\ker G$ 表现得和 $f(a)$ 完全一样，$\\ker G$ 表现得和 $e_G$ 一样。也正是因为左右幺元为同一个，故 $\\ker G\\norm G$。 （二）两种情况下商群结构完全相同，$K/(N\\cap K)=\\set{k(N\\cap K)}$，$NK/N=\\set{kN}$。注意与另一种情况区分：$NK\\subset H$，这时 $K/(N\\cap K)$ 相比于 $H/N$ 会漏一些。 （三）取商群就是划分等价类，只是把某些原来不同的元素视为相同，而保留原先的运算关系（行为），因此原群与大者分别关于小者取商群，并不会真正改变什么。 你甚至可以把（二）（三）都理解成类似约分的东西，一个是同乘的时候约分，一个是链式约分。\n本节相关命题的证明思路：\n只是证明正规或交换律。书里基本上都是用代数推导，也就是先用等价表述 (iv)，即设 $ana^{-1}$，在需要的时候用 (iii)，即令 $an_1=n_2a$。代数推导缺点是没那么直观，我会喜欢只用 (iii)，但有的命题必须用代数。\n证明同构。要么直接构造双射，要么用群的第一同构定理（需要凑同态，一般不难），这里给出二、三同构定理依赖于第一同构定理的证明：\n（二）构造 $K\\to NK/N$，这边需要 $nkN=kN$ 以证明满同态。这个映射干了两个事，一个是划分 $K$ 中的等价类（同时确立了核为 $N\\cap K$），另一个是纯类型转换，把 $k(N\\cap K)$ 转换为 $kN$。 （三）构造 $G/K\\to G/H$。这个映射单纯就是个类型转换，把 $gK$ 转换为 $gH$，当然这个类型转换就伴随着等价类划分（$K\\sub H$ 故不同元素数变少），即按核 $H/K$ 划分。 可以得到一种感觉，就是这种同态的构造就是一种“缩”（按等价类划分），这种缩是伴随着类型转换（小正规子群的陪集到大正规子群的陪集）出现的（注：（二）中的缩其实是 $k\\set e\\to k(N\\cap K)$）。\n5. 对称群、交错群、二面体群 大纲 某些 OIer 众所周知的东西。 对称群（$n\\ge 5$）有唯一正规子群。 证明交错群的单性： 证明三轮换能生成原群，以及包含三轮换的正规子群是原群。 证明正规子群不管长什么样，都得包含三轮换。 二面体群的刻画。 笔记 在对置换较复杂的处理中，不要想着把置换看作作用于某一排列的移动，而应当把它看作一个双射。运算时直接看每个元素从右往左经过映射后到哪就行。\n为了更轻松地理解证明的动机，需要熟悉以下几个置换的运算：\n称形如 $ana^{-1}$ 的东西为 $n$ 的共轭。书里没讲的一点是，$\\tau(i_1\\cdots i_r)\\tau^{-1}=(\\tau(i_1)\\cdots\\tau(i_r))$。这给出了“偷换”轮换中某些元素而不改变结构的一个极佳手段。 $(aJ)(aI)=(aIJ)$，其中 $I\\cap J=\\varnothing$。这边用大写字母表示一段元素。相当于用一个元素把两个轮换“串”起来了（8 字形）。一个特例是 $(i_1\\cdots i_r)=(i_1i_r)\\cdots(i_1i_2)$。 $(aJ_1bJ_2)(aI_1bI_2)=(aI_1J_2)(bI_2J_1)$，其中 $I\\cap J=\\varnothing$。对于三轮换的情况：$(ab)(abc)=(bc)$、$(abc)(ab)=(ac)$、$(abd)(abc)=(ad)(bc)$、$(adb)(abc)=(bcd)$、$(abd)(acb)=(acd)$、$(adb)(acb)=(ac)(bd)$。另外还有 $(abc)^2=(acb)$、$(acb)(abc)=e$。 证明单群要找出三轮换，无非就是自乘和构造 $\\nu^{-1}\\tau\\nu\\tau^{-1}$。\n对 $S_n$ 子群的总结：\n除 $S_4$ 外，其余群只有唯一正规子群 $A_n$，因为如果有另一个，它与 $A_n$ 的交就是 $A_n$ 的正规子群，必须是 $\\set{e}$，那这样的一个正规子群必须恰好包含 $e$ 和一个奇置换（如果有两个，奇奇得偶 $\\ne e$ 就爆了），这个奇置换必须由奇数个对换组成，随便用共轭替换掉其中一两个元素就爆了。 $K_4\\norm A_4\\norm S_4$ 且 $K_4\\norm S_4$。主要就是只要由若干共轭类组成，就至少满足了正规性，只需要再保证封闭即可。$K_4$ 神奇地封闭了，就是这样。$S_4$ 仅有这两个正规子群，$A_4$ 也仅有这个正规子群，证明直接考虑大小。 $A_4$ 没有 $6$ 阶子群。考虑 $3$ 阶元。 $S_n$ 中指数为 $2$ 的子群仅有 $A_n$（利用指数为 $2$ 的子群一定是正规子群，$n=4$ 时如果还有的话，交大小就得是 $6$，矛盾）。 满足二面体群性质的群结构唯一，这个证明比较典型。后面自由群给了一般性的证明。\n$S_n$ 和 $A_n$ 的子群无法刻画。关于 $D_n$：\n正规子群。如果 $a^xb\\in H$，则 $H\\ni(a^ib)(a^xb)(a^ib)=a^{2i-x}b$。因此正规子群有 $\\lang a^d\\rang$（$d\\mid n$），如果 $2\\mid n$，则还有 $\\lang a^2,b\\rang$ 和 $\\lang a^2,ab\\rang$。 子群。如果 $H\\cap\\set{a^ib}\\ne\\varnothing$，那么要么 $|H|=2$，要么 $H\\cap\\set{a^i}=\\lang a^d\\rang$（$d\\mid n$）。后面一种情况下，$H\\cap\\set{a^ib}=\\set{a^{kd+r}b}$（$0\\le r\u0026lt;d$）。如果还有别的元素，就可以用类似循环群子群的证明方法找到更小的 $a^{d^\\prime }$。因此真子群有 $\\lang a^ib\\rang$、$\\lang a^d\\rang$、$\\lang a^d,a^rb\\rang$。 关于 $S_4/K_4\\cong S_3$ 与 $A_4/K_4\\cong Z_3$，固然可以用第二同构定理证，但这里从置换的作用出发给出了一个直观的证明：https://math.stackexchange.com/questions/302654/show-that-s-4-v-is-isomorphic-to-s-3-where-v-is-the-klein-four-group。\n这个证明说了一个事，当使用第一同构定理时，从群的作用意义上来说，我们实际上考虑了被作用对象的一部分特征，而那个同构的小群，就是这部分特征所作出的变化本质不同的作用方式形成的群。\n6. 直积 大纲 直积、外直积、内直积的定义，在同态、取商情况下的性质。 笔记 $\\lang\\rang$ 符号是有限生成， 内、外直积都是在此基础上定义。注意有限和无限情况不同，例如无限位二进制数的异或，逐位为一的直积的阶为 $\\aleph_1$，内、外直积的阶为 $\\aleph_0$。这个就像有理数与无理数间的关系。 在满足条件时，内、外直积的区别只在于类型不同。当我们说（内）直积，或者说一个群等于一些子群的积时，默认这个直积不是多元组的形式，而是直接相乘的形式，也就是说，当且仅当每个 $N_i$ 均为正规子群且与别的子群的积交为 $\\set e$ $\\Longleftrightarrow$ 每个元素的表达方式唯一 $\\Longleftrightarrow$ $e$ 的表达方式唯一时，这个说法才有意义。而当我们说外直积，或者说一个群同构于一些小群的积时，默认是多元组的形式。 注意，$N\\times(G/N)\\cong G$ 是不一定成立的，例如 $2\\Z_4\\oplus(\\Z_4/2\\Z_4)\\cong\\Z_2\\oplus\\Z_2\\not\\cong\\Z_4$。 7. 自由群 大纲 自由群的定义。 用自由群生成任何群。 笔记 虽说自由群也是有运算的群，但我们可以将它理解成字符串，这种字符串刻画的是一堆元素的运算，其中关键的一点是，只要运算式字面上不同，就认为实质不同，这一点在其余群中是基本不会出现的，否则这样的群就没啥性质了。\n但是，这里需要避免混淆的一点是，字内字母的排列，与两个字的运算，都写成了顺次拼接的形式。在证明自由群的结合律时，如果要硬证的话，必须讨论三个字 $a,b,c$ 以不同顺序考虑抵消时实际的抵消情况来证明，或者用归纳法。而不能说“由于每个字都可以看成若干个单 $x^{\\pm 1}$ 运算在一起，而所有 $x^{\\pm 1}$ 是有结合律的，因此所有元素都满足结合律”（相当于只证了部分元素的结合律）。不过，书里的这个证明很有意思：赋予每个元素一个实际含义“对所有字的置换”，这样既保证了区分任何字面不同的情况，又将结合律的证明归约到了对称群的结合律。\n另外，这节的理论很好地解释了 [CSP-S 2023] 消消乐 的 trie 树做法的动机——找所有 $s_i\\cdots s_j=e$，就可以转化成找所有 $(s_1\\cdots s_{i-1})^{-1}s_1\\cdots s_j=e$，也就是 $s_1\\cdots s_j=s_1\\cdots s_i$。这题唯一的特殊性是给定了关系 $xx=e$，不过没什么影响。\n自由群的子群均为自由群，这个证明很难。另外自由群子群的最小生成元集大小可能大于原群的。\n所有群都同构于自由群的商群，以及给定生成元集和关系可以唯一确定“最大”的群，这个很重要。几点理解：\n这个证明的核心是，在自由群的基础上添加特定群的额外关系后不会出现矛盾，而这是平凡的（否则自由群就不够自由了……）。 关系的生成正规子群，这个东西的确定，依赖于正规子群的交仍为正规子群。关于 9.5 的证明，直观的理解就是，最大的群对应那个最小的核，有大核的话有可以它通过 5.6 或 5.8 搞个满射。 一个群的商群可能不同构于其子群，否则由“自由群的子群均为自由群”，就会出现很诡异的事情。 证明某一个表示对应的群是某个群：先验证符合，然后再通过关系的代数推导，得出“所有的元素都能表示为某类形式”，从而证明大小的上界。\n8. 有限生成 Abel 群结构定理 大纲 自由阿贝尔群的定义。 用自由阿贝尔群生成任何阿贝尔群。 若干种取子群的方式（$mG,G[m],G(p),G_t$）的定义及性质。 有限秩的自由阿贝尔群的子群的结构，即所有有限生成阿贝尔群的结构。 笔记 我们来大致梳理以下整个刻画过程的思路：\n定义自由阿贝尔群，知道自由群后，这个定义是很自然的。处理自由阿贝尔群的性质时，套路是和线性代数很相似的，唯一不同的点是线性代数允许一个向量乘有理数加给另一个向量（以及向量本身乘一个数），而阿贝尔群不允许。也正是这一点，导致了。\n导出自由阿贝尔群的一些性质：\n每个元素表示唯一、基在某个元素乘若干倍加给另一个元素的操作下仍为基，以及它的“自由”性（同样，自由的证明仅需要证明良定义即可）。 额外地，证明自由阿贝尔群的基大小唯一。这里对秩有限情况的证明策略是通过取商群，将无限转化为有限，而秩无限的情况就直接用定义和序数理论。我们会注意到，对于唯一性的证明，套路一般就是通过一种不依赖于具体分解的方式，取子群或商群，然后通过这两个不能不相等，证回唯一。 有限秩的自由阿贝尔群的子群的结构。这个证明最好的方式其实是给出一个构造性的算法：首先考虑用自由群的基线性表出子群的各个生成元，写成一个矩阵。对这个矩阵列变换就是改变基，行变换就是改变生成元集。为了保证改变后可生成性不变，只能使用交换两行/列、一个乘整数倍加给另一个、以及一行/列乘 $-1$。现在可以通过一个算法将矩阵化为史密斯标准形：\n每次通过多元素的辗转相除法，将左上角元素变为所在行或所在列的 $\\gcd$，并把对应行/列的其他元素全部减成 $0$。注意到，一旦 $\\gcd$ 不缩小，就可以将行列均变为 $0$，那这样就可以归约到两维各减一的子矩阵。（这里我有一个时间复杂度更优的算法）\n现在可以假定只有 $a_{1,1}$ 到 $a_{r,r}$ 非零。注意到可以用： $$ \\begin{bmatrix}a\u0026amp;0\\\\ 0\u0026amp;b\\end{bmatrix}\\xrightarrow{\\mathrm{B\\acute{e}zout}}\\begin{bmatrix}a\u0026amp;g\\\\ 0\u0026amp;b\\end{bmatrix}\\rightarrow\\begin{bmatrix}a\u0026amp;g\\\\ -l\u0026amp;0\\end{bmatrix}\\rightarrow \\begin{bmatrix}g\u0026amp;0\\\\ 0\u0026amp;l\\end{bmatrix} $$ 将两个元素分别变为它们的 $\\gcd$ 和 $\\lcm$。那就可以用类似冒泡的过程，将这个对角线上的元素调整为依次整除。\n而书里用了一个类似无穷递降法的过程。根据证明贪心的一些经验，由于一般反证只干掉单步，故会比构造性的过程简单一些。书里的思路是：首先找到所有可行生成元被所有基表出的所有系数中最小的一个系数对应的一项 $d_1x_1$，这个 $d_1x_1$ 能作为第一个生成元，然后接着归约就行。其递降的核心是，若不整除，则余数会导致更小项。\n然后就是利用第一同构定理加商群在直积下的同构性，直接导出任何有限生成阿贝尔群存在一种预想的拆分方式。合数阶的拆分太显然了。最后是证明拆分的唯一性：\n$\\Z$ 部分，商掉挠子群，归到自由阿贝尔群表示的唯一性。 “唯一分解定理”，处理方式仍然是抽出子群证相等或矛盾。注意到有限阿贝尔群的商群和子群是可以打通的（https://math.stackexchange.com/questions/64982/is-every-quotient-of-a-finite-abelian-group-g-isomorphic-to-some-subgroup-of），所以用哪种无所谓。 依次整除的表示唯一。这个看起来不大直觉，但是把每个阶都拆开来排成矩阵，就显然了。 阶为 $n$ 的阿贝尔群的数量 $f(n)$ 是积性函数，其中 $f(p^k)=p(k)$，$p(k)$ 是 $k$ 的无序拆分数。\n练习 2.2 的思路：只考虑指数幂情况。归纳，找到一个阶为质数的，与 $\\lang x\\rang$ 交为 $\\set{0}$ 的群 $H$（直接找循环群即可），然后归纳。归纳有个细节，就是 $G/H=(\\lang x\\rang H)\\oplus(K/H)$ 推到 $G=\\lang x\\rang+K+H=\\lang x\\rang\\oplus K$ 时，要用直积那节交为 $\\set{0}$ 的性质。然后推大结论用的是所有元素的阶都整除最大阶。\nhttps://math.libretexts.org/Bookshelves/Abstract_and_Geometric_Algebra/Abstract_Algebra%3A_Theory_and_Applications_(Judson)/13%3A_The_Structure_of_Groups/13.01%3A_Finite_Abelian_Groups 的 Lemma 13.9。\n注意挠群不一定有限，例如 Prüfer 群 $\\Z(p^\\infin)$，它是无限个 $\\Z_p$ 的内直积。\n9. Krull-Schmidt 定理 大纲 最看不懂的一集。\n不可分解群、升降链的定义与关系，正规自同态、幂零的定义。 为证明 Krull-Schmidt 定理所作的准备，自同态在满足升降链条件的情况下的四条性质。 Krull-Schmidt 定理。 笔记 不可分解的条件比单群弱。\n梳理一下证明思路。Krull-Schmidt 定理核心说的就是，ACC 和 DCC 同时成立的情况下分解唯一（我怎么感觉有限群之外一般都用不了这个……）\n满足 ACC\u0026amp;DCC 的不可分解群的自同态要么是自同构，要么是幂零。可根据 $G=(\\ker f^n)(\\im f^n)$ 直接导出，而 3.4 和 3.5(Fitting) 都是把链设出来之后妙妙推式子。注意在 DCC 是 $f$ 需要正规只是为了 DCC 正规，而正规最终是为了和内直积对上。 在 $G=G_1\\times\\cdots\\times G_r\\times H_{r+1}\\times\\cdots\\times H_t$ 的情况下，要找到一个 $H_j\\cong G_{r+1}$。找的思路是，$G$ 中的元素，它在全 $G_i$ 分解中的 $G_{r+1}$ 分量，在当前分解中体现为 $H_{r+1}\\sim H_t$ 分量的一部分，用书中的代数语言写，就是如果让 $\\varphi$、$\\psi$ 为取分量操作，$\\varphi_r=\\sum_{j\\ge r}\\varphi_r\\psi_j$。$\\varphi_r$ 是 $G_r$ 下的单位映射，所以右式不能全是幂零。 要证明最后一句话，就是要证幂零自同态之和封闭 $\\Rightarrow$ 幂零。容易想到反证，因为直觉上来说，多个幂零的东西加起来也是幂零的。但直接取幂，由于自同态关于加法没有交换律，所以搞不了。这里证明搞了个 $g_i=f_i(f_1+f_2)^{-1}$，然后一波妙妙推式子就交换了。这边加法和复合构成环。 回到原证明，找到一个不是幂零的也就是自同构，分析一下单、满射就可以得到 $\\psi_j$ 和 $\\varphi_r$ 是（正反方向）同构，然后就要证直接把 $H_j$ 换成 $G_r$ 就行了，就是说虽然 $H_j$ 和 $G_r$ 的东西不一样，但是它们乘上别的之后就得到了整个 $G$，从两个方面（不重——和别的交为 $\\set{e}$，不漏——单+3.4=双）证即可。最后才导出 $s=t$。 3.4、3.5、3.7 都有妙妙推式子，我真没法理解思路，除了 3.4：\n$\\ker f^n=\\ker f^{n+1}$ 的话，说明只有原来的核是新的核，也就是只有原来的 $e$ 是新的 $e$，则单射则双射。\n$\\im f^n=\\im f^{n+1}$ 的话，说明原来的像能覆盖新的像了，那像以外的部分就得汇聚到像内导致多对一，于是根本就不能有像以外的部分，则满射则双射。\n然后怎么理解 3.8 的这个“逐一替换”强于单说同构呢？可以看 https://math.stackexchange.com/questions/2982433/krull-schmidt-theorem-for-groups，本质上就是内直积它是直接子群直积，避开了多元组然后同构的步骤，也就是说 Krull-Schmidt 定理说的不单单是结构唯一，而且还能直接从 $G$ 里取出一堆来直接生成。\n另外，这个替换过程可以类比线代：比如 $\\R^2$ 的基既可以是 $[1\\quad0]$ 和 $[0\\quad1]$，也可以是 $[1\\quad0]$ 和 $[1\\quad1]$，可以把 $G_r$ 和 $H_j$ 分别看成两个基的后者。\n另外注意证明过程中是否有：有限、$G\\ne\\set{e}$、either ACC/DCC 还是 both ACC\u0026amp;DCC。\n3.3 的证明就反证后随便找找子群（DCC 做个前缀和），不过存在不可分解群不满足 ACC 也不满足 DCC 吗？\n10. 群作用 大纲 群作用、轨道、稳定化子、共轭类、中心化子、正规化子、类方程、中心、内自同构的定义。 关于它们的一些性质，主要是以 $|E||Z|=|G|$ 为核心思想的部分，和质数正规的部分。 笔记 关于群作用的概念较多，研究的核心就是两个：作用者和被作用者。被作用者，我们主要关心其等价类与使它不变的“子”；作用者，主要关心其不动点。特别地，我们非常关心群自身作用自身的情况，这时作用者和被作用者的地位可互换（中心，$gx=xg$）。\n在这几节中，每个定理我们都必须首先明确作用者和被作用者，不然马上就糊涂了。\n指数为最小质因子的子群必正规，这个的证明思路是：考虑陪集 → $G$ 左作用给左陪集是置换 → $G$ 根据作用效果分类 → ① 置换子群最大质因子是 $p$ ② 划分得是 $|G|$ 的因子 → 只可能 $H$ 自身是核（核至多是 $H$）。\n这个过程还算易懂，但是是怎么想到绕这样一个弯证出来的？\n补充一下，内自同构是自同构群的正规子群，其商群成为外自同构。\n11. Sylow 定理 大纲 Sylow 定理的一些引理，主要是关于阶为质数的群的性质。 Sylow $p$ 子群的定义、Sylow 三定理。 笔记 这个部分主要有几个核心思想：\n$|S|\\equiv|S_0|\\pmod p$ 一类。这个说的是，被作用者形成的等价类中，由于稳定化子的陪集构成整个轨道，故每个的大小都是 $p$ 的次幂，然后取 $p^0$（不动点）那部分。这个性质的唯一作用就是说非平凡不动点存在。注意用它的前提条件是作用者的阶必须是质数幂。\n有个重要的思想有点难表述，我们看下几个有相似点的证明思想：\n定理 5.5. $p$ 子群 $H$ 满足：它的“正规化陪集”数（显然，一个 $H$ 的陪集要么全是正规化子要么全不是），与它的陪集数同余。\n首先得明确，引理 5.1 只能用于同余式两边都是被作用者的情况，但是 5.5 的形式中，就算我们考虑把 $H$ 的陪集作为被作用者，这个“正规化陪集”再怎么说都只能是作用者啊！都写明了是“使 $H$ 正规”。这里我们联想 4.7 证明里的一句话：\n$g$ 是中心 $\\Leftrightarrow$ $g$ 是不动点。（前提：$G$ 共轭作用给 $G$ 自身）\n说明：$gxg^{-1}=x\\Leftrightarrow xgx^{-1}=g$\n我们得以从“中心”这一作用者的角度，转化为“不动点”这一被作用者的角度。那这里也是一样的。\n这里，选用的是 $H$ 的元素作为作用者（左作用），这个感觉有点怪异。那么 $|S_0|$ 就应该是在所有 $h$ 的作用下不动的陪集：$h(xH)=xH\\Leftrightarrow xHx^{-1}=H$，于是就打通了。发现这个的本质和上面这种单点的是类似的。\n另外注意：$\\forall h\\in H,x^{-1}hx\\in H\\Rightarrow x^{-1}Hx=H$ 这个是在有限前提下的。\n第二定理：要证 $H\\sub xPx^{-1}$，模仿上面的证明，逆向考虑，我们要找的应当是 $h(xP)=xP$（$p(xH)=xH$ 的话就倒反天罡了），即 $P$ 陪集为被作用者，$H$ 的元素为作用者（左）。然后就是个 $[G:P]\\not\\equiv0$。\n第三定理：其实说的就是 $[G:N_G(P)]\\equiv 1$，拿 5.5 除一下就出来了。不过多个思路也是好事。这里显然考虑被作用者是 $P$ 的所有共轭，即 $\\syl_p(G)$，然后让 $S_0=\\set P$ 就行。$P$ 的元素为作用者，于是 $\\forall p\\in P,pQp^{-1}=Q\\Rightarrow P\\sub N_G(Q)$ 然后由第二定理就得到 $P=Q$。\n容易发现，这里的通用构造是“某个小集合（可能就是这个子集）作用在所有子集的陪集上”，然后从不动点出发，去推一些神奇的结论。前一节中是将作用视作置换群，先从作用者的稳定性考虑，能推的不是很多（仅能推出 $\\mid n!$ 相关的性质）。反正记住有这两类证的思路就行。\n第一定理反而显得简单了，就是用柯西定理找个循环群，然后找稳定化子升幂即可。5.11 和第三定理思路中的一块是相同的，就是共轭不变 $+$ Sylow $p$ $\\Rightarrow$ 唯一。\n看了第一定理后，会有一个直觉，就是 Sylow $p$ 子群唯一，感觉上如果有两个，可以乘一下搞出更大的。但是这个是不对的，可以看 https://planetmath.org/subgroupsofs4 为例。另外两个 Sylow $p$ 子群的交也可能非平凡：https://math.stackexchange.com/questions/24704/distinct-sylow-p-subgroups-intersect-only-at-the-identity-which-somehow-follo。\n这里提一下 Sylow 第三定理的加强版本：\n设 $v_p(|G|)=m$ 且 $G$ 的所有 Sylow $p$ 子群中，交最大大小为 $p^r$，则 $n_p(G)\\equiv1\\pmod{p^{m-r}}$。\n证：我们仍然考虑某一 Sylow $p$ 子群 $P$ 共轭作用在 $\\syl_p(G)$ 上。在上面的第三定理中，我们说明的是 $Q$ 不能不动即 $N_P(Q)\\ne P$ 即 $P\\not\\sub N_G(Q)$，其证明手段是，$N_G(Q)$ 中只有唯一 Sylow $p$ 子群 $Q$。那这里也是一样的，$N_P(Q)=N_G(Q)\\cap P$，现在我们额外地说，由于 $N_G(Q)\\cap P$ 必须是 $p$ 子群，而 $N_G(Q)$ 的 $p$ 子群都包含于 $Q$ 中，因此 $N_P(Q)\\sub P\\cap Q$，故 $|N_P(Q)|\\le|P\\cap Q|\\le p^r$，故 $p^{m-r}\\mid|\\mathrm{Orb}_P(Q)|$。\n这个在有限群分类、证明单群时可以用。\n问题：是否会出现某个大小的 $p$ 子群唯一，但 Sylow $p$ 子群不唯一的情况？\n看个搞笑的：https://www.zhihu.com/question/36479927/answer/1554929023。\n12. 有限群分类 大纲 $pq$、$8$、$12$ 阶群结构。 笔记 下文所有 $n_p$ 默认为 $n_p(G)$。\n主要的几个分析方法：\n最常用的几个基本定理：拉格朗日定理、第一同构定理、阿贝尔群结构、$G/C(G)$ 循环则阿贝尔、全 $2$ 阶则阿贝尔、指数为最小质因子则正规、$p$ 群中心非平凡、Sylow 定理。\n一个极为有效的推导：$n_p=kp+1$ 且 $n_p\\mid\\frac{|G|}{\\gcd(|G|,p^\\infin)}$，然后要么就是单个正规子群，要么数量可能性少。单个正规子群时，可以从正规性和商群的角度列出两个式子 $bab^{-1}=a^?$ 与 $b^{[G:N]}=a^?$。处理共轭时常用的推导是 $ba^jb^{-1}=(bab^{-1})^j$ 以及 $b^{i}ab^{-i}=b^{i-1}a^kb^{-(i-1)}=\\cdots=(bab^{-1})^{k^i}$。\n这样的一个推导实际上是在分析一个任意子群到正规子群自同构的同态。实际上我们主要会遇到：\n$\\aut\\Z_n=\\Z_n^\\times$。然后根据中国剩余定理与原根存在定理进行拆分。 $\\aut\\Z_p^k\\cong\\mathrm{GL}_k(\\F_p)$。就是 $\\bmod p$ 下的 $k$ 阶满秩矩阵，其列向量对应每个生成元映射到哪。 其他一些阿贝尔群的自同构。先尝试按质因子拆，包含多个 $\\Z_{p^k}$ 直积因子可能会不好搞 其他。只能讨论一些小的情况，另外可考虑正规子群的不动性。 如果正规子群太小，可以用 Correspondence Theorem（或叫 Lattice Theorem）扩大。其实感觉比较平凡，就是说 $G/N$ 的正规子群对应 $G$ 的正规子群，其实在 I.5.11 提到过。然后这个反过来也是成立的，即 $G$ 的正规子群也对应 $G/N$ 的正规子群。\n如果正规子群太大，也可以考虑第 4 节笔记里的方法。\n如果搞不出正规子群，我们一定要强制搞出来。有几个处理思路：\n考虑共轭 Sylow 子群多的话可能元素会分配不过来。 考虑对子群的陪集或正规子群共轭的作用，同态于对称群。 考虑中心，可以直接讨论，或者考虑共轭 Sylow 子群的交之类的。中心意味着直积。 然后总结一下各种情况的证明思路。注意当给出一个生成关系时，应当证明它对应的群大小恰好是它且确实是群，不然是不够的，但是这里就略去了。\n$p^2$。中心个数是 $p$ 的倍数，于是 $G/C(G)$ 是 $1$ 或 $p$ 阶的，后一种情况通过写出元素的形式可得交换，于是 $G$ 是阿贝尔群。\n$pq\\,(p\u0026lt;q)$。存在唯一 Sylow $q$ 子群 $\\lang a\\rang$，$n_p\u0026gt;1$ 就必须是 $q\\mid(p-1)$ 情况，取个其中的元素 $b$，$bab^{-1}=a^s\\Rightarrow a=b^pab^{-p}=a^{s^p}\\Rightarrow s^p\\equiv 1\\pmod q$。证明所有 $ba=a^sb$ 的群同构只需构造 $\\varphi(a)=a^\\prime ,\\varphi(b)={b^\\prime }^{\\operatorname{ind}_{s^\\prime }s}$ 即可，这给出了 $G\\cong\\Z_q\\rtimes\\Z_p$ 且半直积的下标可以省略。\n$8$。非阿贝尔的情况一定有一个阶为 $4$ 的元素 $a$，取 $b\\notin\\lang a\\rang$，① $b$ 对 $\\lang a\\rang$ 的共轭形成 $\\lang a\\rang$ 的自同构，于是不交换只能是 $bab^{-1}=a^3\\Rightarrow ba=a^{-1}b$；② $b^2\\in\\lang a\\rang\\Rightarrow b^2=e\\or a^2$。分别对应 $D_4$ 和 $Q_8$。\n$12$。类似证明指数为最小质因子的群正规的方式，考虑对 $4$ 个 Sylow $3$ 子群的陪集的左作用，到 $S_4$ 的同态。若核是 $\\set{e}$，则 $G\\cong A_4$；否则由于核是该 Sylow $3$ 子群的子群，故必为其本身，故 Sylow $3$ 子群正规，设为 $\\lang a\\rang$，它的中心化子里一定有 $|b|=2$，于是 $|ab|=6$。记 $c=ab$，则 $dcd^{-1}=c^5$（非交换）且 $d^2=c^{0\\or2\\or3\\or4}$。如果是 $2\\or 4$ 就会 $c^{\\pm 2}=d^2=dc^{\\pm2}d^{-1}=c^{\\mp2}$ 矛盾，故 $d^2=e\\or c^3$。\n这两种分别对应 $D_6$ 与 $\\Z_6\\rtimes\\Z_2$……吗？？？如果是 $\\Z_6\\rtimes\\Z_2$ 的话，含 $d$ 的元素的阶就全是 $2$ 了，就是 $D_6$。考虑以 $a$ 和 $d$ 作为生成元（$d^2=b$ 所以 $d$ 可以替代 $b$ 的功能），于是关系就变成了 $a^3=d^4=e,dad^{-1}=a^2$，这样就可以写成 $\\Z_3\\rtimes\\Z_4$ 了。\n又看到一个不错的证明思路 https://www.youtube.com/watch?v=dS-fIMHVNcE。\n实际上回头看这里，考虑一个 Sylow $2$ 子群（$\\Z_4$ 或 $\\Z_2^2$）到 $\\aut\\Z_3$ 的同态（非平凡的只有一个）即可。\n$p^3$。如果有 $p^2$ 阶元 $a$ 则 $\\lang a\\rang\\norm G$，那么显然希望找到另一个 $p$ 阶元 $b$ 从而构成 $\\Z_{p^2}\\rtimes\\Z_p$，这个可以先随便取一个 $b$，然后如果它的阶数不对的话，乘上某个 $a^?$ 就行，这个 $?$ 可以待定系数法解出来。然后容易证明所有的 $bab^{-1}=a^k$ 都是同构的，这里要求 $\\delta_{p^2}(k)=p$，所以关系可以写成 $a^{p^2}=b^p=1,ba=a^{p+1}b$。\n如果没有，则选个 $p$ 阶中心 $c$（$|C(G)|=p$ 否则类似 $p^2$ 情况就阿贝尔了），选 $\\lang c\\rang$ 以外 $p$ 阶元 $a$，再选另外的 $b$。这里 $\\Z_p^2\\cong\\lang c\\rang\\times\\lang a\\rang\\norm G$，同样讨论在 $b$ 的共轭作用下这个正规子群会怎样自同构，这里讨论比较复杂，最后得出的同样是所有可能都是同构的，即 $\\Z_p^2\\rtimes\\Z_p$，关系可以写成 $a^p=b^p=c^p=e,ac=ca,bc=cb,c=bab^{-1}a^{-1}$。推导细节详见 https://www.zhihu.com/question/497442031/answer/3098229320。\n在搜资料的时候我发现半直积的性质还是很重要的，所以这里先补充一下相关的知识：\n应该从内半直积开始理解，现在假设 $HK=G$，$H\\cap K=\\set{e}$，但只有 $H\\norm G$。我们想使用类似直积的，$H\\rtimes K\\cong G$ 的方式来拆分 $G$，因此有同构映射 $f:(h,k)\\mapsto hk$，运算必须满足 $$ f((h_1,k_1)\\cdot(h_2,k_2))=f((h_1,k_1))f((h_2,k_2))=h_1k_1h_2k_2 $$ 就需要应对 $h$ 与 $k$ 无法交换的问题（如果 $K\\norm G$ 则根据 $hkh^{-1}k^{-1}\\in H\\cap K=\\set{e}$ 可得交换性）。这里的关键是： $$ h_1k_1h_2k_2=h_1(k_1h_2k_1^{-1})k_1k_2 $$ 于是定义 $(h_1,k_1)\\cdot(h_2,k_2)=(h_1\\cdot k_1h_2k_1^{-1},k_1k_2)$，其余运算规则略，可验证其对应的群符合条件。\n外半直积也是一样的，我们知道在群中，共轭对应了内自同构。这里要构造群，就只需要是自同构就行了，即，若有同态（不能单单是映射，否则运算就不是良定义的了） $\\varphi:K\\to\\aut H$，就可以定义 $(h_1,k_1)\\cdot(h_2,k_2)=(h_1\\varphi(k_1)(h_2),k_1k_2)$。这就是外半直积 $H\\rtimes_\\varphi K$，在不引起歧义时可省略 $\\varphi$。\n以上内容参考了 https://www.youtube.com/watch?v=Pat5Qsmrdaw。\n性质 1：对于 $\\varphi:K\\to\\inn H$，$H\\rtimes_\\varphi K\\cong H\\times K$。\n证：根据 $\\varphi$ 得到一个 $\\psi:K\\to H$，$(h_1,k_1)(h_2,k_2)=(h_1\\psi(k_1)h_2\\psi(k_1)^{-1},k_1k_2)$。构造同构映射 $f:(h,k)\\mapsto h\\psi(k)$，验证 $$ \\begin{align*} \u0026amp;f((h_1,k_1)(h_2,k_2))\\\\ ={}\u0026amp;h_1\\psi(k_1)h_2\\psi(k_1)^{-1}\\psi(k_1k_2)\\\\ ={}\u0026amp;h_1\\psi(k_1)h_2\\psi(k_2)\\\\ ={}\u0026amp;f((h_1,k_1))f((h_2,k_2)) \\end{align*} $$\n性质 2：$\\exists\\chi\\in\\aut H,\\forall k\\in K,\\psi(k)=\\chi\\circ\\varphi(k)\\circ\\chi^{-1}\\Rightarrow H\\rtimes_\\varphi K\\cong H\\rtimes_\\psi K$。\n证：构造 $f:(h,k)\\mapsto(\\chi(h),k)^\\prime $，验证 $$ \\begin{align*} \u0026amp;f((h_1,k_1)(h_2,k_2))\\\\ ={}\u0026amp;f((h_1\\varphi(k_1)(h_2),k_1k_2))\\\\ ={}\u0026amp;(\\chi(h_1)(\\chi\\circ\\varphi(k_1))(h_2),k_1k_2)^\\prime \\\\ ={}\u0026amp;(\\chi(h_1)(\\psi(k_1)\\circ\\chi)(h_2),k_1k_2)^\\prime \\\\ ={}\u0026amp;(\\chi(h_1),k_1)^\\prime (\\chi(h_2),k_2)^\\prime \\\\ ={}\u0026amp;f((h_1,k_1))f((h_2,k_2)) \\end{align*} $$ 这个反过来是不对的，一个简单的反例就是性质 1。\n直觉上来说，这个性质就是对自同构本身作了自同构，或者在实际证明时，往往形如“我们换 $H$ 的生成元（比如 $a$ 换成 $a^3$ 之类），发现它变成了另一个自同构”，于是这两（几）个就只需考虑一个。\n性质 3：对于有限循环群 $K$，$\\exists\\chi\\in\\aut H,\\psi(K)=\\chi\\circ\\varphi(K)\\circ\\chi^{-1}\\Rightarrow H\\rtimes_\\varphi K\\cong H\\rtimes_\\psi K$。\n证：设 $K=\\lang k\\rang$。首先循环群有性质 $\\varphi(k^a)(h)=\\varphi(k)^a(h)$，因此下面以 $\\varphi,\\psi$ 指代 $\\varphi(k),\\psi(k)$。\n设 $\\psi^c=\\chi\\circ\\varphi\\circ\\chi^{-1}$，构造 $f:(h,k^a)\\mapsto(\\chi(h),k^{ac})^\\prime $，验证 $$ \\begin{align*} \u0026amp;f((h_1,k^a)(h_2,k^b))\\\\ ={}\u0026amp;f((h_1\\varphi^a(h_2),k^{a+b}))\\\\ ={}\u0026amp;(\\chi(h_1)(\\chi\\circ\\varphi^a)(h_2),k^{(a+b)c})^\\prime \\\\ ={}\u0026amp;(\\chi(h_1)((\\chi\\circ\\varphi\\circ\\chi^{-1})^a\\chi)(h_2),k^{(a+b)c})^\\prime \\\\ ={}\u0026amp;(\\chi(h_1)(\\psi^{ac}\\circ\\chi)(h_2),k^{(a+b)c})^\\prime \\\\ ={}\u0026amp;(\\chi(h_1),k^{ac})^\\prime (\\chi(h_2),k^{bc})^\\prime \\\\ ={}\u0026amp;f((h_1,k^a))f((h_2,k^b)) \\end{align*} $$ 注意，$K$ 有限时易验证 $c\\perp|K|$，从而 $f$ 是双射。$K$ 无限时 $f$ 就不是双射了。\n更多的反例详见 https://math.stackexchange.com/questions/624672/semi-direct-product-of-groups-with-one-of-them-cyclic 和 https://math.stackexchange.com/questions/527800/when-are-two-semidirect-products-isomorphic。\n由于群分类时大部分情况这个 $K$ 都是循环群，所以性质 3 会更好用。这个性质 3 相比性质 2 强的点在于，它只要求整个像共轭，而不用每个 $k$ 对应共轭。性质 3 和 $pq$ 情况的证明的核心思想是一样的。\n现在，我们可以从更高的角度理解 $p^3$ 情况的分析：若正规子群是 $\\Z_{p^2}$，那么性质 3 就说有本质唯一的 $\\varphi:\\lang b\\rang\\to\\set{f\\in\\aut\\Z_{p^2}\\mid f(a)=a^{kp+1},k\\ne 0}$。若正规子群是 $\\Z_p^2$，$\\aut\\Z_p^2\\cong\\mathrm{GL}_2(\\F_p)$，而 $|\\mathrm{GL}_2(\\F_p)|=(p^2-1)(p^2-p)$，于是它的唯一 Sylow $p$ 子群共轭类 $\\overline{\\left\\langle\\begin{bmatrix}1\u0026amp;1\\\\ 0\u0026amp;1\\end{bmatrix}\\right\\rangle}$ 就对应了所需的映射，于是半直积也是唯一的。\n$p^2q$。这个情况需要一个我不会证的性质，先写出来：\n对于性质 3，如果 $|H|\\perp|K|$，则反推也成立。\n这个性质是 https://math.stackexchange.com/a/1834299 的简单推论。\n这使我们能快速说明分类后各类不同构。接下来是按 $([p\\mid(q-1)],[q\\mid(p^2-1)])$ 的四种情况来分讨。\n$p\\mid(q-1)\\land q\\mid(p^2-1)$。唯一的可能是 $p=2,q=3$，已经在上面讨论过。 $p\\nmid(q-1)\\land q\\nmid(p^2-1)$。阿贝尔。 $p\\nmid(q-1)\\land q\\mid(p^2-1)$。 Sylow $p$ 子群是 $\\Z_{p^2}$。取个 $q$ 阶循环群，如果 $q\\mid(p-1)$，类似于 $pq$ 的时候，会有一个非平凡的情况，就是 $bab^{-1}=a^s$，其中 $\\delta_{p^2}(s)=q$。不同的 $s$ 对应的都是同构的。 Sylow $p$ 子群是 $\\Z_p^2$。这里的分析很复杂，概括一下就是，首先 $q\\mid(p-1)\\lor q\\mid(p+1)$。分三种情况，$q=2$ 是简单的，$q\\mid(p+1)$ 的情况有唯一共轭类，$q\\mid(p-1)$ 的情况有 $(q+3)/2$ 种。这里核心思路是，从特征值角度出发分析 $\\mathrm{GL}_2(\\F_p)$ 中 $q$ 阶循环子群之间的共轭关系。细节详见 https://www.math.purdue.edu/~jlipman/5532011/order-p%5e2q.pdf，注意这篇文章 $q=2$ 多算了个错的。 $p\\mid(q-1)\\land q\\nmid(p^2-1)$。还是随便取一个 Sylow $p$ 子群。 它是 $\\Z_{p^2}$。$bab^{-1}=a^s$ 的 $s$ 满足 $\\delta_q(s)=p$ 或 $\\delta_q(s)=p^2$（如果 $p^2\\mid(q-1)$），分别对应一种。 它是 $\\Z_p^2$。这里用不了性质 3 了，但是也不难搞。设生成元为 $b,c$，$bab^{-1}=a^s,cac^{-1}=a^t$，满足 $\\delta_q(s),\\delta_q(t)\\mid p$ 且不同时为 $1$。我们回顾 $pq$ 情况以及其他形如“不同的阶为 $q$ 的 $s$ 对应群都同构”的证明，它们的思路就是，将生成元换成 $b^?$ 使 $b^?ab^{-?}=a^{s_0}$，就是所有 $s$ 是等价的，所以同构。那 $\\Z_p^2$ 的情况也可以类似地构造——设某个 $p$ 次单位根是 $s_0$。如果 $s,t$ 有个是 $1$ 那让另一个变成 $s_0$ 就行，否则设 $s^i\\equiv t^{-1},t^j\\equiv s_0$，这样将生成元换为 $b^\\prime =b^ic,c^\\prime =c^j$ 就可以了，显然 $b^\\prime ,c^\\prime $ 可以反过来表示 $b,c$。于是无论怎么样都可以变成 $b^\\prime a{b^\\prime }^{-1}=a,c^\\prime a{c^\\prime }^{-1}=a^{s_0}$，也就是唯一。 我们总结一下：\n情况 条件 非阿贝尔群 $n$ 例 平凡 $p\\nmid(q-1)\\land q\\nmid(p^2-1)$ 无 $45,99,153,175,207$ $12$ $n=12$ $3$ 个：$\\Z_3\\rtimes\\Z_4$、$\\Z_3\\rtimes\\Z_2^2$、$\\Z_2^2\\rtimes\\Z_3$ $12$ $p$ 小 $p\\parallel(q-1)\\land n\\ne 12$ $2$ 个：$\\Z_q\\rtimes\\Z_{p^2}$、$\\Z_q\\rtimes\\Z_p^2$ $28,44,63,76,92$ $p^2$ 小 $p^2\\mid(q-1)$ $3$ 个：同上、$\\Z_q\\rtimes_{\\varphi^\\prime }\\Z_{p^2}$ $20,52,68,116,148$ $2p^2$ $q=2$ $3$ 个：$\\Z_{p^2}\\rtimes\\Z_2$、$\\Z_p^2\\rtimes_{\\varphi,\\varphi^\\prime }\\Z_2$ $18,50,98,242,338$ $p+1$ $q\\mid(p+1)\\land q\\ne2\\land n\\ne 12$ $1$ 个：$\\Z_p^2\\rtimes\\Z_q$ $75,363,867$ 变态 $q\\mid(p-1)\\land q\\ne 2$ $(q+5)/2$ 个：$\\Z_{p^2}\\rtimes\\Z_q$、$\\Z_p^2\\rtimes_{\\varphi_i}\\Z_q$ $147,507,605$ 注意 $\\Z_n\\rtimes\\Z_2^2\\cong\\Z_{2n}\\rtimes\\Z_2\\cong D_{2n}$。其余还有某些半直积可以写成循环群与二面体群/置换群/亚循环群的直积，但我不是很清楚是否有通用的转换方法。\n$pqr\\;(p\u0026lt;q\u0026lt;r)$。首先进行以下简单推理：$n_r\\in\\set{1,pq}$ 且 $n_q\\in\\set{1,r,pr}$。若 $n_r=pq$ 且 $n_q\\ne 1$，则 $G$ 中有 $pq(r-1)$ 个阶为 $r$ 的元素，以及 $r(q-1)$ 个阶为 $q$ 的元素，共 $pqr-pq+rq-r=pqr+(r-p)(q-1)-p\u0026gt;pqr$ 个，矛盾。故 $n_r=1\\lor n_q=1$，无论哪个正规，取 $G$ 关于其的商群，商群中一定有 Sylow 另一个质数 子群，取出其对应原群中的部分，即得一 $qr$ 阶正规子群 $H$。同时，由于 $H$ 有正规 Sylow $r$ 子群，故该子群在 $G$ 中也正规。\n如果 $H\\cong\\Z_{qr}$，那就较简单：考虑 $\\varphi:\\Z_p\\to\\aut H\\cong\\Z_{q-1}\\times\\Z_{r-1}$，如果 $p\\nmid(q-1)(r-1)$ 就只有阿贝尔群，如果 $p\\mid(q-1)$ 与 $p\\mid(r-1)$ 其一成立，就有一种，否则模 $q$ 和 $r$ 下的 $p$ 次单位根都可以取，可以固定其中一个单位根，有 $p+1$ 种（$(0,1)$、$(1,i)$）。\n$q\\mid(r-1)$ 时能不能搞些别的？如果 $p\\nmid(q-1)\\land p\\nmid(r-1)$，则 $G/\\syl_r(G)$ 是个循环群，有 $p$ 阶正规子群，于是就有 $pr$ 阶循环正规子群，然后 $\\Z_q$ 对它共轭即可，有一种。注意如果按下面的方式分析，得出的群是和这里同构的。\n其他情况就要直面 $\\varphi:\\Z_p\\to\\aut(\\Z_r\\rtimes\\Z_q)$ 了。设 $\\Z_r\\rtimes\\Z_q$ 中 $bab^{-1}=a^s\\;(s^q\\equiv1\\pmod r\\land s\\not\\equiv 1)$，其中 $|a|=r$。由于 $\\lang a\\rang$ 正规，故 $\\varphi(c)(a)=a^t\\;(t^p\\equiv1\\pmod r)$。在 $p\\nmid(r-1)\\land p\\mid(q-1)$ 的时候，$\\varphi(\\forall)(a)=a$。设 $\\varphi(c)(b)=a^xb^y$，则 $$ \\varphi(c)(ba)=\\varphi(c)(a^sb)\\Rightarrow a^{x+s^y}b^y=a^{s+x}b^y\\Rightarrow s^{y-1}\\equiv1\\pmod r\\Rightarrow q\\mid(y-1)\\Rightarrow y=1\\\\ \\varphi(c^p)(b)=b\\Rightarrow a^{px}b=b\\Rightarrow x=0 $$ 于是 $\\varphi(c)=\\iota$，即 $(\\Z_r\\rtimes\\Z_q)\\times\\Z_p$ 唯一。\n$p\\mid(r-1)$ 时，若 $t\\ne 1$，则 $$ \\varphi(c)(ba)=\\varphi(c)(a^sb)\\Rightarrow a^{x+s^yt}b^y=a^{st+x}b^y\\Rightarrow y=1\\\\ \\varphi(c^p)(b)=b\\Rightarrow a^{\\frac{t^p-1}{t-1}x}b=b\\Leftrightarrow\\top $$ 所以其实跟前面没什么两样，就是 $t,x$ 都有多种取法。首先 $x=0$ 是一种特殊的。其他情况，而考虑变换生成元：$a$ 变成 $a^\\alpha$，$b$ 变成 $b^\\beta$，$c$ 变成 $c^\\gamma$，则 $$ b^\\beta a^\\alpha b^{-\\beta}=(a^\\alpha)^{s^\\beta}\\\\ \\varphi(c^\\gamma)(a^\\alpha)=(a^\\alpha)^{t^\\gamma}\\\\ \\varphi(c^\\gamma)(b^\\beta)=a^{\\frac{t^\\gamma-1}{t-1}\\frac{s^\\beta-1}{s-1}x}b^\\beta $$ 容易发现是可以都变成某组 $(a^{s_0},a^{t_0},ab)$ 的。\n总结一下：\n$[q\\mid(r-1)]$ $[p\\mid(r-1)]$ $[p\\mid(q-1)]$ 非阿贝尔群 $n$ 例 $0$ $0$ $0$ 无 $255,345,435,455,561$ $0$ $0$ $1$ $1$ 个：$\\Z_{qr}\\rtimes\\Z_p$ $231,357,483,663,715$ $0$ $1$ $0$ $1$ 个：$\\Z_{qr}\\rtimes\\Z_p$ $105,195,285,385,429$ $0$ $1$ $1$ $p+1$ 个：$\\Z_{qr}\\rtimes_{\\varphi_i}\\Z_p$ $30,66,70,102,130$ $1$ $0$ $0$ $1$ 个：$\\Z_{pr}\\rtimes\\Z_q$ $165,615,759$ $1$ $0$ $1$ $2$ 个：$\\Z_{qr}\\rtimes\\Z_p$、$(\\Z_r\\rtimes\\Z_q)\\times\\Z_p$ $609,1265,1491$ $1$ $1$ $0$ $3$ 个：$\\Z_{qr}\\rtimes\\Z_p$、$(\\Z_r\\rtimes\\Z_q)\\times\\Z_p$、$(\\Z_r\\rtimes\\Z_q)\\rtimes\\Z_p$ $465,915,2211$ $1$ $1$ $1$ $p+3$ 个：$\\Z_{qr}\\rtimes_{\\varphi_i}\\Z_p$、$(\\Z_r\\rtimes\\Z_q)\\times\\Z_p$、$(\\Z_r\\rtimes\\Z_q)\\rtimes\\Z_p$ $42,78,110,114,903$ $16$。主要有两个思路：分析 $8$ 阶正规子群、分析中心大小。这里考虑前一种。\n首先我们说明非阿贝尔的 $G$ 一定有 $\\Z_8$ 或 $\\Z_4\\times\\Z_2$ 作为子群，这里的推导很别扭：可以立即假设 $G$ 中元素的阶都 $\\le 4$ 且至少有一个是 $4$，然后考虑 $C(G)$，如果大小是 $4$，那么 $G/C(G)\\cong\\Z_2^2$（否则阿贝尔），即得；否则 $C(G)=\\set{1,c}$，若有 $|x|=4,\\lang x\\rang\\cap C(G)=\\set{e}$，那么即得，否则所有 $x^2=c\\or e$，那么 $G/C(G)\\cong\\Z_2^3$，那么一个 $x$ 的共轭就只可能在 $xC(G)$ 内（否则 $G/C(G)$ 不是阿贝尔），那么 $C_G(x)=8$，那么可以找到另一个 $y$，使 $x,y,z$ 交换且 $y^2=z\\or e$，都对应 $\\Z_4\\times\\Z_2$。\n若 $\\Z_8\\norm G$，同样类似于 $p^3$ 的情况，可以找到外面一个 $2$ 阶元 $b$，然后分析自同构，$bab^{-1}=a^{1\\or3\\or5\\or7}$，并且这四种互不同构。\n否则，考虑 $\\Z_4\\times\\Z_2$ 的自同构（也可以用矩阵描述，但这个矩阵里元素的取值范围不同，不容易分析，事实上 $\\aut(\\Z_4\\times\\Z_2)\\cong D_4$），设它的生成元为 $a,b$，$a\\mapsto a^1\\or a^3\\or a^1b\\or a^3b$，$b\\mapsto b\\or a^2b$（如果 $b\\mapsto a^2$ 那就 $f(a)^2=f(b)^2$ 不对了）。在这些自同构中，$(a,b)\\mapsto(ab,b)$ 和 $(a,b)\\mapsto(a^3b,b)$ 共轭，$(a,b)\\mapsto(a,a^2b)$ 和 $(a,b)\\mapsto(a^3,a^2b)$ 共轭，$(a,b)\\mapsto(ab,a^2b)$ 和 $(a,b)\\mapsto(a^3b,a^2b)$ 共轭。\n现在找另一个元素 $c$。最后一个共轭类是一定不行的，因为无论 $|c|=2\\or4$，$c^2$ 都在正规子群里，所以自同构的阶得 $\\le2$。若 $|c|=2$，则四种互不同构；若 $|c|=4$，分类讨论：\n$(a,b)\\mapsto(a^3,b)$ $(a,b)\\mapsto(ab,b)$ $(a,b)\\mapsto(a,a^2b)$ $c^2=a^2$ $\\lang a,b,c\\mid a^4=b^2=[a,b]=[b,c]=e,c^2=a^2,ca=a^{-1}c\\rang$ $\\lang ac,a\\mid(ac)^4=a^4=e,a(ac)=(ac)^{-1}a\\rang$ $|bc|=2$ $c^2=b$ $\\lang a,c\\mid a^4=c^4=e,ca=a^{-1}c\\rang$ $(ac)^2=a^2$ 不可能 $c^2=a^2b$ $\\lang a,c\\mid a^4=c^4=e,ca=a^{-1}c\\rang$ $|ac|=2$ 不可能 所以实际只有两类，至于如何发现第二类（$(1,2),(2,1),(3,1)$）这些情况同构的，只能说实在是注意力惊人，这个表我也是对着论文搞的。最后只需验证这两类无 $8$ 阶元，有 $3$ 个 $2$ 阶元，且不同构即可。\n总结一下，阿贝尔 $5$ 个，有 $8$ 阶元时 $3$ 个，无 $8$ 阶元时 $4+2=6$ 个，共 $14$ 个。\n参考：本方法：http://buzzard.ups.edu/courses/2015spring/projects/whitcomb-groups-16-ups-434-2015.pdf、https://www.researchgate.net/publication/259147732_The_Groups_of_Order_Sixteen_Made_Easy。另一类方法：http://buzzard.ups.edu/courses/2012spring/projects/clausen-groups-16-ups-434-2012.pdf、https://files.eric.ed.gov/fulltext/EJ1054466.pdf、https://hal.science/cel-01841041/document。\n$p^4$。思路是用矩阵分析 $p^3$ 阶正规子群的自同构，太复杂了，见 https://arxiv.org/pdf/1611.00461、https://future-in-tech.net/17.4/R-Hasanat1.pdf。\n$24$。如果 $n_3=1$，设 $\\aut\\Z_3=\\set{1,f}$。考虑任一 Sylow $2$ 子群（多个 Sylow 子群必同构）：\n$\\Z_8$。只有一种，即 $a\\mapsto f$。 $\\Z_4\\times\\Z_2$。两种，$(a,b)\\mapsto(f,1)\\or{}(1,f)$。$(a,b)\\mapsto(f,f)$ 转 $(ab,b)\\mapsto(1,f)$ 与后者同构。 $\\Z_2^3$。将两个 $\\mapsto f$ 的元素相乘作为生成元，这样来变换，可统一归为 $(a,b,c)\\mapsto(f,1,1)$。 $D_4$。两种，$(a,b)\\mapsto(f,1)\\or{}(1,f)$。$(a,b)\\mapsto(f,f)$ 转 $(a,ab)\\mapsto(f,1)$ 与前者同构。 $Q_8$。类似情况 3 只有一种。 否则 $n_3=4$，考虑 $G$ 共轭作用在它上面形成的 $\\varphi:G\\to S_4$ 同态，讨论 $\\ker\\varphi$。由于每个 Sylow $3$ 子群的正规化子均是 $6$ 个，故 $|\\ker\\varphi|\\mid6$。若 $|\\ker\\varphi|\\in\\set{3,6}$，则 $G$ 有大小为 $3$ 的正规子群 （$6$ 的情况取出唯一大小为 $3$ 的子群 $\\set{e,a^2,a^4}$，由于共轭后 $3$ 阶子群，所以正规。这里的正规传递性是个例），矛盾。若 $|\\ker\\varphi|=1$，则 $G\\cong S_4$。最后 $|\\ker\\varphi|=2$。这种情况下 $G/\\ker\\varphi\\cong A_4$，由于 $\\Z_2^2\\norm A_4$，找到原像，即 $G$ 有正规 Sylow $2$ 子群。讨论它：\n$\\Z_8$。无 $3$ 阶元。 $\\Z_4\\times\\Z_2$。在 $|G|=16$ 里讨论过它的自同构为 $D_4$，没有 $3$ 阶元。 $\\Z_2^3$。很棒的一点是，$3\\parallel168=|\\mathrm{GL}_3(\\F_2)|$，于是共轭类唯一。这种情况其实是 $A_4\\times\\Z_2$。 $D_4$。事实上 $\\aut D_4也\\cong D_4$，所以也不行。 $Q_8$。事实上 $\\aut Q_8\\cong S_4$。$3$ 阶元是所有 $3$ 循环，所以唯一。 上面所有一方正规的情况，另一方必不正规（否则两个正规之间可以交换，直接直积了）。最后总结得到，阿贝尔 $3$ 个，非阿贝尔直积 $2$ 个，Sylow $3$ 正规 $7$ 个，$S_4$ $1$ 个，Sylow $8$ 正规 $2$ 个，共 $15$ 个。\n参考：https://www.youtube.com/watch?v=6TWuo2NO8vg、http://www.brahmanandcollege.org.in/pg_math/Modern%20Algebra-01.pdf。\n$56$。如果 $n_7=1$，则分讨跟 $|G|=24$ 一样（因为 $\\aut\\Z_7$ 除了一个 $2$ 阶元以外，其余都是 $3\\or6$ 阶的，都不能碰）。否则就有 $48$ 个 $7$ 阶元，剩余 $8$ 个元素必形成一正规 Sylow $2$ 子群，这里就比楼上简单了。唯一的可能就是 $\\Z_2^3$，同样 $7\\parallel168$，所以唯一，共 $13$ 个。\n$8p\\;(p\\ne3,7)$。这种情况必有 $n_p=1$。\n$40$ 的时候 $\\aut\\Z_5\\cong\\Z_4$，讨论任一 Sylow $2$：\n$\\Z_8$。$a\\mapsto f^{1\\or 2}$ 两种。 $\\Z_4\\times\\Z_2$。$(a,b)\\mapsto(1,f^2)\\or{}(f^2,1)\\or{}(f,1)$。$(f^2,f^2)$ 同 $24$，$(f,f^2)$ 转 $(a,a^2b)\\mapsto(f,1)$。 $\\Z_2^3$。一种。 $D_4$。同 $24$。$(a,b)\\mapsto(f,?)$ 之类的情况会导致 $\\varphi(ba)\\ne\\varphi(a^{-1}b)$，故不行。 $Q_8$。同 $24$。$(a,b)\\mapsto(f,?)$（$a,b$ 即 $i,j$）之类的情况会导致 $\\varphi(a^2)\\ne\\varphi(b^2)\\or\\varphi((ab)^2)$，故不行。 总的就是 $5+2+3+1+2+1=14$ 种。$4\\parallel(p-1)$ 的情况都是 $14$ 种。\n以 $136$ 为首的 $8\\mid(p-1)$ 的情况就是多了个 $\\Z_8$ 时 $|\\varphi(a)|=8$ 的情况，共 $15$ 种。\n以 $88$ 为首的 $2\\parallel(p-1)$ 的情况是 $5+1+2+1+2+1=12$。\n总结一下：\n$p$ $2$ $3$ $7$ $v_2(p-1)=1$ $v_2(p-1)=2$ $v_2(p-1)\\ge3$ $a(8p)$ $14$ $15$ $13$ $12$ $14$ $15$ 关于 $2^kp$ 见 https://zhuanlan.zhihu.com/p/69254703。\n$36$。首先我们需要证明 $n_2=1\\lor n_3=1$。看起来简单的东西推导很变态，我找了一堆证明（https://math.stackexchange.com/questions/3290888/if-g-36-then-g-has-either-a-normal-2-sylow-or-a-normal-3-sylow、https://math.stackexchange.com/questions/2918359/a-group-of-order-36-has-either-a-normal-sylow-2-subgroup-or-a-normal-sylow、https://math.berkeley.edu/~wodzicki/257/G36.pdf、https://max.book118.com/html/2017/0806/126207403.shtm），没一个少于一页的。\n如果 $G$ 有 $4$ 个 Sylow $3$ 子群 $X_{1\\sim 4}$，那么考虑 $G$ 共轭作用在它们上，形成一个 $\\varphi:G\\to S_4$ 的同态。$|\\im \\varphi|\\mid\\gcd(36,24)=12$，同时由于 $\\forall i,\\exists g,gX_1g^{-1}=X_i$，故 $\\im\\varphi$ 中每个 $\\sigma(1)=1$ 的元素都与 $\\sigma(1)=2,3,4$ 元素各一个对应，故 $4\\mid|\\im\\varphi|$，故 $|\\im\\varphi|\\in\\set{4,12}$。若为 $4$，则 $|\\ker\\varphi|=9$ 矛盾；否则 $G/\\ker\\varphi\\cong\\im\\varphi=A_4$，且 $\\ker\\varphi$ 是一个 $3$ 阶正规子群。① 这说明它是所有 Sylow $3$ 子群的子群，而 $9$ 阶群一定是阿贝尔群，故与 $\\ker\\varphi$ 的元素的中心化子至少为 $27$，于是 $\\ker\\varphi\\sub C(G)$。② 如果 $n_2\u0026gt;1$，比如有 $Y_1,Y_2$，它们显然与 $\\ker\\varphi$ 交为 $\\set{e}$，故它们对应到 $G/\\ker\\varphi$ 上也是 Sylow $2$ 子群，而 $A_4$ 的 Sylow $2$ 子群是唯一的 $\\Z_2^2$，故 $Y_1\\ker\\varphi=Y_2\\ker\\varphi$。由 ①，它们都 $\\cong\\Z_3\\times\\Z_2^2$ 阿贝尔群，于是 $Y_1=Y_2$，因此 $n_2=1$。\n正规 Sylow $3$ 子群 $\\Z_9$，Sylow $2$ 子群 $\\Z_4$。由于 $\\varphi(9)=6$（这个 $\\varphi$ 是欧拉函数），故只有一种。 正规 Sylow $3$ 子群 $\\Z_9$，Sylow $2$ 子群 $\\Z_2^2$。同 6.4.2，一种。 正规 Sylow $3$ 子群 $\\Z_3^2$，Sylow $2$ 子群 $\\Z_4$。$\\mathrm{GL}_2(\\F_3)$ 在相似意义下有两个二阶元 $\\begin{bmatrix}-1\u0026amp;0\\\\ 0\u0026amp;\\pm1\\end{bmatrix}$，一个四阶元 $\\begin{bmatrix}0\u0026amp;1\\\\ -1\u0026amp;0\\end{bmatrix}$，因此有三种。 正规 Sylow $3$ 子群 $\\Z_3^2$，Sylow $2$ 子群 $\\Z_2^2$。记 $\\Z_2^2$ 的两个生成元为 $a,b$，如果 $\\varphi(a)\\ne\\varphi(b)$，则 $\\im\\varphi\\cong\\Z_2^2$，一种。否则可以认为 $\\varphi(b)=1$（不是的话可以把 $b$ 换成 $ab$），$\\varphi(a)$ 两种。共三种。 正规 Sylow $2$ 子群 $\\Z_4$，Sylow $3$ 子群 $\\Z_9$。不行。 正规 Sylow $2$ 子群 $\\Z_4$，Sylow $3$ 子群 $\\Z_3^2$。不行。 正规 Sylow $2$ 子群 $\\Z_2^2$，Sylow $3$ 子群 $\\Z_9$。事实上 $\\aut\\Z_2\\cong\\mathrm{GL}_2(\\F_2)\\cong S_3$，有唯一 Sylow $3$ 子群，一种。 正规 Sylow $2$ 子群 $\\Z_2^2$，Sylow $3$ 子群 $\\Z_3^2$。类似情况 2 也可以归为 $(1,f)$。一种。 总共 $2^2+1+1+3+3+0+0+1+1=14$ 种（第一个加数对应阿贝尔，后同）。\n这里关于 $\\aut\\Z_3^2$ 的同构的共轭类是参照 https://groupprops.subwiki.org/wiki/General_linear_group:GL(2,3)，我不大会证这些，可能以后深入学线代会再补充。\n$4p^2\\;(p\\ne3)$。这时必有 $n_p=1$，但同样由于我不会分析 $\\aut\\Z_p^2$ 而且网上没有按这种思路分析的资料所以这里就留坑了。这里先给出结论：$p=4k+1$ 时有 $16$ 个，$p=4k+3$ 时有 $12$ 个。见 https://xueshu.baidu.com/usercenter/paper/show?paperid=1m4n0tf0y90w0vh0py530vs0ax491706。注意 B 站有个讲 $10$、$100$、$1000$ 阶群分类的视频，讲得不完整，最难的部分整个略掉了。\n$2p^3$。也是直接得到正规，但是 $p^3$ 阶群的自同构难以分析。https://www.zhihu.com/question/637163090/answer/3346156282 这里是一个不完整的分析，问题和那个 B 站的视频类似，都是共轭设得不全。\n$60$。我们首先希望 $n_5=1$。如果不是，那么 $n_5=6$，接下来证明 $G$ 是单群。如果 $G$ 有正规子群 $N$，如果 $5\\mid|N|$，那么$|N|=10\\or15\\or20\\or30$。前三种情况显然有正规 Sylow $5$ 子群，$30$ 的情况根据 $|G|=pqr$ 的分析也有正规 Sylow $5$，于是它也是 $G$ 的正规 Sylow $5$。否则 $|G/N|=5\\or10\\or15\\or20\\or30$，后四种情况可以乘回 $N$ 得到 $5\\mid|N^\\prime |$，第一种情况 $|N|=12$，它有正规 Sylow $2\\or 3$，于是 $G$ 也有，归到前面。\n而 $60$ 阶单群只可能是 $A_5$。我们先证明它有 $12$ 阶子群。$n_2=3\\or5\\or15$，若为 $3$，则每个的正规化子有 $20$ 个，说明 $G$ 有 $20$ 阶子群，则 $G$ 作用在该子群的陪集上时，形成一个 $\\varphi:G\\to S_3$，进而 $\\ker\\varphi$ 是 $G$ 的正规子群；若为 $15$，那么如果这些子群两两只有平凡交，则 $2,4$ 阶元有 $15\\times3=45$ 个，而 $5$ 阶元有 $6\\times4=24$ 个，矛盾。因此存在两个 Sylow $2$ 子群 $X_1,X_2$，$X_1\\cap X_2=\\set{e,x}$。由于 $4$ 阶群必阿贝尔，故 $X_1,X_2\\sub C_G(x)$，故 $C_G(x)=12\\or20\\or60$，后两种都不可能。现在 $G$ 有 $12$ 阶子群了，考虑作用在它的陪集上，形成 $\\psi:G\\to S_5$，且单性故 $\\ker\\psi$ 平凡，故 $G\\cong\\im\\psi\\cong A_5$，$n_2=5$ 的情况直接跳到这里。\n现在 $G$ 有正规 Sylow $5$ 子群 $H$，讨论 $n_3$。$G$ 的 Sylow $3$ 子群与 $G/H$ 的 Sylow $3$ 子群一一对应（正过来直接取，反过来是因为可以对应 $15$ 阶子群 $\\cong\\Z_{15}$ 从而有唯一 Sylow $3$ 子群），因此 $n_3\\ne10$。如果 $n_3=4$，那么它们各自乘 $H$ 形成四个同构于 $\\Z_{15}$ 的，两两交于 $H$ 的群，这意味着 $|N_G(H)|\\ge 45$ 从而 $H\\sub C(G)$，这大大简化了讨论——$G/H$ 的 Sylow $3$ 子群不正规，这意味着它 $\\cong A_4$，类似于这段开头，$G/H$ 的唯一 Sylow $2$ 子群与 $G$ 的唯一 Sylow $2$ 子群对应（注意这里的对应依赖于 $H\\sub C(G)$ 因为不然 $20$ 阶群的讨论就爆炸了），于是将这个正规 Sylow $2$ 子群与 Sylow $3$ 子群相乘，立即得到同构于 $A_4$ 的 $12$ 阶子群，从而 $G\\cong\\Z_5\\times A_4$。PS：这里搞得这么麻烦的原因是，如果直接搞出正规子群 $\\Z_5\\times\\Z_2^2$，自同构就很难讨论了。\n如果 $n_3=1$，那么只需考虑 $\\Z_4\\to\\aut\\Z_{15}$ 与 $\\Z_2^2\\to\\aut\\Z_{15}$，显然分别有五、四个。\n总共 $2+1+1+5+4=13$ 种。\n参考：https://www.math.utoronto.ca/alfonso/347/Groups60.pdf、https://math.stackexchange.com/questions/3068904/group-of-order-60、https://math.stackexchange.com/questions/1121248/classifying-groups-of-order-60、https://math.stackexchange.com/questions/360816/about-the-proof-that-a-simple-group-of-order-60-is-isomorphic-to-a5、https://epgp.inflibnet.ac.in/epgpdata/uploads/epgp_content/S000025MS/P001533/M016962/ET/1468557941E-textofChapter3Module4.pdf。\n$90$。核心是说明 $G$ 有 $45$ 阶子群。若 $n_5=1$，则 $18$ 阶商群的 $n_3=1$，即得。否则，如果 $n_3\u0026gt;1$，那么我们说这些子群 $X_{1\\sim 10}$ 不可能两两只有平凡交，因为反之则 $3$ 与 $9$ 阶元有 $80$ 个，但 $5$ 阶元有 $24$ 个。现在找到 $X_i\\cap X_j=H\\ne\\set{e}$，考虑其正规化子数量： $|N_G(H)|\\ge|X_1X_2|\\ge27$。同时 $X_i\u0026lt;N_G(H)$ 故 $|N_G(H)|=45\\or90$。后者即 $H\\norm G$，由于 $G/H$ 这个 $30$ 阶群有 $15$ 阶子群，所以也得到 $45$ 阶。而 $45$ 阶群一定是阿贝尔群。\n那现在只需考虑 $\\Z_2\\to\\aut\\Z_{45}$ 与 $\\Z_2\\to\\aut(\\Z_3\\times\\Z_{15})$。前者有三种。后者，由于正规子群在自同构下不动，故 $\\aut(\\Z_3\\times\\Z_{15})\\cong\\aut\\Z_3^2\\times\\aut\\Z_5$，$\\mathrm{GL_2}(\\F_3)$ 的二阶共轭类有两种，故这个是 $3\\times2-1=5$ 种。共 $2+3+5=10$ 种。\n参考：https://math.stackexchange.com/questions/360790/classifying-groups-of-order-90、https://math.stackexchange.com/questions/146687/how-do-i-show-that-every-group-of-order-90-is-not-simple。\n$132$。首先我们说明 $n_{11}=1$。若 $n_{11}=12$，若 $n_3=1$，则可得到商群的正规 Sylow $11$，然后得到 $G$ 的 $33$ 阶正规子群，由于 $33$ 阶群只能是 $\\Z_{33}$，故 $11$ 阶正规；若 $n_3\u0026gt;1$，它不可能是 $22$，只可能是 $4$。于是有 $G$ 到 $S_4$ 的同态，其像大小整除 $12$ 且是 $4$ 的倍数（同 $|G|=36$ 第二段的分析），因此只可能是 $4\\or 12$，对应核都说明 $11$ 阶正规。\n现在 $n_{11}=1$，这里的分析跟 $|G|=60$ 完全一样：由 $n_3\u0026gt;1$ 可得 $\\Z_{11}\\times A_4$，由 $n_3=1$ 可得正规子群 $\\Z_{33}$，$\\Z_4$ 和 $\\Z_2^2$ 分别对应 $3$ 和 $4$ 个。共 $2+1+3+4=10$ 种。\n$135$。立即得 $45$ 阶正规子群，考虑 $\\Z_3$ 到 $\\aut\\Z_{45}$ 和 $\\aut(\\Z_3\\times\\Z_{15})$。根据 $|G|=36$ 最后的链接，$\\mathrm{GL}_2(\\F_3)$ 有唯一三阶共轭类，故总共 $3+1+1=5$ 种。\n$140$。立即得 $35$ 阶正规，考虑 $\\Z_4$ 和 $\\Z_2^2$ 到 $\\aut\\Z_{35}$，和 $|G|=60$ 一样。共 $2+5+4=11$ 种。\n$198$。立即得 $99$ 阶正规，考虑 $\\Z_2$ 到 $\\aut\\Z_{99}$ 和 $\\aut(\\Z_3\\times\\Z_{33})$。后者是 $3\\times2-1=5$ 种，共 $2+3+5=10$ 种。\n如果说下一步要继续分析的话，$4pq$、$p^2q^2$、$p^2qr$ 可能是相对可做的，但目前感觉都很难了。以下是 $200$ 以内我不会分析的情况：\n$n$ $a(n)$ 情况 $32$ $51$ 变态 $48$ $52$ 变态 $54$ $15$ $2p^3$ $64$ $267$ 变态 $72$ $50$ 变态 $80$ $52$ 变态，$n_2=1\\or n_5=1$ 然后不会 $81$ $15$ $p^4$ $96$ $231$ 变态 $100$ $100$ $4p^2$ $108$ $45$ 变态 $112$ $43$ 变态 $120$ $47$ 变态，https://www.youtube.com/watch?v=t5YcYuDl0hk $126$ $16$ $n_7=1$ 但 $63$ 阶群自同构不好分析 $128$ $2328$ 变态 $144$ $197$ 变态 $150$ $13$ $n_5=1$ 但 $75$ 阶群自同构不好分析 $156$ $18$ $n_{13}=1$ 但 $39$ 阶群不好分析 $160$ $238$ 变态 $162$ $55$ 变态 $168$ $57$ 变态，不过可以了解一下单群 $176$ $42$ 变态 $180$ $37$ 变态 $189$ $13$ $n_7=1$ 但 $63$ 阶群自同构不好分析 $192$ $1543$ 变态 $196$ $12$ $4p^2$ $200$ $52$ 变态 综合的参考资料：\n《有限群构造》（张远达） 《有限群构造新论》（陈松良） https://www.math.auckland.ac.nz/~obrien/research/gnu.pdf https://link.springer.com/article/10.1007/BF01443651 https://groupprops.subwiki.org/ 13. 可解群 大纲 幂零群的定义与性质：直积幂零、正规化子严格包含、幂零群的等价刻画。 换位子群、导子群、特征子群、全不变子群、极小正规子群的定义，特征子群的正规传递性。 可解群的定义与性质：与幂零群的关系、子群与同态像可解、正规子群+商群可解、极小正规子群的结构、Hall 定理。 笔记 幂零群的等价定义是，存在一个从 $\\set{e}$ 到 $G$ 的列 $\\set{G_i}$，只要求 $G_{i+1}/G_i\\sub C(G/G_i)$ 即可。证明考虑归纳证 $G_i\\sub C_i(G)$，这里的核心思想是，$G$ 的两个正规子群 $K\\sub H$ 必满足 $\\pi_K^{-1}(C(G/K))\\sub\\pi_H^{-1}(C(G/H))$。看起来简单的东西设得不好也会证不出来。一个好搞的形式是 $[x,y]\\in K\\Rightarrow[x,y]\\in H$。\n幂零群的子群和同态像也是幂零群。详见 https://math.stackexchange.com/questions/1571815/need-help-proving-any-subgroup-and-quotient-of-a-nilpotent-group-is-nilpotent。这类问题证明思路都是类似的，就是选好归纳假设，然后分析同态，利用同构第二、四定理即可。反倒是可解群证明这类东西容易些，因为导列就是不断选子群。\n可解群的等价定义是，存在一个从 $\\set{e}$ 到 $G$ 的列 $\\set{G_i}$，只要求 $G_i\\norm G_{i+1}$ 且 $G_{i+1}/G_i$ 阿贝尔即可（注意换位子群是最小（其他都包含它）的这样的 $G_i$，这也是求一个群的导列的方法）。证明考虑归纳证 $G^{(i)}\\sub G_{n-i}$，知道了换位子群最小这不就是显然的吗……\n注意极小正规子群不一定唯一：https://math.stackexchange.com/questions/1402526/smallest-normal-subgroup-and-minimal-normal-subgroup-whats-the-difference。\n幂零群结构定理证明的思路并不难，核心是找到一个矛盾：Sylow $p$ 子群的正规化子等于其正规化子的正规化子，以及幂零群中，正规化子是严格包含的。然后就是直积相关的简单东西。\nHall 定理实在无法理解是怎么想到的，所以只能把思路记下来，这下真得死记硬背了。\n存在一个正规子群 $H$，阶不被 $n$ 整除。设阶与 $m,n$ 分别有公因子 $m_1,n_1$。(i) $G/H$ 里找 $m/m_1$ 阶，乘回 $H$ 变 $mn_1$，再找 $m$。(ii) 俩 $m$ 阶的 $B,C$，$|BH|=|CH|=mn_1$，$BH/H$ 与 $CH/H$ 在 $G/H$ 中共轭，于是 $BH$ 与 $CH$ 共轭，于是 $B$ 的共轭与 $C$ 在 $CH$ 中共轭。(iii) $k$ 阶 $D$，$G/H$ 里找包含 $DH/H$ 的，乘回 $H$ 变 $mn_1$ 阶，再找 $m$。\n所有正规子群的阶都被 $n$ 整除。首先证明引理：可解群的极小正规子群为阿贝尔 $p$。$N^\\prime $ 是 $N$ 的正规子群且只能是平凡的（不能是 $N$ 不然就不可解了，事实上这是整个证明中唯一用到可解性的地方），于是 $N$ 阿贝尔，且不能再有真 Sylow 子群。这里值得注意的是，极小正规子群的定义是不存在原群的正规子群是其子群，而并非其本身是单群，因此上述证明中利用与极小矛盾时，至少得说明是特征子群。\n现找出 $G$ 的极小正规子群 $H$，由于 $H$ 是阿贝尔 $p$，故只能 $|H|=n$ 从而 $H$ 是 Sylow。(i) 看图：\n（黄色对应 $B$，蓝色对应 $D$，绿色对应 $DH\\cap M$，蓝灰色对应 $D$ 所属的 $m$ 阶）\n取出 $G/H$ 的极小正规子群 $K/H$，$S$ 为 $K$ 的 Sylow $q$，$S\\cap H=\\set{e}$。记 $N=N_K(S),M=N_G(S)$，$N$ 之于 $K$ 相当于 $M$ 之于 $G$（因为 $S$ 的共轭都在 $K$ 里面），所以只需证明 $N=S$ 即得 $|M|=m$。$N\\cap H$ 中元素与 $S,H$ 中元素均交换从而为 $K$ 的中心，而 $K$ 的中心作为 $G$ 的正规子群只能是 $\\set{e}$。(ii) $m$ 阶子群 $B$ 交 $H$ 于 $\\set{e}$，交 $K$ 于 Sylow $q$，故 $B\\cap K$ 与 $S$ 共轭，正规化子也共轭，$N_G(B)=B$。 (iii) $k$ 阶子群 $D$ 的 $DH$ 交 $M$ 于一 $k$ 阶子群与 $D$ 共轭，扩到 $m$ 阶。\n14. 正规列 大纲 正规列、次正规列、精细、合成列、可解列的定义及它们之间的关系。 Zassenhaus 引理、Schreier 精细定理、Hölder 定理。 笔记 理一下各种列之间的关系：首先讨论的所有列都是次正规列。次正规列有两种特殊情况：合成列和可解列。合成列是“划分最密”的。对于可解群，其导列是“划分最疏”的可解列，其可解列是所有“划分介于导列与合成列之间”的，其合成列具有因子为 $\\Z_p$ 的性质，从而也是可解列（能不用 Hölder 证吗？）。除了可解群的导列和幂零群的中心列以外，所有提到的列都不一定是正规列。例如，$S_4\\vartriangleright A_4\\vartriangleright K_4\\vartriangleright\\textcolor{red}{\\Z_2}\\vartriangleright\\set{e}$。\nZassenhaus 引理也是完全看不懂作者是怎么想的，只能提要一下证明策略：先证明诸如 $(A\\cap B^*)\\norm(A\\cap B)$ 之类的，再构造满同态证明 $$ \\frac{A^*(A\\cap B)}{A^*(A\\cap B^*)}\\cong\\frac{A\\cap B}{(A\\cap B^*)(A^*\\cap B)}\\cong\\frac{B^*(A\\cap B)}{B^*(A^*\\cap B)} $$ 后面两个定理反倒是很好理解的了。就是互相精细，然后合成列没法再精细了。\n注意无限群不一定有合成列，例如 $\\Z$ 没有，而 $A_\\infin$ 就有。\n漏掉的东西 群的扩张 群的可视化（格、环图等） 范畴论 与无限群相关的理论 $168$ 阶单群、有限单群分类、Lie 群 可解性相关进一步的内容，例如 Burnside 定理、Feit-Thompson 定理 ","date":"2024-07-25T00:00:00Z","image":"https://littlereuben.github.io/study/gtm73-group-theory/GTM73.png","permalink":"https://littlereuben.github.io/study/gtm73-group-theory/","title":"抽代（群论部分）自学笔记"},{"content":"这是一篇摘抄笔记。\r这里主要讲一下 Nash-Williams 定理的证明。\n一张图 $G$ 的边集能划分成 $k$ 个森林 $\\Leftrightarrow$ 其每个非空导出子图的 $\\lvert E\\rvert\\le k(\\lvert V\\rvert-1)$。允许重边。\n$\\Rightarrow$ 显然，$\\Leftarrow$ 的证明：\n以下称一个非空导出子图“合法”为 $\\lvert E\\rvert\\le k(\\lvert V\\rvert-1)$，“满”为 $\\lvert E\\rvert=k(\\lvert V\\rvert-1)$。记 $G[S]$ 为 $G$ 中节点子集 $S$ 的导出子图。\n证 1（$k=2$，P5295/UOJ#168 题解里的证法）：归纳。现考虑度数最小的点 $u$，由鸽巢，其度数至多为 $3$。其余情况平凡，度数为 $3$ 时，设相连点为 $v_{1\\sim 3}$，这时删去 $u$，待证的即为在这三个点间加某条边，可以划分，这样加回 $u$ 时只需在这条额外边中间放上 $u$ 即可。\n如果不行，也就是说分别存在包含 $v_1$ 与 $v_2$、包含 $v_1$ 与 $v_3$、包含 $v_2$ 与 $v_3$ 的三个满的导出子图（它们不能额外加边）由于 $G_1+G_2=G_1\\cup G_2+G_1\\cap G_2$，故两个有公共点的满子图，它们的交、并均为满。故存在一个包含 $v_1$、$v_2$ 与 $v_3$ 的满子图，那么包括进 $u$ 时，这个子图就不合法了，矛盾。\n这个思路在 $k\\ge 2$ 时需要稍加修改才能沿用。\n证 2（论文）：考虑度数最小的点 $u$，由鸽巢，其度数 $d\\le 2k-1$，且 $d\\le k$ 时平凡。设 $u$ 邻边的另一个端点从小到大依次为 $v_{1\\sim d}$（可重），现在考虑以下过程：对 $i=1\\sim d-k$，时刻 $i$ 时将 $e_i=(u,v_i)$ 去掉，加入 $e^\\prime_i=(v_i,v_{i+k})$（显然 $v_i\\ne v_{i+k}$）。记 $G^\\prime$ 为改完的图。\n如果直到操作完都没有不合法，那就令 $S=V\\setminus\\set u$，$t=d-k$。否则假设时刻 $t+1$ 是第一个出现不合法的时刻，那么时刻 $t$ 可以找到一个不含 $u$ 的满子图 $G^\\prime[S]$，不妨设 $t$ 及之前所有连上新边的点都在 $S$ 内。在时刻 $t$ 后中止上述过程。\n先归纳构造 $G^\\prime[S]$ 的拆分方案，然后将 $S$ 缩成一个点，这时得到的图 $G^{\\prime\\prime}$ 的导出子图也均合法，第一种情况显然，第二种情况，如果找到了一个不合法的子图，那和 $G^\\prime[S]$ 并在一起也不合法，矛盾。因此也构造出 $G^{\\prime\\prime}$ 的方案。对于 $G^\\prime[S]$ 方案中的一个森林，如果有某个 $e^\\prime_i$ 属于它，那么将它与 $G^{\\prime\\prime}[S]$ 中包含 $e_{i+k}$ 的那个并起来（有多个 $i$ 则任选），称这样得到的为第一类；对于其他森林，随意配对并起来，为第二类。显然目前并出的各图均为森林。\n现在类似于前面的思路，要把 $e^\\prime_i$ 还原回中间接了个 $u$ 的原图方案，即在各个第一类森林中删 $e^\\prime_i$ 加回 $e_i$。这样可能导致环，即 $u$ 原来就与 $v_i$ 通过 $e_i^\\prime$ 以外的边连通，且删了 $e^\\prime_i$ 后 $v_{i+k}$ 与 $u$ 不连通了（不然原来会有环）。找到包含 $e_{i+k}$ 的森林，它一定是第二类，这是因为归纳构造时 $S$ 被缩起来了，故 $e_{i+k}$ 不会与其他 $e_{j+k}$（$j\\le t$）处于同一个森林中。把这两个森林里的 $e_{i}$ 与 $e_{i+k}$ 互换即可。这不会在这个第二类森林中引入环，也是因为构造时 $S$ 被缩起来，即 $u$ 与 $S$ 内 $v$ 间的边对连通性的影响是无区分的，而第二类森林两端在 $S$ 内的边又不会变动（如果不区分一二类森林，直接随便配对并，就可能在还原时无法避免环）。\n然后还有一个对边归纳的思路。\n证 3（论文）：任取一条边 $(u,v)$，归纳构造不含它的方案，这时如果在某个森林中 $u$、$v$ 不连通，则直接补进去即可；否则考虑某个森林 $G_1$ 中它们所在的连通块，设点集为 $S$。在其余森林中分别取出 $S$ 的导出子图，至少有一个导出子图不连通（否则加回 $(u,v)$ 时就不合法了），找出它对应的原森林 $G_2$。\n如果考虑进 $G_2$ 的所有边时，$S$ 中的点仍不连通，那么可从 $G_1[S]$ 中取出一条边改放到 $G_2$ 中使 $G_2$ 仍为森林（与图拟阵的证明相同）；否则，若将 $G_2[S]$ 中各连通块缩成点，那么这些点在 $G_2$ 中的位置关系形成类似树的结构，至少有两个叶子。这说的意思是，$G_2[S]$ 中存在至少两个连通块，如果断开其与 $S$ 之外的某条边，它就与其他 $G_2[S]$ 的连通块都不连通了。选出非 $u$ 所在的这样一个连通块，设其点集为 $S^\\prime$，它与其他连通块连接的唯一“向外通道”为边 $e_1$，$e_1$ 在 $S$ 中侧端点为 $w$，考虑 $G_1$ 中 $u\\rightsquigarrow w$ 路径上第一条一端在 $S^\\prime$ 内的边 $e_2$。将 $e_1$ 换到 $G_1$，$e_2$ 换到 $G_2$，这样两图仍为森林，且 $G_1$ 中 $u$ 所在连通块变小。如此进行下去，直到 $G_1$ 中 $u$、$v$ 不连通即可。\n下图为最后一种情况，红色边为 $G_1$，蓝色与深蓝色边为 $G_2$，深蓝色边省略了在 $S$ 以外的中转点。实质上最后一种情况就是费尽心思想强制让 $G_1[S]$ 丢掉一些点，同时在丢掉点时 $u$ 所在部分不能和别的连通块连起来。\n要判断一个图是否满足上述条件，问题就变为最大权闭合子图问题：选边为 $+1$，选点为 $-k$，要求结果 $\\le -k$。为了避免空图，可以强制选一条边（增流）或一个点（退流）。\n对于 CF1951I，有另一个性质是，所有满足条件的连边情况构成一个拟阵，交换性的证明是，对于两张图的森林划分，考虑边数多的图边数最多的森林与边数少的图的边数最少的森林，套用图拟阵的证明方式即可。边不能一条条地加，考虑二分下一次加边失败的边权，失败后这条边就可以忽略了。时间复杂度 $\\mathrm{O}(m^5\\log mW)$。（这题用退流似乎没什么优势？）\n","date":"2024-05-29T00:00:00Z","permalink":"https://littlereuben.github.io/study/paper3/","title":"读论文系列 #3——Nash-Williams 定理"},{"content":"这是一篇学习笔记。\r好题。考察了找阶段，和对 dp 原理的理解。\n下文提及手牌，指的是打牌后、拿牌前的状态。\n首先，原问题可以转化成：要求在某些 $a_i=a_j$ 之间连线（显然不会跨相同的数连），使得跨过每个 $a_{2t}$ 与 $a_{2t+1}$ 之间间隙的线的数量 $\\le k-2$。这个转化是很直接的，因为连线左端的卡必须保留在手中。有可能产生疑问的一点是：如果一对 $a_{2t-1}$ 和 $a_{2t}$ 均为连线右端，那有一对卡就要顺延到后一轮才能打出，那就在待配对卡的基础上多了一对需要保留的牌啊？但由于这种情况跨 $a_{2t}$ 与 $a_{2t+1}$ 间隙的线的数量必然比跨 $a_{2t-1}$ 与 $a_{2t-1}$ 间隙的少 $2$，故这个间隙不必考虑。实际上就是能打出相同牌的轮，手牌数不变多。因此接下来认为如果拿到两张牌目前均可配对就一次性配掉，即手牌可以 $\u0026lt;k-2$。\n处理转化后的问题。首先，如果没有 $\\le k-2$ 的限制，就是从左往右扫，发现配对了就连线（下称“贪心”）。由于手牌数不可能为奇（后续不可能配对的牌也要保留在手里），故只有为 $k$ 时会不合法，这时直觉上来说要决策放弃两张牌。但是光这么考虑，总感觉不完备，凭什么只用这种决策方式就一定能覆盖最优解？\n从另一个角度看，解的结构可以表述为：强制禁止某几对相同的数连线，然后剩余的贪心，要求最终合法。那么，如果某条线连了不会导致不合法，那禁掉它一定不优（如果不禁导致后面贪心得到的连线改变而不合法，可以在后面禁），因此可以在第一次发现不合法时禁。于是，上文 dp 的过程，就可以理解为决策禁哪些，然后分段贪心。\n令 $f_i$ 表示 $a_{2i}$ 与 $a_{2i+1}$ 处出现了不合法，前面的最优答案。没法直接枚举放弃的两张牌，先考虑直接往后贪心。注意到如果后面某一时刻手牌数为 $k-2$，那么如果放弃的是缺的两张牌，那么这个时刻就会不合法。如果这两张牌的组合在之前没出现过，则要转移。直接转移到末尾的情况需要讨论一下。\n一个实现问题是，如何快速求出缺的两张牌。可以记录缺的牌的和与平方和，也可以惰性删除，将所有新扫到的牌放在一个栈里，求时全拿出来判断。\n时间复杂度 $\\mathrm{O}(n^2)$，代码。\n","date":"2024-05-21T00:00:00Z","permalink":"https://littlereuben.github.io/study/solution-cf1969f/","title":"[题解] CF1969F Card Pairing"},{"content":"这是一篇摘抄笔记。\r考虑求 $(f\\circ g)^{(n)}$。\n我们看几个例子： $$ \\begin{align*} (f\\circ g)^\\prime\u0026amp;=f^\\prime\\circ g\\cdot g^\\prime\\\\ (f\\circ g)^{\\prime\\prime}\u0026amp;=f^{\\prime\\prime}\\circ g\\cdot {g^\\prime}^2+f\u0026rsquo;\\circ g\\cdot g^{\\prime\\prime}\\\\ (f\\circ g)^{\\prime\\prime\\prime}\u0026amp;=f^{\\prime\\prime\\prime}\\circ g\\cdot {g^\\prime}^3+3f^{\\prime\\prime}\\circ g\\cdot g^\\prime\\cdot g^{\\prime\\prime}+f^\\prime\\circ g\\cdot g^{\\prime\\prime\\prime} \\end{align*} $$ 注意到结果可以写成若干 $f^{(i)}\\circ g\\cdot h$ 的形式，其中 $h$ 是一些 $g^{(j)}$ 的积。\n考虑到 $(f^{(i)}\\circ g\\cdot h)^\\prime=f^{(i+1)}\\circ g\\cdot g^\\prime\\cdot h+f^{(i)}\\circ g\\cdot h^\\prime$，也就是说，有两种选择：\n将 $f$ 升一阶导并乘一个 $g^\\prime$； 导一下 $h$。 由于初始形式是 $f\\circ g\\cdot\\mathbf{1}$，故根据决策会得到形如这样的 $h$：一个长为 $n$ 的操作序列，每次要么乘上一个 $g\u0026rsquo;$，要么导一下。而根据乘法法则，每次求导就相当于选一个先前的 $g$ 升一阶导。\n于是 $h$ 的模型就变成这样：一个可重数集，每次要么往里面加一个 $1$，要么选一个 $+1$。然后最终的集合大小就是 $f$ 导的阶数。\n发现直接对操作序列计数不好算。现考虑对于一个最终的集合（也就是结果中的一项），求出其系数。对于一个集合，它的数首先可以任意排列，代表加入它的顺序，然后一个数 $x$ 的后面要有 $x-1$ 个选中它的求导。\n如果把加入顺序的排列和求导选择的排列分开来计数，不容易搞。如果放在一起，就可以理解成，对于一个数 $x$，有 $x$ 个同种颜色无法区分的球（最终放在最开头的就算加入，其余算求导）。然后所有相同的 $x$ 对应的颜色无标号。那么这时如果数 $x$ 有 $m_x$ 个（集合中数的和一定是 $n$），总的系数就是： $$ \\frac{n!}{\\displaystyle\\prod_{x=1}^nm_x!x!^{m_x}} $$ 于是我们就可以写出最终的表达式： $$ (f\\circ g)^{(n)}=\\sum_{\\sum i\\cdot m_i=n}\\frac{n!}{\\prod m_i!i!^{m_i}}f^{(\\sum m_i)}\\circ g\\cdot\\prod {g^{(i)}}^{m_i} $$ 其中 $\\sum$ 和 $\\prod$ 略去了 ${}_{i=1}^n$。\n这就是 Faà di Bruno\u0026rsquo;s formula。它可以直接解决倒数、除法的高阶导（反函数和参数方程可能需要递推）。\n这个公式可以导出几个比较平凡的结论，在解题时可以用： $$ (f(x+k))^{(n)}=f^{(n)}(x+k)\\\\ (f(kx))^{(n)}=k^nf^{(n)}(kx)\\\\ \\left.\\left(f(x^k)\\right)^{(n)}\\right|_{x=0}=\\begin{cases}0,\u0026amp;k\\nmid n\\\\ \\dfrac{n!}{(n/k)!}f^{(n/k)}(0),\u0026amp;k\\mid n\\end{cases} $$ 最后一个可以直接展开级数证（很诡异），用于展开 $\\arcsin x$ 之类的。\n","date":"2024-03-27T00:00:00Z","permalink":"https://littlereuben.github.io/study/faa-di-bruno/","title":"复合函数高阶导的公式"},{"content":"这是一篇学习笔记。\r$\\gdef\\o{\\mathrm{o}}\\gdef\\d{\\mathrm{d}}\\gdef\\D{\\Delta}$\n微分的定义 对于一个在 $x_0$ 邻域内有定义的函数 $f$，如果： $$ f(x_0+\\D x)-f(x_0)=a\\D x+\\o(\\D x)\\quad(\\D x\\to 0) $$ 则称 $\\d f(x_0)=a\\D x=a\\d x$。\n同理对于任意的 $x$，可以记 $\\d y=\\d f(x)=a(x)\\D x=a(x)\\d x$。根据导数与微分的关系，$a(x)=f^\\prime(x)$。\n问题的开端 微分的最大好处在于它将求导这一求极限的动态过程转为了静态的，那么 $\\d y/\\d x$ 就可以视作除法了。那在证明复合函数和反函数的微分时，我们就会想：为什么不能直接进行分数操作呢？为什么高阶微分不具有形式不变性呢？\n对于式： $$ \\frac{\\d y}{\\d x}=\\frac{\\d y}{\\d u}\\frac{\\d u}{\\d x} $$ 如果要利用分数操作，大前提就是将 $\\d y$ 和 $\\d u$ 都写成关于 $\\d x$ 的形式。而在实际求时，我们时直接求出 $y$ 关于 $u$ 的函数的导数，这两者是不同的。如果直接这样证明，会导致循环论证。\n那问题就来了——这里的 $\\d y/\\d u$ 就必须作为一个整体，那就违背微分拆成除法的思想了啊？\n扩展定义 问题的核心出现在数学符号的模糊性上。注意到，在书中，微分是基于函数 $f$ 定义的，而函数只有唯一的自变量和因变量，因此 $\\d f(x)$ 只能写成关于 $\\d x$ 的表达式。但是当 $\\d y=\\d f(x)$ 后，我们就可以不知不觉地将 $y=f(x)=g(t)=\\cdots$ 写出多种表达式了。这时 $\\d y$ 就出现了歧义，因为按定义算它时，到底应该以那个函数关系为准呢？我们还没有说明微分各个函数是等价的，或者说，$y=f(x)=g(t)$ 并不能推出 $\\d f(x)=\\d g(t)$。\n为了处理这个问题，我进一步明确了一下定义。\n变量。$x,y,t$ 这些字母代表的就是变量，它们两两之间存在着唯一的关系，这些关系互不矛盾，可能可以用函数或隐函数描述，也可能需要用间接的变量描述或难以描述。如果一对变量 $u,v$ 之间不存在关系，那么强制认为 $\\d u=0\\d v,\\d v=0\\d u$；如果一个变量 $z$ 必须同时依赖于两个无关变量 $x,y$，那就是多元微分的事情了。总之，在一元函数微分这里，我们希望将所有涉及到的变量对应的高维坐标系画出来，所有符合关系的点应当形成若干曲线，即，可以将这些曲线拆成有限段，每一段曲线中，任何一维坐标的任何可能取值仅出现一次，或者至少要求所有变量能形成一个链式的关系，这样保证能归约到函数上的微分解决。 函数。单独拿出一个函数，也是用例如 $f,g$ 的字母描述。它描述的是一种关系，可以与一个变量进行运算，得到另一个变量，例如 $y=f(x)$。注意 $y$ 和 $f$ 不能视作同一个东西，$\\d f$ 是不合法的，$\\d f(x)$ 才合法。\n函数代入任何变量，得到的结果形式都是相同的；而对一个变量写出关于不同变量的表达式，这些表达式形式是不同的。如果要对变量代入值，必须要写成例如 $y|_{x=1}$。\n定义函数的复合：$(f\\circ g)(x)=f(g(x))$。优先级高于乘除。 微分。非原始形式的微分必须是“什么变量关于什么变量的微分”，记 $y$ 关于 $x$ 的微分为 $\\d_xy$，$y=f(x)$ 则 $\\d_xy$ 就对应书中的 $\\d f(x)$。其结果是一个变量乘上 $\\D x$。这个 $\\D x$ 是一个“形式”，可以理解成类似生成函数里的 $x$ 这样的一个东西，它就是标明微分类型的一个类似常数的东西。当然也可以从极小变化量角度理解，但是这里不管怎么小，都不能一阶近似，$\\d_xy$ 才能一阶近似。微分与微分的商就是一个变量。\n$\\D x$ 与 $x$ 无关，但 $\\d_xx=\\D x$，而 $\\d_xy=a\\D x=\\D y+\\o(\\D x)\\ne\\D y=\\d_yy$，也就是说 $\\d_xy$ 和 $\\d_yy$ 只差一个 $\\o(\\D x)$。这里的 $\\D y$ 既可以理解为 $f(x+\\D x)-f(x)$，也可以直接理解为 $y$ 的一个微小变化量。\n至于这里 $\\D x$ 这类的东西是不需要考虑“什么关于什么”的，只需要所有的变量的 $\\D *\\to 0$ 即可，而这由可导性保证。\n为了避免歧义，规定 $\\d_xuv=(\\d_xu)v$，$\\d_x\\frac uv=\\frac{\\d_xu}v$，$\\d_xu^2=(\\d_xu)^2$。也就是说如果要写在里面必须加括号。 导数。记 $y^\\prime_x=\\d_xy/\\d_xx$。 这样，上面那个式子会被写成： $$ \\frac{\\d_xy}{\\d_xx}=\\frac{\\d_uy}{\\d_uu}\\frac{\\d_xu}{\\d_xx} $$ 或 $y^\\prime_x=y^\\prime_uu^\\prime_x$，从而无法约分。\n推导 现在关于微分只有两样东西可以使用：\n通过定义得到某个 $\\d_x y$，以及将 $\\d_xy$ 反写回定义； $u=v\\Rightarrow\\d_xu=\\d_xv$。 根据这两样东西，可以推出：\n$\\d_x(u+v)=\\d_xu+\\d_xv$，$\\d_x(cu)=c\\d_xu$。证略。\n$\\d_x(uv)=v\\d_xu+u\\d_xv$。证： $$ \\begin{align*} \\d_x(uv)\u0026amp;=\\D(uv)+\\o(\\D x)\\\\ \u0026amp;=(u+\\D u)(v+\\D v)-uv+\\o(\\D x)\\\\ \u0026amp;=v\\D u+u\\D v+\\D u\\D v+\\o(\\D x)\\\\ \u0026amp;=v(\\d_xu+\\o(\\D x))+u(\\d_xv+\\o(\\D x))+(\\d_xu+\\o(\\D x))(\\d_xv+\\o(\\D x))+\\o(\\D x)\\\\ \u0026amp;=v\\d_xu+u\\d_xv+\\o(\\D x) \\end{align*} $$ 由于含 $\\d$ 的部分都是常数倍 $\\D x$，故这里的 $\\o(\\D x)$ 应该是 $0$。\n注意 $\\d_x u\\d_x v=\\Theta(\\D x^2)=\\o(\\D x)$。\n$\\d_xu^{-1}=-\\d_xu/u^2$。证： $$ \\begin{align*} \\d_x\\left(\\frac 1u\\right)\u0026amp;=\\frac 1{u+\\D u}-\\frac 1u+\\o(\\D x)\\\\ \u0026amp;=-\\frac{\\D u}{u(u+\\D u)}+\\o(\\D x)\\\\ \u0026amp;=-\\frac{\\d_x u}{u(u+\\D u)}+\\o(\\D x)\\\\ \u0026amp;=-\\frac{\\d_x u}{u^2}+\\frac{\\d_x u}{u^2}-\\frac{\\d_x u}{u(u+\\D u)}+\\o(\\D x)\\\\ \u0026amp;=-\\frac{\\d_x u}{u^2}+\\frac{\\d_x u(\\d_x u+\\o(\\D x))}{u^2(u+\\D u)}+\\o(\\D x)\\\\ \u0026amp;=-\\frac{\\d_x u}{u^2}+\\o(\\D x) \\end{align*} $$\n$\\d_xy=\\d_uy/\\d_uu\\cdot\\d_xu$。证： $$ \\begin{align*} \\d_xy\u0026amp;=\\D y+\\o(\\D x)\\\\ \u0026amp;=\\frac{\\d_uy}{\\d_uu}\\D u+\\o(\\D u)+\\o(\\D x)\\\\ \u0026amp;=\\frac{\\d_uy}{\\d_uu}(\\d_xu+\\o(\\D x))+\\o(\\D x)\\\\ \u0026amp;=\\frac{\\d_uy}{\\d_uu}\\d_xu+\\o(\\D x) \\end{align*} $$\n$\\d_yx/\\d_yy=1/(\\d_xy/\\d_xx)$。证：只需令 4 中 $u=y$ 即可。\n以上给出了微分形式的求导法则证明。注意到，3 的证明比直接 $\\lim$ 麻烦。\n一阶微分形式的不变性，可以理解成（注意 $\\d_xy\\ne\\d_uy$）： $$ \\forall u,\\frac{\\d_xy}{\\d_xx}=\\frac{\\d_uy}{\\d_ux} $$ 或是（注意 $y^\\prime_u\\ne y^\\prime_x$）： $$ \\d_xy=y^\\prime_u\\d_xu=y^\\prime_x\\d_xx $$ 关于自变量微分时，中间变量的微分形式和自变量的微分形式相同。这个性质一般会这样被使用：求 $\\d_xy$ 时，先求出 $\\d_uy$，然后把等式两侧的 $\\d_u$ 替换为 $\\d_x$ 再把 $\\d_x u$ 展开。这在不标关于谁微分的时候是不容易被发觉的，书里的写法 $\\d y=y^\\prime_u\\d u=y^\\prime_x\\d x$ 感觉像在说废话，其本质原因是它会被混淆成 $\\d_uy=y^\\prime_u\\d_uu$，而这就是定义啊。\n至于为什么教材里不表明是对谁微分，主要因为一般微分都是关于分母，不然得到的东西类型就不对了。\n那么在答题时如何用教材中的形式呢？在没有使用链式法则或直接处理高阶微分时，默认是关于上文中唯一的自变量微分；用链式法则处理一阶微分时，必须单独写出一步，并且在脑中，如果要替换“关于谁微分”，必须是成对替换，这种成对可以是分子分母，也可以是等式两边。\n高阶微分 如果硬要用类似一阶的定义方法定义高阶微分，可以这样类比定义：\n对于一个在 $x_0$ 邻域内有定义的函数 $f$，如果： $$ \\D^nf(x)=\\sum_{i=0}^n(-1)^{n-i}\\binom nif(x_0+i\\D x)=a\\D x^n+\\o(\\D x^n)\\quad(\\D x\\to 0) $$ 则称 $\\d^nf(x_0)=a\\D x^n=a\\d x^n$。\n但是这个似乎只能直接用导数的 $\\lim$ 形式证，我没法通过反复利用一阶微分的定义证。\n回到正常的定义。高阶微分的写法也是好理解的： $$ \\d_x\\left(\\frac{\\d_xy}{\\d_xx}\\right)=\\frac{\\d_x^2y\\d_xx-\\d_xy\\d_x^2x}{\\d_xx^2}=\\frac{\\d_x^2y}{\\d_xx} $$ 核心是 $\\d_x^2x=\\d_x(\\D x)=0$。\n二阶微分不具有形式不变性，可以如下试验：\n记 $u=g(x)$，$y=f(u)$。 $$ \\begin{align*} \\d_u^2y\u0026amp;=\\textcolor{teal}{f^{\\prime\\prime}(u)\\d_uu^2}\\\\ \u0026amp;=(f^{\\prime\\prime}\\circ g)(x)\\d_uu^2\\\\ \u0026amp;=\\textcolor{green}{(f^{\\prime\\prime}\\circ g\\cdot {g^\\prime}^2)(x)\\d_ux^2}\\\\ \\d_x^2y\u0026amp;=(f\\circ g)^{\\prime\\prime}(x)\\d_xx^2\\\\ \u0026amp;=\\textcolor{green}{(f^{\\prime\\prime}\\circ g\\cdot {g^\\prime}^2+f^\\prime\\circ g\\cdot g^{\\prime\\prime})(x)\\d_xx^2}\\\\ \u0026amp;=\\textcolor{teal}{f^{\\prime\\prime}(u)\\d_xu^2+f^\\prime(u)\\d_x^2u} \\end{align*} $$ 也就是： $$ \\frac{\\d_x^2y}{\\d_xx^2}\\ne\\frac{\\d_u^2y}{\\d_ux^2} $$ 至于为什么不一样，可以大致理解为有一项高阶项不能忽略。由于水平有限，我无法指出到底源自于哪儿。\n从而我们也就能理解，为什么在书里，参数方程一阶导可以 $\\d y/\\d x=\\d y/\\d t\\cdot\\d t/\\d x$，而二阶导必须拆成两次一阶导，而不能 $\\d^2y/\\d x^2=\\d^2y/\\d t^2\\cdot (\\d t/\\d x)^2$。\n","date":"2024-03-26T00:00:00Z","permalink":"https://littlereuben.github.io/study/differential/","title":"关于微分的理解问题"},{"content":"这是一篇学习笔记。\r关于本题的一个注记。\n钦定背包上界为 $72$，这样搜得的状态数为 $12880$。对其进行 dfa 最小化，状态数优化到 $715$（注意到设上界较大时最小化 dfa 后大小仍为该值）。预处理 $f_{k,i,s,r}$ 表示限制差 $\\le k$，$i$ 位待定，当前 dfa 上状态为 $s$，当前位至多取 $r$ 的答案，即可 $\\mathrm{O}(\\log r)$ 回答单组。远古最优解代码。\n这题在徐哲安的 2021 年集训队论文《浅谈有限状态自动机及其应用》中作为例题出现，其证明了背包上界只需开到 $80$ 即可，但没证 $72$。以下是我口胡的证明。\n结论：对于一个只包含 $\\le w$ 的正整数的序列，给每个数安排正负号，使得和的绝对值最小。那么最大前缀和绝对值 $\\le w(w-1)$。\n引理（CF618F）：对于大小 $\\ge n$ 的可重集合 $A$ 和任意大小（设为 $m$）的可重集合 $B$，它们的元素都是 $\\le n$ 的正整数。如果 $n+\\sum_{b\\in B}b\u0026gt;\\sum_{a\\in A}a$，那么可选两者各自的一个非空子集，使得和相同。证略。\n证明：首先最优答案一定 $\\le w$，并且当且仅当序列为奇数个 $w$ 时最优答案为 $w$，这是易证的。接下来只考虑最优答案 $\\le w-1$ 的情况。\n考虑某组最优解，找到其最靠前的前缀和绝对值 $\u0026gt;w(w-1)$ 的位置 $t$，不妨设该前缀和是正的。取出该前缀中最靠后的 $w$ 个取正号的数 $x_{1\\cdots w}$，以及剩余后缀中所有共 $k$ 个取负号的数 $y_{1\\cdots k}$。其中由鸽巢原理，$x_1,\\cdots,x_w$ 一定是可以取出来的，而由于 $\\sum_{i=1}^ky_i\\ge w(w-2)+2$，故 $k\\ge w-1$。\n接下来的目标是选择某些 $x$ 和某些 $y$，改变它们的符号，使全体和不变，且 $t$ 及之前不反而出现前缀和 $\u0026lt;-w(w-1)$ 的情况，且 $t$ 处的前缀和降低。这样就可以不断归纳了。\n如果 $\\sum_{i=1}^wx_i\\le w(w-1)$，则令 $A=\\set{x_{1\\cdots w}}$，$B=\\set{y_{1\\cdots k}}$，套用引理即可。\n否则随意套用引理可能会导致 $x_1$ 处前缀和 $\u0026lt;-w(w-1)$。这时，$x$ 中必然有 $w$。如果 $y$ 中也有 $w$，那么选这两个互换符号即可1。\n否则，选择 $y$ 中最短的前缀 $y_{1\\cdots k^\\prime}$，使得和 $\\ge w(w-2)+2$。由于 $y$ 中无 $w$，故 $k^\\prime\\ge n$。这时由于 $w(w-2)\u0026lt;\\sum_{i=2}^wx_i\\le w(w-1)$，$\\sum_{i=1}^{k^\\prime}y_i\\le w(w-1)$，故可令 $A=\\set{y_{1\\cdots k^\\prime}}$，$B=\\set{x_{2\\cdots w}}$，套用引理即可。\n这里其实有个特殊情况，就是 $x_1=w$，然后 $x_1$ 前的前缀和最小会达到 $-w+1$，这样一来 $x_1$ 处的前缀和会达到 $-2w+1$，在 $w=2$ 时会炸。但 $x_1$ 前的前缀和达到 $-w+1$ 时 $x$ 会全是 $w$，所以选后面的 $x$ 就行。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2024-02-18T00:00:00Z","permalink":"https://littlereuben.github.io/study/solution-cf924f/","title":"[题解] CF924F Minimal Subset Difference"},{"content":"这是一篇学习笔记。\r提供一个自己做的思路。用到的性质比其他正解弱，但更容易想。\n考虑单棵树的判定。初步读题后会得到两个性质：\n一个点的儿子边权不能重复。 设所有权为 $i$ 的边的较浅端点形成集合 $S_i$，则所有 $S_i$ 形成一个“连续包含链”的结构。或者也可以从一个点的所有儿子边权角度等价描述。 这些性质都是 beautiful subtree 的必要条件，并且对于想象力不够丰富的选手来说，难以加强至充要条件。既然必要角度不行，那考虑充分角度——同样是一个很常见的套路，我们希望找到一种排列的构造，使得对于 beautiful subtree，构造出来的排列必定是 beautiful permutation；如果不是 beautiful subtree，那就不用考虑了。于是剩余要做的就是验证一遍题意中的条件即可。\n归纳易证排列中越靠前的点子树 size 越大，因此先按 size 排序；如果两棵子树 size 相同，那么也归纳易证它们同构，因此它们的相对顺序只取决于它们各自父亲的相对顺序。因此可以在按 size 排序后再扫一遍，size 相同的按父亲在序列中的位置排序。这样可以做到 $\\mathrm{O}(n\\log n)$ 单次判定。这些归纳易证的部分也都很直觉的。\n对于原问题，一个有意思的猜想是，一棵 beautiful subtree 的子树也都是 beautiful 的。考试中当然可以直接 assert 然后交上去看看，不过这也是好证的。考虑 $T(u)$ 对应的某个 beautiful permutation $p$。对于 $v\\in T(u)$，将 $p$ 中 ${}\\in T(v)$ 的点对应的子序列 $p\u0026rsquo;$ 取出来，可以证明这就符合条件。因为对于某种权值的边，除去它的较深端点为 $v$ 的情况以外（$v$ 本身在 $p\u0026rsquo;$ 中不贡献给计数器，故也不用考虑），其余该权值的边的两端点要么同时在 $p\u0026rsquo;$ 中，要么同时不在 $p\u0026rsquo;$ 中。因此扔掉 $p\u0026rsquo;$ 以外的部分后，剩余的连边情况是保持不变的。\n剩下的就是思想类似 [WC2018] 即时战略 的二分了。取出重链，在上面二分，然后往轻儿子递归。硬二分是 $\\mathrm{O}(n\\log^3n)$ 的（代码），如果按全局平衡二叉树的方式带权二分，则是 $\\mathrm{O}(n\\log^2 n)$ 的。这是因为考虑大小为 $n$ 的树的第一轮二分，假设得到的根最浅 beautiful subtree 大小为 $s$，那么分 $\\ge 2s$ 和 $\u0026lt;2s$ 的子树判定讨论，这轮二分的复杂度为 $\\mathrm{O}(n\\log n+s\\log^2 n)$。接下来，剩余若干大小 $\\le n/2$，和为 $n-s$ 的子问题，这样分析下来就是 $\\log^2$ 的。\n","date":"2024-01-23T00:00:00Z","permalink":"https://littlereuben.github.io/study/solution-lgp9603/","title":"[题解] lgP9603 [IOI2023] 山毛榉树"},{"content":"这是一篇学习笔记。\r本文非常地粗糙和民科，算法很可能是假的。如果您知道已有的其他解法或者找到了我的证明的问题，请告知我是小丑。\n最近做 CF1909G 的时候想复杂了，结果发现了一些奇怪的性质，感觉不大平凡？\n引理：一个足够长的串 $s$，$s_1\\ne s_{n+1}$。若 $s_{1\\cdots n}$ 的最小整周期为 $p\u0026lt;n$，有某个 $1\u0026lt;i\\le n$，$s_{i\\cdots i+n-1}$ 的最小整周期为 $q\u0026lt;n$，那么 $i\u0026gt;n-p-q+\\gcd(p,q)+1$。\n证：反证，假设 $i\\le n-p-q+\\gcd(p,q)+1$。\n$p\\mid q$ 的情况下，$i\\le n-q+1$，$s_{n+1}=s_{n-q+1}=s_{1}$，矛盾。\n$p\\nmid q$ 的情况下，$s_{i\\cdots n}$ 这一段长度至少为 $p+q-\\gcd(p,q)$，且有 $p$ 和 $q$ 作为周期，由强周期引理，$p$ 不是 $s_{1\\cdots n}$ 的最小整周期，矛盾。\n$i$ 取到 $n-p-q+\\gcd(p,q)+2$ 的情况应该可以构造，不过我现在还没找到通用的形式。\n一个有趣的推论是 $i\u0026gt;n/3+1$，这可以通过讨论所有 $p,q\u0026gt;n/6$ 证明。取到 $i=n/3+2$ 的情况是这样的： $$ \\texttt{a}t\\texttt{b}t\\texttt{a}\\textcolor{red}{t\\texttt{a}t\\texttt{b}t\\texttt{a}t}+\\textcolor{red}{\\texttt{b}t\\texttt{a}t\\texttt{b}} $$ $t$ 表示任意串。前面一个串 $p=n/2$，红色部分 $q=n/3$。\n然后发现了一个求定长区间最小整周期的线性算法（定长长为 $n$）：\n首先 $p=n/2$ 的情况要暴力判掉。\n从左往右移窗口。对于当前子串 $s_{l\\cdots r=l+n-1}$，反过来跑 KMP。\ncase 1. 如果找到了 $\u0026lt;n$ 的最小整周期（这里找到 $n/2$ 也无所谓），那就可以一步步移左右端点，看能否维持当前周期，如果不行，根据引理可以至少一次性往后跳 $(n-p)/2$。称这个为优化 A。\ncase 2. 否则，如果下一个具有最小整周期 $p\\le n/3$ 的区间与 $[l,r]$ 有交，那么交的部分一定也有 $p$ 的周期。并且，如果交的部分长 $\\ge 2n/3$，那么 $p$ 一定是它的最小周期（否则可以用弱周期引理导出更小的 $p$）。现在，找到当前区间的最长后缀 $[t,r]$，满足这个后缀的最小周期是 $\\le n/3$ 的 $n$ 的因数，把区间左端点移到 $\\min(t,l+n/3)$。称这个为优化 B。注意优化 B 是不能兼容 $p=n/2$ 的，因为交里的循环节不足 $2$ 次，无法保证最小周期。比如当前子串为 $\\texttt{aaaaaaaaaabaaaaa}$，那么后续必须逐一检查。\n性质：连续进行两次优化 B，左端点移动超过 $n/3$。\n证：如果两次中有至少一次左端点移到的这个 $\\min$ 式子取的后一项，那么已证毕。\n否则考虑反证，如果左端点移动 $\\le n/3$，设两次分别移动到 $[l^\\prime,r^\\prime],[l^{\\prime\\prime},r^{\\prime\\prime}]$，$[l^\\prime,r]$ 和 $[l^{\\prime\\prime},r^\\prime]$ 的最小周期分别为 $p,q\\le n/3$。由于 $r-l^{\\prime\\prime}+1\\ge 2n/3$，故 $[l^{\\prime\\prime},r]$ 具有周期 $\\gcd(p,q)$，故 $[l^\\prime,r^\\prime]$ 具有周期 $\\gcd(p,q)$，不应有第二次优化 B，矛盾。\n综上，无论何种情况，都可以一次性跳过至少 $n/3$ 个位置，总时间复杂度为 $\\mathrm{O}(n\\cdot \\lvert s\\rvert/n)=\\mathrm{O}(\\lvert s\\rvert)$。\n优化 A 应该是不必要的（可以直接从 $l+1$ 继续），因为如果 case 1 紧跟 case 2 的话，case 2 应当一定会跳 $\\min$ 的后一项。这个我没仔细证。\n","date":"2024-01-18T00:00:00Z","permalink":"https://littlereuben.github.io/study/string-period/","title":"定长区间最小整周期问题的线性解法"},{"content":"这是一篇学习笔记。\r声明 本文非严谨的算法理论研究，仅仅是个人对解题经验的归纳和实验性的系统总结，不保证理论上的完备性与纯粹性。仅对解题实践提供一个较为自洽的解释，作为参考。\n本文所有题都不会提供题意和完整包含细节的题解，也就是说您需要先做一遍或看其他题解，因为没有做题经验就无法感受解题思想。您也可以把本文理解成一个归类好的题单。\n如果一题包含多项技巧则会放在多处，但如果包含多项思想则只会在一处解说，其余处记入“其他”项并打+号。如果出现一题多解会记入多个类别并多次解说。有些不是非常典型或过难过易的题也会记入“其他”项。\n带括号的题是内部训练题或经典问题。\n如果您认为一些理论表述有偏颇，或找到文章无法解释的题目（反例），可以告诉我。\n本文会时常更新。\n引言 dp 在 OI 中应用之广，变化之多，难度之大，已使它不再仅限于原先 \u0026ldquo;dynamic programming\u0026rdquo; 的定义和特质。《算法导论》给了 dp 一个严谨的基本定义，但缺乏实操性和可扩展性。本文不会采用算导中的描述方法，而是用一个解题方法论的方式展开，但是也会牵涉到一些基本定义及术语。因此，在阅读本文前，您应当先掌握算导第 15 章（动态规划）的内容。\n在 OI 中，狭义的 dp 基于的是一个类自动机结构（一般生成过程只有串联和并联两种，串联就是在自动机上走，并联可以理解成多维状态的降维，我不清楚这个东西有没有更形式化的描述）。考虑某种组合结构，所有满足某一条件的该结构作为元素（称为“解”）组成一个解集，题意要求求出这些解的某种权值经过某种运算后的结果。dp 就是使得自动机在这些解上运行。这种情况下的 dp 大致有三类：最优化、计数、判定。在所有合法解不漏的前提下，它们需要满足的关键条件是：最优子结构、不计重、无。\n广义上来说，习惯于将大部分用递推解决问题的方法都称作 dp。\n可以大致限定一下狭义 dp 的使用范围：如果可以找到一种生成方式，能恰好（逐步）刻画出所有满足条件的解，并且中途为了判定符合条件以及为了辅助求出权值所记录的信息是局部的或可能性较少的，那就有机会使用 dp。当然进一步地，如果有更好的结论能刻画模型，使得无需逐步生成解（解的可能性只有 $\\mathrm{O}(1)$ 种或可以通过某类极简单的方式生成），那就是贪心、构造、直接计数或其他无算法题了。\ndp 题的核心就是对原问题模型的分析、转化、拆解和重构，通过钦定生成的顺序以及分析其变化的本质，将原先可能性极多的解“少量多次”地用变量来描述从而解决。\n下面我会从一些特殊类型的 dp 技巧和通用 dp 解题方法两方面，介绍如何思考 dp 题。由于 dp 的设计思想较细较杂，故有一些小的思想和套路不会单独写出来，而是会在例题讲解的最后一段，我会将它加粗。\n本文（将）是我的集训队论文的素材来源，预计论文对方法论的叙述方式可能与本文有出入，您可以结合着看。与论文有关的注释以 \u0026ldquo;remark.\u0026rdquo; 开头。\n基于特殊结构的技巧 决策单调性优化与 ds 优化等的具体技术详见下一章。\n括号序列 括号序列的生成思路一般有以下几种：\n直接按下标，记录当前多的 $\\texttt{(}$ 数。 按外层配对括号 $\\texttt(\\mathtt\\cdots\\texttt)\\texttt(\\mathtt\\cdots\\texttt)\\mathtt\\cdots\\texttt(\\mathtt\\cdots\\texttt)$ 拆开。 拆第一对配对括号，剩下视作整体 $\\texttt(\\mathtt\\cdots\\texttt)\\mathtt\\cdots$。 视作折线，进行容斥。 其中 2、3 是直接对着定义 dp，3 可以理解成对括号树三度化再 dp，会方便一些，同时避免计重。2 在最优化问题下可以随便选一个断点拆。\n例：\nCF1781F：称第 $i$ 轮加入的为第 $i$ 组括号。这题由于增加了时间维度，故又多出几种思路，但直接按时间维 dp 是不行的：正着信息量太大，倒着会把同一组括号拆到两部分。不按时间 dp 的话考虑概率不方便，先求出方案数。\n先分析一下题目条件的静态表述：把每个括号加入的时间写成序列，则不能出现 $[j,i,i,j],[i,j,i,j],[j,i,j,i]$（其中 $i\u0026lt;j$）的子序列。\n（解 1）考虑第一组括号，它们将序列切分成三部分，同一组括号在同一部分。这样只需在记一维“当前段前面多的 $\\texttt{(}$ 数”即可。由于是三部分，故是 $\\mathrm{O}(n^4)$。先对其中两个卷积即可做到 $\\mathrm{O}(n^3)$。\n（解 2）尝试方式 3，问题在于这对匹配的括号可能不是同一组。那就改成找与开头括号同一组的括号，它将序列切成两部分，同一组括号在同一部分，第一部分都后于开头括号加入。dp 状态与第一种相同，直接三次方。\n一些类括号序列的结构，主要依据递归定义来 dp（定义可能不唯一）。主要找形式相同的子问题。\n例 CF888F：断环为链，直觉上来说结构属于以下两种（红色的是边）：\n一种是在两种类型之间交替 dp，type 1 按方式 3 转移，type 2 找中间断点。另一种是只对 type 2 dp，即先逐步确定左侧的子结构，到达断点后再右侧（如果每次随意转移左右侧则会计重）。\nCF913E：这题多了个优先级，dp 得记当前表达式的层级。我的具体思路是记能否被 T 或 F 识别（最外层是否没有 $\\texttt{or}$），转移有几种：$\\texttt{or}$ 连接、$\\texttt{and}$ 连接、加 $\\texttt{()}$、加 $\\texttt{!()}$。由于后效性得多轮松弛。\n另一个跟 01 序列相关的罕见技巧也放这（来源于 dmy WC2022 讲课的 PA2021R2T1(lgP9047)）：如果有一些 0 和一些 1，每个都有权值，要选一个子集 01 数量相同，最优化权值相关某个东西，可以把元素随机打乱再 dp，记录当前 0 比 1 多多少，这一维可以只开到 $\\Theta(\\sqrt n)$。\n排列 这一节侧重于排列未知的情况。\n排列的关键是找到一个生成顺序，使得已生成部分的数不需要逐个记录，而只需抽象成少量的几个量。最基本的排列生成顺序如下：\n预定（绝对） 插入（相对） 按下标 从左往右逐一确定值 从左往右逐一确定当前值在前缀中排第几大 按值 从小到大逐一确定位置 从小到大逐一插入排列 还有几个典型的应用。一种是只对一个单调子序列 dp，剩余部分直接用组合数确定（属于按值、断点）；一种是基于笛卡尔树或类似笛卡尔树的分治结构，合并时确定相对大小，乘组合数（属于按值、预定、单步）。\n例 CF1806D：（解 1）对答案有贡献的是所有 $p_i=\\operatorname{mex}_{j\u0026lt;i}\\set{p_j}$ 的 $i$，对它们 dp，其余部分可以用组合数插入。$f_i$ 表示到 $i$，$1\\sim i-1$ 都在 $i$ 之前，且目前根为 $1$ 的方案数。$f_i=[a_i=0]\\sum_{j\u0026lt;i}(i-2)^{\\underline{i-j-1}}f_j$，可以换元做到线性，然后统计一下即可。这属于按值、插入、断点转移。\n（解 2）尝试按值、插入、单步转移。如果 $i$ 不插到末尾则无影响，否则当且仅当 $1\\sim i-1$ 操作结束后根仍为 $1$ 且 $a_i=0$ 时有贡献。从另一个角度看，这个解法的处理是把每个点的贡献拆开，将原所求转化为容易转移的“前 $i$ 个点操作后根仍为 $1$ 的方案数”，属于拆分要素。\nCF1437F：可以线性。对更新前缀 $\\max$ 的值 dp。如果从大到小 dp，就是 $f_i$ 每次从 $2a_j\\ge a_i$ 的 $f_j$ 转移，并在 $j$ 之后插入范围在 $(a_i/2,a_j/2]$ 的剩余 $a$，同样可以换元做到线性。这属于按值、插入、断点转移。\n如果从小到大 dp，就必须按值、预定、断点转移。当 $f_i$ 从 $f_j$ 转移时，$a_i$ 塞到第一个空位，后面的空位选填 $(a_j/2,a_i/2]$ 中的剩余 $a$。注意到这个问题中的两个两倍是有意义的，如果两个倍数不同，可能导致“剩余 $a$”数量无法确定。\n本题具体 dp 方程详见概率 \u0026amp; 期望一节。\nUSACO21DECPlatinumT3：（解 1）同样，对猜的数 dp，处于转移之间的无用数直接用组合数算。官方解法是先对答案的期望 dp，这样可以避免 dp 同时要记方案数（这个技巧详见后）。前缀和优化即可。这也属于按值、断点转移。\n（解 2）尝试按下标、插入、单步转移，即每次在末尾加入一个数，不妨设是 $\\le x$ 的，那么只需要分它会被猜和被忽略两种情况即可。这个同样可以期望化以省掉方案数 dp。\n这三个例子本质上是形如“确定了主要元素（某个单调子序列），剩余元素必须出现在某个主要元素前或后”，为了使状态维数小，就对主要元素 dp。这时剩余元素的位置应当在对应的主要元素被 dp 到时用数学方法确定。如果限制方向与 dp 方向相同则用预定法，否则用插入法。\nCF1363F：问题转化为找到一个排列 $p$，使 $s_i=t_{p_i}$ 且 $\\sum_i[\\max_{j\u0026lt;i}\\set{p_j}\u0026lt;p_i]$ 最大。这个模型和前三个例子很像，但由于本题限制条件难以适应断点转移，故考虑单步转移。$f_{i,j}$ 表示到 $i$，目前最大值为 $j$。对于不更新最大值的转移，只需要判定同类字符在 $t$ 中位置 $\\le j$ 的数量够用即可。更新最大值时有性质保证转移唯一，总的来说转移就是 0D 的。这属于按下标、预定、单步转移。\nCF1799G：如果不容斥至少得 $\\mathrm{O}(n^5)$。容斥的话麻烦的一点是，如果一组内有多个钦定不合法的投票，它们的方案数无法确定（类似一个有上限的整数拆分）。这里的一个技巧是，把投给同一个人的票也视作有先后顺序，这样投票方案就变成了一个排列，最后除以 $\\prod c_i!$ 即可。这样直接枚举组内钦定数，然后用组合数即可。\nCF1439D：正反 dp 要记的信息量都太大，考虑到多个占用位置极长连续段之间是无关的，因此可以分开 dp。对于一个连续段，考虑其最后一个人，拆成两段即可。段的合并或并列就乘组合数确定相对大小。\n其他. +CF1784D、+CF856C、ABC134F\n背包 基础的背包技巧包括：\n多重背包的二进制拆分和同余转移。 换维。价值较小时可以定义状态为得到 $i$ 的价值至少要多少重量。 物品大小和有限制时只有根号种物品。 无序整数拆分相关的两个：“全体 +1 \u0026amp; 新开一个”的转移方式，以及按下标 dp 总状态数为 $n^2\\ln n$。 从 GF 角度考虑。 同余最短路。 例 （经典问题）（无序整数拆分）：除了五边形数解法外，还有一种 $1.5$ 次的。对于 $\\le\\sqrt n$ 的数，直接完全背包，$\u0026gt;\\sqrt n$ 的数少于 $\\sqrt n$ 个，套用平方的做法，$f_{i,j}$ 表示 $i$ 个数和为 $j$，每次加入单个 $1$ 或全体加 $1$，最后全体加 $\\sqrt n$，两类卷起来即可。\nCF1425B：情况只会有两种：两人在某个环上卡住、两人分工将所有环走完（且最终至少有一人停在点 $1$）。后者简单。前者需要枚举卡住的环，这时相当于求 $\\prod_{j\\ne i}\\left(x^{l_j}+1+x^{-l_j}\\right)$ 某一区间的系数，可以预处理前后缀乘积拼合，也可以预处理所有的积然后 $\\mathrm{O}(n)$ 除以当前的因式，都是 $\\mathrm{O}(n^2)$ 的。只利用环大小只有 $\\mathrm{O}(\\sqrt n)$ 种也可以优化成 $\\mathrm{O}(n^2)$，但上述两种技巧不能同时优化，变成 $\\mathrm{O}(n\\sqrt n)$。\nCF1442D：容易用调整法证明只有一个数组选一部分，其余要么全选要么全不选。于是问题就变成了 $[x^k]\\sum_iA_i(x)\\cdot\\prod_{j\\ne i}\\left(1+s_jx^{t_j}\\right)$ 的 $(\\max,+)$ 卷积版本。这不适用于例 1 的两种处理方法，因为前后缀拼合会由于 $A_i(x)$ 没有简单形式而必须把每一项算出来，就得 $\\mathrm{O}(k^2)$，而本题没有可减性，不能作除法。这时可以利用分治方法做到 $\\mathrm{O}(nk\\log n)$。这个方法也可以用到上一题，做到 $\\mathrm{O}(n^2\\log n)$ 或 $\\mathrm{O}(n^2)$（如果分治时控制多项式次数得当）。\nCF1740F：充要条件是前 $k$ 大的 $\\text{size}$ 之和 $\\le \\sum\\min(cnt_i,k)=s_k$。$f_{i,j,k}$ 表示前 $i$ 大，和为 $j$，目前 $k$，$ik\\le j$，状态总数 $\\mathrm{O}(n^2\\log n)$，转移可以做到 $\\mathrm{O}(1)$（新加一个数或 $k$ 减一）。用“全体 +1 \u0026amp; 新开一个”的转移思路也是可以的：$g_{i,j,k}$ 表示已确定 $i$ 个，和为 $j$，还能全体加至多 $k$ 次，其中 $k\\le s_i/i$。\n[十二省联考 2019] 皮配：正常的暴力 dp 可以记录红阵营和 R 派系的选手数。用 GF 解释就是，一个城市会贡献 $\\left(1+x^{\\sum s_i}\\right)\\prod(1+y^{s_i})$，这意味着除了有偏好的城市以外，其余的可以分离阵营和派系两个要素。有偏好的城市贡献形如 $\\prod_{i\\notin T}(1+y^{s_i})\\cdot \\left(A(y)+B(y)x^{\\sum s_i}\\right)$（$T$ 为有偏好的学校）。一个大致的思路是把后面特殊的部分全部卷起来（记作 $E(x,y)$），这样需要 $\\mathrm{O}(k^2s^2M)$。但由于 $A,B$ 都是若干单项和二项式的积，故分别可以逐一乘（求出 $E(x,y)A(y)$ 和 $E(x,y)B(y)$），然后最后再决定阵营，即 $E\\cdot A+E\\cdot B\\cdot x^{\\sum s_i}$。最终没必要把 $E$ 和 $x,y$ 剩余整齐部分卷起来，只需要枚举 $E$ 的每一项，然后乘上两段系数和的积即可。\n这题的几个技巧是：逐个乘项数小的多项式一般比先把这些小多项式乘起来再统一卷更优；求最终答案时可以视作求卷积的单点值，避免全体卷积；同时，对于这类最终不使用多项式算法的背包题，不能完全抛弃组合意义，要结合代数和原模型推导，否则可能会丢失方向或性质。\n然后有几个很牛的技巧（仅用于最优化）：\n完全背包的倍增方法。当容量 $T$ 很大，最大重量 $W$ 较小时，通过将解按重量排序交替放，可证明一定能将解拆成两个总重量差 $\\le W$ 的部分，于是求出 $[T-W,T+W]$ 的最优解可以 $\\mathrm{O}(W^2)$ 递推到 $[2T-W,2T+W]$。如果额外对选的数量 $C$ 有限制，同样可以证明一定能将解拆成两个总重量差 $\\le W$ 且数量差 $\\le [2\\nmid C]$ 的部分，从而有两种转移方式：一种是如果 $C$ 为奇数就转移单个，否则直接对半，这样做为了保证状态的封闭性就得求 $[T-2W,T+W]$ 的最优解；另一种是直接对于 $\\lfloor C/2\\rfloor$ 和 $\\lceil C/2\\rceil$ 的数量要求都 dp 即可。无论如何都会多一倍常数。\n只有完全背包能这么搞。$\\mathrm{O}(nT)\\rightarrow\\mathrm{O}(W^2\\log T)$。\n背包的贪心性质。考虑按性价比贪心选直到第一次遇到无法选的物品就停止，设选出的物品集合为 $G$，最优解为 $O$。有性质：存在 $O$ 使 $\\lvert G\\oplus O\\rvert\\le 2W$。\n证明：考虑 $G$ 加删元素（不重复加删一个元素）逐渐变成 $O$ 的过程，容易维持重量和 $\\in[T-W,T+W)$。如果 $\\lvert G\\oplus O\\rvert\u0026gt;2W$，那么由鸽巢原理，一定存在两个中间状态重量和相等。由于 $G$ 选的是性价比最高的一些，故把这两个重量和相等的中间的加删部分去掉，一定不劣。\n那么只需一个状态数为 $4W^2$ 的背包即可。$\\mathrm{O}(nT)\\rightarrow\\mathrm{O}(nW^2)$。\n如果价格最大值 $V$ 很小，也有类似的性质（$\\lvert G\\oplus O\\rvert\\le 2V$），实现用换维技巧即可。\n例 （经典问题）（给定 $n$ 个数，选出一些使和 $\\le T$ 且最大）：先随意贪心选，问题转化为有正数和负数的情况，且剩余容量 $\u0026lt;W$。这时存在一个容易 dp 的生成方式且可以保证时刻和 $\\in (-W,+W)$：$f_{i,j,k}$ 表示考虑前 $i$ 个正的，前 $j$ 个负的，能否达到和 $k$。易做到 $\\mathrm{O}(n^2W/w)$。考虑使用判定性转最优化技巧，$g_{j,k}$ 表示前 $j$ 个负的，和为 $k$，最小要考虑前几个正的可以达到。看似选正的转移需要再 1D，但实际上对于固定的 $k$，选第 $i$ 个正的只需要在最小的 $j$ 满足 $g_{j,k}\u0026lt;i$ 处转移即可。也可以理解为 $f$ 按 $k$ 切片，每片的 $1$ 都是右下一个阶梯形的部分，而转移只需使用阶梯的“边界”部分即可。$\\mathrm{O}(nW)$。 （物品）（有 $a_i$ 个数 $i$，$\\lvert i\\rvert\\le W\\le 300$，选出尽量多的数使和为 $T$）：如果只需和 $\\le T$，那么选上所有负的再贪心选正的即可（也可以从性价比角度理解，但由于所有物品价值均为 $1$，故依次选直接就是最优解）。要求 $=T$ 时，仍然考虑使得和与 $T$ 尽量接近且与最优解相差较小，于是推广贪心：在不超过 $T$ 的前提下，把能选的正的选完后如果还不够 $T$，再贪心撤回负的（可以理解成也是符合性价比原则）。这时即可同理证明贪心解与最优解相差不超过 $2W$ 个元素，可以 $\\mathrm{O}(W^3)$ 多重背包。 [THUPC 2023 初赛] 背包：设 $(v_0,c_0)$ 为性价比最高的物品。有了之前的结论，显然最优解一定塞了一堆该物品，因此只需关心 $V\\bmod v_0$，或者说，问题可以转化为，对于 $i\\in[0,v_0)$，可以随意选物品，其中性价比最高的物品可以选负数个，最优的答案。看起来就是个同余最短路。枚举每种物品，图可以拆成若干个环，对于一个环，易证依次松弛松两圈就够了，那就是 $\\mathrm{O}(nv_0)$。 状压 状压 dp 的难点主要在两块：刻画生成过程和优化。前者没有固定方法（详见通用解题方法），后者有几个经典技巧。\n第一个单独的技巧类似 meet-in-the-middle。如果转移时要考虑两个数之间的某个位运算，可以两者分别枚举一半。例子是 CSP-S 2020 初赛的最后一题。\n其余的技巧都和位运算卷积有关，这里有几个经典的转移形式（$\\sqcup$ 表示不交并）：\n$g_i=\\sum_{j\\sqcup k=i}f_jg_k$：这个是经典的半在线子集卷积，写成集合幂级数就是 $(1-f)^{-1}$。可以直接套用普通子集卷积的变换，然后每一位的占位多项式进行半在线卷积。仍然是 $\\mathrm{O}(n^22^n)$。 $g_i=T_i\\left(\\sum_{j\\sqcup k=i}f_jg_k\\right)$：也就是 [WC2018] 州区划分。这时可以按照 $\\lvert i\\rvert$ 从小到大处理（同样 popcount 的内部的 $i$ 互不影响）。也就是逐一确定所有位的占位多项式的某一项的系数。每次要先 IFMT 再 FMT，仍然是 $\\mathrm{O}(n^22^n)$。 $g_i=\\sum_{j\\sqcup k=i,h(j)=h(i)}f_jg_k$：也就是 USACO22FEBGoldT1。这里 $h(j)=h(i)$ 意思是 $j$ 的最高位和 $i$ 的最高位要相同。可以理解成全集的无序划分，因此写成集合幂级数就是 $\\mathrm{e}^f$，因此可以直接对每一位的占位多项式求 $\\exp$。第二种是按 $h(i)$ 从小到大处理，每次是一个子集卷积，时间复杂度也是 $\\mathrm{O}\\left(\\sum t^22^t\\right)=\\mathrm{O}(n^22^n)$。 $g_i=T_i\\left(\\sum_{j\\subset i}g_j\\right)$：也就是 USACO23FEBPlatinumT2。一种直观的思路是按最高位 01 分治，同时维护子集和数组。求完左边后更新右边，求完右边后更新子集和。另一种更加本质的思路是，考虑如何外层从小到大循环下标，求出子集和。为了防止计重，对于下标 $i$，考虑贡献它的 $j$ 与它最高的不同的位。那所求的就是形如 $s_{i,k}$ 表示第 $k$ 位及以上与 $i$ 相同，低于 $k$ 位的部分是 $i$ 的子集的所有 $j$ 的 $g_j$。这两种都可以 $\\mathrm{O}(n2^n)$，它们本质上是相同的（第一种将第二种的子集和数组压缩成一维了）。 一个小技巧是多次位运算卷积可以把 DFT 过的数组放着，最后再 IDFT 回来，能省个 $n$。另外，$(\\max,+)$ 位运算卷积应该只能做到 $\\mathrm{O}(3^n)$，可以用 Karatsuba 的思路。\n进一步的扩展详见浅谈集合幂级数和 EI 的 21 年集训队论文。\n关于 DFT 和类 Karatsuba 算法的设计详见 LCA 的 18 年集训队论文、梁晏成的 18 年集训队论文、hehezhou 的 22 年集训队论文。\n例 [UCup2Stage4] I. Interval Addition：问题可以转化成将和为 $0$ 的数划分成尽量多的集合，使每个集合和均为 $0$。令 $t_i$ 表示集合 $i$ 内的和是否为 $0$，初步来看转移为 $f_i=\\max_{j\\sqcup k=i}\\set{t_j(f_k+1)}$，是一个无法处理的半在线 $\\max$ 子集卷积，但由于 $f_i$ 也只有在 $t_i=1$ 时有效，结合相关性质，可以直接化成 $f_i=\\max_{j\\subset i}\\set{f_j}+t_i$，$\\mathrm{O}(n2^n)$ 解决。 [互测 2022] 整数：每一轮转移，相当于 dp 数组和允许选数的桶数组的一个复杂位运算卷积，且每一位的位运算不同，这取决于每个 $a_i$ 当前位的值。有两种运算，如果某个 $a_i$ 当前位为 $0$，那么桶数组这一位作后缀和即可转化为点积，否则相当于一个 and 卷积。 概率 \u0026amp; 期望 概率或期望 dp 有一个很经典的困惑是，为什么设计 dp 状态必须是“当前状态到达终止状态”的概率或期望，而不能是“从初始状态到当前状态”？\n这个问题的根源在于没有澄清 dp 的对象，而普通的计数 dp 是可以设计“从初始状态到当前状态”的 dp 含义的，这就导致初学者会习惯性地类推到概率或期望 dp，但这时转移是要乘概率的，这会导致转移意义与状态意义不符。\n首先，基于的模型仍然是 dfa，只不过转移边上带了个概率，dp 的本质还是统计所有路径。**先假定 dfa 无环。**概率 dp 如果设计“从初始状态到当前状态”其实是对的（设为 $f_i$），但是期望 dp 会有歧义：例如，设 $g_i$ 表示到达状态 $i$ 的期望步数，问题是初始状态可能不经过 $i$ 就到达终止状态。那 $g_i$ 到底表示的是一个条件期望（已知到达 $i$，这时期望的步数），还是前者乘上到达 $i$ 的概率（即所有初始状态到 $i$ 的路径的【长度乘概率积】的和）呢？\n设某个前驱状态为 $j$。如果 $g_i$ 是前者，那么 $j\\to i$ 转移不应乘这条边的概率（记为 $p_{j,i}$），而应该乘”$j\\to i$ 在所有转移到 $i$ 的情况中占的比例，即 $P(是j\\to i\\mid 到了i)$“，而这个玩意只能由 $\\dfrac{f_jp_{j,i}}{f_i}=\\dfrac{f_jp_{j,i}}{\\sum_k f_kp_{k,i}}$ 得到。如果 $g_i$ 是后者，那么转移加的常数就不是 $1$，而是 $f_i$。也就是说，无论如何都要同时计算 $f$。\ndfa 有环时，尽管转移类似，但是由于可能会多次到达状态 $i$，故状态的原定义出现歧义，只能改成”所有以当前状态为终点的路径的概率积和或期望和“（路径可能有无限条，但只需和收敛即可），而这个东西没有好的组合意义（甚至在概率 dp 里这个概率和可能 $\u0026gt;1$），就更难思考了。\n总之，硬要这样设计也不是不行，但如果设计成“当前状态到达终止状态”就可以避免这些问题，从而比较简洁地直接转移。这主要是因为除了不合法情况外一定会到终止状态且立即终止（废话）。\n关于概率或期望 dp 的技巧很少，有一个是某些计数问题题可以通过转成求概率或期望来简化转移公式，例如排列部分例 1~3。例 1\u0026amp;2 的换元形式的组合意义就是概率 dp，例 3 这类对于某些满足条件的结构的某个量计数的题，直接 dp 需要记方案数和总和，如果化成期望 dp，这个方案数就直接变成恒为 $1$ 的概率了，就只需记一个。另外一个好处是可以忽略结构中对状态没有影响的元素，直接找下一个有用的元素。\n期望 dp 的一个推广是鞅的停时定理的应用，主要用于计算多结构集合和多终止状态的随机过程的期望步数。这里就不深入了。\n例 CF1392H：（解 1）令一轮表示两次打乱间的所有操作。$f_{i,j}$ 表示剩余 $i$ 种牌没抽中过，当前轮还剩 $j$ 张牌，期望的剩余抽牌次数，转移很简单。题解区有些神仙直接通过这个利用待定系数法推出了正解。\n（解 2）$f_i$ 表示剩余 $i$ 种牌没抽中过（当前在轮与轮之间），期望的剩余抽牌次数。这个玩意相当于解 1 的断点转移形式，可以经过数小时的推导，利用组合恒等式和换元得到正确的线性公式。\n（解 3）涉及到处理期望的技巧： $$ E[抽牌数]=\\sum_{i}P(轮数\\ge i)E[第i轮抽牌数\\mid轮数\\ge i]=E[轮数]E[单轮抽牌数] $$\n注：这个东西不大符合直觉的原因是，如果恰好在第 $i$ 轮终止，那么这轮的期望抽牌数确实不是不带任何条件时的期望单轮抽牌数。但是这里是轮数 $\\ge i$，也就是说只要进入了第 $i$ 轮就算进，也就是第 $i$ 轮的所有情况都是等概率的。或者也可以从树状图的角度理解。\n其中 $E[单轮抽牌数]=n\\cdot P(某张牌在所有\\text{joker}之前)+1=n/(m+1)+1$。$E[轮数]$ 的计算有两种简单的思路：一是 min-max 容斥： $$ \\begin{aligned} E[轮数]\u0026amp;=E[\\max_{i=1}^n\\set{首抽i号牌的轮数}]\\\\ \u0026amp;=\\sum_{i=1}^n(-1)^{i+1}\\binom niE[首抽某i张牌中至少一张的轮数]\\\\ \u0026amp;=\\sum_{i=1}^n(-1)^{i+1}\\binom ni\\frac{1}{P(某i张牌中至少一张在所有\\text{joker}之前)}\\\\ \u0026amp;=\\sum_{i=1}^n(-1)^{i+1}\\binom ni\\frac{m+i}{i} \\end{aligned} $$ 二是令 $f_i$ 表示剩余 $i$ 种牌没抽中过（当前在轮与轮之间），期望的剩余轮数。这里就可以用上忽略无关牌的技巧了，也就是当前抽牌只可能是未抽中的或 joker，并且抽中非 joker 后可以当场把它忽略，即 $f_i=\\frac{i}{m+i}f_{i-1}+\\frac{m}{m+i}(f_i+1)$，解得 $f_n=1+mH(n)$。\nCF1823F：（解 1）$u\\ne t$ 时 $f_u=[u=s]+\\sum_{v\\mid(u,v)\\in E}[v\\ne t]f_v/d_v$，于是以 $s$ 为根每个点的 $f_u$ 可表示为 $a\\cdot f_{fa_u}+b$，然后再 dfs 一遍即可。不过这会有求 $0$ 的逆元之嫌。官方题解直接把 $f$ 的公式解出来了，我也是很被震撼。\n（解 2）（来源）令 $f_e$ 表示经过有向边 $e$ 的期望次数（$e$ 的反向边记作 $\\overline e$），对于 $s\\rightsquigarrow t$ 上的正向边，$f_e=f_{\\overline e}+1$，不在该路径上的边 $f_e=f_{\\overline e}$，另外一个点的所有出边的 $f$ 相等，递推即可。这个做法洞察到了更有效的数量关系。\nCF1437F：先排序。为了更好地理解计数转概率的优点，这里给出这题的四种 dp 方式。记 $#_I$ 表示大小在区间 $I$ 内的 $a_i$ 数量。\n$f_i$ 表示从后往前确定，当前在 $a_i$，$\u0026gt;a_i/2$ 的部分的方案数。这里使用插入法，枚举下一个峰值 $a_j$，将 $(a_i/2,a_j/2]$ 部分加入 $a_j$ 后面： $$ f_i=\\sum_{a_j\\ge 2a_i}f_j\\cdot(\\#_{(a_i/2,+\\infin)}-1)^{\\underline{\\# _{(a_i/2,a_j/2]}-1}} $$ 令 $g_i=f_i/\\#_{(a_i/2,+\\infin)}$ 即可后缀和优化。\n$g_i$ 表示剩余 $\u0026gt;a_i/2$ 部分待确定，当前结尾为 $a_i$，合法的概率。枚举在只考虑 $\u0026gt;a_i/2$ 部分时，$a_i$ 后面一个数 $a_j$，$(a_i/2,a_j/2]$ 必须在 $a_j$ 后面，相当于 $a_j$ 是剩余部分开头： $$ g_i=\\sum_{a_j\\ge 2a_i}\\frac{g_j}{\\#_{(a_i/2,+\\infin)}-1} $$ 这个 $g$ 就是 1 中的 $g$。\n$f_i$ 表示从前往后确定，当前在 $a_i$，$\\le a_i/2$ 的部分的方案数。这里使用预定法，枚举上一个峰值 $a_j$，第一个空位放 $a_i$，后面加入 $(a_j/2,a_i/2]$ 部分： $$ f_i=\\sum_{2a_j\\le a_i}f_j\\cdot(\\#_{(a_j/2,+\\infin)}-2)^{\\underline{\\#_{(a_j/2,a_i/2]}-1}} $$ 令 $g_i=f_i\\cdot\\#_{(a_i/2,+\\infin)}!$ 即可前缀和优化。\n$g_i$ 表示剩余 $\\le a_i/2$ 部分待确定，当前开头为 $a_i$，合法的概率。枚举上一个峰值 $a_j$，$(a_j/2,a_i/2]$ 必须在 $a_i$ 后面，相当于 $(a_i/2,+\\infin)$ 已确定并以 $a_i$ 为开头，现在和未确定的 $(a_j/2,a_i/2]$ 部分混合，要求开头是 $a_j$，并且第二个是 $a_j$： $$ g_i=\\sum_{2a_j\\le a_i}g_j\\cdot\\frac{\\#_{(a_i/2,+\\infin)}}{\\#_{(a_j/2,+\\infin)}^{\\underline{2}}} $$ 这个 $g$ 就是 3 中的 $g$。\n[THUPC 2023 初赛] 公平合作：这题很好地说明了，概率 dp 两种状态定义方式其实是通的。设先手倒入 $x$，后手倒入 $y$， $m=\\max a_i$，那么 $x,y\u0026gt;L-m$，目的是求每种可能的 $x$，后手的最优胜率 $f_x$。\n（解 1）按一般的思路，$g_i$ 表示先手目前倒了 $i$ 时的最优胜率，则 $g_i=\\max\\left(1-f_i,\\sum_jg_{i+a_j}/n\\right)$。对于 $i\\le L-m$，一定取后者，是一个线性递推。对于每个 $i$ 求 $f_i$，后手策略一定是 $y\\le i$ 时继续随机，$y\u0026gt;i$ 时停止，因此仍然是个线性递推。这些递推（包括 $g$）的公式均相同，待求远处项位置也相近（至多差 $m$），只是初值不同，因此利用倍增求线性递推数列一项的技巧，可以 $m^2\\log L$ 求得一个，然后 $m^2$ 推出其他。\n（解 2）计算某个 $f_i$ 是一个单起点多终点的 DAG 上游走问题，官解是令 $f^\\prime _{i,j}$ 表示从 $x=i$ 时，后手从 $0$ 开始，最终停在 $j\u0026gt;i$ 的概率（必须是在 $\u0026gt;i$ 是最先到 $j$，否则会计重）。$f^\\prime _{i}\\to f^\\prime _{i+1}$ 就转移一下 $f^\\prime _{i,i+1}$ 即可，计算 $f^\\prime _{L-m}$ 也可以线性递推。计算答案时也是考虑 $x$ 最终到几，$ans=\\sum_{i\u0026gt;L-m}f^\\prime_{L-m,i}g_i$。这个思路初看不大自然，但它其实就是正着定义状态的版本。\n数位 一般的数位 dp 无非就是在进位和压上界的处理上变个形，没什么可多说。\n关于全体 ${}+x$ 的最优化问题（例如 CF778E、ARC153D），考虑逐位 dp，记录进位的分界线。如果当前确定的是低 $i$ 位，那一定是所有数按低 $i$ 位排序后的一个后缀进位。转移时先基数排序，再枚举进位分解，得到下一位每种数占的区间，再枚举下一位。\n另一个值得注意的模型是，考虑函数 $f(S)=\\set{\\lfloor x/2\\rfloor,\\lceil x/2\\rceil\\mid x\\in S}$，那么 $f^{(i)}(\\set{x})$ 的大小至多为 $2$。这是因为 $\\lfloor\\lfloor x/a\\rfloor/b\\rfloor=\\lfloor x/(ab)\\rfloor$，故 $f^{(i)}(\\set{x})=\\set{\\lfloor x/2^i\\rfloor,\\lceil x/2^i\\rceil}$。如果考虑的是可重集合，那么 $f^{(i)}(\\set{x})$ 中恰有 $2^i-x\\bmod 2^i$ 个 $\\lfloor x/2^i\\rfloor$。这可以通过 $\\lceil x/2\\rceil=\\lfloor (x+1)/2\\rfloor$ 推得。\n例 CF1815D：$m\\ge 3$ 时显然可取到所有 $\\le n$ 且与 $n$ 奇偶性相同的数。$m=2$ 时考虑逐位 dp。如果 $n$ 最低位为 $1$，那么只有一种转移，否则可能两个数最低位均取 $0/1$，且由于这两种情况下剩余部分 $n$ 的奇偶性不同，故可取得的异或值一定不交，因此转移形如 $f_n=f_{n/2}+f_{n/2-1}$。无论如何，有效状态至多 $2\\log_2 n$ 个。可以用 map，也可以将状态理解成是否进位，开一维 $0/1$。\nAGC064C：暴力是把二进制表示倒过来建 trie 树，$f_u=f_{{ls}_u}\\operatorname{nand}f_{{rs}_u}$。建树的过程是如果当前要插入 $[l,r]$，就往左子树插入 $[\\lceil l/2\\rceil,\\lfloor r/2\\rfloor]$，往右子树插入 $[\\lceil(l-1)/2\\rceil,\\lfloor(r-1)/2\\rfloor]$，这立即启发我考虑，同一层内的不同构的子树数量少。确实是这样的：\n这是 $[11,21]$ 的 trie 树，发现每一层至多 $3$ 种子树。进一步地，对于第 $i$ 层（从 $0$ 开始）的 $x$ 号（编号定义为从根到它的路径的 01 序列反过来对应的二进制数）节点，$[l,r]$ 在它上面生成的子树为 $\\left[\\lceil(l-x)/2^i\\rceil,\\lfloor(r-x)/2^i\\rfloor\\right]$，也就是会将 $x$ 可以取的 $[0,2^i)$ 切成至多三段。那么 $n$ 个区间至多切 $2n+1$ 段。总体来说，逐层枚举，使用基数排序和指针扫描可以做到一个 $\\log$。\n树形 树形 dp 的套路基本上已经出烂了，可参考任轩笛的 18 年集训队论文和张哲宇的 19 年集训队论文。\n设计思路上基本就是考虑加一条边和合并两个儿子，把状态和转移定出来。比较初级的技巧包括换根 dp、多儿子选择时的反悔技巧、树上背包。其中树上背包如果强制大小与 $k$ 取 $\\min$ 的话时间是 $\\mathrm{O}(nk)$ 的，证明见下。\n还有一种 dp 方式是在 dfs 序上跳。\n例 CF1097G：考虑 $\\lvert E\\rvert^k$ 等于选出虚树中边的有序可重 $k$ 元组数量，这就可以树上背包，合并用组合数。对于底部选出的边，子树里至少选一个；如果有一条最顶部的边，那外部至少选一个。稍加讨论即可。$\\mathrm{O}(nk)$ 的证明可以考虑模仿一种树分块：子树 $siz\\le k$ 的点称为小点，剩余称为大点。每个极大的小点子树都是 $\\mathrm{O}(siz^2)$，由均值不等式至多 $\\mathrm{O}(nk)$。小点顶部转移给大点是 $\\mathrm{O}(siz\\cdot k)$，共 $\\mathrm{O}(nk)$。大点之间，两个大点合并为 $\\mathrm{O}(k^2)$，合并共发生 $\\mathrm{O}(n/k)$ 次，也是 $\\mathrm{O}(nk)$。 [APIO2021] 封闭道路=CF1119F：由于 $\\sum_k\\sum_u[deg_u\\ge k]=\\sum_udeg_u=n$，故可以暴力做。对于一个点，有一些 $deg\\ge k$ 的儿子，还有一些其他边。使用反悔技巧，断儿子的代价为 $f_{v,1}-f_{v,0}$。这些其他边不能全部排序，必须只取最小的 $deg_u-k$ 个来归并，从大到小枚举 $k$，用链表维护即可。 其他. CF868E\n区间 这部分不是指区间 dp，而是某些给定若干区间然后选的问题。这类问题较罕见，我尚未总结出较好的技巧，几个初步的处理方式是按某个端点排序，以及处理掉一些区间使得左右端点同时递增或只有包含和相离情况，典型的例子（非 dp 题）分别是 CF1774G 和 CF319E。\n例 CF1832F：对于一个人工区间，所有可能的自动区间与它配合导致的失守时间是一个斜率一次为 $1,0,-1$ 的分段函数，因此原问题是按 $(l_i+r_i)/2$ 排序后分段贡献，这就将二维化成一维，更好处理了。求一段共用一个自动区间的最优解是容易平方的，因为代价是凸的，离散化一下走指针即可。剩下的就是四边形不等式的形式 2，证一下四边形不等式即可。\nCF1250D：称不高兴的科学家为全同区间，容易发现全同区间形成一些内部同色的不交段。考虑按右端点排序后 dp，那致命的问题是在一个区间后面的区间可能包含它，无法确定后者是否全同。按左端点排序则能避免这个问题，状态只能记目前最后一个全同区间（否则也会信息爆炸），我们将会看到这个状态的隐含条件（与当前区间相交的区间均与它同色）十分重要。记区间为 $I_{1\\cdots n}$。若 $I_{i+1}\\subseteq I_i$，则继续往后看，注意不能转移到 $i+1$，否则会丢隐含信息。若走到了一个不是包含但有交的 $I_j$，如果决策它也是全同，那就无虑地转移过去；如果不这样决策，就继续扫，直到不交，后面就任选一个开启新的全同段。这个是 2D/1D 的，我感觉可以再优化，但不会。\n像这种区间问题就感觉很奇怪，一个合理的状态能给出极好的无关性。\n数学方法 GF 相关详见这里。\n这里讲些题外话。一些具体的数学处理方法详见下一章。\n我们无法找到一个通用的方法，判断解一道（计数）题设计 dp 和直接推式子孰优孰劣。推式子往往需要更透彻的对模型的分析（从而转化成能只用乘法原理描述的结构），但可以利用各种数学工具得到不依赖于组合意义的、更本质的解法，因此我们往往发现推式子后复杂度更优，例如 USACO21DECPlatinumT3，以及一些经典递推序列的通项等等。但情况也不全是这样，例如 [联合省选 2023] 染色数组 的第一问有一个 $\\mathrm{O}(nm^2)$ 的 dp，但推式子（应该？）只能做到 $\\mathrm{O}(n^3m)$。这两者的分界到底是什么？这是一个让我很困惑的问题。\n在 dp 题中，数学方法往往用于引导一些难以赋予组合意义的优化，例如 GF 等等。一些可以机械化的优化包括：矩乘相关（行列式、特征多项式、对角化等）、常系数线性递推、整式递推（详见 zzq 的 19 年集训队论文）。\n一维的递推数列已经基本上能解决了，但是二维的我目前找到这篇和这篇，或许依次处理两个方向即可？那我的互测题能否代数推导保平安呢？能否线性呢？\n另外一个方向是，常系数线性递推的快速幂+多项式取模方法意味着 $P(x)/Q(x)$ 的远处项可以快速求，于是可导出 $\\ln P(x)$ 的远处项也可以快速求。整式递推的点值平移方法给出了一类生成函数的远处项的根号做法。那其他的特殊情况的远处项呢？例如 $\\sqrt{P(x)}$ 和 $\\mathrm{e}^{P(x)}$？是不是扯得太远了……\n如果您对这些方面有了解，请不吝赐教。\n通用的解题方法 思考一道 dp 题的过程可以归纳为如下四步：\n分析模型性质，简化模型，揭开模型“真面目”； 处理模型，找到可以用 dp 解决的对象； 明确转化后的问题，设计 dp 方式； 优化 dp。 其中相邻两步之间没有明确的分界。同时思考过程并不一定是依次做这四个步骤就行了，可能在第四步时会返回到前三步，重新分析组合意义，反复寻找更优的 dp 方式。\n接下来就逐个讲解。\n第一步 分析性质 与其说这是 dp 的第一步，不如说所有题第一步都要做类似的工作。这一步主要是在不主动改变或加强模型的情况下，分析模型的性质，从而转化模型，使其更容易被把握。\n第一、二步的核心都是减少总体（静态）的模型可能性，区别在于，第一步是基于题目条件作有充分性的推导，明确在题目条件下未知部分的哪些情况是可能的，如何用更简单的命题描述；而第二步的目的性更强，会为了使结构能被 dp，更加激进地主动转化模型，改变原有的模型结构和要素组织方式，寻找一个具体的刻画，组织所有可能的解。\n这一步和贪心或无算法题的分析过程较类似，具体技巧千变万化，这里就简单讲一下基本的方法。\n在这一步中，主要思考以下内容：\n寻找可以直接从题目条件导出，或与题目条件等价的条件；\n模拟（包括打表）小样例、特殊样例找到简化的方向和规律；\n想象某个最终解，利用（广义的）调整法排除可能性，即“具有这样特征的解一定包含最优解”。更具体的技巧可以参考这里。这个思考主要用于最优化，但是其他类型的模型如果条件较复杂，交织在一起，也可以通过想象解，并调整或排除使之切合题目条件，得到对解的结构的直观认知。画非具体样例式的模型图是很有用的。\n另外，如果解是一个过程，有时倒推一些必要的东西会比较容易。\n联想一些与题目条件相关或类似的模型，尝试套用。\n具体来说，主要会得到以下两类观察：\n条件或模型的等价但更适合处理的转述。有的题有着非常晦涩的条件，通过分析或换角度描述，可以使它更容易处理。 结构、情况、过程的简化。这种简化不仅仅包含贪心性或排除性的简化，也包含对模型更深入的理解，将结构更明确、更简单地描述出来。算了比较难描述，还是看一些具体例子吧…… 例 [联合省选 2023] 染色数组：这题显然要将“划分成增减序列至少有两种方案”转化成更直观的条件，然后再 dp 或推式子。转化的分析详见题解区。\n[NOI2016] 国王饮水记：如果任选子集，那完全无法处理。考虑挖掘性质：① $h_1$ 一定递增；每次选一定包含 $h_1$；除 $h_1$ 以外，其他的一定至多选一次；② 每次选的 $h$ 中 $\\max$ 一定 $\\le$ 下一次选的 $h$ 中 $\\min$；③ 将 $h_{2\\cdots n}$ 排序，每次一定选连续一段，且相邻两次选的之间一定无空隙，且最后一次一定选到末尾。这样分析完之后 dp 自然就出来了。后面进一步的除决策单调性以外的优化其实也是基于对原问题模型的分析（长度不为 $1$ 的区间很少）。\n注：① 得三个子性质一起归纳，每次调整最后一个不满足性质的，不然是无法严谨证明的；②③ 可以直接反证法+调整。参考官方题解。\nCF1368H1：题目是以最大流的语言给出的，但如果只从最大流或最小割的角度来看是无法简化结构的，必须要考虑对偶图最短路——参考 [CSP-S 2021] 交通规划，模型等价于所有红蓝交替处作为端点，两两匹配（奇偶性必须不同）求最短路之和。本题中 $n,m$ 很大，但由于边权都是 $1$，故只需保证路径长等于曼哈顿距离即可。可以将矩形邻边上的匹配贴到边界上，对边上的匹配拉直（只会有一组对边上匹配），简化了结构。但这样的匹配还无法 dp，必须将该性质用最小割的语言描述——每行或每列颜色均相同，然后即可线性 dp。\n这题是非常典型的不断转化等价模型并观察，从而找到突破性质的题。\nCF906C：注意到选的点集导出子图一定是连通的（否则选的点之间会无边），同时易证选这个操作其实是无序的。这两个观察使模型清晰了很多。问题就转化成选一些连通的点使得它们的邻点并集包含所有未选点。按 bfs 的顺序状压 dp 即可。\nCF1503E：考虑蓝色的区间从上到下的移动情况，如果相邻两行不交则称为“断”。发现至多断一次，即蓝色形成 $1/2$ 个连通块，否则一列中的黄色会被割裂。如果是两个连通块，则一定分别是单峰的，否则黄色部分一定是两个单峰的连通块。这题可以直接推式子算。\nUSACO22DECGoldT1：想象最终选的朋友，发现 $B$ 一定花给这些朋友按 $X$ 排序后的前缀。于是按 $X$ 排序后背包，一定是先花 $B$ 再花 $A$，三维 dp 转成两个两维 dp。\n第二步 处理模型 （第一、二步往往是连续进行的，尤其是一些没有固定形式的转化和抽象过程，很难说清属于哪一步。）\n这一步中应当完成对静态模型的处理，将其彻底转化成可以 dp 的模型，并用更本质的语言去描述它，用更有效的角度去看待它，并在最后进行汇总。注意，这里的“静态”是与第三步的 dp 生成过程（局部）形成对照，并不是说模型本身必须是静态的，而是从一个整体的角度看待模型。\n您可能还不是很明白。可以类比推式子题来理解——当我拿到一个计数模型，一般不能直接写出式子，而是要考虑：要先转化等价模型吗？是否要套容斥或反演？该对模型的哪个部分计数，这些部分如何组织？枚举什么量，枚举顺序如何？等等。这些问题的答案共同构成了处理一个模型的具体思路，然后再写式子。\n要寻找处理模型的方法，固然对于某些有特定特征的题可以套用一些转化技巧，接下来也会讲；这里我先提出一个通用的思考方法：考虑模型的“要素”。要素，一般是模型结构的组成部分、相关量或维度。一个模型包含多个要素，要素之间的关系就是题目条件和描述，以及导出的性质。通过改变（增删、合并、拆分、等价转述）要素，调整这些要素的主次关系、自变量与因变量关系（包括无关、守恒等特殊关系）、组织顺序（例如有两个维度，先看哪个，或者时光倒流等）、枚举顺序等，得到一个新的看待模型的方式。在新的模型描述下，所有解应与原模型的所有解形成一个映射（双射）。至于如何判断转化是否有用，那就还是从信息量（不确定性）的角度考虑。\n一个最简单的例子就是上文中排列部分前两题，原模型是一个排列，但排列中各个元素的效果不同。现在只关心其贪心单调子序列这一部分要素，剩余部分通过组合数，也就是数学方法消除掉。\n例 [CSP-J 2019] 纪念品：这题的关键在于拆分“纪念品的持有时间区间”这一要素，将它拆成相邻两天之间是否买进卖出，这样各天之间的决策就无关了，逐天背包即可。\nCF1580D：这题难处理的是一堆区间 $\\min$ 这个东西，考虑搬到笛卡尔树上，全局 $\\min$ 的贡献就变成了左右选的数量之积，往下递归形式是一样的，dp 状态自然就出来了，树上背包即可。这题就是寻找一个更好的结构，转述要素（注意和第一步中的套用模型是不同的，这里考虑笛卡尔树不是为了进一步发掘性质，而是直接尝试 dp 了）。\nAGC056E：先固定没吃的老鼠。从时间维看该过程是没法多项式时间的。考虑一起看所有奶酪的轨迹（轨迹包含投掷初始位，多次尝试被吃和最终被吃三个部分），注意到如果有多块奶酪经过一只老鼠，它们后续的轨迹之间是可以交换的，也就是说只需保证同一块奶酪按顺序依次尝试被吃即可，多块奶酪之间的尝试是无序的，因此就可以从下标维来看轨迹，dp 记录当前已确定的奶酪数 $x$，每次以 $1-1/2^x$ 的概率吃。然后问题就在于它这个过程是无限的，但是只要所有奶酪确定了，就可以用数学方法算剩下的无限圈了。题解区第一篇的考虑方法很有意思，再将问题转化回逐个奶酪移动，这样概率就变成了一个乘积式。\nCF1842H：初始的题目模型无法处理，考虑将所有 $x_i$ 减 $0.5$ 后转化成一堆 $x_i\\;\\boxed{\u0026lt;/\u0026gt;}\\;{-x_j}$ 形式的偏序关系。想象数轴上这些 $\\pm x_i$ 的分布，$O$ 的两侧是对称的两半，直接 dp 一半发现得记已确定的变量和它的正负情况，那就得 $3^n$。但细看发现很多状态不合法，因为例如 $x_i+x_j\u0026lt;0$，那么 $x_i$ 与 $x_j$ 中绝对值大的一方必须 $\u0026lt;0$，因此只要按绝对值大小 dp，就只有那些最先（或最后）（相对于它所受约束的其他相关变量）确定的变量可能正负不定，但这些正负不定是无所谓的，而其他变量的正负都可以通过当前的已确定 bitmask 推得。从拓扑序角度也可以得到符合直觉的解释。\n这题不仅考察对模型的处理，还要求转化后不遗忘原模型的对称性质，再次回到第一步进行性质分析。\n补充一下，并不是所有对模型的处理都要进行转化，导致 dp 困难的往往是对模型的理解不够本质。所以不要急于改变要素，要先看清所有要素。\n例 USACO21DECPlatinumT2：显然配对端点同时递增。$T=1$ 利用扩大可行域技巧即可。$T=2$ 时，我当时执意考虑按从小到大扫一类牛的顺序 dp，这样直接做得记录当前对以及上一个（或两个）未配对牛以保证极大性，如果要避免第三维就得在出现不选时断点转移到下一个不必要考虑之前未配对牛的状态，但这样中间的讨论就炸飞了。我犯的错误是没有全局观，应当同时观察两类，这时不选的牛的品种随坐标增加在两种之间交替，且交替处间隔多余 $K$。因此得到了一个新的方案：记录当前两类待配对的下标，以及当前允许不选的品种。如果要更换品种就进行一段选满的断点转移，合法性可以预处理。\n其实可以发现，后面这种观察方式说的其实都是废话，也没有转化模型，但是若不这么考虑就是没法 dp。所以角度很重要。\nCF1299D：首先要知道 dfs 树上所有返祖边对应环构成所有可能回路经过奇数次的边（若干不交简单环）的异或空间的一组基，相应地只考虑边权也是一样。因此可以把根伸出的各块每个视作一组异或空间。这里要将 $5$ 位异或空间及其合并运算一起视作一个交换半群（元素个数为 $374$，详见 A006116），再分讨根周围的块：要么与根连一条边，要么与根形成三元环，然后就做一个类似背包的东西即可。\n这题的关键在于把线性基合并抽象成代数运算。\n然后是一些特定的转化技巧。\n外套方法 这类方法直接作用于变量，主要包括枚举、二分（仅限最优化）和容斥（仅限计数）。二分主要包括二分答案和 WQS 二分（入门、进阶），容斥其实就是各类反演（炫酷反演魔术，还可以参考周子衡的 23 年集训队论文），不过建议推导时不要丢掉组合意义，不然可能会漏性质或失去动机。枚举和二分答案的实质就是减少不确定性，WQS 二分和容斥的实质就是去除或弱化变量限制条件。\n例 CF1784E：只考虑 $\\Delta$ 表示 A 赢减 B 赢（经典套路）。这题大致的模型是，把循环节理解成一个黑盒，循环连接处只需提供少量信息即可确定整体的 $\\Delta$。具体的接口抽象方式有两种：一种是考虑每个开头忽略 $0\\sim 2$ 个后，结尾还需在下一次循环中取几个。这个必须要枚举开头两个字符。另一种是将比赛过程抽象成四个点的 dfa，考虑开头时的状态和结尾时的状态。\n这里就出问题了，将每种情况 $\\Delta$ 记在状态里，势必会导致 $n$ 的较大次方（且事实上即使利用各情况的 $\\Delta$ 间关系也不足以将次方缩得足够小）。而反复循环的接口处状态实际上构成基环树形态，结合题目所求，只需关注基环部分状态的 $\\sum\\Delta_s$。那就枚举基环所包含的状态集合，这样 dp 只用记状态之间的转移关系用于吻合枚举的情况，时间复杂度大常数 $\\mathrm{O}(n^2)$。\n[IOI2016] Aliens：可以将兴趣点转化成区间。对于不限制 $k$ 的情况，首先有一个 $\\mathrm{O}(m^2)$ 的 dp，似乎不大能优化。考虑将 dp 对象转为区间（按右端点排序），或者发现只有右端点位置的 dp 值有用。列出 dp 方程发现可以四边形不等式优化或斜率优化。另有性质：答案关于 $k$ 下凸（用四边形不等式证），WQS 二分即可。细节详见官方题解。\nCF1707D：直接 dp 得记每个时刻是否选真子集，爆炸了。令 $f_i$ 表示 $i$ 次内消得只剩根的，允许单次不变的方案数，$g_i$ 表示原答案，那么 $f_i=\\sum_{j=1}^i\\binom ijg_j\\Rightarrow g_i=\\sum_{j=1}^i(-1)^{i-j}\\binom ijf_j$。$f$ 可以通过最自然地 dp 子树 $i$ 在 $j$ 步以内消光的方案数得到。转移时枚举根何时消去，消去后仍允许一个子树剩余。方程的主要部分形如 $f_{u,i}=\\sum_{v}f_{v,i}\\left(\\sum_{j\\le i}\\prod_{w\\ne v}f_{w,j}\\right)$，可以前后缀积优化。\n（相互再归的鹅妈妈）：不容斥没法搞。容斥后的计数有两个思路，一个是无序（强制不降），一个是有序。无序得状压；有序可以只记压上界的数量，进一步考虑到一旦有不压上界的数就选出一个用于凑 $0$，从而用公式计算，应该可以做到 $\\mathrm{O}(m)$，但是容斥起来麻烦些。一种思路是直接对于两两不相等的条件容斥，枚举钦定相等形成的等价类，设大小 $a_{1\\cdots k}$，容斥系数为 $\\prod f(a_i)$，$f(n)$ 表示所有 $n$ 点连通图的 $(-1)^{\\lvert E\\rvert}$ 之和，有 $[n=1]=\\sum_{x_1+\\cdots+x_m=n}n!/(m!\\prod x_i!)\\cdot\\prod f(x_i)=[x^n/n!]\\mathrm{e}^{\\operatorname{EGF}(f)}$，从而 $f(n)=[x^n/n!]\\ln(1+x)=(-1)^{n-1}(n-1)!$。这部分理论上可以做到 $\\mathrm{O}(k\\log k)$。\n[互测 2023] Permutation Counting 2：欧拉数的和式推导可谓非常经典——钦定连续上升段，段间无法保证下降，就用二项式反演容斥：钦定 $i$ 个上升段的情况，会将恰好有 $j$ 个上升段的情况计入 $\\binom{n-j}{i-j}$ 次。具体推导就不写了。那这道题这样容斥后就转化成，求 $q_{1\\cdots n}$ 数量，满足 $1\\le q_k\\le i$，$1\\sim i$ 中每个数至少出现一次，且 $q_k\\le q_{k+1}$ 恰好有 $j$ 个。 “每个数都出现”这一条件可以套容斥，规定上升数可以再一次容斥，内层就变成了简单的非空不降序列。最内层的容斥可以推出一个线性的类似欧拉数的求和式，再依次进行剩余两层容斥就行，$\\mathrm{O}(n^3)$。\n这里补充一下。个人感觉二项式反演很费脑，考试时建议把正向的式子写出来然后直接套结论（如果形式不对就换元），但平时还是尽量在脑中过一遍组合意义，还是很精妙的。\n其他. +CF663D、+CF1799G、判定型计数里的一些题、+[NOIP2018] 赛道修建、CF1322F、CF739E、CF1799F\n公式变形 这个就不必解释了。\n例 CF946F：（解 1）对于所有子序列，求出 $s$ 出现的次数，那实质上就是在 KMP 自动机上走，每遇到一个字符允许不走。矩乘描述即可。\n（解 2）考虑交换解 1 中的两个 $\\sum$，对于 $F(x)$ 中所有的子序列 $s$，设开头在 $l$，结尾在 $r$，那贡献为 $2^{l-1+n-r}$。令 $f_{i,l,r}$ 表示 $s_{l\\cdots r}$ 几次作为子序列出现在 $F(i)$ 中，特殊地，若 $l=1$ 或 $r=n$，就同时算上外部的 $2$ 的次幂。\nCF856C：数字 $x$ 可抽象为 $(x\\bmod 11,\\operatorname{len}(x)\\bmod 2)$，方案中一个数的贡献取决于它所在数位的奇偶性，得考虑顺序，但无法直接 dp 排列。只能考虑先 dp 每个数所在位的奇偶性，然后再用数学方法算。$\\operatorname{len}$ 为奇的恰好一半一半，偶的任意插空，先分开 dp，再合并。\nUSACO23OPENPlatinumT1：将子序列匹配理解成自动机上走，可以得到一个矩乘表示，但是得记 $7\\times 7$ 太大了。考虑抽象成一维的表示。线段树上每个节点记录：① 每种状态经过该区间后的状态；② 每种状态经过该区间且在该区间内终止的贡献；③ 每种状态经过该区间且尚未终止（走到右端点）的贡献；④ 在该区间内起始且尚未终止（走到右端点）的新增各状态数；⑤ 在该区间内起始且在该区间内终止的贡献；⑥ 在该区间内起始且尚未终止（走到右端点）的贡献。要把区间内终止和尚未终止（走到右端点）分开来记是因为往后延伸的话会贡献多次。\n以上是我考试时的做法，后来看题解发现可以只记四类信息：将 ② 和 ③ 合并成 $②+(n-r)\\cdot ③$，⑤ 和 ⑥ 同理。为什么我写复杂了？因为我是按题意原样做的，而合并实质上是对于每一组（区间开头，一组匹配）分开看它们的贡献，出现一组匹配后后面结尾在哪是无关的，直接乘 $n-r$ 就行。所以说对初始模型理解的细微差别可能导致实现时复杂程度的大差距。\nUSACO20OPENPlatinumT2：（解 1）考虑对于每一个 $p^k$ 计算有几个置换中包含至少一个长为 $p^k$ 倍数的环 $\\bmod(M-1)$。令 $f_i$ 表示大小为 $i$ 时，有几个不包含。转移模仿第一类斯特林数： $$ f_i=\\sum_{p^k\\nmid j}(i-1)^{\\underline{j-1}}f_{i-j} $$ 由于模非质数故无法换元，但可以记前缀和每次乘 $(i-1)$。可以利用同余技巧，通过对 $i\\bmod{p^k}$ 分组记和做到单次 $\\mathrm{O}(n)$。\n（解 2）（来源）：钦定 $c$ 个长为 $p^k$ 倍数的环，是普通容斥，系数 $(-1)^{c-1}$。$f_i$ 表示钦定 $ip^k$ 个数（环数不记，直接压在一起）的和： $$ f_i=-\\sum_{j=1}^i\\left(ip^k-1\\right)^{\\underline{jp^k-1}}f_{i-j}\\\\ ans\\xleftarrow{\\times}\\operatorname{pow}\\left(p,\\sum_{i\\ge 1}n^{\\underline{n-ip^k}}f_i\\right) $$ 总状态数是 $\\mathrm{O}(n\\log\\log n)$ 的，可以用 ds 优化连乘。\n[WC2021] 表达式求值：这类涉及大小关系的问题常考虑 $01$ 情况。数组逐位做，设当前 $a_{*,j}$ 排序成 $x_{1\\cdots m}$，将其差分，答案转化成 $\\sum_{i}(x_i-x_{i-1})[E([a_{1,j}\\ge x_i],\\cdots,[a_{m,j}\\ge x_i])=1]$（这个套路也往往在算期望时用），这时所有叶子只有 $2^m$ 种分布情况，且 dp 可转移。\n判定型计数 判定型计数问题主要指一类直接对着题目合法条件 dp 会导致同一个解被重复计入的问题（广义地说，所有计数都是判定型的，但显然这不是这里希望讨论的）。这类问题的通用处理方法有四类：转述条件（例 9\u0026amp;11）、钦定单射（例 1\u0026amp;4\u0026amp;5）、容斥（例 4\u0026amp;7）、对判定过程 dp（例 2\u0026amp;3\u0026amp;6\u0026amp;8\u0026amp;10\u0026amp;12）。转述条件就是将判定条件能转化成对解本身更简单的限制，然后强制直接对解 dp。钦定单射主要指对于一个合法解的多个证书，通过规定偏序关系等方式，钦定唯一一个被计入的证书，来 dp。对判定过程 dp，如果判定过程是 dp，那就是常说的 dp 套 dp。也可能是贪心等其他算法，不一定要是 01 的判定过程。有些非判定型计数问题（不易计重，但也不易直接 dp）也会用这个技术，例子都放在这里。\n另外某些简单的问题可以记录一维 $0/1$ 表示是否存在至少一个达成的方案。\nremark. 钦定单射和容斥在论文中统称带权计数，注意两者的区别。例 4 不能理解成对计重容斥，因为并没有某组 $A/B$ 选择贡献了负数，用论文中的话来说就是没有 $w(y)\u0026lt;0$。这题的容斥只是为了保证有且仅有 $w(独立区间均选A的方案)=1$。而例 7 是实打实的容斥，这题不能把 $Y$ 看作 $1\\sim n$，而必须看成 $1\\sim n$ 的所有子集，不然“计同时能被多个下标满足的方案数”这个事就没法解释了。当然讲的这些在实操时没必要刻意区分。\n例 CF1679F：这题虽然不是判定型的，但也易计重，用到了钦定单射的思想。考虑只对每个等价类的极小元素计数，极小元素定义为，每个数字 $d_i$ 向前看，都有一段相邻的可以交换的数（然后遇到头或一个不能交换的数），这些数都要 $\\le d_i$。这个极小元素是存在且唯一的，可以借助字典序这一偏序结构证明。于是可以状压 dp，记录当前位可以取的数。\nCF1810G：这题也不是判定型，但是官解（解 2）用到了对判定过程 dp 的思想，故也放在这里。\n（解 1）我的思路是，考虑固定前缀和的 $\\max$。$f_{i,j}$ 表示 $s_i$ 将前缀最大值刷新为 $j$ 的概率，这可以通过有限制折线的经典容斥来转移：$f_{i,j}=c_{i,j}-\\sum_{k\u0026lt;i}c_{i-k,0}\\cdot f_{k,j}$，其中 $c_{i,j}$ 表示 $i$ 个 $\\pm 1$ 和为 $j$ 的概率。$ans_{i}=\\sum_j(h_{j-1}-h_j)(1-\\sum_{k\\le i}f_{k,j})$，发现可以令 $g_i=\\sum_j(h_{j-1}-h_j)f_{i,j}$ 将所有 $f_{i,*}$ 压缩成一个数同时仍能转移，从而变成 1D/1D。常数较大。\n这个方法的大致思想是，直接 dp 需要记当前的和与总的 $\\max$（都会变），尝试省掉一方，那就固定 $\\max$。最近又去看了一下题解区，发现这篇题解虽然不是容斥，但是也同时用了“固定 $\\max$”和“多个 dp 合并起来做”这两个思想，饶有趣味~~（如果您能给出对这类技巧更宏观的解释，请告诉我）~~。\n（解 2）考虑寻找一个不需要记三次方状态的求最大前缀和的方法，然后对该方法 dp。一个脑洞大开的想法是，从后往前扫，只维护求最大子段和时的 now 变量（含当前位置的最大和），当 $\u0026lt;0$ 时丢弃，置成 $0$。\nCF924F：求划分最小差只能用背包，可以证明背包只需开到 $72$，这时状态数只有 $12880$ 个。通过合并等价状态可以达到 $715$ 个。然后就是一个数位 dp，预处理 $f_{k,i,s,r}$ 表示限制差 $\\le k$，$i$ 位待定，当前 dfa 上状态为 $s$，当前位至多取 $r$ 的答案，即可 $\\mathrm{O}(T\\log r)$ 回答。\n这里用到了 dp 套 dp 中两个核心技巧：只 bfs 可能被达到的状态和合并等价状态。其中后者也是 SAM 的思想来源。两种朴素的合并方法是哈希（求出每个点向后 $C$ 层的状态，取一个合适的 $C$）和连锁合并（先合并出点编号完全相同的，再不断找新的可以合并的，缺点是有两个完全相同的环时无法缩）。\n关于 $72$ 的证明与最小 dfa 的求法（Hopcroft 方法）详见徐哲安的 21 年集训队论文以及我的题解。\nAGC061C：这题涉及两个对象的关系：$A/B$ 之间的选择以及得到的排列，多个选择可能对应同一排列。考虑计重如何发生，直觉上来说形如一个区间内没有其他端点被选（称为独立区间），然后它分别选两个端点，并且容易想到对于每个独立区间，钦定它必选 $A$。但是为了保证这样，dp 时就要记上一次选 $B$ 的位置，至少平方。考虑容斥，钦定若干错误（独立区间选 $B$）选择，它们必然不交，且由输入性质，不存在与它们都有交的区间（否则就会两头均无法选），从而，只能选一端的区间数量为与每个钦定独立区间有交的区间数之和，只需要前缀和优化即可 1D/0D。可以把这个设计理解成先钦定单射（选择的字典序尽量小，只记）再容斥，也可以理解成直接对计重容斥。\n这里的钦定单射还要严谨证明正确性：如果有两个选择方案，它们的独立区间全选了 $A$，却仍然生成了相同的排列，那么按排列中的顺序，找到第一个选择得不同的区间，这个区间不能是独立区间，那么它内部被选的其他端点必然会导致两个排列不同，矛盾。\nAGC056B：这题是排列映射到 $\\operatorname{argmax}$ 序列。考虑计重的特征，换句话说，考虑一个 $\\operatorname{argmax}$ 序列对应的所有原排列的刻画。模拟样例发现，直觉上有多个“局部最大值”，它们互不影响，那么原排列任意换这些位置的相对大小，这时会计重。将直觉严谨化，如果所有包含位置 $i$ 的区间的 $\\operatorname{argmax}$ 都取到 $i$，那么可以 $p_i=n$。钦定单射，若有多个 $i$ 就取最小的，这样易证不会计重。将这些区间去掉后可以得到形式基本相同的子问题，唯一的限制的是左侧不能再出现上述的 $i^\\prime $，即规定左侧的最大值必须取在某个包含 $i$ 的区间内，即属于一个后缀。这可以做到 3D/0D。\nUSACO22FEBPlatinumT3：考虑如何判定一个序列 $t$ 能被原序列 $s$ 生成。$f_{i}$ 表示 $t_{1\\cdots i}$ 能否被 $s_{1\\cdots i}$ 生成，除了 $s$ 中的元素，$f_i$ 还依赖于 $f_{i-1},f_{i-2},f_{i-3},f_{i-4},t_{i-1},t_{i-2},t_{i-3}$。dp 套 dp 的常数不得上天？考虑对记的状态剪枝：只有 $f_{i-4}=1$ 且 $\\set{s_{i-3\\cdots i}}$ 合法（为四种 $2\\times 2$ 之一）且 $\\set{t_{i-3\\cdots i-1}}\\subset\\set{s_{i-3\\cdots i}}$ 才有必要记 $t_{i-3}$，这时只有 $24$ 种可能；否则考虑 $\\set{s_{i-2\\cdots i+1}}$，$\\set{t_{i-2\\cdots i-1}}$ 有 $12$ 种；否则 $9$ 种。我的实现是不考虑 $f_{i-*}=0$ 的剪枝，这样共有 $15\\times 45=675$ 种状态。应该可以进一步缩，可能也能套用 dfa 的通用缩状态技巧（加之删去只能到达非法状态的状态），但是转移边得同时定 $s_i$ 和 $t_i$，这不如直接剪枝（还可以利用 $s_{i+1}$）。像这种判定条件由输入给定的情况建议直接结合组合意义缩状态。\nremark. 这题也可以跑缩 DFA，结果也很优秀，详见论文，劲爆代码。\n[NOI2021] 机器人游戏：这题求的是有几组 $(\\set{X_i},\\set{Y_i})$ 能被至少一个初始位置 $p$ 生成，那就容斥，枚举初始位置的集合，会得到每一个格子的方案数，暴搜或 dp 即可。后续分两类处理与 dp 无关，略。\n同样使用容斥处理计重的还有 [十二省联考 2019] 希望，利用树的连通子图点减边 $=1$ 的特性。\n[互测 2023] 栞：考虑求 $f_k(p)$ 的方法，存在一个简单的贪心——容易证明 $f_{k}(p)\\le f_{k+1}(p)$，因此每次对于所有可能的第一段，选择排序后的最小者（如果 $s$ 是 $t$ 的真前缀则 $s\u0026lt;t$），然后递归做。这个“第一段”的等价叙述是 $p_{1\\cdots n-k}$ 中相对值域取到前缀的最小前缀。好，现在还是不能按照 dp 套 dp 的思路死板地逐位确定，而是考虑直接对贪心决策 dp，用数学方法求决策前缀部分的方案，用延后决策技巧处理决策以后的有限制的部分（即后面到 $p_{n-k}$ 为止都不能有小于前面的数）。\n但是延后决策毕竟要记一个下界，还是比较麻烦，考虑结合条件进一步分析。设 $q$ 的第一个上升段是 $q_{1\\cdots l}$，那么 $p_l$ 处一定会分段。设进行以 $l$ 结尾的这一段的决策时，最右可选为 $p_{l^\\prime }$，如果 $l^\\prime =l$ 那就没事了。否则 $p_{l+1\\cdots l^\\prime }$ 都得大于 $q_l$，且下一段最右可选为 $p_{l^\\prime +1}$，又由于 $q_{l}\u0026gt;q_{l+1}$，故 $p_{l^\\prime +1}$ 必须 $=q_{l+1}$，且 $\\set{p_{l+1\\cdots l^\\prime }}=\\set{q_{l+2\\cdots l^\\prime +1}}$，这又表明 $q_{l+1\\cdots l^\\prime +1}$ 必须是上升段且除了 $q_{l+1}$ 外其余都大于 $q_l$。这一连串的推理表明除非在 $p_{1\\cdots l}$ 就把 $k$ 用得只剩 $1$ 或 $p=\\iota$，否则答案应当是 $f$ 中某一段卷上阶乘之和，这里 $f_i$ 表示 $l$ 排列中按照贪心分段恰好分 $i$ 段的数量，为 A003319 的 GF 的 $i$ 次方的 $x^l$ 次项。\nCF1762F：考虑 $a_l\u0026lt;a_r$ 时 $(l,r)$ 好的条件。发现：① 子序列一定是递增的；② 贪心往大的取，到了 $r$ 时如果能到 $\\ge a_r$ 的值那么 $(l,r)$ 就是好的。这就在多个子序列中找到了“极大”的一个，然后再将 $=a_r$ 转化成 $\u0026gt;a_r$。这时可以维护目前贪心可以到达每个值的 $l$ 数，问题转化为区间求和，区间清空，单点改。\nPA2021R1T1(lgP8386)：判定型 dp 是 $f_i$ 表示前 $i$ 个能否消光，$f_i=\\bigvee_{j\u0026lt;i}[a_j=a_i]f_{j-1}$。关键在于计数时不必记录每一个 $f_i$，而是考虑记录 $\\lvert\\set{a_{i+1}\\mid f_i=1}\\rvert$，那状态就是 2D 了。现在剩下一个问题：如果当前 $f_i=1$，那么更新这个 size 就得枚举 $a_{i+1}$，然后就得不停地连锁枚举了怎么办？可以多记一维 $0/1$ 表示上一位 $f_{i-1}$ 是否等于 $1$，枚举当前 $a_i$ 时再更新 size。可以理解为延后决策。\nAGC064D：考虑如何判定。可以将最终从底向上写的序列理解成一棵树的 dfs 序对应的字符，这棵树编号满足大根堆性质，且儿子从小到大排序，且非叶子对应的字符均为 B。考虑从大到小生成这棵树，每次加一个叶子。现在回到序列角度，相当于初始有个 B，倒扫，每次将当前字符插到某个 B 后面。可以将一个 B 及其后面连续 R 看作一个整体，用单个变量表示后面有几个 R，那么对原序列的插入可以理解成对变量序列 $x$ 的操作：插入 R 就是某个 $x_i\\xleftarrow{+}1$，插入 B 就是在非末尾插入一个 $0$。设 B 有 $b$ 个，那么合法条件就是若干不等式：$x_b\\ge$ 某个值，$x_b+{}$前 $b-1$ 个中最大值 $\\ge$ 某个值，$x_b+{}$前 $b-1$ 个中最大值 $+$ 次大值 $\\ge$ 某个值，等等。那这就和 CF1740F 很像了（只不过这题有序）。$f_{i,j,k}$ 表示前 $i$ 大，和 $j$，目前考虑值为 $k$。$x_b$ 单独决策，作为初值。转移得枚举为 $k$ 的数量，复杂度 $\\sum_i\\sum_j\\sum_{k\\le j/i}(n-j)/k=\\sum_j\\sum_k(n-j)/k\\sum_{i\\le j/k}=\\sum_j(n-j)j\\sum_k 1/k^2=\\mathrm{O}(n^3)$。\n这题难点在从后往前考虑。我所考虑的 dfs 树其实就是帮我想到倒过来考虑的一个跳板而已。\n[CTT2023] 黄焖鸡：判定方法是，扫描右端点，维护每个左端点的 $(f_0,f_1)$ 表示当前位不选/选，选减不选的最大值，新加一个数 $a$，$(f_0,f_1)\\circ a=(\\max(f_0,f_1)-a,f_0+a)$。如果 $\\max(f_0,f_1)=0$ 就爆了。组合性质或归纳易证以下性质：$f_0+f_1\\ge 0,\\lvert f_0-f_1\\rvert\\le 2m$。考虑什么样的对没前途，即永远不会导致不合法。$f_0\u0026gt;0$ 肯定不用管；假设后面又接了一段序列，奇数项和为 $s$，偶数项和为 $t$，$\\max(f_0+s-t,f_1+t-s)=0$ 必须有可能出现（不可能 $\u0026lt;0$），综合 $f_0+f_1\\ge 0$，得到 $f_0+f_1=0$，这时只需后面加一个 $f_1$ 就爆了。因此只有 $(-1,1),\\cdots,(-m,m)$ 有必要记，可以状压。转移形如：要求第 $i$ 位为 $0$，将低 $i-1$ 位 reverse，第 $i$ 位置 $1$，其余置 $0$，容易感知到一个 $2^m+2^{m-1}+\\cdots$ 的去掉一个 $m$ 的突破口，用一个类高维前缀和优化填表法即可 $\\mathrm{O}(n2^m)$。\n其他. [NOI2022] 移除石子、[ZJOI2019] 麻将\n第三步 设计 dp 这里首先要排除掉非生成类 dp 也就是一般的递推式的设计方法。这类问题难点单一，关键在于找到一个封闭（可以转移）的状态描述，然后填表即可。技巧性不强，因此后文不讲。\n例：\nCF1778D：$f_i$ 表示有 $i$ 个 $1$ 的答案，$f_i=\\frac{i}{n}f_{i-1}+\\frac{n-i}{n}f_{i+1}+1$，有点难解。整理得 $i(f_i-f_{i-1})=(n-i)(f_{i+1}-f_i)+n$，换元 $g_i=f_i-f_{i-1},g_n=1$，然后递推即可。\nCF1667E：（解 1）$u$ 为重心，一方面 $u$ 子树以外的点 $\u0026lt;n/2$ 个，另一方面 $u$ 的每个子树大小均 $\u0026lt;n/2$。重心又唯一，故考虑容斥。$siz_u\u0026gt;n/2$ 的方案数 $f_u$ 容易算，然后答案 $g_u=f_u-\\sum_{v\u0026gt;u}g_v/u$。这个 ${}\\div u$ 可以从概率的角度理解——$v$ 是否为重心与前 $u$ 个点树形无关，且可以将前 $u$ 个点视作不可区分的，故 $P(v为重心\\mid v在u子树中)=1/u$。\n（解 2）一个不递推的推式子做法。考虑删去 $u$ 后有个连通块 $siz\u0026gt;n/2$ 的方案数，补集转化，分类 $u$ 子树和 $u$ 以外两种情况讨论，枚举 $siz$。最终会得到一个卷积形式。\n其他. CF1534F2、+CF1770E、dmy stars\n对于生成结构类 dp，设计 dp 是解题的核心。在考虑具体的设计前，先思考一个问题：dp 到底计算的是什么？\n对于一个有待定信息的结构，每个 dp 状态以及值都表示确定待定信息中的某一部分，所有满足某些条件的解（即确定内容）它们的一个概括量。这些条件就是状态，概括量就是 dp 值。\n**因此考虑 dp 的前提是，先明确这个结构以及其待定部分是什么样的。**这里我想表达的是，建议在做完前两步后进行一个小结，明确 dp 的对象，以及其特征与性质。这样有助于后续思考清晰。不要认为这是废话，出现混淆状态含义等设计失误往往是因为没有明确 dp 对象造成的。\n几个原则 好，接下来我先列出 dp 设计的几个原则，再详述思考方式。\n众所周知，严谨地来说，一个 dp 的要素包括：最优子结构、重叠子问题和无后效性。但在实际设计时，一般会考虑这三点：\n每个希望被考虑（合法，或可能成为最优）的解均被恰当地（主要指计数题中次数正确）计入，不希望被考虑（不合法但会影响答案）的解均不被计入。这决定了无论在设计 dp 还是验证 dp 时，我们都会想象一个解，然后考虑它被计入的情况。“考虑一个解被计入的情况”，这是非常重要的思考习惯，因为当这样考虑时，可以跳出当前 dp 生成过程的语境，不被组合意义限制，去考虑本质上要记的东西，找到一些非常规的 dp 方式。 状态数足够少。换句话说，可以将“确定待定信息中的某一部分”这个确定部分视作一个黑盒，其只有少量的信息会与剩余待定信息以及所求限制产生互动关系，一般体现为确定部分的某些数量特征或边缘（某个邻域）的确定情况，在题解中往往会以”我们只需记录某类信息/只需求某类子结构的答案“出现。 状态是封闭的。这个更好理解，其实就是重叠子问题的意思。如果状态不封闭，那么从某个状态出发就会推出或依赖更多的状态，进而导致状态数爆炸，子问题的重叠情况就不够密集。这个可以类比分治类数据结构的信息封闭性来理解（例如推复杂线段树的记录信息与 tag）。同时这个要求会引出一类 dp 的设计方式，详见从转移推状态。 在设计 dp 前，应当有以下几个意识：\n优先考虑优化暴力 dp 和推广特殊情况 dp。相比凭空定 dp 状态，这两种方法显然更容易。不要急于一次性将高度优化或有复杂细节处理的最终 dp 想出来。 优先考虑组合意义，优化时结合组合意义。用数学方法或形式化描述容易把自己搞晕，或丢失性质。 优先寻找突破口，而不是一味地强制钦定某个顺序或规定状态定义再硬推转移。突破口可能是某个贪心性质、结构简单特征、信息量小或限制多的子结构、无关性或独立性等等。 设计方法 注意，这里会讲得比较抽象和概括。dp 设计有非常多零碎的技巧，尤其是关于局部生成时序和状态选择相关，这些会在例子中提及。建议看理论的同时结合例子。\n好，现在是主要的两类 dp 设计方法。\n第一类是设计生成过程，再确定状态。首先确定一个解大致的生成顺序，然后确定生成过程中的部分结构或时刻，用状态去表出这部分，用转移表出状态之间的部分。值得注意的是，状态相同时可能有不同的转移方程。\n该方法的核心以及难点就在于生成顺序的选取和子结构的选取。首先所谓的“生成顺序”绝不仅仅代表线性地扫一遍的顺序，因为难题的模型可能有多个维度（例如元素是区间，结构是带时间维的过程，带别的权值等等），有复杂的限制条件，或者结构本身就不是线性的。其次对于大致相同的顺序，子结构的选取就像在生成过程中寻找一些“checkpoint”，选取的不同会导致需要记录的信息量的差异。\n有些特定的结构有常用的生成方法，但诚然不存在通用的定法，有时只能靠枚举试错。但还是有些好的思考习惯。首先既然说是“想象法”，那就必须对静态和（以各种顺序）动态的模型有清晰的认知，在纸上画图，明晰模型在生成过程中呈现的特征，从而发现信息量小的部分（即突破口）。从否定的角度来说，可以尝试先排除不可能的方向，剩余少量可能。另外在设计状态时要尝试寻找不必要的状态（不可能、去除该状态也能对）以及不必要记的信息（可以合并、可以不管、可以多并一）等等。\n第二类是关注单步决策，推理出状态。这种方法可以先确定大致的顺序或先后关系，也可以不确定。关键思想在于，先通过观察（顺序未知的）生成过程中某个静态的片刻或局部（只考虑某一步），发现无关性，作为定状态的突破口。思考过程一般是，首先寻找结构的单个决策（往往是最终结构，即考虑最后一步），然后分析该部分与剩余待决策部分的关系（可以想象该部分已确定或去除该部分之类的），得到剩余部分必要的限制条件或信息。如果出现多个无关部分就拆开来。反复进行上述操作，不断扩充状态使其关于转移封闭即可。这个有点像某些 ds 设计复杂 tag 的过程。\n这个思路更符合 dp 原本的定义，但是如果模型中与单步决策相关的信息太多，会导致状态不确定性太大，由于这个思路靠的是找必要性，故容易定不出状态，这时就得用第一类方法——先确定生成过程，本质上就是通过猜一部分状态相关的信息来减少不确定性。但是如果第一类方法猜不出来，例如下文中某些奇怪的树型 dp 和断点转移，以及上文的 CF1781F 和 CF1439D，就可以用这个方法，较容易地获得状态设计线索。但相对来说这种方法用得并不多，要不就出现在较难的题里。\n无论如何，这两类方法并不是泾渭分明的。例如第一类方法定出的状态数太大，再结合模型特点与转移微调状态；第二类方法也可以猜一部分的生成顺序。\n另外提及一下两类对立的 dp 特征：单步转移和断点转移。这个分类源于与 crn 的讨论（原话的第一种是“逐步转移”）。单步转移的 dp 每次只决策一个“最小单元”，而断点转移更像“跳跃”，一次性决策连续的待定部分（利用数学方法或其他性质）。在数据范围允许的情况下，一般建议单步转移，因为更易写转移方程，且不容易漏性质；断点转移往往在单步转移状态量太大（指数或多了若干维）时用于缩状态，但往往转移需要优化。一个经典的例子是在一个序列中选多个位置时，单步转移需要记两维，而断点转移可以规定当前末尾必选，然后用一些优化解决。\n注意单步和断点的对立是相对而言的，有时单步转移的也可能是较长的一个部分。可以结合例子理解。\n这里，再强调一下一个重要的性质——无关性，或者叫独立性，这是 dp 的重要信号。这种性质分为两个方面，一是当前步决策与先前步决策情况无关或关系较小（只需记少量变量），这在最优化 dp 中体现为最优子结构（只需规定少量限制，就可以保证候选解包含全局最优）；二是多个不交部分间的决策无关（也就是第二类方法利用的），而它们在某处汇聚。这两个特征共同导向的重叠子问题，也就导向了封闭且足够少的状态。\n转移方式 关于看待模型的方式对转移方程的影响，这里有两类情况。\n第一类是填表法，指对于当前状态找出它可能的前驱状态来求得自己的答案；第二类是刷表法，指对于当前状态找出它可能的后继状态去更新它们的答案。\n这两个名词我也不知道是从哪里来的，据说很多初学者就知道。这里主要想讲一下这两类转移的思路差别。\n在构造题方法总汇中，我提到一类构造方法是 k. 归约法和增量法。这两种方法的大思想相同，但具体思考方式有差别。dp 也是一样，考虑一个结构删去（可能先待定）或确定某个部分后，剩余部分如何归约，这就是填表法；考虑一个未完成结构上增加一些部分后信息的变化，这就是刷表法。\n在一些结构较简单的题中，这两种方法是相通的，一方面转移简单时可以直接转换，另一方面可以将 dp 确定部分和未确定取反（可以理解成“起点到它的方案数”与“它到终点的方案数”这两种），通过改变状态定义中的方向来转换。但情况复杂的时候只有一种是可行（或容易思考）的，所以要多换几种思考方式。\n例 CF354D：将金字塔顺时针转 $45^\\circ$，视作直角三角形。方案形如：\n且每个小三角边长至多 $\\sqrt{6k}$ 左右。（解 1）最直接的思路是对小三角 dp，断点转移。可以记当前的最右竖边（这条边对应的直线前面的全部考虑完），转移时枚举（上一个小三角竖边）和（当前边长）之一，另一方的选择可以优化掉。注意上一个不交时应当先单步（不选）转移到当前开头，强制相交。\n（解 2）类似扫描线，逐行或逐列扫描，记录当前最右或最上的被小三角覆盖的坐标。新开小三角形可以断点转移也可以单步转移，取决于怎样计入小三角的代价。\n这题的灵活性很强。其实大致的生成顺序都是一样的，就是局部的先后关系和计代价的拆分方式有些差异。解 1 的优点在于整体思考每个小三角形，状态较简洁，易推广；解 2 的优点在于转移容易想。这题是从状态推转移。\n（落月摇情满江树）（给定一棵儿子有序的有根树，所有相邻叶子额外连边，求能否将点划分成若干简单环）：（解 1）考虑一个子树的情况，如果有非完整环那么要记下，与外部产生关系。发现仅有四种：全完整、最左叶子到根路径、根到最右叶子路径、最左叶子到最右叶子路径。从所有儿子转移，做到线性需要一些处理。\n（解 2）考虑逐个儿子加入，方便讨论转移。此时状态除了原来的四类外还有（根未覆盖，其余完整）和（根未覆盖，最左叶子到最右叶子路径）这两种。对于六类情况分别讨论在最后一个子树和前面部分如何拼合可以得到即可。解 1 和解 2 的关系有点类似断点转移和单步转移的关系。\n这题非常形象地体现了“状态封闭性”要求。要求确定状态集合使得转移能够自洽，这就像每个状态都是一个拼图，要能完美地吻合起来一样。\nCF1784D：结构如图（ans 表示获得 Wooden Spoon 的人）：\n乍一看不容易 dp，先考虑静态模型。和上文中排列的部分题很像，都是有一些主要元素，其余元素与其中一个有偏序关系这么一个拓扑序计数。这一题中对主要元素有绝对大小的要求，故只能从右往左钦定。对于深度为 $i$ 的点（根深度为 $1$）其下面挂的子树 $\\min$ 为 $j$，那么它贡献倍数为 $\\binom{2^n-j-2^{n-i}}{2^{n-i}-1}$。而这只与 $i,j$ 有关。\n第一种思路是枚举获得 WS 的人，然后从右往左 dp，但这样至少带 $2^{2n}$。（解 1）从左往右 dp 时，由于目标限制出现在状态中（获得 WS 的是某个人），故可以。$\\mathrm{O}(n2^n)$。\n（解 2）第三种思路是按值域从小到大填入。记录当前前缀中几个子树至少填了一个数，单步转移即可。\nCF1765C：问题转化为对于 $l=1\\sim k$，求任选 $l$ 张牌，最少的有 $c_0$ 张的概率。如果已知四种分别有 $c_{1\\cdots 4}$ 张，那么概率为 $\\binom{n}{c_1}\\binom{n}{c_2}\\binom{n}{c_3}\\binom{n}{c_4}/\\binom{4n}{l}$，（解 1）因此可以枚举 $c_0$ 后卷积，得 $\\mathrm{O}(n^3)$。（解 2）$\\mathrm{O}(n^2)$ 的做法是，按数量从大到小 dp。令 $f_{i,j,k}$ 表示当前上界是 $i$（接下来钦定的牌至多单种 $i$ 张），已定牌数为 $j$，已定了 $k$ 种牌，每次确定当前这个 $i$ 钦定给几种牌。（解 3）这题可以从小到大，只需将猜测成功率作为 dp 初值即可，相当于多个 dp 合并起来做，这是官解。\n这里有两个技巧，一是背包的单步转移，实际上解 2 和解 3 的 dp 数组同时承担着两种定义（这个在背包专题例 4 中也提到）：当前最少的是 $i$ 张，和当前最少的 $\\ge i$（$\\le i$）张。根据是否允许转移给不变的 $k$，可以区分这两种定义（解 2 更新答案时 $k$ 必须变）。二是解 2 和例 3 相同的技巧：**通过改变 dp 顺序，使得目标限制和（终）状态吻合，减少一维枚举或状态。**这是想象顺序生成的重要技巧。\nCF1060F：先枚举最后得到的节点 $r$，然后完全不会定状态。这时考虑以 $r$ 为根，所有儿子的子树是互相独立的，这就得到了 dp 的启发。每个儿子的子树要求的都是内部先合并若干次，然后 $r$ 在某一时刻合并上它了，之后再合并若干次，得到的仍为 $r$ 的概率。因此考虑 $f_{u,i}$ 表示点 $u$，内部剩余 $i$ 次合并时，$r$ 从上面下来和 $u$ 合并了，最终仍为 $r$ 的概率（这个概率只考虑合并时的 $1/2$，不考虑合并顺序，因为方便（考虑也行）。最后除以 $(n-1)!$ 即可）。分析转移发现这个状态是封闭的。具体来说，先考虑一个儿子 $v$，从 $f_{v,j}$ 转移。如果 $r$ 合并到 $u$ 在 $u$ 合并到 $v$ 之后，那么只从 $j=i$ 转移，因为从 $r$ 合并到 $u$ 开始计概率；否则，从 $j\u0026lt;i$ 转移，因为从 $u$ 合并到 $v$ 开始计概率。多个儿子时依据无关性，做树上背包即可。前缀和优化即可 $\\mathrm{O}(n^3)$。\n你可能会有疑问：为什么要这样定状态？因为考虑一个子树内的边合并序列，根合并下来相当于在这个序列中某处插入一个分界。因此子树外面与内部产生关系的只与一个数量有关。为什么不令 $i$ 表示内部剩余含根的 $i$ 次合并呢？因为无法转移。另外，我当时在思考时又记了一维 $k$ 表示根恰好在子树中合并了几次（即，和“为什么”之后的这个含根合并的意思相同），然后最后让 $ans=\\sum_kf_{r,n-1,k}/2^k$，这个得 $\\mathrm{O}(n^5)$。正解对其的优化本质上就是将多个状态的值压成了一个，这也是很常见的技巧。\n这题是典型的第二类方法。状态非常地怪，要真正理解可以从边合并序列的角度看，这启发我们要从多个角度同时看模型。同时还涉及了关于概率的处理，对于何时记概率，何时记方案数最后再除以总方案数的问题，答案是考虑转移时怎么方便怎么来。\nCF771E：（解 1）正解的核心思想是，**dp 只要使得任何合法解都能被生成即可，从而不必要记所有可能的状态。**想象一个解，容易考虑一个类似归并的生成过程：当前如果接下来两行都是单行矩形，那么选右端点小的那个。也相当于不允许出现第一行右端点为 $i$，第二行右端点为 $j$，且 $nxt_j\u0026lt;i$ 或对称的情况。但这样状态数还是很大。考虑对于一个 $i$，固定 $j\\le i\u0026lt;nxt_j$，发现只需要记使 $f_{i,j}$ 取到最大值的最小 $j$ 即可。因为如果没取到最大值，由于 $nxt_j\u0026gt;i$，故该状态所有的导出状态都不优于取到最大值的状态的导出状态。因此只需 1D，记对称的两个情况，刷表法转移即可。一个类似利用这个思想的是这篇题解，但是我无法理解他是怎么想出这个“不必要”条件的。另外还有一种见鬼的记搜解法，如果您知道它的状态数证明请告诉我。\nCF1608F：只能从左往右生成。问题出在 $\\operatorname{mex}$ 被更新时的连锁增加，这就会要求记录已决策的数中 $\u0026gt;\\operatorname{mex}$ 的 bitmask，那就完了。但是仔细一想：真有必要全部决策吗？是不是在连锁增加时有用才决策更好呢？因此考虑 $f_{i,j,k}$ 表示在 $i$，$\\operatorname{mex}=j$，前面 $\u0026gt;j$ 的有 $k$ 个的方案数。当 $\\operatorname{mex}$ 更新时，枚举连锁更新的量，用组合数分配即可。然而由于得枚举 $k^\\prime $，故无法避免 $\\Omega(n^3k)$。\n考虑将 $k$ 的定义改成“有 $k$ 种”，这样转移时只需要让 $j$ 单步即可。转移系数的下降幂妨碍单步，可以拆开来分给转移的起点和终点，也可以在定等价类时先决策大小关系。$\\mathrm{O}(n^2k)$。\n这题的延后决策技巧是局部生成时序的典型例子。从另一个角度理解，相当于 dp 已决策部分为下标—值域平面上的一个左下角矩形。这个矩形的上方既不能先决策，也不能完全不决策。\n[联合省选 2021] 滚榜：初步思路是逐个确定，记当前的状压、末尾编号，末尾 $b$ 与 $\\sum b$。优化，考虑记 $b$ 的目的是保证 $b$ 递增以及 $a+b$ 递增。而相邻的 $b_x\\le b_y\\Leftrightarrow b_y-b_x\\ge 0$，$a_x+b_x\\le a_y+b_y\\Leftrightarrow a_x-a_y\\le b_y-b_x$，可以考虑差分数组，$\\Delta b$ 的下界是 $\\max(a_x-a_y,0)$，同时这些下界可以确定一个 $\\sum b$，只需要它 $\\le m$ 即可。那就不必记末尾 $b$ 了，$\\mathrm{O}(2^nn^2m)$。\n这题实质上决策的东西没有变，只不过换了一种方式刻画已决策部分的影响。可以通过画出 $b$ 的柱状图然后换一个方向看来得到突破口——原来记的和是左下角的三角形，现在记的是下方的一个梯形。这题也可以算是状态合并的例子。\n[IOI2020] 装饼干：也是个判定型计数，考虑题目条件更好的描述。首先有个简化，如果 $a_i\\ge x+2$，那么它可以合并一对。然后，合法的充要条件是，$y$ 的低 $i$ 位的 $x$ 倍必须 $\\le \\sum_{j=0}^{i-1}a_j2^j$，充分性的构造是，从高位到低位贪心使用下标大的，或从低到高随便用。如果从低到高，那就得记一个当前剩余可用和，不好优化；如果从高到低，考虑钦定了一个最高 $1$ 位 $i$，它往下贪心用掉，最后一个用掉的是下标为 $j$ 的，且其剩余 $a^\\prime _j$。\n如果 $a^\\prime_j=x$（不可能再大了），那么次高 $1$ 位至多是 $j+1$，并且如果次高 $1$ 位 $\\le j$，那最高 $1$ 位实质上不产生影响，因此是一个无关的子问题；如果 $a_j^\\prime \u0026lt;x$，那么次高 $1$ 位至多是 $j$，并且如果次高 $1$ 位 $\u0026lt;j$，那上面也不产生影响。因此，如果令 $f_i$ 表示只考虑低 $i$ 位且第 $i$ 位为 $1$ 的答案，$g_i=\\sum_{j\\le i}f_i$，那么 $f_i$ 的转移会形如 $g_{j-1}+f^\\prime _j$，$f^\\prime _j$ 是个特殊的东西。而这个特殊的因为只有一支，故可以直接迭代往下看。$\\mathrm{O}(qk^2)$。如果不规范化使 $a_i\\le x+1$，也是可以分析的，就是 $j$ 变成了最高的可以为 $1$ 的次高位。\n这题是一个从转移推状态的例子。由于发现决策时只有一种情况会被影响，其他情况都可以归为形式相同的子问题，那就找到了 dp 突破口。\n[ZJOI2022] 树：初步思路是逐一钦定每个点在哪棵树中是叶子，第一棵树要记录当前非叶子数与已有至少一个儿子（已满足）的非叶子数，第二棵树由于是倒过来，故生成模型变成了一个若干子树合并到当前点的形式，记录当前子树数，若是非叶子则枚举选几个作为儿子。这样一共是 4D/1D 的。分开来看每棵树，考虑以下思路转变：\n第二棵树记子树数必然导致一维卷积，得改。实际上其状态可以和第一棵树类似——记录当前尚待决策的点中有几个是非叶子以及满足的情况。这实质上是先前提到过的“将 dp 确定部分和未确定取反”的技巧，相当于第一棵树是不断生成，第二棵树是不断消去。\n为保证非叶子所记的另一维需要消去，可以用容斥——不保证非叶子有至少一个儿子，而钦定非叶子时新增一个强制它无儿子的 $\\times (-1)$ 的转移。\n保证非叶子可以用另一种方法：在一个非叶子的最后一个儿子处将该非叶子的“接口”删掉，即，将非叶子数减一（第二棵树就是在第一个儿子处加一）。这个和 USAC23JANPlatinumT2 中只在钦定的最后一次访问某个点时才修改 bitmask 对应位置的思路异曲同工。\n这样就 3D/0D 了。第一个优化本质上是决策时序的微调，将决策叶子同时决策儿子改成决策叶子同时决策父亲。第二、三个优化单纯就是改变当前刻画信息的方式。这题深刻地说明了几个事情：确定了大的生成顺序并不意味着局部决策顺序唯一，确定了精确的决策顺序并不意味着状态唯一，确定了状态并不意味着方程唯一。\n[联合省选 2022] 最大权独立集问题：只考虑有两个儿子的情况，称先交换的儿子为左儿子。根的左儿子子问题为 ① “父亲点权为初始点权，$u$ 子树（含父亲边）完成交换，最后传给父亲的权为 $d_x$ 的最优解”，右儿子子问题为 ② “父亲点权为 $d_x$，$u$ 子树（含父亲边）完成交换的最优解”。继续往下看子问题 ②：\n父左右。子问题为 ③ “$u$ 点权为 $d_x$，$u$ 子树内（不含父亲边）完成交换的最优解”。\n左父右。左儿子换给 $u$ 的点权会额外贡献一倍，需要记；换给右儿子的点权为 $d_x$。因此左儿子是一个子问题 ①，右儿子是个子问题 ②。\n左右父。$d_x$ 恰好贡献一倍，$u$ 在与父亲交换前的权值也额外贡献一倍。子问题为 ④ “$u$ 点权为初始点权，$u$ 子树（不含父亲边）完成交换，最后 $u$ 的权为 $d_x$ 的最优解”。\n子问题 ① 是对称的。然后看子问题 ③。这时必须枚举左儿子交换上来的点权，导致三次方。但是，这里的一个直觉是，这个左儿子交换上来的点权和 $u$ 当前的点权 $d_x$ 很大程度上是无关的，也就是不必嵌套而是可以分开枚举。这个直觉可以通过分析左儿子的交换情况得到（令 $u$ 的左右儿子分别为 $v,w$，下面的父、左、右指 $v$ 的父、左、右）：\n父左右。$v$ 还是子问题 ③，$w$ 是 $x=v$ 的子问题 ①。 左父右。$v$ 左儿子传上来的点权会交换给 $w$，$u$ 传下去的点权会给 $v$ 右儿子，因此这两个权值它们不会共同影响一个子问题，或者说它们的贡献是用加法连接，可以拆开的。因此，先把 $v$ 左儿子的这条路线的最优解算出来就行了。$v$ 左儿子是子问题 ②，$w$ 是子问题 ①，$v$ 右儿子是子问题 ①。 左右父。这时 $d_x$ 恰好贡献一倍，与 $v$ 交换上来什么无关。因此可以不枚举 $x$ 但枚举 $v$ 交换上来的点权就算出答案，$v$ 为子问题 ④，$w$ 为子问题 ①。 如果从公式角度看，这个三次变两次的过程实际上就是通过再往下讨论一层，使转移 $f_{u,x}=\\min_yF_u(x,y)$ 变成了 $f_{u,x}=\\min_y\\set{G_u(x)+H_u(y)}=G_u(x)+\\min_y H_u(y)$。**所以说在解题过程中要对独立性非常敏感。**另外这题也是状态推转移的很好的例子。\nTHUSC2023D1T2：尽量避免记燃料和能量，能量很傻，直接分段。现考虑不补充能量的一段的最优解，关键思路是将状态定在补给燃料的位置，这样只需记当前的区间与所在点。断点转移会五次方，考虑到转移范围是一个一维偏序，故只需用 ds 维护当前右端点的所有可能转移，到下一个游乐园理解成全体位移 $w$ 即可。同一个右端点内部预处理两两最短路即可。$\\mathrm{O}(n^2m^2+n^2m\\log{})$。\n这题的难点是选取合适的子结构。\n[NOI2023] 桂花树：默认已知 $T^\\prime $ 的结构刻画。对相对值域 dp 不可行。\n（解 1）条件 2 可以描述成“点 $u$ 的儿子中至多有一个，其子树 $\\min\u0026lt;u-k$”。因此，考虑最大点，删去他和除了特别子树外的部分，然后把特别子树接给父亲，这样就归约成形式相同的问题了。$f_{u,s}$ 表示当前最大点为 $u$，$(u-k,u)$ 部分尚存的状态为 $s$ 的方案数。转移枚举子集，另外还要容斥掉子树全 $\\ge u-k$ 的情况。可以用子集卷积优化到 $\\mathrm{O}(mk^22^k)$。\n（解 2）考虑从小到大加入点，即考虑编号前缀点在 $T^\\prime $ 中的虚树。可以在随意的位置加一个叶子，裂一条边，或有条件地加一个 $\\operatorname{lca}$ 尚未加入的叶子，这个 $\\operatorname{lca}$ 会有一个编号大小的限制，要记一个状压。也可以理解成一个部分延后决策。$\\mathrm{O}(mk2^k)$。\n这两个做法，一个是从大到小填表，一个是从小到大刷表，而最终的解法本质上恰好是差不多的，是同一种生成思路的断点转移和单步转移形式。\n[NOI2023] 深搜：还是判定型计数，两个思路：直接对边集计数（记录是否存在至少一个关键点满足），枚举点集容斥。都先考虑特殊性质。\n（解 1）直接对边集计数，性质 B：$f_{u,d,0/1}$ 表示一端在点 $u$ 子树内的非树边已定，选的非树边最浅达到多少的深度（与 $dep_u$ 取 $\\min$），子树内是否有满足的关键点，这样的方案数。这个可以整体 dp：如果有多于一个儿子内有跨 $u$ 的非树边，那所有子树中的关键点都废了；如果恰有一个，那当前 $0/1$ 取决于该儿子的 $0/1$；否则直接乘起来。这些都可以线段树合并。正解：横叉边会限制关键点只能选在一或两棵子树内，这一或两棵子树内是独立的，因此有希望结合原 dp 解决。先解决只有一棵子树可以的，枚举该子树根，从它出发至少有一条横叉边，两端都在它外部的非树边可以换根 dp 解决。现在只需容斥掉有两棵子树均可以的情况：\n以 dfs 的方式枚举 $u$，用 dfs 序上的线段树维护所有可能的 $v$ 的系数：对于一个 $v$，$\\operatorname{lca}$ 是定的，因此这两者之间的返祖边方案数易求（必须两端均在链上或均在链上点某个非链上儿子子树内），同时两端分别在 $\\operatorname{lca}{}-u$、$\\operatorname{lca}{}-v$ 上的横叉边也在 $v$ 处维护，是形如区间乘 $2$ 的更新，然后再是 $v$ 子树的答案，这三者的乘积。对于一个 $u$，枚举选以它为一端的横叉边 $e$，现在要求其他以它为一端的横叉边的另一端都是 $e$ 的另一端的祖先。然后就是一个区间查询，再乘上与 $u$ 相关的系数和 $\\operatorname{lca}$ 向上的部分。注意由于要强制 $v$ 有至少一条横叉边，故要对 $u$ 出发新的横叉边的另一端和另一端子树内其他点分开讨论一下。\n这个做法我只是口胡了一下，实际写起来会极度复杂。如果您发现这个做法有锅请指出。\n（解 2）（来源）还是看原题解比较好。大致思路就是容斥，边只能完全在钦定的关键点的虚树单边内或单边内点的其他邻点的子树内。然后这个东西在性质 B 时就要断点转移（解 1 是单步），但可以 ds 维护；优势在于有横叉边时只需枚举顶部，“稍加”讨论即可。\n（[原创] 禁止套娃）（求一个序列所有本质不同子序列的本质不同子序列个数之和，$n\\le 5000$）：首先有个经典的算本质不同子序列数的线性 dp，也就是钦定单射，只对最左匹配计数，要求选的相邻两数之间不能有等于后者的。考虑仿照其思想：\n设选择的外层子序列下标为集合 $I$，内层为集合 $J\\subseteq I$。为了方便表述，设占位下标 $0\\in I,J$。同样只计贪心匹配的情况，限制如下：\n$I$ 中相邻两个数 $i,i^\\prime $，$a_{i+1\\sim i^\\prime -1}$ 中不存在 $=a_{i^\\prime }$ 的值。 $J$ 中相邻两个数 $j,j^\\prime $，$a_{I\\cap(j,j^\\prime )}$ 中不存在 $=a_{j^\\prime }$ 的值。 考虑对 $J$ dp。$f_i$ 表示目前考虑到 $i$ 且内外层末尾均选 $i$ 的答案。如果要从 $f_j$ 转移过来，那么就要决定 $a_{j+1\\sim i-1}$ 这部分如何选外层，设选择了集合 $K$，限制如下；\n$K$ 中相邻两个数 $k,k^\\prime $，$a_{k+1\\sim k^\\prime -1}$ 中不存在 $=a_{k^\\prime }$ 的值。 $K$ 中最大值 $k_r$，$a_{k_r+1\\sim i-1}$ 中不存在 $=a_i$ 的值。 $K$ 中任意 $k$，$a_k\\ne a_i$。 一个简洁的处理方法是，对于每一个 $i$，dp 出 $\u0026gt;$ 每个 $j$ 的只需满足 1、3 条件的本质不同子序列个数 $g_{i,j}$，真正转移时 $f_i\\xleftarrow{+}(g_{i,j}-g_{pre_i,j})\\cdot f_j$ 即可。最后汇总答案可以弄一个必选的占位下标 $n+1$。\n这题其实不难，关键是把结构看清楚。\n[互测 2021] Imbalance：（参考）只讲 Subtask 3。描述计数限制：$s_i$ 表示前 $i$ 个中 $1$ 的个数，$s_i-s_{i-1}=0/1,s_i-s_{i-k}\\ne k/2$。像题解中一样将 $s$ 排成矩阵，暴力状压实际上是先行后列的轮廓线 dp，而先列后行在 $k$ 大时状态数更少，这就像一些二维问题状压 dp 前 if(n\u0026lt;m)swap(n,m);。又由于只需考虑所有 $s_i-s_{i-k}$ 全部 $\u0026lt;$ 或 全部 $\u0026gt;k/2$ 故可做到题解中的复杂度。这题也是观察与生成顺序很大程度上影响状态数的有力说明。\n[互测 2023] Tree Topological Order Counting：想象某个拓扑序，一个点 $u$ 的祖先都在 $u$ 前面，且他们各自的不包含 $u$ 的儿子子树在他们后面随意穿插。而这题又得固定 $u$ 的绝对位置，因此就和 CF1784D 相似，这题我用的单步转移思路。外部子树的后续占用情况不宜直接确定，因此考虑记 $f_{u,i}$ 表示 $u$ 在第 $i$ 位的方案数，这里的方案数包含外部子树内的拓扑序数量（形如 $n!/\\prod siz_i$），以及他们在 $i$ 之前的部分的方案，但不含在 $i$ 后的（但数量已知且相对顺序已决策）。对于一个 $v$，先加入非 $v$ 儿子子树并穿插，再往后塞若干数，再塞 $v$。这题更能看出局部时序的技巧——往往要决策，但只决策一部分信息。\n[互测 2023] 雷同：同样考虑合并树，同样书的深度随重量递减，同样想象最优的树的生成过程。这里我考虑的是自底向上合并：如果书的深度均确定，那么过程可以看作，从大到小扫深度 $d$，每次加入当前深度的，然后两两合并，点上记一下磨损度。易发现按磨损度排序后两两合并是最优的，调整法易证这是个“下界”。立即可以得到一个 $\\mathrm{O}(n^3\\log{})$ 的区间 dp。\n考虑直接对叶子形成的折线 dp，如果从浅到深 dp，必须记深度和剩余允许的同层叶子数，多了个 $\\log$。如果从深到浅，则不必记深度，只需记：以目前已生成叶子的 $\\operatorname{lca}$ 为根的子树，将其视作 01 trie，到当前叶子的路径状态。转移包括直接定一个叶子和上移一层，其中后者可能导致根变，要加一个重量的前缀和。时间平方。\n容易发现，后一种 dp 更优的根源在于，其计算代价的方式从逐叶子变成了逐层，这与 [联合省选 2021] 滚榜 的思想一致。\n待填坑. [UR #20] 跳蚤电话、[UNR #7] 璀璨宝石\n第四步 优化 dp 首先要明确一点：最好的优化 dp 的方法，是做好前三步，或在较劣的 dp 基础上重做前三步。很多时候 dp 不够优，要么是漏性质，要么是观察角度或结构生成方法不对。对着复杂的转移方程做一堆细节很多的优化，不如先重新审视模型，改变 dp 思路。当然有的题优化也是必需的。\n优化 dp 的第一步是观察清楚现有的 dp。观察的角度包括：\ndp 的组合意义。清晰的组合意义不仅能使一般的优化变得容易，还能提供“dp 方程之外的东西”。例如表达状态更本质的方法、不必要的状态和转移、转化状态的可能性、dp 的决策单调性等等。 dp 的转移方程。这里个人建议在草稿纸上写清关于 dp 的所有信息：状态定义、转移方程、转移顺序、初值、终值、时间复杂度。通过写清这些东西，可以找到一些通用优化方法适用的特征，或是直接对方程进行数学方法处理。同时对写代码也有帮助。 dp 的转移图。主要包括基于原模型的 dp 转移示意图和基于 dp 转移的表格图。可以较直观地找到优化方向，处理一些细节。 dp 的优化分为对状态的优化和对转移的优化。注意，下面列举的许多优化都可以且建议在第三步设计 dp 的同时完成，而不是写出一个暴力 dp 后在其基础上优化。先讲对状态的优化。\n状态数的自简化 有时，真正可能 dp 到的状态远少于 dp 状态每一维最大值之积。可能使用记搜简化代码。\n例 其他. CF1188C、+CF662E、+CF771E、+CF1740F\n下标换元 令 $g_i$ 表示 $f_{t(i)}$ 然后对 $g$ 做 dp，这样的一个换元优化不仅能方便一些转移优化，还常能暴露出一些不必记或不必分开记的状态，触发状态数的自简化或状态合并等，从而减少状态数。建议从组合意义角度入手优化（微调状态定义）。\n例 CF1801F：如果记 $f_{i,p}$ 表示当前 $b$ 之积为 $p$，那是过不了的。考虑到剩余的 $b$ 应当满足积 $\\ge\\lceil k/p\\rceil$，因此可以只记 $f_{i,r}$ 表示当前 $\\lceil k/p\\rceil=r$。对于一个 $i$，状态就只有 $\\mathrm{O}(\\sqrt{k})$ 个，转移再套一个整除分块，共 $\\mathrm{O}\\left(\\sum_{i\\le\\sqrt k}(\\sqrt{i}+\\sqrt{k/i})\\right)=\\mathrm{O}(k^{3/4})$。 CF662E：如果有 $\\ge 90$ 个负的则答案为 $1$，否则显然考虑枚举每题属于哪一档，会得到一个背包，总共是 $6^3\\cdot{30}^3\\cdot90$ 这样。如果状态改为“剩下几个不被 hack”而不是“hack 几个”，总状态数就变为 $(30/2+30/4+\\cdots)^3$，那就是 ${30}^3\\cdot90$。 状态合并 在初步设计 dp 时，可能会设计一些含义较好理解的，但实际上有些信息没有必要区分的 dp 状态，可以在进一步分析时合并。\n例 其他. [CSP-S 2019] Emiya 家的饭、+CF1060F、+CF1810G（解 1）\n最优性去状态 对于最优化 dp，可以利用一些性质去除不必要记的状态，一般是这个状态不可能生成最优解，或有多条路线可以生成最优解，去掉其中的部分。思考方法一般是想象一个解，然后调整它。计数问题一般不用这个套路，因为要么可以归到自简化一类，要么优化前的 dp 会计重。\n例 [NOIP2023] 天天爱打卡：注意到使连续打卡段的起点是奖励区间的起点，终点同理，一定不劣。因此只需要在这些断点上 dp 即可。奖励部分是一个经典的扫描后前缀加，用线段树维护即可。dp 按归并顺序。 [IOI2022] 鲶鱼塘：关键性质是：可以调整使每列的堤一定建在一条鱼的下方，或者空或满。但这样还不够，因为一条鱼可能被两个堤同时覆盖，从而计重，另一个性质是，不可能 $h_{i-1}\\ge h_i\\le h_{i+1}$，或者说结构一定形如若干空列分隔的单峰。这时转移的代价只需在一侧计即可。归并顺序+前/后缀 $\\max$ 转移。 最优性换维 对于最优化 dp，这就是常说的定义域值域互换。有一类交换一维状态和所记值的优化，即，将求“某种情况下最优的……值”转为求“要达到最优值为……，某维的值至少/多要达到多少”。对于判定性 dp，如果 dp 值关于某一维具有二分性，或具有“只需关注最左/右的 1”这类性质，也可以将这一维压到 dp 值里。\n注意，要刻意证明最优子结构。或者说，只考虑与记的最优值有关的转移，必然能把全局最优解/合法性求出来。\n例 [UCup2Stage4] J. Joining Cats：考虑最后一步，比如是从左往右，那必定只有第一只猫是合并过的。因此任何时刻被合并的一定是一段。于是得到一个 3D 的判定性 dp，有两个压的思路：对一个区间求最小并完时间，对一个左端点和一个时间求最大右端点。刷表，每次要求一个点向左/右最远可以合并到哪里，这个可以双指针替代二分。\nCF822E：暴力 dp 为 $f_{i,j}$ 表示 $s,t$ 分别匹配到 $i,j$，最少分几段。断点转移是一次决策一段，单步转移得再记维 $0/1$，表示当前段匹配是否完结。换维，如果保留 $j$ 则由于原 dp 存在一个 $f_{i,j}\\rightarrow f_{i+1,j}$ 的转移，故转移难以 0D，因此考虑 $g_{i,k}$ 表示 $s$ 匹配到 $i$，分了 $k$ 段，最多匹配到 $t$ 的哪里。这时我就考虑也写成单步转移，结果错了。反例是 $s=\\texttt{aaab},t=\\texttt{aab}$，由于 $g_{2,1,1}=2$，故后面会断掉。这就是一个不具有最优子结构的例子，这题不能单步（您可能会问，如果对于每个 $j\\le g_{当前}$ 都做呢？问题是并非每个 $j$ 都合法）。但断点转移是有最优子结构的（易调整法证明），得支持求两个后缀的 LCP，套 SA 或哈希+二分即可。\n经验是，如果 dp 值用于决定转移的条件或位置，那就要当心最优子结构。\nCF1091H：转化略。打表发现 SG 值至多为 $l=54$，这里用一个神奇的优化：从小到大枚举 SG 值，求出哪些情况的 SG 值为它。用刷表法，每当确定了一个位置，它的所有可能的前一步情况的 SG 值就不可能是当前值。这可以 bitset 优化为 $\\mathrm{O}(lm+m^2\\log\\log m/(w\\log m))$。这个优化相当于逆着用判定性转最优化，常用于最优化 dp 值域 $l$ 较小的情况，可以将复杂度除掉 $w$（如果转移比较好处理）或乘以 $l/w$。\nCF936D：位置必须要记，这样的话状态里就不能记别的东西了。注意到如果摧毁一个障碍，那么必须经过它，且经过前不换行。但也不能记摧毁了几个障碍和装弹时间。这里就考虑 dp 值记录当前最长预留装弹时间，可以 $\u0026gt;t$，每经过一个障碍减 $t$，换行时与 $t$ 取 $\\min$。最后改成断点转移来减少状态：换行只会出现在一个障碍物后面一格，因为晚换行不如早换行。这里建议先分析清暴力 dp 的方程，再改成离散化过的状态，更易写方程。以归并的顺序 dp 即可。\n其他. [NOI2022] 移除石子、dmy guess\n最优性去维 对于最优化 dp，有时性质较强，可以将状态维度移入最优化目标，形成一个 pair 形 dp 值且不损失最优子结构性质。一般来说性质形如“如果值不够优，那么另一维再怎么样也没用；如果值最优了，那就尽量使另一维更优”。这个性质一般通过分析数量关系或通过找样例守恒规律得到。\n当最优性去维的性质强到一定程度，决策就变得单一，dp 就变成了贪心，如下面的例子。\n例 CF1453E：走的是个 dfs 序，直接树形 dp 会涉及子树内答案和最后一个访问的叶子深度，不能做，因此可以二分后只记最优的最后一步深度。但这题有更强的性质：考虑一个非根点的所有儿子子树的最后一步深度 $h_i$ 都已确定，那么除了这个点最后一个走的儿子以外，其余的儿子的 $h$ 都要加一后取 $\\max$ 给答案，而最后一个儿子的 $h$ 要加至少一，因为它要到子树外面去。故会选 $\\min h$ 作为最后一个，归纳地，每个点子树最后一个必走最浅叶子。根特殊讨论。从而“最后一步深度”这维可以去掉，或者说变成一个待统计的定值。\n[CSP-S 2019] 划分：（参考）有一个显然的 2D 暴力，打表发现最后一段尽量短是最优的，因此不用记第二维。证明考虑归纳+调整。设最后一段最短，前面也最优的解为 $P$，另一个解为 $Q$，它一定形如这样：\nP: x|x|x x|x x|x x x|x x|x x x|x x x Q: x|x|x|x x|x x x|x x|x x x|x x x x 即 $O$ 的倒数第 $i$ 个切点都在 $P$ 的对应切点前面（如果不是则可以调整证 $P$ 不优）。现在尝试调整证 $Q$ 不优于 $P$，发现直接硬调整是困难的。考虑直接从数值上证，即不增序列 $p_{1\\cdots k},q_{1\\cdots k}$，$p_1\u0026lt;q_1$，$\\forall\\,i,\\sum_{j=1}^ip_j\\le \\sum_{j=1}^iq_j$ 且 $\\sum_{j=1}^kp_j=\\sum_{j=1}^kq_j$，则 $\\sum_{j=1}^kp_j^2\u0026lt;\\sum_{j=1}^kq_j^2$。由于和相等，故必然有两位置 $j_1\u0026lt;j_2,\\text{ s.t. }p_{j_1}\u0026lt;q_{j_1},p_{j_1+1}=q_{j_1+1},\\cdots,p_{j_2-1}=q_{j_2-1},p_{j_2}\u0026gt;q_{j_2}$，这时将 $q_{j_1}\\xleftarrow{-}1$，$q_{j_2}\\xleftarrow{+}1$ 会更优。剩下就是每个位置求出以它结尾的最后一个切点 $f_{i}$，$f_i=\\max\\set{j\\mid s_i-s_j\\ge s_j-s_{f_j}}$，单调队列即可。\n这个调整法很有教育意义。\n[NOIP2018 提高组] 赛道修建：二分。剩下的 dp 需考虑内部已有的路径数和当前传上来未完结的直链长度。一个符合直觉的结论是，一定优先让内部路径数最优，再使当前直链尽量长。因为当前直链至多贡献 $1$，如果内部路径数不是最优，直链再怎么长也不会优，这和 CF771E（解 1）类似。于是问题转化为，有一堆数，要尽可能两两匹配使和 $\\ge mid$，再最大化未匹配的最大值。一个性质是，如果最小值可以匹配，那一定有最优解中它匹配了，这个可以调整证。显然找 lower_bound 配即可，于是就归约下去。\n其他. +CF771E（解 1）、CF1795F\n扩大可行域 对于最优化 dp，可能为了保证解的合法，需要记录额外的维度；但有些不合法解它不可能成为最优，这时就可以默许它被考虑，从而减少要记的信息量。一个利用该思想的非 dp 问题是，定义一个序列合法条件，求一个序列的最长合法区间。区间会要求有一个一维偏序，但显然不考虑 $l\\le r$ 也是可以的。\n例 USAC23JANPlatinumT2：每个点的收益取决于最后一次到的时刻，但 $q$ 较大，故不能与询问时间相关，因此只能考虑每个点的亏损，但如果有点从未到达那还是会出问题，因此考虑枚举到过的点集（dp 刚好也要用上这些中间状态），这时对于询问相当于查某个 $x$ 的最高直线，可以处理出凸壳再回答。第二步完成，现在的 dp 对象相当于是给每个固定终点的点集安排一条线路，直接 dp 需要记录当前已耗时，不行；这时可以模仿 [联合省选 2021] 滚榜 的思路，直接考虑走一条边对之前的最后一次到达的点的亏损增量。$f_{S,i}$ 表示当前在 $i$，先前已经强制钦定最后一次到达的点集为 $S$（$i\\in S$）的最小亏损，枚举下一个点即可。\n这里有两个问题：① 既然每次决策一条路径，那么如果又经过了已钦定“最后一次到达”的点那怎么计算？② 如果一个方案总时间大于询问的 $s$ 那怎么办？回答是：如果一个解违反了这两个问题中的合法条件，那么它一定不会是最优解，但最优解总是会被 dp 到的，所以没事。如果偏要考虑这两个问题，那 dp 就不容易了。\n你可能会问：是怎么想到如此扩大可行域的？答案是优先考虑生成过程的完备性（涵盖所有合法解），暂且忽略纯粹性（不含不合法解），然后到头来再简单证明一下。也就是说这个设计过程是有些冒险的，但对本题模型的直觉告诉我应该没什么问题。他有一个“偏序关系”在里面。\n[互测 2022] 翻修道路：对最短路树 dp。$f_{i,j,s}$ 表示目前根为 $i$，子树内关键点集合为 $s$，至多改 $j$ 条边权。当 $j$ 和 $s$ 不变时，所有的 $i$ 之间跑最短路互相更新；两个子树合并时，注意到 $f_{i,*,s}$ 递减，故决策一定形如归并，可以做到 $\\mathrm{O}(2^knm\\log m+3^knm)$。\n这题的问题在于，dp 不能保证最短路树是真的最短，甚至不能保证是树，不能保证不会重复改同一条边的权！但是这些都是无所谓的，因为它们不会导致不合法的更优解。这题是一个经典的类型：要求 $\\min_S\\set{f(S)}$，然后 $f(S)$ 也是个 $\\min$ 的形式，就直接用 dp 同时最优化这两个 $\\min$。另外这题的生成思路和最小斯坦纳树相同。\n（就硬推销自己的博客）您看这个问题的求解中第二步也用了这个技巧！\n接下来是转移优化。\n前后缀 对于一类转移范围为一个前后缀（或能转化为前后缀，例如利用可减性，或记次优值等等）且方程中的项都只与转移和被转移的其中一方有关的 dp，可以（换元后）用前后缀或类似预处理方法优化。通常用填表法会比刷表法方便，有时也可以用刷表，就是会变成差分。\n前后缀处理优化实在是太入门了，这里就不给例子了。\n例 其他. USACO21OPENPlatinumT3\n多步拆单步 这个优化范围比较广，也没有固定的模式。前后缀优化可以视作这个的子集。多步拆单步的核心思想就是构造中间状态去“合并”转移，在 dp 设计思路也提到过，在可以单步时，单步往往比断点优。这张图很直观地展现了其原理，很像某些建图优化。\n除了对着公式优化外，直接从组合意义出发寻找新增的中间状态也是可以的。\n例 CF1736E：称当前轮数取的 $a_i$ 位置为取值点。分析解的结构，某些数字会往前交换使其早贡献，然后在到达取值点后会往后交换跟着走。一定不会取值取到交换导致的 $0$，否则可以少往前交换使答案不劣。\n（解 1）$f_{i,j,k}$ 表示取值点在 $i$，取值 $a_j$，目前前面空余的交换轮数为 $k$。一种是 $a_j$ 跟着走，一种是换取值，$f_{i,j,k}\\rightarrow f_{i+1,j^\\prime ,k-j^\\prime +i+2}(j^\\prime \u0026gt;\\max(i,j))$。从填表法角度看好优化，只需求出 $f$ 关于 $j$ 的前缀 $\\max$ 即可。\n（解 2）考虑断点转移，$f$ 的状态类似解 1，$j$ 在取值点 $i$ 开始贡献，但转移直接枚举下一段贡献，$f_{i,j,k}\\xrightarrow {(i^\\prime -i)a_j}f_{i^\\prime ,j^\\prime ,k-j^\\prime +i^\\prime +1}(i^\\prime \u0026gt;i,j^\\prime \u0026gt;j,j^\\prime \\ge i^\\prime )$。可以拆贡献后两次前缀 $\\max$ 处理，我当时考虑的是令 $g_{i,j,k}$ 表示 $j$ 在取值点 $i$ 最后一次贡献，这样 $f\\rightarrow g$ 是枚举 $i^\\prime $，$g\\rightarrow f$ 是枚举 $j^\\prime $，我当时原地化了一下，显得很符合直觉。结果发现这个 $g$ 不就是辅助数组嘛！\n这两个解法它的辅助数组都是有组合意义的（解 1 的前缀 $\\max$ 就是变选择但不决策，类似于前文里一些整数拆分背包），这就是为什么说直接从组合意义出发寻找新增的中间状态也是可以的。\n倍增 倍增优化适用于状态数量与转移轮数（较大）无关的情况，在具体题目中一般体现为“不需要记用了几次”这类。一些典型问题包括各种矩乘、完全背包、某些卷积（哎呀反正是个半群就行）等。也是很入门，不讲例子了。\n提几个延伸的东西：\n我感觉矩乘并算不上 dp 的优化，只是一类 dp 转移的通用刻画方法。真正和 ds 无关的技巧也不多，一个是乘向量优化，即，有多组询问时先预处理每个 $T^{2^i}$，然后二进制分解后逐一乘给向量。例子包括 [NOI2020] 美食节 和 [POI2015] Wycieczki。另一个是对于一些特殊矩乘，可能会抽象过度，实际可以记更少的信息。例如 USACO23OPENPlatinumT1 以及某些 ddp。 这类倍增可以解决的 dp 在指数极大时往往能通过分析循环节等找到更优的做法，至少能避免倍增的大 $\\log$。例如矩乘可以找特征多项式后线性递推，完全背包可以利用上面提到过的性质先贪心，图上定长最短路可以参考 [互测 2023] 【模板】矩阵快速幂。大的思想就是存在不依靠 dp 的更简单的规律。这些就不讨论了。 有一类树上倍增维护 dp 支持多次询问的问题，例如 [NOIP2018 提高组] 保卫王国、[CSP-S 2022] 数据传输，它们实质上是纯 ds 问题，跟这里讲的“倍增”是不同的。一般有记录头尾状态和直接套矩乘两种思路，可以推广到 ddp。这篇文章里不会讲 ddp。可以详见猫锟的 ppt 和 17 年集训队论文，以及任轩笛的 18 年集训队论文。反正大不了就套 top tree。 例 咕\nds 维护 dp 数组 对于一类状态过多，但转移有规律可循的 dp，可以使用 ds 维护 dp 数组，本质就是快速维护 dp 转移时的增量。这类优化有很多子类别：\n原地化（？）。谁说数组不是 ds 呢？众所周知背包问题可以原地转移而不必滚动数组，这实质上是在状态中隐去了一个维度，使同一位置在一些不相交的时段具有不同的含义（注意要与去维/合并状态区分开，它们是不必考虑某一维，而这里说的是不显式记某一维）。这类优化在状态多于转移时有很好的作用。 各类线段树维护（注意与线段树优化 dp 区分）。除了基础的在序列上优化外，还有一类所谓整体 dp，也就是树上 dp 中每个节点上要记一个数组，合并儿子时是直接对应位合并然后加少量修改。这可以直接用线段树合并维护。注意这类线段树是可以打 tag 的，如果 tag 对未建出节点无影响，就判一下即可，否则可以 pushdown 时再新建并下放一层，merge 中出现有一方有点但无儿子时视作 base case 即可（我是从（nfls 7.19 秒速五厘米）的非官方解法学到的），这个 trick 又出现在了 [CTT2023] emerald 里。 重剖（dsu on tree）与长剖。值得注意的是它们是支持换根 dp 的，只要保证轻儿子要用的子树外 dp 状态数只与该子树的 siz/dep 有关即可。详见 [十二省联考 2019] 希望，由于太阴间这里就不讲了。 slope trick。用于 dp 值关于某一维有凸性的一些情况，详见这篇和这篇。 例 CF1770E：答案可以转化为求每条边贡献的期望，而每条边的贡献只会在它本身交换时变化，因此只需考虑每个时刻每个点为关键点的概率 $p_{u}$，发现转移相当于是将边两端的 $p$ 取平均。这个 dp 实际原地掉了时间维。 CF1699E：不妨枚举 $\\max$，最大化 $\\min$。注意到最优拆分的变化次数为 $\\sum\\sigma(a_i)$，时间能接受，但空间不行。这时如果放弃该思路就无路可走了。考虑维护每个 $a_i$ 当前的最大 $\\min$，搞不了，得求出 $f_{m,x}$ 表示最大值 $\\le m$ 时数 $x$ 的最优解，如果 $m\\mid x$ 则 $f_{m,x}=\\max\\left(f_{m-1,x},f_{m,x/m}\\right)$，否则 $f_{m,x}=f_{m-1,x}$。这就给出了一个可以原地优化的转移数为 $\\mathrm{O}(m\\log m)$ 的 dp，从小到大扫 $m$，用桶+指针维护最优 $\\min$ 即可。 [IOI2018] 会议：从笛卡尔树角度来看，只需求每个节点的每个前后缀的答案。以前缀为例，左半直接继承，$f_{u,[l_u,u)}=f_{ls_u,[l_u,u)}$；对于 $i\u0026gt;u$，$f_{u,i}=\\min(f_{ls_u,u-1}+(i-u+1)h_u,f_{rs_u,i}+(u-l_u+1)h_u)$，这是先继承 $f_{rs_u}$ 全体加，然后与一条直线取 $\\min$。固然可以扩展李超树（区间加时不必沿途下方直线），但是考虑到 $f_{rs_u}$ 是递增且差分均 $\\le h_u$（直接考虑意义即可），故可以二分取 $\\min$ 切换点做到单 $\\log$。在线段树上做，继承直接不动即可。 [NOI2020] 命运：容斥不容斥最后 dp 形式类似，这里以容斥为例。如果强制钦定一条链全 $0$，那从树形 dp 角度相当于限制了当前点到根最深的 $1$ 的深度上界。把该限制对应的维度用线段树维护，在一条链的底部，选该链就相当于区间求和后减到 $dep_{top}$ 上；两树合并相当于 $\\min$ 卷积，可以线段树合并时记一个后缀和。 CF1534G：顺时针转 $45^\\circ$，一个土豆一定在到达对应横坐标时种。dp 状态就记录当前坐标，每次跳到下一个有土豆的横坐标，这个转移相当于与长为 $\\Delta x$ 的水平线段作闵可夫斯基和；加土豆相当于全体加上 $\\lvert y-C\\rvert$。归纳即可证凹。这题涉及斜率区间加和斜率交界点区间位移，线段树无法胜任，可以用平衡树。特殊地，由于只会延长壳的底部，故可以把谷两边的斜率交界点分开维护，用堆就行。 其他. CF671D\nds 优化 dp 转移 这类优化没有通用的方法，得结合具体 dp 方程来看。多步拆单步优化也算属于这个。\n注意复杂的 ds 优化 dp 题在填表和刷表时会有较大区别，都要试一下。\nds 优化 dp 转移有一个重要的子集，是决策单调性优化，这里详细讲一下。\n决策单调性 所谓决策单调性就是决策点有单调性的 dp。对于在线形式的 dp，如果仅有决策单调性，那应该是无法优化的，必须具有更强的性质（参见 4）。\n单调队列/单调栈优化。一般从“没前途”角度考虑。略。\n二分求决策点。只有在转移值严格单峰时才能用，较少见。\n斜率优化。斜率优化有两种等价形式，分别是将其中一方视作直线/点，另一方视作一个横坐标/去切的斜率。当转移方是静态或加入具有单调性时，可以直接用单调队列/单调栈维护凸壳，否则需要用平衡树或李超树维护。值得注意的是，并非只有 $f_i=\\min/\\max\\set{k_ik_j+b_j}$ 形式可以优化，有些特殊形式的具有较强“没前途”性质的 dp 也可以，详见 [NOI2016] 国王饮水记。另外这类利用”没前途“性质排除转移的 dp 应该能推广到凸壳外的其他结构（例如曼哈顿距离下的凸壳等等），参考 [互测 2023] Grievous Lady。我不是很会。\n四边形不等式优化。有三个形式：\n$f_{i,j}=\\min_{k=i}^{j-1}\\set{f_{i,k}+f_{k+1,j}}+w_{i,j}$。若 $w$ 满足 QI，且 $\\forall a\\le b\\le c\\le d,w_{a,d}\\le w_{b,c}$，则 $f$ 也满足 QI，且 $p_{i,j-1}\\le p_{i,j}\\le p_{i+1,j}$，可以按区间长度从小到大转移，三次方变两次方。 $f_{i,j}=\\min_{k=0}^{j-1}\\set{f_{i-1,k}+w_{k,j}}$。若 $w$ 满足 QI，则 $f$ 也满足类 QI，且 $p_{i-1,j}\\le p_{i,j}\\le p_{i,j+1}$，可以类似形式 1 转移，也可以利用分治（对于一个 $i$，先求 $p_{i,n/2}$），都是减一次方。这里计算单点 $w$ 可以暴力移指针。 $f_i=\\min_{j=0}^{i-1}\\set{f_j+w_{j,i}}$。若 $w$ 满足 QI，则 $p_i\\le p_{i+1}$，且对于 $i\u0026lt;i^\\prime ,j\u0026lt;j^\\prime $，若在 $i$ 处 $j^\\prime $ 更优，则在 $i^\\prime $ 处 $j^\\prime $ 必定更优。这就给出了一个单调队列上二分的方法。 其中后两个情况的 $\\log$ 是可以去掉的，详见冯哲的 17 年集训队论文。\n闵可夫斯基和以及其他与凸性相关的东西。\n例 CF1830F：（解 1）$f_i$ 表示最后一个选点 $i$，填表：记 $c_{i,j}$ 表示 $l\\le j\\le r\u0026lt;i$ 的区间数量，$f_i=\\max_j\\set{f_j+a_jc_{i,j}}$。相当于有一堆直线 $y_j=a_jx_j+f_j$，每次选一段 $x_j$ 加一，求全局 $\\max$。只能 KTT。\n（解 2）状态同解 1，刷表：希望对于一个 $j$，一次性更新所有的 $i$，因此对于所有 $i$，维护解 1 中的 $c$，如果它不变，那相当于一个序列，每次与一条直线取 $\\max$；但随着 $j$ 的移动，这些 $c$ 可能会区间加减，但原先更新的又不能变。相当于要维护一个取值点会变的李超树，由于 $c_{i,j}$ 关于 $i$ 递增，故可以用扩展李超树维护。\n（解 3）倒过来考虑，填表：记 $c_{i,j}$ 表示 $j\u0026lt;l\\le i\\le r$ 的区间数量，$f_i=\\max_j\\set{f_j+a_jc^\\prime_{i,j}}$，这相当于维护一堆斜率会变（后缀加减）的直线，求某个横坐标对应的最大值。由于 $c_{i,j}$ 关于 $j$ 递减，故可以尝试用线段树套凸壳维护，合并时二分。如果一个节点上全体加减，那凸壳的结构是不变的。估计很难写。另外倒过来刷表涉及到一个奇怪的历史最值，不大能维护。\nCF1720D2：一个 $i$ 从所有 $j\u0026lt;i$ 满足 $a_i\\oplus j\u0026gt;a_j\\oplus i$ 转移，无法直接 trie 树优化。如果是 $=$ 则可以变成 $a_i\\oplus i=a_j\\oplus j$。考虑硬套 trie 树，当 $a_i\\oplus i$ 在上面走时，比如从一个点走到一个儿子，那在另一个儿子子树中的 $j$ 应当恰好有“一半”可以转移，这样的 $j$ 满足 $j$ 与 $a_i$ 的当前位相同。因此每个节点只需记两类值即可。这种同时与异或和偏序相关的问题可以魔改 trie 树，类似的套路出现在 [NOI Online 2021 提高组] 岛屿探险。\nCF1603D：易证只需考虑 $k\\le\\log n$。$f_{i,j}$ 表示考虑到 $x_i=j$ 的答案。\n（解 1）注意到所有 $c(*,j-1)\\rightarrow c(*,j)$ 是 $\\sigma(j)$ 段区间加。因此用线段树维护所有 $f_{i-1,k}+c(k,j)$ 即可 $\\log^3$。\n（解 2）$c(l,r)=\\sum_{g=l}^rS(r/g)$，其中 $S(n)$ 为 $\\varphi$ 的前缀和。注意到 $\\forall\\,l_1\\le l_2\\le r_1\\le r_2,c(l_1,r_2)+c(l_2,r_1)-c(l_1,r_1)-c(l_2,r_2)=\\sum_{g=l_1}^{l_2-1}(S(r_2/g)-S(r_1/g))\\ge 0$，故可以套四边形不等式的分治做法。求 $c$ 的方法，注意到可以 $\\mathrm{O}(1)$ 移动左端点，均摊 $\\mathrm{O}(\\log n)$ 移动右端点，而分治做法中左右端点移动在 $1\\sim n$ 上求值次数是均匀的，故是 $\\log^3$ 的。另一个常数较小的做法是先整除分块求出某个 $c(?,mid)$，再只移左端点。\n[NOI2016] 国王饮水记：转移方程形如 $f^\\prime_i=\\max_{j\u0026lt;i}\\set{(f_j+s_i-s_j)/(i-j+1)}$，发现似乎是求 $(j-1,s_j-f_j)-(i,s_i)$ 的最大斜率，因此可以维护一个下凸壳。同时，打表发现决策点有单调性，因此用队列维护即可 $\\mathrm{O}(nkp)$，后面的优化与本节无关，略。\n决策单调性的证明似乎网上的题解都有问题。考虑 $j^\\prime \u0026lt;j$ 且 $j^\\prime $ 劣于 $j$，即 $(f_{j^\\prime }+s_i-s_{j^\\prime })/(i-j^\\prime +1)\\le(f_j+s_i-s_j)/(i-j+1)$。那么 $i+1$ 时： $$ \\begin{aligned} \u0026amp;(f_j+s_{i+1}-s_j)(i-j^\\prime +2)-(f_{j^\\prime }+s_{i+1}-s_{j^\\prime })(i-j+2)\\\\ ={}\u0026amp;(f_j+s_i-s_j)(i-j^\\prime +1)-(f_{j^\\prime }+s_i-s_{j^\\prime })(i-j+1)+h_{i+1}(j-j^\\prime )+f_j-s_j-f_{j^\\prime }+s_{j^\\prime }\\\\ \\ge{}\u0026amp;h_{i+1}(j-j^\\prime )-(s_j-s_{j^\\prime })\\\\ \\ge{}\u0026amp;0 \\end{aligned} $$ 不是只有四边形不等式才有这个性质的。注意，如果不求凸壳直接走指针是错的，数据专门卡了。\n[Tsinghua Bootcamp 2023 Qualification Round] L. Fence Decoration（给定 $x_{1\\cdots n},c_{1\\cdots n},d_{1\\cdots m}$，$x$ 递增，选择 $x$ 的子序列下标 $p_{1\\cdots k}(p_1=1,p_k=n)$，最大化 $\\sum_i\\sum_j\\lvert x_{p_{i+1}}-x_{p_i}-d_j\\rvert-\\sum_ic_{p_i}$）：dp 是 $f_i=\\max_{j\u0026lt;i}\\set{f_j+g(x_i-x_j)}-c_i$，其中 $g(x)$ 是下凸的。直接维护所有可选项 $\\max$ 起来的凸壳或用 KTT 的话需要求两个多段凸壳的交点，很困难。\n（解 1）注意到，两个可选项对应的凸壳只在至多一处相交（因为是全等的），这就可以用李超树维护。\n（解 2）由于琴生不等式，转移的代价有四边形不等式，但是这里是 $\\max$，也就是对于 $i\u0026lt;i^\\prime ,j\u0026lt;j^\\prime $，如果 $i$ 处 $j$ 更优，则 $i^\\prime $ 处 $j$ 也更优。因此这里可以用一个类似上文方法 3 的做法，用单调栈维护转移点的递减段。\n其他. CF1067D\n有后效性 dp 的处理 对于最优化问题，如果所有转移的起点只与一个 dp 值相关，那就是最短路，否则我也不会。计数问题要么魔改高斯消元，要么手玩方程。\n有些比较诡异的题。\n例 其他. CF865C、[THUPC 2023 初赛] 最后的活动、+CF1778D、+CF1667E、（字符串）\ncdq 分治 这里指的是四边形不等式以外的 cdq 分治优化转移。对于复杂的断点转移问题，有时可以用 cdq 分治，求出转移和被转移双方与当前 mid 的关系，再借助 ds 优化转移。有些类似于多步拆单步的变形。\n这类题较罕见，我目前只遇到过两道。\n例 CF1175G：先写出暴力 dp：记 $mx_{l,r}=\\max_{i=l}^r\\set{a_i}$，则 $f_{i,j}=\\min_{k\u0026lt;j}\\set{f_{i-1,k}+(j-k)mx_{k+1,j}}$。不存在决策单调性。这里只考虑逐个 $i$，全体转移，因此接下来忽略 $i$。\n（解 1）填表。用栈维护 $mx$ 相同的段 $s$，每段的 $mx_s$ 会永远相同但会变，最优解形如 $opt_s=\\min\\set{f_k-k\\cdot mx_s}$，维护其凸壳，支持合并，可以用李超树（也可以用单调队列之类的，启发式合并）。转移考虑每段，形如 $\\max_s\\set{opt_s+mx_s\\cdot j}$，要维护一个大的凸壳，支持加直线和撤销上一次加入，可以用可持久化李超树。\n（解 2）利用笛卡尔树结构固定 $\\max$。在点 $j$ 处求 $f_j$ 并将其挂到点 $j+1$ 上，这样所有的转移就形如：对于一个点 $u$，求出 $\\min_{v\\in\\mathrm{lsub}_u\\cup\\set{u}}\\set{f_{v-1}-(v-1)a_u}$，并将它更新给 $\\mathrm{rsub}_u$，或者说，将该值记为 $g_u$，每次求 $\\min_{v\\in\\mathrm{anc}_u}\\set{g_v+a_v\\cdot u}$。这个和解 1 本质上是相同的。\n（解 3）cdq 分治。直接扫 $[mid+1,r]$ 之间的每个位置转移还是不行的，这里关键要利用 $mid$。如果 $\\max$ 选在左半段，那么被转移点只能从左半段的一个前缀转移，从右往左扫被转移点 $j$，维护可选前缀（只增不减）的凸壳，转移形如 $\\min_{l\\le k\\le p}\\set{f^\\prime_k+mx_k\\cdot j}$，由于 $mx$ 只减不增，故可以直接栈维护。如果 $\\max$ 选在右半段，类似地从左往右扫被转移点 $j$，维护可选后缀的凸壳，转移形如 $\\min_{mid\\ge k\\ge p}\\set{f_k-k\\cdot mx_j}$，还是可以用栈维护。注意这里不是用队列维护的原因是，加线和最优取值删线是同侧的。这个写起来比前两种简单很多。\nCF771E：（解 2）考虑断点转移，dp 状态只记录跨行矩形的尾。在 $i$ 时枚举 $j\u0026gt;i$，先贪心放一堆行内矩形到 $j$，再从 $j$ 往后放一个跨行矩形。直接转移会平方，考虑 cdq 分治优化，$i$ 在 $mid$ 之前，$j$ 在 $mid$ 之后。两边可以分别以 $mid$ 为边界贪心向右/向左跳，然后考虑跨 $mid$ 的行内矩形，共四种情况。有跨 $mid$ 的矩形就左边再贪心跳一次，这样就转化成一次全体更新，两次一维偏序，一次二维偏序。$\\mathrm{O}(n\\log^2n)$。\n参考文章 邓明扬，《杂题选讲》，WC2022 讲课。 《一类动态规划选讲》。 Alex_Wei，《DP 优化方法大杂烩》，https://www.cnblogs.com/alex-wei/p/DP_Involution.html \u0026amp; https://www.cnblogs.com/alex-wei/p/DP_optimization_method_II.html。 OI-Wiki，《四边形不等式优化》，https://oi-wiki.org/dp/opt/quadrangle/。 @changruinian2020 给予我的指示。 @linrui 与我讨论的一些题目和思路。 一些例题参考了各处的题解，但是基本都是我先自己想出来的。如果是后来发现的一些他人独创的解法我都标出来了，如果您觉得漏标了可以提醒我。\n","date":"2023-12-31T00:00:00Z","permalink":"https://littlereuben.github.io/study/dp-problems/","title":"dp 题方法总汇"},{"content":"这是一篇学习笔记。\r下文中的 $\\max/\\min$ 可以为了严谨起见理解成 $\\sup/\\inf$。\n众所周知，WQS 二分优化的是这样一类问题：有一个函数 $f(x)$，给定 $a$，希望求得 $f(a)$，但是 $f$ 的单点值无法快速求。这时，如果有以下性质之一：\n$f(x)$ 上凸，且能快速求 $\\max_x\\set{f(x)-kx}$。 $f(x)$ 下凸，且能快速求 $\\min_x\\set{f(x)-kx}$。 那么就可以利用二分 $k$（也就是所谓的“多选扣分”）的方法“凑”出所需的 $f(a)$。\n接下来只以满足第 1 种性质的 $f$ 为例。\n常用的不严谨方法 问题出在二分判定的时候。常用的写法要求 check 函数返回一个取到 $\\max$ 的 $x_0$ 值，然后与 $a$ 比较大小。如果 $x_0$ 是任选的，那么如果二分的斜率恰好正确，而切线上有多于一个点（所谓“共线情况”），那么 $x_0$ 与 $a$ 的大小关系是任意的。而由于整数二分一定有一边会排斥掉 $mid$，故这个做法是错误的。\n相应的弥补方案有两种。一种是 check 返回最小或最大的 $x_0$。例如返回最小的 $x_0$，如果 $x_0\\le a$，那么 $r\\gets mid$，否则 $l\\gets mid+1$。另一种是实数二分，其正确的原因在于总是不排除 $mid$，这样正确的斜率总是包含在 $[l,r]$ 中，而如果整数二分这样做，就会在区间为 $[l,l+1]$ 时卡住。以 $l=1$ 为例：\n实数二分考虑了这条红切线（$k=l+0.5$），因此可以区分绿点是在哪一边。\n但是这两种处理方法面对着一个共同的问题，即高维的情况无法简易地处理：CF739E 和 CF1799F。\n以二维的情况为例，有函数 $f(x,y)$，要求 $f(a,b)$（其中 $f(x,b)$ 关于 $x$ 是上凸的，且 $\\forall,k,\\max_x\\set{f(x,y)-kx}$ 关于 $y$ 是上凸的）。这时外层二分的判定条件应该是“使 $f(x,b)-kx$ 取到 $\\max$ 的 $x$ 值”，然而这个值是难求的。\n你可能会说，内层二分的斜率 $k^\\prime$ 已经求出来了，那拿它和 $k$ 一起跑一遍 check，尽量使 $x$ 最小或最大就行了呀。这里的问题在于，无法保证 $y$ 恰好取到 $b$，因为 $y$ 这一维同时也会出现共线情况，这时可能会取到错误的 $y$，从而取到不该取的 $x$。这个问题即使用实数二分也无法解决，例如这个提交记录。\n一种解决方法 Neal Wu 在这里提出了一种精细的处理方法。例如要求最小的取到 $\\max$ 的 $x_0$，那么在 check 中求出必须要用几个 $x$，必须要用几个 $y$，和既可以用 $x$ 又可以用 $y$ 但不能都不用（必须都用的情况不算在内，应算作前两个各自加一）的数量，分别记作 $\\alpha,\\beta,\\gamma$。外层二分如果 $\\alpha\\le a\\land \\alpha+\\beta+\\gamma\\le a+b$，那么 $r\\gets mid$。这个判断的正确性如下：\n如果这些条件不满足，那么显然不存在合法分配方案，斜率一定是太小了。 如果这些条件满足，那么一定存在一个 $x\\le a$，使得 $f(x,b)$ 被切线切到。构造方法是，$y$ 先取 $\\beta$ 部分，显然 $\\beta\\le b$（不然内层二分就不会二分到这个斜率）。然后尽量用 $\\gamma$ 的部分补满 $b$。如果补满了，那么由 $\\alpha+\\beta+\\gamma\\le a+b$，故 $x=\\alpha+\\gamma-(b-\\beta)$ 一定可以。如果没补满，那么找另一些不影响 $x$ 用量的元素补满 $y$（一定能补满，不然内层二分就不会二分到这个斜率），这时由 $\\alpha\\le a$，故 $x=\\alpha$ 一定可以。 这里是另一题我写的类似的处理方法。\n但是这个方法缺乏通用性。首先，刚才这个解法中“用”的定义只在这两题里成立（即用两类精灵球和用两类操作），如果没有类似的组合意义就不行了，所求条件就再次变成了不可解决的，类似于原问题的“强制限定 $y=b$”。其次，维数再高就难以讨论了。\n通用的解决方法 核心性质：对于上凸的 $f(x)$，令 $g(k)=\\max_x\\set{f(x)-kx}+ka$，$g(k)$ 是下凸的，且最小值恰为 $f(a)$。（在力学中这个称为 Legendre 变换）\n这张动图中红色轨迹即为 $g(k)$。\n证 1：若 $f(k)$ 处处可导，令 $h(k)=\\min\\set{x\\mid f^\\prime(x)=k}$，则 $g(k)=f(h(k))-k(h(k)-a)$。 $$ \\begin{aligned} g^\\prime(k)\u0026amp;=f^\\prime(h(k))h^\\prime(k)-kh^\\prime(k)-(h(k)-a)\\\\ \u0026amp;=kh^\\prime(k)-kh^\\prime(k)-h(k)+a\\\\ \u0026amp;=-h(k)+a \\end{aligned} $$ 而 $h(k)$ 是递减的，故 $g^\\prime(k)$ 递增。\n证 2：用更加普遍的定义来证。同样令 $h(k)$ 为使 $g(k)$ 取到 $\\max$ 的某个 $x$。$\\forall,k_1,k_2$，对于 $\\lambda\\in (0,1)$，令 $k_m=\\lambda k_1+(1-\\lambda)k_2$： $$ \\begin{aligned} \u0026amp;\\lambda g(k_1)+(1-\\lambda)g(k_2)\\\\ ={}\u0026amp;\\lambda\\max_x\\set{f(x)-k_1x}+(1-\\lambda)\\max_x\\set{f(x)-k_2x}+k_ma\\\\ \\ge{}\u0026amp;\\lambda(f(h(k_m))-k_1h(k_m))+(1-\\lambda)(f(h(k_m))-k_2h(k_m))+k_ma\\\\ ={}\u0026amp;f(h(k_m))-k_mh(k_m)+k_ma\\\\ ={}\u0026amp;g(k_m) \\end{aligned} $$ 同时，显然 $\\forall,k,g(k)\\ge f(a)$，又由于 $f$ 的凸性，一定存在一个 $k$ 使得 $g(k)=f(a)$，故得证。\n另外我们会惊奇地发现：除了最后一步外，证 2 甚至没用 $f$ 的凸性！\n于是就可以直接二分了，判定时只需比较 $mid$ 和 $mid+1$（或 $mid+\\varepsilon$）的 check 结果。CF1799 的代码。\n这样做唯一的缺点在于会有 $2^d$ 倍常数（$d$ 为维数）。可以用优选法（按黄金比划分的三分）优化到 ${1.44}^d$ 倍。\n一个小细节 考虑实数二分的精度问题，设当前二分区间为 $[l,r]$，取 $f(h(l))-lh(l)+la$ 来估算答案，它与 $f(a)$ 的差距为： $$ \\begin{aligned} \\lvert f(h(l))-lh(l)+la-f(a)\\rvert\u0026amp;=\\left\\lvert l(a-h(l))-\\int_{h(l)}^af^\\prime(x)\\mathrm{d}x\\right\\rvert\\\\ \u0026amp;=\\left\\lvert\\int_{h(l)}^a(l-f^\\prime(x))\\mathrm{d}x\\right\\rvert\\\\ \u0026amp;\\le\\lvert a-h(l)\\rvert\\cdot(r-l)\\\\ \u0026amp;\\le\\lvert I\\rvert\\cdot(r-l) \\end{aligned} $$ 其中 $I$ 为 $f$ 的定义域。因此二分一般得在 $r-l$ 小于允许的绝对误差除以 $n$ 时才结束。$f(x)=C$ 时可以取到最差情况下的误差。\n参考资料 \u0026amp; 总结 本文基本上就是 Theoretical grounds of lambda optimization 的提要版本。\n目前，WQS 二分在应用中仍难以解决的问题主要是凸性的证明。大量题目直觉上目标函数具有凸性，但无法严格证明。归约费用流可能是一种有前途的方案，但目前这几道题例仍未找到证明。adamant 的这篇文章关于 CF739E 的证明应该是错的，我在下面的评论区也有提问，如果您有想法可以与我交流。\n目前已知的证明方法：\n[IOI2016] Aliens：四边形不等式是要的，然后有两个证明方法，分别于 Kubic 23 年的论文、我 24 年的论文。\nCF739E 和 CF1799F：用题解区这篇的方法建图，然后把一种精灵球选的代价改为 $+\\infty$，这样就可以证 $f(x,b)$ 或 $f(a,x)$ 的凸性；内层的凸性更容易，可以用流或 dp 证。这题外层不能用 dp 归纳证，分讨会有一种情况去世。\nP1792 种树：这类题如果是奇环我是不会证的，并且我目前没看到对的证明。偶环、链、树这类二分图的情况可以看 Kubic 的论文。对于链的情况，可以将限制扩展到“任意两个选的距离必须 $\\ge k$”，这样就只能用四边形不等式（一个区间的代价为除去开头 $k$ 个，剩余的 $\\max$，这样就有四边形不等式了）或者 dp 归纳证。\n[八省联考 2018] 林克卡特树：这篇题解似乎有证明，我没仔细看，不知道是否严谨。反正 dp 归纳是不行的。\n","date":"2023-10-31T00:00:00Z","permalink":"https://littlereuben.github.io/study/wqs/","title":"严谨的 WQS 二分方法"},{"content":"这是一篇学习笔记。\r声明 本文非严谨的算法理论研究，仅仅是个人对解题经验的归纳和实验性的系统总结，不保证理论上的完备性与纯粹性。仅对解题实践提供一个较为自洽的解释，作为参考。\n本文所有题都不会提供题意和完整包含细节的题解，也就是说您需要先做一遍或看其他题解，因为没有做题经验就无法感受解题思想。您也可以把本文理解成一个归类好的题单。\n如果一题包含多项技巧则会放在多处，但如果包含多项思想则只会在一处解说。如果出现一题多解会记入多个类别并多次解说。\n带括号的题是内部训练题。\n如果您认为一些理论表述有偏颇，或找到文章无法解释的题目（反例），可以告诉我。\n本文会时常更新。\n引言 在 OI 中，“构造题”的定义是什么？我也没法给出一个精准的答案。似乎这类题确实有某些明确的特征，但这一概念的边界却是模糊的。广义地来说，所有算法都是构造——dp 构造状态和转移，ds 构造维护的结构……但我们常说的构造更多的是一种无算法的构造，或者说，不是将问题模型转化成一种特定的算法所能解决的问题，再去间接求解，而是直接去构造所求组合结构。\n最关键的是这类题的思维方式很特殊，这使曾经的我面对构造题不知如何下手。其余类型的题都主要侧重于分析，通过分析问题模型的性质，刻画其结构，从而将它转化成更容易解决的模型。而构造题则往往给人一种“凭空”出现了答案的感觉，例如，考虑一个方式/过程/结构，它刚好就是对的，然后就解完了。另外，其他类型的求解型问题往往是以最优化为目标，某些不要求最优化的题可能还得硬转成最优化（例如一些流问题），而构造题则倾向于消去最优化目标。当然也不能否定，构造和其他算法是密切相关的。\n不存在简单地区分构造和非构造题的方法。解题后期如果感觉解的可能性很复杂，无法用简单的方式统一描述，那就需要考虑 dp、网络流等方法，否则可以尝试直接构造。这其实是废话。\n接下来，我会介绍解构造题的技巧和方法。所有归约 dp、差分约束、2-SAT、流、线性规划的题，以及交互、部分数学求解方面的构造这些非构造组合结构而是构造求解方法的题均不会讨论，我也会尽量避免无法证明概率的随机化构造题。\n分类 这部分其实对解题没啥帮助……\n构造题的所求一般来说有以下几类：\n凭空构造一个结构或补充结构；\n安排（排列、划分、组合、选一部分）给出元素；\n构造一系列操作以达到目标。\n另外可以关注以下几个特征：\n输入是否是 $\\mathrm{O}(1)$ 的；\n是否有可能无解；\n是否要求最优化。\n基于特性的技巧 以下题例可能不完全是构造题，但如果某个技巧没法出到构造题里就不会收录。\n括号序列相关 技巧 题例 前缀和化。将左右括号分别视作 $\\pm 1$ 并作前缀和，画出折线图。能给 flip 和 reverse 提供一个直观的几何解释，还能处理 $\\min/\\max$ 相关，以及利用类介值定理证明存在性。 CF1458D、CF1685C 路径化。将左右括号分别视作向右和向下，画出折线图。与上一种类似。 匹配括号连弧线。 CF1503F 括号树。根据定义，合法括号序列一般有两种观察方式：多个括号序列拼接并在外面套一对括号：(ABC\u0026hellip;)，以及找到开头括号匹配的右括号将序列分成两块：(A)B。这两种分别对应着正常括号树与三度化后的括号树。 [WC2022] 序列变换 排列相关 技巧 题例 画点。在平面直角坐标系中画出 $(i,p_i)$ 是一种直观反映偏序关系的方法。 [APIO2022] 排列 按值域构造。一种是以某种顺序扫描值域，另一种是只维护相对大小关系，每次插入再在值域中空出一个位置给新元素。这样可以减少构造受限性，可以用增量思想构造。 置换环。涉及置换、交换使排序这类的题都可以把 $i\\rightarrow p_i$ 画出来。还有类似的排列转有向图的处理方法。 CF1491G、CF1656G、CF1787F、[THUPC2024 初赛] 排序大师 考虑逆置换。 CFgym102154C 拓扑序。用 DAG 的拓扑序来理解所求的排列。 CF1477D、CF798E 逆序对数。常用于分析无解。 CF804E、（樱花抄）、[互测 2022] 魔术师 贪心。要求排列字典序最小时，逐位贪心判断可行性即可。 CF1530E、CF1844F1、（roast） 二维相关 技巧 题例 拆成一维。 CF417E、（巧克力） 转 $45^\\circ$。 [IOI2021] 喷泉公园、[IOI2019] 视觉程序 拼图法。找到构造中的小单元去试探。 CF1628C、CF1034B 棋盘染色。即按 $(x+y)\\bmod k$ 将格子分类，保证长为 $k$ 的段必然包含每类各一个，用于加强命题方便构造，或判断无解。 CF1450C2、CF763B、CF1268B、CF1485D 拓扑学方法。主要包括转向度数和、穿过次数奇偶性、欧拉定理、皮克定理。 行列和。作为守恒量用于判断无解。 CF1672G 数论相关 技巧 题例 互质对构造。$(n,n+1)$、$(n,2^k-1)$（n 奇）、$(p,n)$（p 质）。 CFgym102055C、LOJ3392、CF922F、[互测 2022] 大冬天题 拆二进制以及辗转相除法。 CF341E 原根。乘转加。 互质/整除图。可以更加直观。 CF1148G 预处理常数。如果只允许使用特定材料构造出某个数，那么可以考虑先用方程把相关要用的常数解出来，然后用二进制拆分等构造。 CF1060H、CF1427E 模意义下考虑。如果条件是不等式，那么模意义就是加强条件；如果是等式，那就需要倍增。 CF1218G、CF1844G 生成树相关 技巧 题例 归约最小/大生成树。 CF1054G 叶子调整法。叶子是树中最灵活的部分，就像质数在数论构造中的作用。可用于保证某个相关数值“能够调整至任意一个 $[l,r]$ 内的值”。 CF1311E、CF1098C 边权为标号差绝对值的最大生成树。前一半连 $n$，后一半连 $1$。 CF1474E、CF1656F 图论相关 技巧 题例 考虑反图。 利用 $\\sum deg=2m$ 来均摊。在处理实现细节，确定枚举方式时可以提供依据。 CF1444C 找 dfs 树。往往可以简化构造。 CF1680F、[IOI2019] 景点划分、CF1515F 缩点。 考虑二分图。 CF1515F、CF1218G、[湖北省选模拟 2023] 棋圣 进行 bfs。主要是从邻边和距离视角观察。 CF1470D、CF1368E、CF1019C、CF794D 竞赛图性质。存在哈密顿路、可分层、度数最小的点到其他点距离均 $\\le 2$。 CF1779E 图相关序列判定定理。包括 Erdős–Gallai 定理、Landau 定理等。 USACO14MARGoldT3 邻接矩阵。 AGC061B 赋点权来决定边权。 CF42D 互斥条件。有一类题目是要求在图中找两种结构之一。先尝试找一种，假设找不到再试另一种。 CF1364D、CF1148G、CF1439B、（ schrodingersjerry 和图染色） 格雷码 格雷码的本质是利用二进制表示的唯一性，来保证每种数恰好出现一次。\n题例：CF1673F、ARC138D=P7949、CF1163E\n欧拉回路/路径 遇到类似与“相关和为 $0$” 的守恒条件时可以考虑用欧拉回路/路径构造。\n题例：CF1634E、CF1610F、CF1458D\n鸽巢原理 鸽巢原理一般用于有多个备选项，它们从总体来看有某个数量关系，可以导出存在一个个体满足特定条件。偶尔也反过来用证明无解。在实际应用中，备选项可能是给定模型的局部，也可能需要自己构造，后者会比较难，关键在于找到可能性足够少的“鸽巢”。\n例：CF1450C2、CFgym102900B、CF1515F、CF1090C、CF618F、CF1835C、[NOI2021] 量子通信、[NOI2020] 制作菜品\n绝对众数 涉及到绝对众数最简单的模型就是：排列一些数使得相邻数不同。这类问题要抓住主要矛盾，其他次要矛盾都会自动消解，就可以专注于构造一个内容。另外这类题常使用逐步构造。\n另外，对于树上问题，通过找重心作为根可以避免出现大小为绝对众数的子树，这也是一个简化讨论的技巧。\n例：CF1242E、CF1762G、CF1329D、[IOI2019] 景点划分、ARC156C\n题外话：用爬山或退火构造时也常常会先满足最紧的限制，体现形式也往往是类似绝对众数的东西。详见此处。\nDilworth 定理 往往给人一种“双向限制”的感觉。\n例：CF1097E、CF1738G、CF1630F\n简单写一下相关的证明：\n最长链 = 最小反链覆盖：≤ 显然，≥ 每次剥掉一层入/出度为 $0$ 的点。\n最长反链 = 最小链覆盖：≤ 显然，≥ 删掉一个出度为 $0$ 的点 $u$ 归纳，取出覆盖方案的每条链中最后的能出现在最长反链里的点，如果没有一个与 $u$ 有偏序关系则最长反链 $+1$，否则最长反链不变，且有一个点 $\\le u$，取出它所在的链中所有能出现在最长反链里的点与 $u$ 共同作为一条链，剩余的点最小链覆盖也 $-1$，总体不变。\n求最长反链法 1：取二分图最大独立集中两部均在内的点。记最小链覆盖为 $s$，则最大匹配为 $n-s$，最大独立集为 $n+s$，两部均在内的点至少 $s$ 个。\n求最长反链法 2：求出所有可能在最长反链中的点，每次任选一个，删除与它有偏序关系的点，归纳。\n常用的解题思想 所有解题思想之间大多没有明确的分界，往往结合使用。\na. 等价表述条件和观察模型 使用不同的方式和图形去表示问题模型，可能会突出问题的某一部分特征，从而带来新的启发。有一个经典的例子可以说明换一种方式描述会产生多大的区别（一道 dp）：CF1368H1。原问题（最大流模型）和最小割模型都看似无法解决，但如果转变到平面图最短路的角度去分析出路径的简化性质（每行或每列均相同），再回到最小割模型，就可以 dp 了。因此，不要认为等价模型没有意义，否则会错失动机。\n在转述过程中要注意可能会不小心加强模型或丢性质，反而导致无解，这个后面会提到。\n例：\nCF1680F：奇环上会出现两端均选的边。因此原题意可以转述为“删除一条边使得图变成二分图”，dfs 树讨论即可。 CF1110E：经典套路，这种就两类，$(a_{i-1},a_i,a_{i+1})\\rightarrow(a_{i-1},a_{i-1}+a_{i+1}-a_i,a_{i+1})$ 作差分解决，$(a_{i-1},a_i,a_{i+1})\\rightarrow(a_{i-1}+a_i,-a_i,a_{i+1}+a_i)$ 作前缀和解决。 CF1458D：将 01 序列转化为前缀和序列化成折线，从而将奇怪操作翻译成区间翻转。容易用调整法证明任意符合守恒条件的序列均可达到。因此可用欧拉路径的方式去描述合法折线，从而贪心。 CF1054G：“集合内所有点形成一个连通块”等价于“集合内所有点之间边共有 $size-1$ 条”，加之边不可能多于 $size-1$ 条，故原条件可以转述成“所有集合的点之间边数量之和取到理论上界”，这就可以用 MST 了。边权用 bitset 加速计算。 b. 将无解和最优化条件转成已知条件 首先是经验：CF 中如果 Output 里说无解输出 $-1$ 但 Example 里没有 $-1$，那么就不会有无解的情况。\n部分构造题有一个很大的特点，就是在解题开头就确定无解条件或最优解公式，也就是先确定充要条件的一边，去构造另一边，或是先给出不等式的一边，再构造取等。可以说这是一种“先猜后证”，也为构造增加了提示。当然这种猜测要足够谨慎，尽量思考通过题目条件能推导出的必然性，以及从数学角度去分析模型（找到模型的某个示性数，或守恒量）。\n不是所有构造题都可以使用这个技巧，同时要避免将非构造题误判成构造（例如，有时无解和最优化情况必须通过 dp 求出）。关键是通过分析条件来感知题目模型的解是可以用一种特定的规律描述，还是要根据输入数据，去遍历所有可能的解才能确定。\n例：\nCF1543E：对于第二问，首先分析图的点与边的数量关系。每个点恰有一个颜色 $x$ 的邻居，一个颜色为 $x$ 的点会作为 $n$ 个点的邻居，因此一共有 $2^n/n$ 个颜色为 $x$ 的点，所以原问题在 $n\\ne 2^k$ 时无解。这个无解条件反过来启发我们使用递归构造和拆分二进制的思路去构造 $n=2^k$ 的情况。可参考 3b1b 的视频。 [CTSC2016] 单调上升序列：套用题面中给出的证明，可得到最优解 $\\ge n-1$。并且达到 $n-1$ 时限制是很紧的，遂考虑每一轮安排边权使得所有“探险家”均走一步，也就是将完全图的边划分为 $n-1$ 组完美匹配。 c. 从特殊情况获取提示 特殊情况包括特殊输入和特殊解，这一条侧重于特殊输入。这样思考的帮助是：\n通过特殊情况的解获取一般构造的线索； 通过将所有情况用某些手段归约到特殊情况，从而只需解决特殊情况； 通过构造极端输入确认无解性/答案上下界，或排除不可能的构造方法。 但是不是所有题的特殊情况都能给出有效的提示，有时候反而会起到误导作用。要很警惕的一点是一些不成熟的思路可能会被构造的极端情况排除掉，但是实际上改一改就对了。\n例：\nCF1311E：先考虑完全二叉树和链的特殊情况，然后寻找能符合题意的，处于两种特殊情况之间的“连续的”变化，调整法。 CF1515F：结合 b，有足够的理由猜测 $\\sum a_i\\ge (n-1)x$ 即有界，于是任意图就可以归约到树这一特殊情况。然后根据 b 的数学上分析（核心分析：如果有一条边不能并那么一定存在一个点 $a_u\u0026gt;x$），结合鸽巢原理，构造出一个合并方法。 CF618F：考虑 $B={n\\,个\\,n}$ 的情况，容易想到将 $A$ 作前缀和后对模 $n$ 余数鸽巢，这样就把正解的提示都集齐了：鸽巢、前缀和、$A$ 的前缀和减 $B$ 的前缀和。 CF1019C：一种思路是，考虑 DAG，可以做到任何不选的点都能被选的点走 $1$ 步到达；稍稍加强，考虑对原图 dfs 后只有树边、前向边和返祖边，树边和前向边就相当于 DAG，返祖边导致的矛盾可以通过取消选择祖先那个点，同时保证至多走 $2$ 步可达。推广到一般情况，将原图拆成两张 DAG（根据边的起终点的编号大小关系分），套用原来的方法即可。\n作为一个反例：我在解这道题时考虑了竞赛图这一特例，这没有帮助，反而把方向带歪到关注节点度数上去了。因此要多考虑几种特殊情况，并结合分析筛选。 AGC064B：如果不考虑特殊情况，容易考虑使用 j，每次找一个点，周围只有一条可行（加入不成环）同色边，选择这条边。这样思路就走歪了。正确的思路是先考虑一些无解情况，发现点边颜色均交替的偶环无解，进一步分析发现如果要形成一棵树，就必须有一条边，两端的颜色都与它相同（记为一类边）。进一步地，发现如果存在一个点，它不断走这样的边 $u\\xrightarrow{e}v$（$u$ 和 $e$ 同色，与 $v$ 异色，记作二类边），最后走不到任何一类边，那就无解了。因此先尽量选所有一类边，然后再从这些边的端点向外扩展二类边（一个点只能被扩展到一次）。如果所有点都被扩展到了，再用剩下的边尽量连接这些森林即可保证有解。 d. 分析数量关系 模型的数量关系可能不仅仅能用于 b，而且能指导构造的过程。往往结合待定系数法，列出方程或不等式来分析。c 例 2 就是一个典型的例子。\n例：\nCF1667C：设答案为 $k$，则有 $(n-k)\\times(n-k)$ 的部分只能用对角线覆盖，故 $2(n-k)-1\\le k\\Rightarrow k\\ge \\lfloor(2n+1)/3\\rfloor$。固定右下这样一个空矩形，剩余部分试探构造即可。换句话说，下界分析直接给出了构造思路。\nCF1158B：经过一些尝试，直觉上串必须要有循环节，长设为 $l$。长 $\u0026lt;k$ 出现过的至少出现两次，也就是 $\\forall\\,i,i-l\\ge 1\\lor i+l+k-2\\le n$，长 $=k$ 的有恰好出现一次的，也就是 $\\exists\\,i,\\lnot(i-l\\ge 1\\lor i+l+k-1\\le n)$，综上解得 $l=(n-k)/2+1$。立即得出构造为 $(n-k)/2$ 个 $0$ 加上一个 $1$ 不断循环直到长为 $n$。\n（樱花抄）：不妨设输入是排列。先考虑对每个位置操作对逆序对奇偶性的影响：$n\\equiv 0\\pmod 4$ 是 $1111\\cdots 1$，$n\\equiv 1\\pmod 4$ 是 $0101\\cdots 0$，$n\\equiv 2\\pmod 4$ 是 $0000\\cdots 0$，$n\\equiv 3\\pmod 4$ 是 $1010\\cdots 1$。因此 $n\\equiv 2$（以下省略 $\\bmod 4$）时可能无解。构造可以考虑 k，发现每次将一个数移到开头或结尾是容易的，因此考虑在维护一段后缀为 $1\\sim i-1$。现在要加入 $i$，设位置为 $p$，若 $p\\ne 1$，则可以操作 $p$ 后操作 $p-1$；否则一定无法 $\\le 3$ 步搞定，就必须要操作 $1$、操作 $i+2$、操作 $1$、操作 $n-i$，共 $4$ 步。特殊地，$i=n-1$ 时如果出现后一种情况就完了，因为搜索小情况可发现还要大量步骤。因此在一开始就要把逆序对数调整为偶，又由于每一轮都不会改变其奇偶性，故最终一定形如 $[n-1,n,1,2,\\cdots,n-2]$，操作 $1$ 再操作 $n$ 即可。为避免大量出现四步情况，可以先随机操作 $C$ 次打乱排列，这样总次数为 $C+2n+\\mathrm{O}(\\log n)$。\n为什么要先分析逆序对的奇偶性呢？因为只有奇偶性可能成为这类排序题的“守恒量”，逆序对是定义在每一对数上的。另外真正的解题过程中其实是先尝试构造，发现最后出现 $[n,n-1,1,2,\\cdots,n-2]$ 这种无法处理情况时，再去研究逆序对奇偶性的。最后再对操作进行微调，保证不会改变奇偶性。也就是说，手动构造和对数量关系的分析是交织着进行的。\n[THUPC2022 复赛] 拯救还是毁灭：这题与 [THUPC2024 初赛] 排序大师 的难点都在于，抓住“势能”刻画剩余步数。\n我的思路：① 仿照一维时的最差情况，考虑构造行列均循环移一位，这时有 $2n(n-1)$ 步的方案，且直觉上无法做到更优。猜测这就是 $M(n)$，尝试构造即证。② 直接构造实在太复杂了，考虑加强——分阶段，逐行归位。由于最后一行只需 $n-1$ 步，故前面每行只需在暴力（每个数行列依次归位）的基础上省去一步即可，模样例发现应该一定可以。现在抓住推论：如果一个数要移两步，那第二步必须归位，同时不能所有数都移两步，要利用一维情况的性质省掉一步。看起来复杂情况下，这两个要求是互斥的，因为一旦开始“移两步”，就有可能每个数都要这样做。考虑到 $1\\sim n$一一分布在每列的情况，这时就要先全部放到第一行再做。这就启发我考虑最终将问题归为这一类情况。如果有空列，那可以把对应数归位；否则没有空列，由鸽巢，必然是上面所说的情况。那么这个解法的后半部分构造，就是不断尝试、调整，找到一个自洽的分讨，这个并没有一个通法，不过一般只要抓住特殊、极端情况的提示，做好假设和推理，就不会太难。\n这篇题解给出了严格的图论角度分析。对这类问题，图论思路的核心就是，复原一个环的步数是环长减一，因为最后一步可以两个同时归位。我没想清楚的，一个是两维分别开环，来证上界，这个实际上是普通置换环的重边推广版本，值得学习；另一个就是再同行归位时，搞不出那个“减一”，最后只能硬凑，这个题解说的则是，当该行元素到处分布时，尽管列重叠会导致无法构造完整的置换环，但总能找出一个环，这就够了。\ne. 寻找诈骗条件 主要是要有这个意识。有些题目的条件或性质可以极大程度地减小可能性，不要忽视。往往可以通过思考极端情况获得启发。\n例：\nCF425B：“所有连通块均为矩形”这一条件可被简化为“$a_{i,j}=r_i\\oplus c_j$”，将 $nm$ 个未知量减少为 $n+m$ 个。于是只需暴力枚举 $r_{1\\cdots n}$ 即可。 CF1689E：默认 $a_i\u0026gt;0$，发现存在一个策略只需两步，因此问题变为判断答案是否为 $0$ 或 $1$，可以暴力。 CF1685C：打表发现 $ans\\le 2$，结合括号序列技巧画图可得，以前缀和最大值为界左右各翻转一次，一定可以完成，因此只需讨论答案是否为 $1$。 CF1781G：尝试构造达到理论下界的解，可以使用归约构造，逐步删掉儿子均为叶子的点的子树，base case 分讨即可。同样 $ans\\le 2$。 CF1852E：刻画完结构后发现未知元素的可能性太多了，但是可以找到性质，只有至多一种未出现过的数被填入，并且它一定是某个出现过的数 ${}-1$，且可以较简单地确定它填的情况，暴力枚举这种数即可。 CF1375F：不必多说。 f. 加强构造条件 这个方法很像数竞不等式放缩的过程。有时构造的限制太松了，反而不知道如何下手。通过加强构造条件减少可能性是构造题非常常用的手段，它可以体现为通解、逆向、归约、调整、分治等复杂的技巧，在后面会提到。这一节以较为初级的增强限制和减少变量为主。\n在构造的过程中自然地加强和通过模型特征提示试探加强是加强构造条件的两个主要方法，加强过程中要保证有解性或最优性不变（否则就像不等式放缩过头）。考虑特殊情况下“必须得怎么构造”也能给加强条件指明方向（例 5\u0026amp;6）。\n在条件分析不下去的时候，也可以跳出复杂的关系限制，冒无解的风险去尝试一些特定的构造策略，有可能它刚好就符合了所有要求，或者有少量不符合可以微调改对。例如 yhx 在 WC2022 上讲的 [IOI2021] 喷泉公园 的贪心构造做法，就是通过试探得到的。\n总的来说就是不要因为题目给的条件无从下手就懵了，要主动尝试一些可能性。\n例：\nCF1599A=ISIJ2021CupT3：题目条件给人一种“可以任意改变左右和大小关系”的感觉，考虑一种大小关系的必然性（加强）：左右砝码可以配对，所有对要么都是左边大，要么都是右边大。容易想到排序 $a_{1\\cdots n}$ 后连续段交替取，可以保证有解，就解完了。 CF1270G：考虑将 $a_i$ 换元使得所有变量的限制条件都相同，否则感觉不好处理。令 $b_i=i-a_i$，则 $b_i\\in[1,n]$，目标条件转化成 $\\sum_{i\\in S}b_i=\\sum_{i\\in S}i$。考虑加强，试图使得每个 $b_i$ 都等于一个 $i\u0026rsquo;$，类似回路的结构可以满足该条件。建 $n$ 点图连边 $i\\rightarrow b_i$，找个基环即可。 CF1835C：作前缀和，目标转化为找到 $0\\le a\u0026lt;b\\le c\u0026lt;d\\le n,\\text{ s.t. }s_a\\oplus s_b\\oplus s_c\\oplus s_d=0$。可以鸽巢证明一定有解，但是 $4^k$ 这个大小太大了，考虑加强，通过强制使得低 $k$ 位相同，只对高 $k$ 位做鸽巢。按低 $k$ 位分组后发现恰可以取出 $2^k+1$ 对数，低 $k$ 位相同，分别求出它们高 $k$ 位的异或后即可找到所求。 CF1391E：pairing 的条件极为诡异，无法处理。考虑 dfs 树，好处在于额外的边只可能出现在祖先后代之间。结合菊花等特殊情况或者用排除法，容易考虑选的点对不形成祖先后代关系，而这恰好吻合 pairing 的条件。最粗暴的方法是同深度的点两两配对，如果最长直链长 $\\ge\\lceil n/2\\rceil$ 那么就 path，否则因为同层奇数个而扔掉的点数至多 $\\lfloor n/2\\rfloor$。 ARC153C：其实也可以归到调整一节里。先随便安排 $x$。我当时的思路是，如果 $\\sum A_i\\ne 0$，那么可以全体 $\\pm$，否则如果 $A$ 形如括号序列那么无解，否则可以找到两个位置（$n$ 和后缀中第一个 $j$ 满足 $A_j\\ne A_n$ 且 $\\sum_{i=j+1}^nA_i=0$）作为“调整工具”。题解区大部分是利用前后缀统一 $\\pm$ 来调整，异曲同工之处就是将 $n$ 个变量加强成只有 $\\le 2$ 个变量可以调整，反而方便构造。 CF1218G：先加强成要求三部的点邻边和 $\\bmod 3$ 必须分别为 $0,1,2$。考虑只取出一棵树（最“紧”的情况，也算加强），其余边全部赋 $3$。可以调整 $n-1$ 条边，因此只有根可能不满足，试图微调。如果是一个基环树，那么环长为奇时可以解方程，全体满足；否则原图为二分图，仅要求要求一部 $\\bmod 3=1$，另一部可以为 $0$ 或 $2$，这样只需调成两部的目标和 $\\bmod 3$ 同余即可。 USACO22OPENGoldT3：考虑答案下界，是有祖先后代关系的点的区间距离与无祖先后代关系的点的区间距离的一半的 $\\max$。只考虑 $s_1$，发现 $s_1$ 取合适的值，其他 $s_i$ 尽量向 $s_1$ 靠拢，就可以直接达到下界，其他点之间复杂的关系不形成瓶颈，自动消解掉了。 [互测 2023] 天空度假山庄：可以置换使得必然依次捡 $1,2,\\cdots,n$ 的草莓（不算加强）。然后想象如何证明正解构造一定不会两次经过同一条边，如果构造过于混乱那肯定没法证，所以要先缩小可能性。希望证明形如：对于一条边 $(u,v)$，它只会出现在从 $f(u,v)$ 走 $k$ 步到 $f(u,v)+1$ 的路径上。初步思路是按编号差分类，如果 $i\\rightsquigarrow i+1$ 上面只放 $v-u\\equiv i$ 的边，不行。又立即考虑到所有路径上同一步放编号差相同的（例如 $k=2$ 是 $[2,-1]$），问题转化为构造一个长为 $k$ 的序列，和 $\\equiv 1\\pmod n$，且 $\\forall\\,i\\le n/2$，序列中 $i$ 和 $n-i$ 出现的总次数 $\\le 1$。这个可以先构造 $[\\lfloor n/2\\rfloor,\\lfloor n/2\\rfloor-1,\\cdots,\\lfloor n/2\\rfloor-k+1]$，再随便调整一下。 g. 构造不依赖于输入的通解 对于输入非 $\\mathrm{O}(1)$ 的情况，如果对构造的限制较小，可能性较大，但难以基于题目要求条件进行讨论，可以尝试直接构造一个解，无论输入如何都满足条件。这其实也是一种加强，一种寻找模型当中的“必然性”的思维。有的时候只考虑根据输入推导出解也是一种错误的思维惯性。\n例：\nAGC052A。构造 $0^n1^n0$ 一定对，因为第 $n$ 个 $0$ 和第 $2n$ 个 $0$ 之间是一个完整的串，一定有 $n$ 个 $1$。 CF1495C。每三行填满一行，这样任何输入的 X 都能被“粘进来”。然后用一个竖线串起来一定可以，竖线稍微讨论一下。 CF1485D。$a_{i,j}$ 很小，如果 $b_{i,j}=\\operatorname{lcm}(2,\\cdots,16)$ 就非常地安全。部分加强，棋盘染色后黑格子置 $720720$，只剩下白格子的条件，取 $b_{i,j}=720720-a_{i,j}^4$ 即可。 h. 研究操作能实现的功能 在符合要求的情况下寻找（正推或逆推）某些具有特定功能的小结构或组合操作，再以这些“小单元”为跳板，去构造整个问题的解。另外一种情况是只有效利用题目允许的操作的一部分功能，这个思想也常在交互题中用到，例如 CF1299E 中第一步找 $1$ 和 $n$ 的过程。也是整题的突破口。\n核心思想是加强，以及分多步思考。\n例：\nCF715D：这类构造某结构使某方案数等于给定值的问题一般都可以二进制拆分（倍增）。但这题 $T$ 太大了，得六（$C_4^2$）进制拆分才行。建立 $6^k$ 的“源泉”，然后在旁边附着一个“管道”，收集需要的每一位数。\nCF1773J：这题必要的无解条件并不明确，先考虑仅部分利用这个复杂的操作，生成树联想到消圈法，发现如果 $e_1,e_2$ 同属于一个简单环，则可用两步操作将 $e_1\\xleftarrow{+}x,e_2\\xleftarrow{-}x$，其余边不变，因此有且仅有同一点双内的边是“连通”的（点双内的每对边都同处于某个简单环内）。并且一个点双选的边数固定，故有解当且仅当存在一个 $S$，操作一次 $+S$ 后每个点双内边和等于目标和。微调操作可做到 $m$ 步。\nCF1748F：发现可以在 $4\\cdot (j-i)$ 次内远程异或，将 $a_j\\xleftarrow{\\oplus}a_i$。利用 y^=x^=y^=x 等价于 swap(x,y) 直接构造需要 $3n^2$，但可以去除多个远程操作之间的重复部分做到 $1.5n^2$，利用环的另一个方向可以做到 $1.25n^2$。\nCF1060H：倒推。在只能作幂的情况下，$xy$ 仅能通过 $(x+y)^2-x^2-y^2$ 得到。考虑通过 $x^d,(x+1)^d,\\cdots,(x+d)^d$ 的线性组合得到 $x^2$，由于方程的系数是范德蒙德矩阵，故一定有解。现在只需支持乘常数即可，用二进制拆分。\nCF1120E：首先明确的一点是 $an$ 一定被大量的 $0$ 占据，但并不能直接找到。考虑 $an=10^kh+l$，然后在此基础上对个别位调整，改变 $w(n)=S(n)-S(an)\\cdot a$。然而容许调整的范围太小，转而考虑多个 $10^kh+l$ 拼接在一起。对 $w(n)$ 做背包或按 $w(n)$ 值域建点跑最短路即可。\nUOJ #75：不必多说。\ni. 逆操作与中继状态 对于构造操作序列类题来说，这也是一种转换视角的方式。\n逆操作不要求给定操作可逆，只需要把操作本身逆过来看就行了，可能有更多性质。\n还有一类起始状态与终止状态均给定的情况，不容易直接构造，就可以考虑分别将两个状态先操作到某个固定的中继状态，再把后一半逆过来。\n例：\n[WC2022] 序列变换：思考这题需要一定的冒险，因为正解的线索不多。第一部分构造是将 $s_1$ 变成 $\\texttt{(())()()…()}$，然后删掉开头里面的那个括号。每次考虑末尾最后一段非 $\\texttt{()}$ 的子合法段，可以用 $1,2,3$ 操作之一将一部分脱离出来，构造得当可以做到 $\\le 2n-4$ 次（需要均摊分析）。第二部分是将 $\\texttt{()()…()}$ 变成 $s_2$。设 $s_2=\\texttt{((A)…(Z))}$，那么可以先递归得到 $\\texttt{(A)…(Z)()()}$，然后不断 $4$ 操作将倒数第二个括号扩到完整包含前面。注意最后一个括号是 $5$ 操作额外加的，不然 $4$ 操作无法进行。这一部分 $\\le n$ 次，总共 $\\le 3n$ 次。 CF778D：操作两次等于不操作，考虑将任意状态归到骨牌全部水平。正解思路是依次扫描，遇到竖直的硬调整；实际上每一轮扫描全体，奇数轮尽量把竖变横，偶数轮尽量把横变竖，进行足够多轮也能过。 [第五届图灵杯高级组 T2] 基础循环结构练习题：倒过来考虑，操作变成：① 全体减（不能有负）；② 选一个 $\u0026gt;\\max$ 的数 $v$，每个数加若干倍 $v$。其中第二个操作灵活性就很大。在递增的情况下，可以逐个把最小的数减成 $0$ 后变为最大的数；在非递增的情况下可以先 $b_i\\xleftarrow{+}iv$。 j. 外围排除法 对于安排给出元素类题，常常会出现限制过于紧或复杂，无法直接构造的情况。这时可以尝试先基于题目条件，进行一些大规模的，充分的推理，或许可以有效地简化甚至解决原问题。\n这种排除法的要点有：\n找到排除的突破口。往往是题目条件的一个定量形式的推论。 解决无法继续排除时的问题。 确定排除的顺序和实现方法。可以将排除过程类比为不断消除一个有向图入度为 $0$ 的点。使用外围排除法的题目常常会要求优化时间复杂度。 这种方法的本质恰好是与 f 相反的，这里是只利用条件的一部分（弱化），然后就能构造成功。可以类比为数独中的排除法和假设法。\n用这种方法的题可能无法在一开始就确定无解条件，一般这样考虑：如果有解，那么推理就能一直进行下去；因此逆否命题就是，如果推理进行不下去，就无解了（例 2）；或者是无法推理了就是合法解，空了则无解（例 4\u0026amp;5）。\n例 6\u0026amp;7 讲的是一类变形，一般基于图。它的排除条件不一定是基于必要性的推理，而可能也是加强。这种反倒类似于 k，其关键在于保证每一步操作前后有解/最优性不变。\n例：\nCF1546E：排除线索是，若某一列一种数恰好只有一个那就可以确定对应排列一定在拉丁方里，同时可以排除与它有冲突的一些排列。这样，每时每刻剩余的排列一定是 $x$ 个拉丁方内的，$y$ 个拉丁方外的，并且每个外部的一定对应 $x$ 个内部的中的一个（$y\\le x$）。如果无法排除，则每列都有 $\\ge x$ 种数，且每种数 $\\ge 2$ 个，由鸽巢原理，$y=x$，同时如果找到了一组拉丁方的剩余 $x$ 行，那它的补集也是合法的剩余 $x$ 行。因此可以随便选一个排列固定选它，答案 $\\times 2$，继续递归处理。\nCF1054G：叶子是一个值得考虑的突破口。如果某集合只有单个元素则可以忽略。设点 $x$ 所在的集合编号集合为 $A_x$，如果 $A_u\\subseteq A_v$，那么 $u$ 可以作为 $v$ 的儿子叶子。因为如果原问题有解，$u$ 不是 $v$ 的儿子叶子，则可以调整成 $v$ 的儿子叶子并保持合法。并且每个叶子 $A$ 一定存在一个超集，因此找不到包含关系就无解。具体实现用 bitset，维护包含关系的二维数组，每次删点只会更新一小部分。\nCF1439B：也是一个图找子集二选一问题，但是不能直接构造。显然度 $\u0026lt;k-1$ 的点可以忽略，度 $=k-1$ 的点只可能参与唯一的团，如果所有点度都 $\\ge k$ 那么就完事了。由于是一个归纳的过程故已删去的点不考虑也没问题。判团可以用哈希表或离线每个点依次判定。由于一个团花费 $k^2$ 时间，边数减了 $k$，而 $k=\\omega(\\sqrt m)$ 时无解，故至多 $\\mathrm{O}(m\\sqrt m)$。\nCF1656H：突破口是，（对称地来说）如果对于某个质数 $p$，$\\exists\\,i,\\forall\\,j,v_p(a_i)\u0026gt;v_p(b_j)\\quad\\cdots(*)$，那么 $a_i$ 可以扔掉。如果没得扔，剩余部分就一定符合条件。发现无法分解质因数，但 $(*)$ 等价于 $\\gcd_j(a_i/\\gcd(a_i,b_j))=1$，可以用 $2n$ 棵线段树维护这些值。\n[IOI2022] 千岛：通过小样例模拟可以感知到环的作用，大致需要两个环且需要有特定的位置关系，但难以简单地描述和寻找。考虑如果有点没有出度则可以删去，如果起点出度为 $1$ 可以直接向后走，若这两个情况都排除完毕，则可以除起点外其余点任取一条出边，这样起点可以到达两个或重合或不交的环，即可构造方案。\nCF1503F：将每张卡视作一个节点，如果一面的数是正的就像对应负的卡连边，这样入度+出度=2。尝试大量样例，发现有解性与只有出度的点和只有入度的点之间的路径距离奇偶性有关，但具体构造仍无法处理。发现如果出现一条三个点的链，那么这三个点可以紧邻着构造，也就是可以合并，于是用队列不断合并即可，最终出现环则无解。我在解这题时并没有对最终的合并法给出严谨的证明，题解区应该有。\n与这题类似的是 [WC2021] 括号路径（非构造题）。\nCF1610F：上界是邻边中权为 $1$ 的有奇数个的点数。这样的点的其他邻边都可以一入一出，两两匹配，这就启发进行合并或欧拉回路。事实上这两种方向都可以解。第一种方向就直接合并，用链表维护边序列即可。最终会剩下一堆 $1/2$ 交错链和环，直接安排。\n与这题类似的是 CF1499G。\nk. 归约法和增量法 这两种方法的最大特征在于递归，类似于数学归纳法在数学中的地位。它们与 j 的共同点在于，都无法直接解决整个问题，而是着眼于每一个“单步构造”，多个“单步”自动构成整个解。\n归约法的思想是考虑找到结构的某个子部分先构造掉并删去，缩小到一个形式相同，规模较小的子问题。\n增量法的思想是假设目前结构有一个现成的构造方法，如何将它扩展到更大的情况。\n归约法的思考往往比增量法容易，因为增量法是自依赖的，而归约法可以假定子问题必定可以解决。增量法的增量结构有时较复杂，难以确定，可能需要先递归地思考，再用增量法回溯。无论如何，要根据具体题目模型的条件限制关系来决定使用哪种思考顺序。\n例：\nCFgym101221A：经过多次尝试，发现最优解开头与结尾有规律，可以通过四步将开头的四个 A 与结尾的四个 B 归位，中间部分递归构造。最优性分析可通过“相邻相同数”作为势能来分析。\nCF1470D：归约法的思路是，（加强）每次任选一个点，将它与相邻点删去，实质上连出一个”菊花“。为了保证删去部分时刻连通，任选的点应当有至少一个邻点已被删去。增量法的思路是，每次加入一个与当前点集至少连有一条边的点，决定其是否要选。两者实质相同。\nCF1019C：直接归约是不行的，因为不能在不考虑剩余结构的情况下贸然钦定一个点选。如果用增量法，加入一个点时若其出点选了则会出问题，入点则不会。于是考虑原图，每次删去任一点及其出点，然后倒过来加入。若其入点已选则没问题，否则选本身。\n[CCO2020] 旅行商问题：下界为 $n-1$，考虑增量法，维护先全红后全蓝的链，设红蓝交界点为 $m$。加入一个点时如果能直接连接到 $m$ 之后则直接连，否则它与 $m$ 的边一定是蓝色，这时可以夹到 $m$ 和 $m$ 的前驱之间。这个构造和竞赛图哈密顿路径的构造有异曲同工之处。\nCF1267H：一定有一种颜色很多，并且考虑到这种颜色参与使得原条件满足的一个必要条件是永不出现两个都是该颜色的相邻。这是一个弱化的条件，但是如果要求只考虑其他颜色仍然满足原条件，那就是充分的了。于是就有一个归约方法。将出现过相邻的位置之间连边，容易贪心选出一个大小至少为 $\\lceil n/3\\rceil$ 的独立集，剩下的归约即可。这题关键在于一开始对题意正确的诠释与转化。\nCF1744D：第一反应应该是给边定向，使得拓扑序变化量尽量大。首先满度点可以忽略，其次尝试达到上界。发现如果两点 $u,v$ 之间无边则可以互换 $p_u+1=q_v+1=p_v=q_u$，因而考虑反图。由于不能保证完美匹配故考虑加强只取反图的生成森林，然后将互换法推广成菊花，然后菊花剖分。菊花剖分用归约，根处特殊讨论类似 e 例 4。\nl. 调整法 注意构造题的调整法与 exchange argument 无关。\n调整的本质是基于已构造的结构进行二次构造，也是一种加强。一般用于两种情况：\n基本上已构造完毕，完善局部在最极端情况下会错的构造（初步构造→发现矛盾→解决矛盾）。 从极端构造出发，多步调整直到符合条件（往往用于构造某个结构使得某个相关值为 $K$ 这类）。 调整法往往与 c、h、k 等共同使用。\n例：\nCF1098C：首先可以二分出答案 $d$，然后考虑从完全 $d$ 叉树开始调整（类似 CF1311E），需要保证 $s$ 时刻属于当前未确定点的可调整范围内——如果再在当前层放点，就算剩余点连成直链也不够 $s$，就要直接跳到下一层。这样一定不会出现上一层未放满父亲数还不够的情况，否则上一层应该再多点。\nCF922F：确定最优解后，考虑从全选调整到 $f$ 恰好为 $k$。$\u0026gt;m/2$ 的数调整不会导致贡献的连锁改变，可控性较强。$m$ 足够大时 $\\sigma_0(m)\\le (m/2,m)$ 中的质数数量，$m$ 较小时可以直接贪心，打表验证。\n[IOI2020] 网络站点：先考虑直接用 dfs 序，发现最后一个儿子的子树与本身子树外后 dfs 到的节点无法区分，因此考虑调整为所有儿子记出栈时间，以此类推，按层数奇偶性决定记入栈还是出栈时间戳。\n[NOIP2022] 喵了个喵：思考 subtask 1，每个栈维护两个牌，分别记为“底”和“顶”。留一个空栈用于消底。在 $k=2n-1$ 时仅有所有种类牌均存在 $1$ 张时会出问题。出现这种情况时不应贸然将最后一种牌（记为 $x$）放到仅有的空栈里——如果下一步消的是一个底，那么 $x$ 直接放到这个底对应的顶上。推而广之，这启发我考虑后面第一个消底的步骤，在这之前消的都是顶，好处理。如果这个底对应的顶在期间出现了偶数次，那么也可以将 $x$ 放在这个顶上，否则 $x$ 可以放在空栈里。这样的话当消第一个底后至少留有一个空栈。如果后面第一个消底之前先消了 $x$，则可以直接把 $x$ 放在空栈里。\n这题实际上最恶心的是实现。\nm. 做法拼合 用这类方法的题较少见，其主要难点在于找到一个分界条件，使得两种做法恰好能完美覆盖所有情况。一个重要的点是不要因为一个构造方法不能解决整个问题就把它舍弃掉。\n常用于找图的一部分，满足两个条件中的一个这类问题。\n例：\nCF1097E：发现上界至少是 $f(n)=\\max{k\\mid k(k+1)/2\\le n}$，可由 $[1,3,2,6,5,4,10,9,8,7,\\cdots]$ 取到。一个基本的归约思路是每次取 LIS 和 LDS 中较长的删去，但通过随机大数据筛选发现这个长度可能 $\u0026lt;f(n)$，这可能导致多划分了一个但上界不变。正确的方法是如果 $\\text{|LIS|}\\ge f(n)$ 则选 LIS，否则由 Dilworth 定理，最小 DS 覆盖必 $\u0026lt;f(n)$，直接覆盖即可。 CF1364D：dfs 树。如果所有返祖边跨度都 $\u0026gt;k$，那么任选一个环，隔一个选一个即可得到独立集。 CF1148G：将互质的数之间连边构成一张图，直觉上来说连通块数量较大就可以选独立集，否则可以选每个点至少有一条边。后者只对连通块保留生成树即可。加强，考虑对于每一个数求出前面任意一个与它互质的数连父亲，这样如果根数 $\\ge k$ 就有独立集了，否则由鸽巢原理必存在一个大小至少为 $3$ 的树（不选它，用于后面调整用），现在可以随意贪心选树，如果出现剩余只需选一个点的情况就不行了，这时上一步应当与开始找到的大小至少为 $3$ 的树之间调整一下使得每棵树里都至少选两个点。 n. 分组与分治 例：\n[NOIP2020] 移球游戏：如果每次只分离一种颜色那太浪费了。考虑如果只有两种颜色但每种颜色不止一根柱子怎么做。一种思路是每次合并两根杂色柱子。先将一根柱子的颜色分出，多的一种颜色放在该柱子上，少的一种放在一根临时柱上。再将另一根柱子的该颜色归过去，剩余部分归入临时柱，这样就变出一根纯色柱子。 以下是一个例子：\ninitial 柱一: 122112112 柱二: 212221122 临时: ????????? 空柱: stage 1 柱一: 122112112 柱二: 212221122 临时: ????? 空柱: ???? stage 2 柱一: 柱二: 212221122 临时: ?????2222 空柱: ????11111 stage 3 柱一: 2222 柱二: 212221122 临时: ????? 空柱: ????11111 stage 4 柱一: 222222222 柱二: 临时: ?????1112 空柱: ????11111 设较多的一种颜色在柱一中出现了 $a$ 次，那么四个阶段分别的移动次数为：$\\min(a,m-a),m,a,m$，因此至多 $3m$ 次，套上值域分治即可。只剩余两根杂色柱子时要特殊规划一下，也可以做到 $3m$。\n[互测 2021] 聚会/Steiner 三元系：首先用 b 证明仅有 $n\\equiv 1/3\\pmod 6$ 时有解，其次构造无法直接递归或增量构造。考虑分组。$n=6k+3$ 时考虑将点平分成三组，连这样的结构：\n这相当于构造一个 $2k+1$ 阶对称拉丁方 $A$（下标从 $0$ 始），且 $a_{i,i}=i$。可取 $a_{i,j}=\\frac{i+j}{2}\\bmod (2k+1)$。\n$n=6k+1$ 时考虑拿出一个点 $o$，剩余平分三组。将组内边消光后应当还剩余组间的 $6k$ 条边及与 $o$ 的 $6k$ 条边。取 $a_{i,j}\\equiv\\begin{cases}\\frac{(i+j)\\bmod 2k}{2},\u0026amp;2\\mid(i+j)\\\\ \\frac{(i+j)\\bmod 2k+2k-1}{2},\u0026amp;2\\nmid(i+j)\\end{cases}$，这样相邻层间只剩 $(i,i)$ 和 $(n+i,i)$（$0\\le i\u0026lt;n$），可以处理掉。\n通用的思考方法 以上的技巧与解题思想都只是构造题的冰山一角，还存在着大量的技巧变式和无技巧构造，我们不能对于每道题都枚举所有套路逐一试错，而需要具体情况具体分析。对于任意给出的一道构造题，我们该如何入手思考？\n首先要明确的一点是，OI 中的构造题一定有一个很突出的突破口，一般来说是一个具体的思考方向（观察角度、加强方式、构造顺序或初步构造结构形式等）。这与其他题目是有很大不同的。当没有想到这个突破口时，一切分析都看似杂乱无章，没有作用；但从突破口向下推导，构造的正确性就会自然浮出水面。\n突破口不应当完全依靠猜或试找出来，而是主要通过线索推断出来。这样的线索可能是特殊的题目条件（包括数据范围）、某种特殊情况、导出的性质、对模型某个量的数学分析、对必然性的分析、对模型的观察转化，甚至是打表的结果或者对部分分解法或错误解法的进一步调整和研究。\n从而我提出解构造题的一个思考过程：\n读题，获取模型特征，结构类型，条件限制的类型和可能性多少。 分析条件，转化条件，试图导出初步结论，例如确定无解和最优化条件。 模拟样例，对模型有初步的感知，并尝试对模型的观察角度及呈现形式进行转变，重复做该步骤。 小结，总结目前已知的性质和转化方式，剩余的问题的特征，并指出可能的方向与角度。 进一步深入尝试，循环往复。 找到一个正确的方法后，尝试换角度描述或找性质以进一步简化、优化实现。 当解构造题长时间卡住时，我的经验是自己一直在一个不可能解决的范围内打转，而真正漏的方向或错误排除的方向是在其他的地方。因此要回到原题目模型，再次分析特征，寻找可能的方向，同时也要回顾自己先前想到的方向，写清楚问题模型和错误解法模型，尝试调整错误，可能会柳暗花明又一村。如果没有陈述清楚问题，也会妨碍构造，遗漏正确思路。\n参考文章 蒋凌宇，《信息学竞赛中构造题的常用解题方法》，IOI 2021 集训队论文集 虞皓翔，《构造题选讲》，WC 2022 讲课 William Cherowitzo，《Steiner Triple System》，http://www-math.ucdenver.edu/~wcherowi/courses/m6406/sts.pdf ","date":"2023-10-08T00:00:00Z","permalink":"https://littlereuben.github.io/study/constructive-problems/","title":"构造题方法总汇"},{"content":"这是一篇摘抄笔记。\r本文基本上就是 Optimal Preprocessing for Answering On-line Product Queries 和 Data Structures for Range Minimum Queries in Multidimensional Arrays 的非形式化翻译，掺杂了自己的理解和思路，略去了一些细节。\n主要讲一下比较基础的静态数组、高维数组的区间查询问题。两篇论文其实关系不大，只是后一篇用了前一篇的部分成果。\n理论性比较强，尤其是后一篇，基本上出不成题。\n静态序列区间半群查询问题 问题：给定半群元素序列 $a_{1\\cdots n}$，在只能使用半群运算 $\\circ$ 的情况下，多次询问区间 $[l,r]$，回答 $\\circ_{i=l}^r a_i$。\n解决思路无非就是预处理一些区间的积，查询时拼起来就行。联想到正常的动态区间查询问题，动态情况下下界就是 $\\Omega(\\log n)$ 的。静态情况下允许的预处理量大大增加，因此分析下去会不一样，但思路还是可以借鉴的。总体来说，核心的思想就是两点：\n预处理与查询的平衡。 分块与分治。 记 $k$ 表示回答查询时允许的半群运算次数 ${}+1$。\n最初的思考从 $k=2$ 开始（$k=1$ 只能预处理所有平方个区间），我们要给每个区间 $[l,r]$ 选定一个切分点，然后进行所需的预处理。为了使公共预处理区间尽量多，考虑每次选择一个点，将所有尚未确定切分点，且能以该点为切分点的区间的切分点选定为该点。这个就是猫树，下面说点题外话。\n记猫树的预处理量为 $p(n)$。每次选取中点作为切分点的最优性是由 $p(n)$ 的凸性保证的。我们可以通过解递归式得到： $$ p(n)=n\\lfloor\\log_2(n-1)\\rfloor+2n-2^{\\lfloor\\log_2(n-1)\\rfloor+1} $$ 为了方便 $\\Omicron(1)$ LCA，猫树有少量冗余。理论上递归可以只进行 build(l,mid-1) 和 build(mid+2,r)，并且在 $r-l\\le 1$ 时结束，记猫树最优的预处理量为 $p^\\prime(n)$： $$ p^\\prime(n)=(n+2)\\lfloor\\log_2(n+1)\\rfloor-n+2-2^{\\lfloor\\log_2(n+1)\\rfloor+1} $$ 猜想：对于长为 $n$ 的序列，$k=2$ 情况下符合条件的预处理区间集合 $\\mathcal{P}$，除去 $n$ 个单元素区间，${\\lvert\\mathcal{P}\\rvert}_{\\min}=p^\\prime(n)$。\n注意这里的最优性和上文的最优性是不一样的，上文是“每次选择一个切分点，然后两边递归”这个思路前提的基础上的最优性。\n纠结于系数意义不大，我们关注 $k=2$ 情况的结构带来的启发。“预处理前/后缀和”是非常有效的线性手段。\n但是如何推理 $k\u0026gt;2$ 呢？众所周知，动态情况下的线段树是从分块嵌套演化过来的，因此考虑类比逆推多个切分点的情况（只预处理每一块内的前后缀和）：\n对于一个询问，如果它在块内部，则递归 $T_2$ 处理，否则两头散块可以用前后缀和算出，然后考虑 $T_1$ 用于维护每块的和形成的较短序列，处理块间部分。\n记块大小为 $B(n)$，预处理复杂度为 $p(n)$，回答询问使用的运算次数最多为 $q(n)-1$。下文中可能出现多个 $f(n)$，作用域仅在单自然段内。\n利用分治的思想，考虑三种可能（记 $q(n)=k$ 的数据结构为 $S_k$，$S_2=$ 猫树）：\n$T_1=T,T_2=T$。\n$p(n)=p(n/B(n))+n/B(n)\\cdot p(B(n))+\\Theta(n),q(n)=\\max\\set{q(n/B(n))+2,q(B(n))}$，上下均自递归的结构其实很像 vEB 树，因此考虑取 $B(n)=\\sqrt n$，将 $p(n)$ 展开后使用初中处理因式的技巧，就可以得到 $p(n)=\\Theta(n\\log\\log n)$，同时 $q(n)=\\Theta(\\log\\log n)$。我猜测无法更优了。 $T_1=T,T_2=S_2$。\n$p(n)=p(n/B(n))+\\Theta(n\\log B(n)),q(n)=q(n/B(n))+2$，可以对输入的固定的 $n$ 取 $\\forall i,B(i)=2^{\\sqrt{\\log n}}$，这样可以平衡成 $p(n)=\\Theta\\left(n\\sqrt{\\log n}\\right),q(n)=\\Theta\\left(\\sqrt{\\log n}\\right)$。这个方向没有前途的直觉解释是：分块后问题分成了 $T_1$——单个规模较小、$T_2$——若干规模很小，但总和不变 这两个子问题，直觉上后者是比前者难的，拿已有的结构作为 $T_2$ 基本没法优化。 $T_1=S_2,T_2=T$。\n$p(n)=\\Theta(n/B(n)\\cdot\\log(n/B(n)))+n/B\\cdot p(B(n))+\\Theta(n),q(n)=4$，很明显可取 $B(n)=\\log n$，从而做到 $p(n)=\\Omicron(n\\log^*n)$，这个就是 $S_4$。 第三种可能实际上提供了一个以 $q(n)$ 增加 $2$ 为代价，将 $p(n)=\\Omicron(n\\cdot f(n))$ 变为 $\\Omicron(n\\cdot f^*(n))$ 的通法（得满足 $f(n)=\\Omicron(\\log n)$，取 $B(n)=f(n)$ 即可），其中 $f^*(n)=\\min\\set{i\\mid f^{(i)}(n)\\le 1}$。 因此我们可以做到： $$ \\forall 2\\mid k\\ge 4,p(n)=\\Omicron(n\\log^{\\begin{matrix}k/2-1\\\\ \\overbrace{**\\cdots*}\\end{matrix}}n),q(n)=k $$ ……吗？\n这里有一个很容易犯的错误，就是如果不用主定理解递归式，那么解的过程中严谨地来说必须避免渐进记号。但 OI 实践中往往不拆也不会出问题，这里实际上套上了一个归纳，并且把 $k$ 作为变量塞进渐进记号里了，就得谨慎地算一下了。$k=4$ 时： $$ \\begin{aligned} p(n)\u0026amp;=n/\\log n\\cdot \\log(n/\\log n)+n/\\log n\\cdot p(\\log n)+2n-2\\log n\\\\ \u0026amp;\u0026lt;3n+n/\\log n\\cdot p(\\log n)\\\\ \u0026amp;=3n\\log^*n \\end{aligned} $$ 同理，可以算得 $k=6$ 时 $p(n)\u0026lt;5n\\log^*n$ 等等。因此： $$ \\forall 2\\mid k\\ge 4,p(n)=\\Omicron(n\\textcolor{red}{k}\\log^{\\begin{matrix}k/2-1\\\\ \\overbrace{**\\cdots*}\\end{matrix}}n),q(n)=k $$ 另外，为了完整，我们把 $2\\nmid k$ 也补上。$k=3$ 套上 $T_1=S_1$，（特例）取 $B(n)=\\sqrt n$，可以得到 $p(n)=\\Theta(n\\log\\log n)$ 的 $S_3$，$k\\ge 5$ 就跟 $k-1$ 情况一样了。\n为了平衡 $p(n)/n$ 和 $q(n)$，考虑取 $k=2\\alpha(n)+2$，其中： $$ \\alpha(n)=\\min\\set{i\\mid\\log^{\\begin{matrix}i\\\\ \\overbrace{**\\cdots*}\\end{matrix}}n\\le 3} $$ 这里 $\\le 3$ 时因为 $n\\ge 5$ 时不管有几个星，结果都至少是 $3$。您可能在其他地方见过 $\\alpha(n)$ 的不同定义方式，不同的定义应该都只差一个常数。\n这时 $p(n)=\\Omicron(n\\alpha(n)),q(n)=\\Theta(\\alpha(n))$。注意这里的 $\\alpha(n)$ 是无法变成 $\\alpha^*(n)$ 的，但是有另一个看起来不大优美的优化方式：\n仍然考虑上文的分块模型，$T_1=S_{2\\alpha(n)+2},T_2=T_{?}$，设 $T_{?}$ 的预处理时间为 $p_{?}(n)=\\Omicron(n\\cdot f(n))$。那么总的 $p(n)=\\Omicron(n/B(n)\\cdot\\alpha(n)+n\\cdot f(B(n)))$，如果要使得 $p(n)=\\Theta(n)$，唯一的方法是取 $B(n)=\\alpha(n),f(n)=\\Omicron(1)$，那么 $T_{?}$ 可以选择普通线段树。好在这部分的询问运算次数不是瓶颈，因此总的 $q(n)$ 只会加 $2$（最外层两端的散块）。这里主要是通过类似于待定系数法的方式解释一下论文里为什么会突然冒出普通线段树。\n这个优化的思想是，用“单个规模较小”优化预处理“常数”（红色的 $k$），“若干规模很小，但总和不变”尽管无法有效减小预处理复杂度，但是可以保证查询次数足够少。二者互补。\n我尝试类推优化掉任意 $k$ 的“常数”（红色的 $k$）（这个原论文里没讲），但 $q(n)$ 会加 $2$。这个是可以避免的：\n希望 $q(n)=k\\ge 3$，最外层是 $T_1=S^\\prime_k,T_2=普通线段树,B(n)=k$。$S^\\prime_k$ 是修改过的结构，基本与 $S_k$ 相同，即 $T_1=S_{k-2},T_2=S^\\prime_k,B(n)=f(n)$，这里 $f(n)$ 指的是设 $S_{k-2}$ 的预处理复杂度为 $\\Omicron(n(k-2)f(n))$。不同的点在于 $S^\\prime_k$ 处理的块内前后缀和是细分到原序列的，而不是严格遵循最外层分块结构把每 $k$ 个一组的和视为整体。这样就避免了最外层跨块时额外查一对前后缀和。$S^\\prime_k$ 的预处理复杂度仍然是 $p(n)=\\Omicron(nk/B(n)\\cdot f(n))+n/B(n)\\cdot p(B(n))+\\Theta(nk)=\\Omicron(nk\\cdot f^*(n))$，其他部分也都没有问题，总体来说就把 $p(n)$ 的 $k$ 除掉了，$q(n)$ 不变。最终我们得到了： $$ p(n)=\\begin{cases}\\Omicron(n^2)\u0026amp;q(n)=1\\\\ \\Omicron(n\\log n)\u0026amp;q(n)=2\\\\ \\Omicron(n\\log\\log n)\u0026amp;q(n)=3\\\\ \\Omicron(n\\log^{\\begin{matrix}\\lfloor k/2\\rfloor-1\\\\ \\overbrace{**\\cdots *}\\end{matrix}}n)\u0026amp;q(n)=k\\ge 4\\end{cases} $$ 但如果具体实现真想做到查询时间复杂度 $=\\Theta(q(n))$，那就得处理一个“变进制数 LCP 问题”，而且 $q(n)\\ge 4$ 后基本没法体现区别，所以只能套一个交互限制运算次数或者像 【北大集训2021】末日魔法少女计划 这样。\n下界的证明思路是对着这个分块结构硬证。对于 $k=2$，选择序列中点 $m$，将只包含于中点左侧（不含中点）和只包含于中点右侧（不含中点）的预处理作为一类，跨左右的预处理作为一类。考虑询问 $[m-i,m+i]$，要用两个预处理拼成该询问，就必须有一个跨左右的预处理。因此 $p(n)\\ge p(\\lfloor n/2\\rfloor)+p(\\lceil n/2\\rceil-1)+\\lceil n/2\\rceil-1$，解得 $p(n)=\\Omega(n\\log n)$。对于 $k\\ge 3$，按 $S_k$ 的块大小分块，但块间空出一位。也是先忽略块内的预处理，剩余跨块的预处理。对于一个位置，如果它不是任何跨块预处理的端点，则标记它。如果含有被标记位置的块不足一半，那么跨块预处理至少 $\\Omega(n)$；超过一半，那么考虑所有以标记位置为两端的询问，组成询问区间的最左右预处理一定是块内的，去掉这两部分后剩余问题一定不弱于 $k^\\prime=k-2,n^\\prime=n/B(n)$ 情况的问题，跨块预处理也是至少 $\\Omega(n)$，归纳即可，这里注意不会带有因子 $k$。论文里提到这个证明可以直接推广成“预处理可以是任意子集且不要求不交并”情况。\n因此，上述解法的半群运算次数是渐进最优的。论文标题上加了个 on-line，不知离线是否会有更好的结果。\n高维 RMQ 问题 问题：给定高维数组 $a_{1\\cdots n_1,\\cdots,1\\cdots n_d}$，在只能使用比较运算的情况下，多次询问高维区间 $[l_1,r_1],\\cdots,[l_d,r_d]$，回答 $\\min_{i_1\\in[l_1,r_1]}\\cdots\\min_{i_d\\in[l_d,r_d]}\\set{a_{i_1,\\cdots,i_d}}$。记 $N=\\prod n_i$。\n以下视 $d$ 为定值，但还是会尽量写一下关于 $d$ 的常数。以下假设 $a$ 中数互不同。\n先尝试把上文的静态区间半群查询问题的 $S_k$ 扩展到 $d$ 维结构 $S_k^d$：非常简单，处理块内前后缀和时，不再是存储单个元素，而是一个 $d-1$ 维数组，就需要嵌套下去，那就归约 $S_k^{d-1}$ 了。时间复杂度的变化是预处理的 $\\log$ 以及查询会带上 $d$ 次方。\n目前可以做到的是预处理 $\\Omicron(N\\log^{d-1}N)$，查询 $\\Omicron(2^d)$，也就是把最内层一维套个四毛子。\n但是我们的目标是预处理 $\\Theta(N)$，查询 $\\Omicron(1)$。可以推理得到以下几点：\n得用四毛子。 直接用 $S_2^d$ 之类的结构肯定不行。 那如果是 $S_3^d$ 的最内层套四毛子，是不是就可以做到 $\\Omicron\\left(N\\frac{(\\log\\log N)^d}{\\log N}\\right)=\\omicron(N)$ 了呢？答案是否定的，因为次内层的结构是带一个前后缀 $\\min$ 的，也就是要得到最内层建树所基于的序列，就先得乘 $\\Theta(n_d)$，而其他外层又无法直接套四毛子，所以如果用这种思路，就必定是 $\\Omega(N(\\log\\log N)^{d-1})$ 的。因此一维的四毛子不行。\n四毛子的关键是找到一个信息量足够小的贴近本质的刻画，那如何找到一个高维数组的所有可能的区间 $\\min$ 的刻画呢？不幸的是，论文中提到，二维的 $n\\times n$ 方阵不存在类笛卡尔树的刻画，因为在矩形 $\\min$ 查询意义下本质不同的方阵个数为 $\\Omega(((n/4)!)^{n/4})$，取对数发现光是靠比较来区分所有的情况都无法做到 $\\Omicron(n^2)$。\n一种新的刻画一维序列的方式如下：考虑猫树，树的每个节点预处理所有前后缀 $\\min$。尽管建树复杂度无法做到 $\\Theta(n)$，但比较次数是可以的：考虑一个节点的前缀 $\\min$，前一半从左儿子继承，后一半从右儿子继承的同时，要与左儿子 $\\min$ 再取个 $\\min$，而这个取 $\\min$ 的决策情况显然可以二分分界点，因此一个节点的比较次数可以做到长度的对数，总体来说就是至多 $2\\sum_{i\\ge1}i\\cdot\\frac{n}{2^i}=4n$ 次。\n猫树可以扩展到高维 $S_2^d$，但为了保证比较次数，处理方法要稍作调整：对于某个节点，设其对应的区间长度为 $2^{i_1}\\times\\cdots\\times 2^{i_d}$，由于不能多维同时二分，故选择最长的一维，将这一维切成两半后对应的节点信息作为继承 $\\min$ 值的来源，其他维暴力扫描，这一维二分。比较次数为（这里的 $2^d$ 是每一维都要前后缀）： $$ \\begin{aligned} \u0026amp;\\sum_{i_1,\\cdots,i_d}\\max_j\\set{i_j}\\cdot\\frac{\\prod_j2^{i_j}}{\\max_j\\set{2^{i_j}}}\\cdot 2^d\\cdot\\frac{N}{\\prod_j2^{i_j}}\\\\ ={}\u0026amp;2^dN\\sum_{i_1,\\cdots,i_d}\\frac{\\max_j\\set{i_j}}{2^{\\max_j\\set{i_j}}}\\\\ ={}\u0026amp;2^dN\\sum_i\\frac{i}{2^i}\\left[(i+1)^d-i^d\\right]\\\\ \u0026lt;{}\u0026amp;2^dN\\sum_i\\frac{i^{d+1}}{2^{i-1}}\\\\ ={}\u0026amp;2^{d+2}N\\cdot \\tilde{b}(d+1)\\\\ \\approx{}\u0026amp;\\frac{2^{d+1}(d+1)!}{(\\ln 2)^{d+2}}N\\\\ ={}\u0026amp;\\Theta(N) \\end{aligned} $$ 其中 $\\tilde{b}(n)$ 是 A000670。注意如果不选最长的一维切就不能线性了。\n由于这个结构并非确定唯一的最小值位置，而是给出 $\\Omicron(2^d)$ 个候选最小值，故它的线性复杂度并不与上文所说的“无法刻画”矛盾。\n好，现在选取边长为 $B=c\\log^{1/d}N$ 的 $d$ 维超立方体作为小块，使用四毛子（为了快速识别输入的每一小块的类型，避免带上 $\\log^d$，可以选取足够小的常数 $c$，$\\Omicron(N)$ 地预处理出判断块类型的决策树）。这种分块方式不是严格意义上的高维嵌套分块，需要重新考虑如何回答询问。\n注意到，只要询问有一个维度的区间是跨块，那么整块部分就可以直接利用除以 $\\log^{1/d} N$ 这个因子，套上 $S_3^d$ 从而达到 $\\Theta\\left(\\max\\Set{N,N\\frac{(\\log\\log N)^d}{\\log^{1/d}N}}\\right)$ 也就是 $\\Theta(N)$（因为 $d$ 是定值）；查询的每一维都是块内的情况不必多说。\n现在就剩下跨块时去掉中间整块后，散块即两端块内前后缀部分的处理。\n论文中给出的方法是：对跨块的这一维的所有块内前后缀 $\\min$（指的是多个内层 $d-1$ 维数组对应位置分别取 $\\min$），递归建 $d-1$ 维时的原问题结构。总体来说，需要预处理以下三部分：\n每个小块的类型； 每一维求出每个块的 $\\min$（$B$ 个内层 $d-1$ 维数组对应位置分别取 $\\min$），然后建 $S_3^d$。 每一维求出每个块内前后缀的 $\\min$，然后递归建 $d-1$ 维的结构。 询问时，如果所有维度都是块内，则直接回答，否则任选一个跨块维度，拆成三个部分处理。\n预处理复杂度 $p(n)=\\Theta(2^d\\tilde{b}(d+1)N)$，具体算一下会发现递归减一维的部分并不是瓶颈，识别小块类型才是。查询 $q(n)=\\Omicron(3^d)$。\n我想到的一个更简单的方法是：只预处理上文中 1 和 2 结构，$p(n)$ 不变。查询时利用 RMQ 可以重复考虑同一个数的性质，分别考虑每一个跨块的维度，忽略其散块部分（其他维保留原询问区间），在 2 结构中查询，这个是 $\\Omicron(d3^d)$；剩余未考虑的就是每一维都是散块的部分，一共有 $\\Omicron(2^d)$ 个（左右段各一个）块，每个小块 $\\Omicron(2^d)$，乍一看是 $\\Omicron(4^d)$，但实际上如果一个维度跨块了，它会给查询数量贡献 $\\times 2$，但在高维猫树中由于这维查的是前后缀，所以对候选最小值数量就不贡献 $\\times 2$ 了，因此还是 $\\Omicron(2^d)$。最终 $q(n)=\\Omicron(d3^d)$。\n","date":"2023-08-27T00:00:00Z","permalink":"https://littlereuben.github.io/study/paper2/","title":"读论文系列 #2——两个偏理论的静态数据结构问题"},{"content":"这是一篇摘抄笔记。\r前天 @changruinian2020 发了我一篇论文，让我帮他读读。以前基本上没有在毫无相关理论准备的情况下读论文，这里记录一下，挺有帮助的。链接。\n首先这篇论文在 OI 范围内没啥意义，纯粹就是练阅读能力，相对一些其他论文来说比较友好。如果您也想练习，推荐先去看原文，再对照一下下面提供的我的理解（不保证正确）。\n问题：给定一张 DAG $G$，点上带有字符串 $\\ell(v)$，给定串 $Q$，求 $Q$ 与 $G$（的所有路径中）的 LCS，一条路径对应的串就是点的串顺次拼起来。\n结构：求得每个单点 $v$ 与 $Q$ 的所有极长公共子串 MEM（说是可以关于 MEM 个数线性地求出，在另一篇论文里。记为 $N$ 个），记作 $(Q[x\\cdots x+\\kappa-1],\\ell(v)[i\\cdots j])$，然后选出一个 MEM 序列，要求 $x\\le x\u0026rsquo;,v\\rightsquigarrow v\u0026rsquo;$，允许 $v=v\u0026rsquo;$，如果这样有额外的条件 $i\\le i\u0026rsquo;$（这里加一撇表示序列中的下一项）。这个时候把这个序列在 $Q$ 和所有涉及到的 $\\ell(v)$ 中都划出对应匹配的子串，如果相邻两个 MEM 在 $Q$ 中或者某个 $\\ell(v)$ 中划的线有重合，就把前面的一个区间缩一下（$Q$ 和 $\\ell(v)$ 同时缩）。这样子得出的公共子序列一定能考虑到最优解。例子可以参见 Figure 1。\n求解：\n先考虑每个点只能选一个 MEM 的情况，那么只能在 $Q$ 中出现划线重合。这个问题相当于：$G$ 中每个点都挂了一些区间，要选一条路径，路径上的每个点选挂在上面的 $0$ 或 $1$ 个区间，得到 $[l_1,r_1],\\cdots,[l_t,r_t]$，其中要求 $l_i\\le l_{i+1}$。现在最大化 $\\sum(\\min(r_i+1,l_{i+1})-l_i)$。由于可能是在 DAG 上跳着走，所以有点难搞。给所有挂着的区间一起编个号，记 $dp[i]$ 表示 $i$ 号区间作为最后一个区间的答案。通过另一个神秘算法找到图的最小（可相交）路径覆盖（记为 $k$ 条），每一条路径统一更新其他所有点（对于每个希望被更新的点，找到路径上最后一个可达它的点，在那个点处理完时更新，这样就避免了后效性），然后就剩下路径内部转移了。具体统一更新的方法就是讨论 $\\sum$ 里的 $\\min$ 取哪一项，就变成了一个单点更新，求区间 $\\max$ 的问题了，每条路径维护两棵线段树/平衡树即可。这样就是 $\\mathrm{O}(kN\\log N)$ 的。\n补充一句，斜体部分在原文中说若要做到与 $\\lvert E\\rvert$ 无关得用 transitive reduction，这个东西看起来有些前途，NOI2021D1T3 用到了这个思想。\n然后要考虑点内部选多个 MEM 的情况。先考虑两个串之间的问题，仍然是已知两者的所有 MEM。这里我认为论文有笔误，显然 M.sort() 应该按照 $i$ 而不是 $x$ 排序。转移就按照 coverage 公式讨论：a. 两者都不重合；b. $T$ 中不重合 $Q$ 中重合（与第一步中类似）；c. $T$ 中重合且比 $Q$ 中重合得多（允许 $Q$ 不重合）；d. $T$ 中重合且比 $Q$ 中重合得少。值得思考的是：① 为什么不能将 bd 合并成 $T$ 中重合得且比 $Q$ 中重合的少（允许 $T$ 不重合）？因为这时要保证 $Q$ 中有重合，那就有两维限制，无法维护。② 为什么 d 无需考虑 $x$ 递增条件不满足的情况？因为这个在后续转移中一定不会成为最优解。\n综合起来，2 中的 ab 情况和 1 的点间更新是兼容的，不用额外转移了。\n这里最感到奇怪的就是这个 MEM 的引入以及链覆盖的做法。现在理论界确实有很多 parameterized 的解法（主要理论下界都被研究完了），即关于输入的某个示性数较优的解法。OI 中这类情况就较少。\n然后是一些闲话。\n形式化是一把双刃剑，保证了严谨性的同时给没有相关基础的读者竖起了一面妨碍理解的高墙。vuq 也讨论过“知识的诅咒”这一问题。当你会了一个模型时，你可以任意地把它形式化地表述出来，但是读者初步看了之后，不懂的还是不懂，因为他们看不到你的文字背后的思考过程（而且实际表述顺序很可能相对于思考顺序是颠倒的），你的 motivation 和 intuition，在理论体系上是怎样的存在（本质、意义、等价表述），当然也包括 vuq 里提到的联想知识；甚至单纯就是被一堆定义绕晕了，就放弃了。我以前看算法导论和部分集训队论文就是这种感觉，就像看别人的代码一样。\n但是论文都得保证严谨性。友善的作者可能会加入例子和非形式化解释，但不多。那我硬啃的过程就是把它变成自己的理解，我觉得关键就是在明确定义的前提下尽量带入自己的思路，尝试还原作者的想法。如果硬着头皮逐字逐句地去看文章，被动地理解，会很痛苦（很多情况下就是莫名其妙提出来一个 theorem 然后证明），而且无法收获思维上的营养。读的过程中要经常停下来，想象目前模型的图形化解释、例子以及如果我面对这个模型，我会怎么考虑。主动地去思考，会比较好。当然前提是核心 definition 和问题模型得先搞清楚，如果发现定义不自洽可以检查一下是不是有些专业表述望文生义了。一些无关紧要的延伸的定义也没必要抠得很明白。当然也没法 100% 搞清背后的动机，毕竟都是基于先前已有的论文成果往上堆。\n欢迎讨论。\n","date":"2023-08-22T00:00:00Z","permalink":"https://littlereuben.github.io/study/paper1/","title":"读论文系列 #1——串与 DAG 的 LCS"},{"content":"这是一篇学习笔记。\r提供一个 $\\mathrm{O}(Tn^3m)$ 的做法，目前在各 oj 上是 rank 1，运行时间为第二名的 $\\frac{1}{6}$ 以内。\n类似于本题解的方法不建议在考试中使用，非常耗时间。并且公式很丑。\n坐稳了！！\nStep 1 @Alex_Wei 已经把严谨的结构刻画讲清楚了，这里再写一下自己的理解（本质上是等价的），看起来不大优美，但比较直观。\n对于一个完整的序列 $a_{1\\cdots n}$，找出其最长的前缀 $a_{1\\cdots r}$，满足：前缀中 $\\le a_r$ 的数严格递增，$\\ge a_r$ 的数严格递减，类似于形成一个尖角。接下来暂时默认 $r\u0026lt;n$。\n如果 $a_{r+1}=a_r$，那么要求 $a_{r+1\\cdots n}$ 中，$\\le a_r$ 的数严格递减，$\\ge a_r$ 的数严格递增。这种情况恰好有 $2$ 种染色方案且得分相同。\n否则，记 $a_{1\\cdots r}$ 中最大的 $\u0026lt;a_r$ 的数为 $D$（不存在则为 $0$），最小的 $\u0026gt;a_r$ 的数为 $U$（不存在则为 $m+1$），不妨设 $a_{r+1}\\le D$（与之对称的一种情况是 $\\ge U$）。现在找到以 $a_{r+1}$ 开头的最长严格递减子段，如果子段末尾还有下一项，则记为 $a_s$，否则肯定是完美的。\n结论：此时完美数组的充要条件是，在 $a_{r+1\\cdots n}$ 中，$\\le a_{r+1}$ 的数严格递减，不存在 $(a_{r+1},a_r]$ 以内的数，且 $\\ge a_s$ 的数严格递增。\n如图，这是一个完美数组的例子（横坐标为下标，纵坐标为值）：\n它共有 $4$ 种染色方案，分别对应着下图中全不选/选一个黄色点染成绿色，其他黄色点染成红色：\n如果 $a_s\\in (D,a_r]$，那么只有 $1$ 种染色方案，以下是一例；如果 $a_s\\in (a_{r+1},D]$ 则无染色方案。\n同时，通过观察例子，可以发现多种染色方案一定是形如：一段前后缀颜色固定，中间剩下的区间，它有一个染色方案是全染红/绿，其余方案仅通过选其中某一个反转颜色得到。若 $a_{r+1}\\le D$，则允许变颜色的点是以 $(a_U^{-1},U)$ 为左上角，$(r+1, a_{r+1})$ 为右下角的矩形以内的点。这部分实际上是递增的，且相对值域是连续的。$a_{r+1}\\ge U$ 类似。\n以上的证明都是容易的，需要一些分类讨论。\n考虑哪种染色方案得分最大，容易发现最后一个可以变的点变色一定比其他点变色更优。因此最优染色一定是：$a_{1\\cdots r-1}$ 中 $\u0026lt;a_r$ 的和 $a_{r+1\\cdots n}$ 中 $\u0026gt;a_r$ 的染红色，$a_{1\\cdots r-1}$ 中 $\u0026gt;a_r$ 的和 $a_{r+1\\cdots n}$ 中 $\u0026lt;a_r$ 的染绿色，$a_r$ 两种均有可能。\nStep 2 下文中 $r,U,D$ 的含义不变。称出现了满足 $a_{r+1}=a_r$ 或 $\\le D$ 或 $\\ge U$ 的情况为“交叉”，$a_r$ 为“交叉点”。称 $a_{1\\cdots t}$ 为“前面”，$a_{t+1\\cdots n}$ 为“后面”。组合数里只要有负数结果就是 $0$，除了 $\\binom{-1}{-1}=1$。\n回到原问题。先来道开胃菜：前面已经交叉了。这时可以由 $a_{1\\cdots t}$ 确定后面染绿部分必须要小于某个值 $L$，染红部分必须要大于某个值 $R$。\n枚举后面有 $i$ 个染绿的。方案数为： $$ \\binom{L-1}{i}\\binom{m-R}{n-t-i}\\binom{n-t}{i} $$ 得分贡献为： $$ \\begin{aligned} \u0026amp;\\left[\\sum_{j\u0026lt;L}\\sum_{k\\le t}[a_k\u0026lt;j]j\\right]\\binom{L-2}{i-1}\\binom{m-R}{n-t-i}\\binom{n-t}{i}\\\\ +{}\u0026amp;\\left[\\sum_{j\u0026gt;R}\\sum_{k\\le t}[a_k\u0026gt;j](m-j+1)\\right]\\binom{L-1}{i}\\binom{m-R-1}{n-t-i-1}\\binom{n-t}{i} \\end{aligned} $$ 可以共 $\\mathrm{O}(n+m)$ 计算。另外需要求前面的贡献，可以用树状数组。\nStep 3 前面尚未交叉时，为了简化起见，分 $a_r;\\fbox{\u0026lt;/=/\u0026gt;};a_t$ 讨论。$a_r=a_t$ 也就是 $r=t$，这时暴力枚举 $a_{r+1}$ 后套用 Step 2 方法，时复只有两次方。\n$a_r\u0026gt;a_t$ 与 $a_r\u0026lt;a_t$ 的算法完全相同。下记 $L$ 为前面最大的 $\u0026lt;a_t$ 的数（不存在则为 $0$），$R=a_r$，$X$ 为前面 $\\le L$ 的数的个数，$Y=t-X$。\n求方案数可以用 dp。交叉之前，想象“识别尖角”的过程，每次新加入的 $a$ 允许处于两个区间中：\n实际计数时，只需要钦定一个区间就行了，一般不会计重。于是 $f_{i,j,k}$ 表示，交叉之前，$a_i=j$，区间另一个端点为 $k$ 的方案数。一种转移是枚举 $a_{i+1}$，然后转移到 $f_{i,a,j/k}$。\n$g_{i,j,k}$ 表示交叉之后，上一个染绿的为 $j$ ，上一个染红的为 $k$ 的方案数，转移略。$f$ 在 $i$ 作为 $r$ 时要转移给 $g$，为了避免信息不够无法转移以及计重的情况，$j\u0026gt;k$ 的 $f_{i,j,k}$ 只枚举 $a_{i+1}\\le k$ 以及 $a_{i+1}=a_i$ 的情况进行贡献，$j\u0026lt;k$ 的只枚举 $a_{i+1}\\ge k$ 的情况进行贡献。\n以上 dp 均可以用前缀和优化做到 $\\mathrm{O}(nm^2)$，但是这个 dp 无法类推求出得分和，我们放弃 dp，尝试直接推式子。同样地，还是只考虑 $a_{r+1}\\le D$、 $a_{r+1}=a_r$ 以及 $r=n$ 的情况，$a_{r+1}\\ge U$ 情况可以将 $a_i\\mapsto m-a_i+1$ 后套用 $a_{r+1}\\le D$ 的算法。\n首先，后面的结构大致包含这些要素：交叉前 $\u0026lt;a_r$ 的数个数、交叉前 $\u0026gt;a_r$ 的数个数、$r$、$a_r$、$a_{r+1}$、交叉后 $\u0026lt;a_r$ 的数个数、交叉后 $\u0026gt;a_r$ 的数个数。考虑枚举其中一些。\n对于 $a_{r+1}\\le D$，枚举交叉前 $\u0026lt;a_r$ 的数个数 $i$，交叉前 $\u0026gt;a_r$ 的数个数 $j$，交叉后 $\u0026lt;a_r$ 的数个数 $k$，方案数为： $$ \\begin{aligned} \u0026amp;\\sum_{a_r}\\sum_{D\u0026lt;a_r}\\textcolor{red}{\\binom{D-L-1}{i-1}\\binom{m-a_r}{n-t-i-j-k-1}}\\textcolor{green}{\\binom{D}{k}\\binom{R-a_r-1}{j}}\\textcolor{blue}{\\binom{i+j}{i}\\binom{n-t-i-j-2}{k-1}}\\\\ ={}\u0026amp;\\binom{i+j}{i}\\binom{n-t-i-j-2}{k-1}\\sum_{a_r}\\left[\\sum_{D\u0026lt;a_r}\\binom{D-L-1}{i-1}\\binom{D}{k}\\right]\\binom{R-a_r-1}{j}\\binom{m-a_r}{n-t-i-j-k-1}\\\\ ={}\u0026amp;\\binom{i+j}{i}\\binom{n-t-i-j-2}{k-1}\\sum_{a_r}C_D(i,k,a_r)\\cdot C_U(j,n-t-i-j-k-1,a_r) \\end{aligned} $$ 红色表示染红部分的方案数，绿色表示染绿部分的方案数，蓝色表示“交织”的方案数。枚举 $D$ 会比枚举 $a_{r+1}$ 稍微方便一点。$C_D$ 和 $C_U$ 主要是为了突出有关变量仅有三个（预处理即可）。\n对于 $a_{r+1}=a_r$，枚举 $l=r-t-1$ 以及 $a_r$，方案数为： $$ \\begin{aligned} \u0026amp;\\sum_i\\sum_k\\textcolor{red}{\\binom{a_r-L-1}{i}\\binom{m-a_r}{n-t-l-k-2}}\\textcolor{green}{\\binom{R-a_r-1}{l-i}\\binom{a_r-1}{k}}\\textcolor{blue}{\\binom{l}{i}\\binom{n-t-l-2}{k}}\\\\ ={}\u0026amp;\\left[\\sum_i\\binom{a_r-L-1}{i}\\binom{R-a_r-1}{l-i}\\binom{l}{i}\\right]\\left[\\sum_k\\binom{a_r-1}{k}\\binom{m-a_r}{n-t-l-k-2}\\binom{n-t-l-2}{k}\\right]\\\\ ={}\u0026amp;C_L(l,a_r)\\cdot C_R(n-t-l-2,a_r) \\end{aligned} $$ 这里明确一下组合意义：\n$C_D(i,j,a)$ 表示 $a_r=a$，要安排 $\u0026lt;a_r$ 的数，交叉前个数为 $i$，交叉后个数为 $j$ 的方案数。 $C_U(i,j,a)$ 表示 $a_r=a$，要安排 $\u0026gt;a_r$ 的数，交叉前个数为 $i$，交叉后个数为 $j$ 的方案数。 $C_L(i,a)$ 表示 $a_r=a$，要安排 $r$ 之前的数共 $i$ 个的方案数（不考虑交叉条件）。 $C_R(i,a)$ 表示 $a_r=a$，要安排 $r$ 之后的数共 $i$ 个的方案数（不考虑交叉条件）。 $r=n$ 的情况可以顺便计入。总体来说，计算方案数为 $\\mathrm{O}(n^3m)$，实际表现比 dp 还快。下面是计算得分和，思路与求方案数类似。\nStep 4 以下 $a_r=a_{r+1}$ 情况部分时间复杂度都是 $\\mathrm{O}(n^2m)$，一般情况部分则是 $\\mathrm{O}(n^3m)$。代码中的顺序和分析的顺序是一样的。\n交叉前下部 首先，不考虑交叉后部分与交叉前上部数值的安排，它们充其量就是外面乘一个系数。枚举交叉前 $\u0026lt;a_r$ 的数个数 $i$，交叉前 $\u0026gt;a_r$ 的数个数 $j$，以及 $D$，该部分得分为： $$ \\begin{aligned} \u0026amp;\\sum_{p=1}^i\\left[\\sum_{q=0}^j\\binom{p-1+q}{p-1}\\binom{i-p+j-q}{i-p}(q+Y)\\right]\\left[\\sum_{a=L+1}^D\\binom{a-L-1}{p-1}\\binom{D-a-1}{i-p-1}(m-a+1)\\right]\\\\ ={}\u0026amp;\\sum_{p=1}^i\\left[\\binom{i+j}{i+1}p+\\binom{i+j}{i}Y\\right]\\left[\\binom{D-L-1}{i-1}(m-L+1)-\\binom{D-L}{i}p\\right]\\\\ ={}\u0026amp;\\binom{i+j}{i}\\binom{D-L-1}{i-1}\\left[\\frac{ij(m-L+1)}{2}-\\frac{(2i+1)j(D-L)}{6}+iY(m-L+1)-\\frac{(i+1)Y(D-L)}{2}\\right] \\end{aligned} $$ 其中 $p$ 枚举交叉前下部的第几个数（称为“它”），$q$ 枚举有交叉前上部有几个数在它前面，$a$ 枚举它的值。第一个等号是利用 Vandermonde 恒等式，第二个等号就是正整数次方求和。记该式为 $(*)$。\n接下来再把剩余未确定的部分确定，枚举交叉后 $\u0026lt;a_r$ 的数个数 $k$，最终得分为： $$ \\begin{aligned} \u0026amp;\\sum_{a_r\u0026gt;D}(*)\\binom{R-a_r-1}{j}\\binom{D}{k}\\binom{m-a_r}{n-t-i-j-k-1}\\binom{n-t-i-j-2}{k-1}\\\\ ={}\u0026amp;(*)\\binom{D}{k}\\binom{n-t-i-j-2}{k-1}\\sum_{a_r\u0026gt;D}C_U(j,n-t-i-j-k-1,a_r)\\\\ ={}\u0026amp;(*)\\binom{D}{k}\\binom{n-t-i-j-2}{k-1}C^\\prime_U(j,n-t-i-j-k-1,D) \\end{aligned} $$ 预处理 $C_U(i,j,*)$ 的后缀和就不用枚举 $a_r$ 了。\n交叉前上部 思路是差不多的。先枚举交叉前 $\u0026lt;a_r$ 的数个数 $i$，交叉前 $\u0026gt;a_r$ 的数个数 $j$，以及 $a_r$，该部分得分为： $$ \\begin{aligned} \u0026amp;\\sum_{p=1}^j\\left[\\sum_{q=0}^i\\binom{p-1+q}{p-1}\\binom{j-p+i-q}{j-p}(q+X)\\right]\\left[\\sum_{a=a_r+1}^{R-1}\\binom{R-a-1}{p-1}\\binom{a-a_r-1}{j-p}a\\right]\\\\ ={}\u0026amp;\\sum_{p=1}^j\\left[\\binom{i+j}{j+1}p+\\binom{i+j}{j}X\\right]\\left[\\binom{R-a_r-1}{j}R-\\binom{R-a_r}{j+1}p\\right]\\\\ ={}\u0026amp;\\binom{i+j}{j}j\\left[\\binom{R-a_r-1}{j}\\left(\\frac{i}{2}+X\\right)R-\\binom{R-a}{j+1}\\left(\\frac{i(2j+1)}{6}+\\frac{(j+1)X}{2}\\right)\\right] \\end{aligned} $$ 抱歉让强迫症难受了，没法化得对称，否则分母上就会有未知数，得乘逆元了 /lb。\n剩余未确定的部分的方案数同理，枚举一下 $k$，就不写了，要乘 $C_D$ 等。\n另外 $a_{r+1}=a_r$ 和 $r=n$ 的情况的交叉前也可以方便地在这里算掉（反正都枚举 $a_r$ 了）。交叉前下部里就不用算了，会在 $a_i\\mapsto m-a_i+1$ 时当成上部算掉。\n另一种思路是不推上部，直接推 $a_{r+1}\u0026gt;a_r$ 情况的下部，我没试过，应该也是可以的。\n交叉点 枚举交叉前 $\u0026lt;a_r$ 的数个数 $i$，交叉前 $\u0026gt;a_r$ 的数个数 $j$，交叉后 $\u0026lt;a_r$ 的数个数 $k$，最终得分为： $$ \\sum_{a_r}C_D(i,k,a_r)\\cdot C_U(j,n-t-i-j-k-1,a_r)\\cdot\\max((Y+j)(m-a_r+1),(X+i)a_r) $$ $a_{r+1}=a_r$ 的部分可能要特殊考虑一下，代码里处理的思路是和交叉前放在一起算，直接乘 $C_R$，就不用枚举 $k$ 了。\n交叉后下部 交叉后就无需考虑 $r=n$ 了。先不考虑上部与“交织”的安排。枚举交叉前 $\u0026lt;a_r$ 的数个数 $i$，交叉后 $\u0026lt;a_r$ 的数个数 $k$，以及 $D$，该部分得分为：\n$$ \\begin{aligned} \u0026amp;\\sum_{i\\le t,a_i\\le L}\\sum_{p=a_i+1}^D\\binom{D-L-1}{i-1}\\binom{D-1}{k-1}p+\\sum_{a=L+1}^D\\sum_{p=a+1}^D\\binom{D-L-2}{i-2}\\binom{D-1}{k-1}p\\\\ =\u0026amp;\\binom{D-1}{k-1}\\left[\\binom{D-L-1}{i-1}\\underline{\\sum_{i\\le t,a_i\\le L}\\frac{(a_i+1+D)(D-a_i)}{2}}_{f_0(D)}+\\binom{D-L-2}{i-2}\\underline{\\sum_{a=L+1}^D\\frac{(a+1+D)(D-a)}{2}}_{f(D)}\\right] \\end{aligned} $$\n其中 $p$ 枚举的是交叉后下部的某个数值。记该式为 $(*)$。划线部分可以预处理。\n考虑剩余部分，枚举交叉前 $\u0026gt;a_r$ 的数个数 $j$，最终得分为： $$ (*)\\binom{i+j}{i}\\binom{n-t-i-j-2}{k-1}C^\\prime_U(j,n-t-i-j-k-1,D) $$\n交叉后上部 $$ {\\underline{a}{f}}{\\underline{b}{f}} $$\n先枚举交叉前 $\u0026gt;a_r$ 的数个数 $j$，交叉后 $\u0026gt;a_r$ 的数个数 $k$，以及 $a_r$，该部分得分为： $$ \\binom{m-a_r-1}{k-1}\\underline{\\left[\\binom{R-a_r-1}{j}\\sum_{i\\le t,a_i\\ge R}\\frac{(2m-a_i-a_r+2)(a_i-a_r-1)}{2}+\\binom{R-a_r-2}{j-1}\\sum_{a=a_r+1}^{R-1}\\frac{(2m-a-a_r+2)(a-a_r-1)}{2}\\right]}_{F(j,a_r)} $$ 最终得分同理也是要乘 $C_D$ 等，略。\n同样要处理一下 $a_{r+1}=a_r$，要做到三次方还得分离一下变量： $$ \\begin{align} \u0026amp;\\sum_{i,j,k,a_r}\\binom{a_r-L-1}{i}\\binom{m-a_r-1}{k-1}F(j,a_r)\\binom{a_r-1}{n-t-i-j-k-2}\\binom{i+j}{j}\\binom{n-t-i-j-2}{k}\\\\ =\u0026amp;\\sum_{a_r}\\sum_l\\left[\\sum_i\\binom{a_r-L-1}{i}F(l-i,a_r)\\binom{l}{i}\\right]\\left[\\sum_k\\binom{a_r-1}{n-t-l-k-2}\\binom{m-a_r-1}{k-1}\\binom{n-t-l-2}{k}\\right] \\end{align} $$ $l$ 就是 $i+j$ 换元，跟 Step 3 里的 $l$ 是一样的。注意第二个中括号里的不是 $C_R$。\nStep 5 说一下优化：我们希望瓶颈部分（四次方的最内层循环）运算次数尽量少，所以可以把只涉及到一部分变量的乘法先预处理掉，把能用分配律的乘法提到外层。\n然后就是 $18$ 次一取模优化。\nCode #define ansc ans. first #define anss ans. second int calcP() { int res = 0; CL (tree); for (int i=1; i\u0026lt;=t; i++) update(A[i]), res += c[i] ? getsum(A[i] - 1) * A[i] : (i - getsum(A[i])) * (m - A[i] + 1); return res; } pii calcX(int L, int R) { pii ans (0, 0); CL (cnt); int pre = calcP(), sumd = 0, sumu = 0; if (t == n) return {1, pre}; for (int i=1; i\u0026lt;=t; i++) cnt[A[i]] ++; for (int i=1; i\u0026lt;L; i++) sumd += cnt[i-1] * i, cnt[i] += cnt[i-1]; for (int i=m; i\u0026gt;R; i--) sumu += cnt[i+1] * (m - i + 1), cnt[i] += cnt[i+1]; for (int i=max(0,n-t-m+R); i\u0026lt;=min(L-1,n-t); i++) { ansc = (ansc + 1ll * C[L-1][i] * C[m-R][n-t-i] % MOD * C[n-t][i]) % MOD; if (i) anss = (anss + 1ll * C[L-2][i-1] * C[m-R][n-t-i] % MOD * C[n-t][i] % MOD * sumd) % MOD; if (n - t - i) anss = (anss + 1ll * C[L-1][i] * C[m-R-1][n-t-i-1] % MOD * C[n-t][i] % MOD * sumu) % MOD; } anss = (anss + 1ll * ansc * pre) % MOD; return ans; } pii calcI(int L, int R, bool flag) { pii ans (0, 0); CL (CD), CL (CU), CL (CUS), CL (CR); for (int k=0; k\u0026lt;n-t; k++) for (int a=L+1; a\u0026lt;=m; a++) CD[0][k][a] = C[L][k]; for (int i=1; i\u0026lt;n-t; i++) for (int k=0; k\u0026lt;n-t-i; k++) for (int a=L+i+1; a\u0026lt;=m; a++) CD[i][k][a] = (CD[i][k][a-1] + 1ll * C[a-L-2][i-1] * C[a-1][k]) % MOD; for (int j=0; j\u0026lt;n-t; j++) for (int k=0; k\u0026lt;n-t-j; k++) for (int a=R-j-1; a\u0026gt;0; a--) CU[j][k][a] = 1ll * C[R-a-1][j] * C[m-a][k] % MOD, CUS[j][k][a] = P(CUS[j][k][a+1], CU[j][k][a+1]); for (int l=0; l\u0026lt;n-t; l++) for (int a=1; a\u0026lt;=m; a++) for (int k=0; k\u0026lt;=l; k++) CR[l][a] = (CR[l][a] + 1ll * C[a-1][k] * C[m-a][l-k] % MOD * C[l][k]) % MOD; for (int i=0; i\u0026lt;n-t-1; i++) for (int j=0; j\u0026lt;n-t-i-1; j++) for (int k=1; k\u0026lt;n-t-i-j; k++) { ull res = 0; for (int a=L+i+1, _=0; a\u0026lt;=R-j-1; a++) { ADD(1ll * CD[i][k][a] * CU[j][n-t-i-j-k-1][a]); } res %= MOD; ansc = (ansc + 1ll * C[i+j][i] * C[n-t-i-j-2][k-1] % MOD * res) % MOD; } if (flag) for (int l=0; l\u0026lt;n-t; l++) for (int a=L+1; a\u0026lt;=R-1; a++) { int CL = 0; for (int i=0; i\u0026lt;=l; i++) CL = (CL + 1ll * C[a-L-1][i] * C[R-a-1][l-i] % MOD * C[l][i]) % MOD; ansc = (ansc + 1ll * CL * (l \u0026lt; n - t - 1 ? CR[n-t-l-2][a] : 1)) % MOD; } for (int i=1; i\u0026lt;n-t-1; i++) for (int j=0; j\u0026lt;n-t-i-1; j++) { for (int a=L+i; a\u0026lt;=R-j-2; a++) F[a] = (i3 * j * (3 * i * (m - L + 1) - (2 * i + 1) * (a - L)) + Y * (2 * i * (m - L + 1) - (i + 1) * (a - L))) % MOD * i2 % MOD * C[i+j][i] % MOD * C[a-L-1][i-1] % MOD; for (int k=1; k\u0026lt;n-t-i-j; k++) { ull res = 0; for (int a=L+i, _=0; a\u0026lt;=R-j-2; a++) { ADD(1ll * C[a][k] * CUS[j][n-t-i-j-k-1][a] % MOD * F[a]); } res %= MOD; anss = (anss + 1ll * C[n-t-i-j-2][k-1] * res) % MOD; } } for (int i=0; i\u0026lt;n-t; i++) for (int j=0; j\u0026lt;n-t-i; j++) { for (int a=L+i+1; a\u0026lt;=R-j-1; a++) F[a] = (1ll * C[R-a-1][j] * R * (i + 2 * X) + i3 * (MOD - C[R-a][j+1]) % MOD * (i * (2 * j + 1) + 3 * (j + 1) * X)) * j % MOD * i2 % MOD * C[i+j][j] % MOD; if (j) if (i + j \u0026lt; n - t - 1) for (int k=0; k\u0026lt;n-t-i-j-1; k++) { ull res = 0; for (int a=L+i+1, _=0; a\u0026lt;=R-j-1; a++) { ADD(1ll * C[m-a][k] * CD[i][n-t-i-j-k-1][a] % MOD * F[a]); } res %= MOD; anss = (anss + 1ll * C[n-t-i-j-2][k] * res) % MOD; } else for (int a=L+i+1; a\u0026lt;=R-j-1; a++) anss = (anss + 1ll * CD[i][0][a] * F[a]) % MOD; if (i + j \u0026lt; n - t - 1) for (int a=L+i+1; a\u0026lt;=R-j-1; a++) anss = (anss + 1ll * (F[a] + 1ll * (X + i) * a * C[R-a-1][j] % MOD * C[i+j][i]) % MOD * C[a-L-1][i] % MOD * CR[n-t-i-j-2][a]) % MOD; } for (int i=0; i\u0026lt;n-t; i++) for (int j=0; j\u0026lt;n-t-i; j++) for (int k=0; k\u0026lt;n-t-i-j; k++) { ull res = 0; for (int a=L+i+1, wr=(Y+j)*(m-a+1), wg=(X+i)*a; a\u0026lt;=R-j-1; a++, wr-=Y+j, wg+=X+i) { res += 1ll * CD[i][k][a] * CU[j][n-t-i-j-k-1][a] % MOD * max(wr, wg); } res %= MOD; if (i + j == n - t - 1 \u0026amp;\u0026amp; flag) anss = (anss + 1ll * C[i+j][i] * res) % MOD; else if (k) anss = (anss + 1ll * C[i+j][i] * C[n-t-i-j-2][k-1] % MOD * res) % MOD; } CL (f0), CL (f); for (int a=L; a\u0026lt;=R-2; a++) { for (int i=1; i\u0026lt;=t; i++) if (A[i] \u0026lt;= L) f0[a] += (A[i] + 1 + a) * (a - A[i]) \u0026gt;\u0026gt; 1; for (int i=L+1; i\u0026lt;=a; i++) f[a] += (i + 1 + a) * (a - i) \u0026gt;\u0026gt; 1; } for (int i=0; i\u0026lt;n-t-1; i++) for (int k=1; k\u0026lt;n-t-i; k++) { if (! i) { F[L] = L ? 1ll * C[L-1][k-1] * f0[L] % MOD : 0; for (int a=L+1; a\u0026lt;=R-2; a++) F[a] = 0; } else for (int a=L+i; a\u0026lt;=R-2; a++) F[a] = (1ll * C[a-L-1][i-1] * f0[a] + (i \u0026gt; 1 ? 1ll * C[a-L-2][i-2] * f[a] : 0)) % MOD * C[a-1][k-1] % MOD; for (int j=0; j\u0026lt;n-t-i-k; j++) { ull res = 0; for (int a=L+i, _=0; a\u0026lt;=R-j-2; a++) { ADD(1ll * CUS[j][n-t-i-j-k-1][a] * F[a]); } res %= MOD; anss = (anss + 1ll * C[i+j][i] * C[n-t-i-j-2][k-1] % MOD * res) % MOD; } } CL (f0), CL (f), CL (_F); for (int a=L+1; a\u0026lt;=R-1; a++) { for (int i=1; i\u0026lt;=t; i++) if (A[i] \u0026gt;= R) f0[a] += (2 * (m + 1) - A[i] - a) * (A[i] - a - 1) \u0026gt;\u0026gt; 1; for (int i=a+1; i\u0026lt;=R-1; i++) f[a] += (2 * (m + 1) - i - a) * (i - a - 1) \u0026gt;\u0026gt; 1; } for (int j=0; j\u0026lt;n-t-1; j++) { for (int a=L+1; a\u0026lt;=R-j-1; a++) _F[a][j] = (1ll * C[R-a-1][j] * f0[a] + (j ? 1ll * C[R-a-2][j-1] * f[a] : 0)) % MOD; for (int k=1; k\u0026lt;n-t-j-1; k++) { for (int a=L+1; a\u0026lt;=R-j-1; a++) F[a] = a \u0026lt; m ? 1ll * C[m-a-1][k-1] * _F[a][j] % MOD : 0; for (int i=0; i\u0026lt;n-t-j-k-1; i++) { ull res = 0; for (int a=L+i+1, _=0; a\u0026lt;=R-j-1; a++) { ADD(1ll * CD[i][n-t-i-j-k-1][a] * F[a]); } res %= MOD; anss = (anss + 1ll * C[i+j][j] * C[n-t-i-j-2][k] % MOD * res) % MOD; } } } for (int l=0; l\u0026lt;n-t-1; l++) for (int a=L+1; a\u0026lt;=min(R-1,m-1); a++) { int res1 = 0, res2 = 0; for (int i=max(0,a-R+l+1); i\u0026lt;=min(l,a-L-1); i++) res1 = (res1 + 1ll * C[a-L-1][i] * C[l][i] % MOD * _F[a][l-i]) % MOD; for (int k=1; k\u0026lt;n-t-l-1; k++) res2 = (res2 + 1ll * C[n-t-l-2][k] * C[a-1][n-t-l-k-2] % MOD * C[m-a-1][k-1]) % MOD; anss = (anss + 1ll * res1 * res2) % MOD; } return ans; } pii calcF(int L, int R) { pii ans (0, 0); ans += calcI(L, R, 1); for (int i=1; i\u0026lt;=t; i++) A[i] = m - A[i] + 1; swap(X, Y); ans += calcI(m - R + 1, m - L + 1, 0); for (int i=1; i\u0026lt;=t; i++) A[i] = m - A[i] + 1; swap(X, Y); anss = (anss + 1ll * ansc * calcP()) % MOD; return ans; } pii calcN() { pii ans (0, 0); c[t] = 1, Y ++, ans += calcF(L, A[t]), Y --; c[t] = A[t] * X \u0026gt; (m - A[t] + 1) * Y, t ++; for (int i=1; i\u0026lt;=L; i++) A[t] = i, c[t] = 1, ans += calcX(i, A[t-1]); c[t] = c[t-1] ^ 1, ans += calcX(A[t-1], A[t] = A[t-1]); for (int i=R; i\u0026lt;=m; i++) A[t] = i, c[t] = 0, ans += calcX(A[t-1], i); t --; c[t] = 0, X ++, ans += calcF(A[t], R), X --; return ans; } int main() { for (int i=0; i\u0026lt;=200; i++) { C[i][0] = 1; for (int j=1; j\u0026lt;=min(i,50); j++) C[i][j] = P(C[i-1][j-1], C[i-1][j]); } cin \u0026gt;\u0026gt; T; while (T --) { cin \u0026gt;\u0026gt; n \u0026gt;\u0026gt; m \u0026gt;\u0026gt; t, L = X = Y = 0, R = m + 1; for (int i=1; i\u0026lt;=t; i++) scanf (\u0026#34;%d\u0026#34;, \u0026amp;A[i]); for (int i=2; i\u0026lt;=t; i++) if (L \u0026lt; R) if (L \u0026lt; A[i] \u0026amp;\u0026amp; A[i] \u0026lt; A[i-1]) R = A[i-1], c[i-1] = 1, Y ++; else if (A[i-1] \u0026lt; A[i] \u0026amp;\u0026amp; A[i] \u0026lt; R) L = A[i-1], c[i-1] = 0, X ++; else if (A[i] == A[i-1]) L = R = A[i], c[i-1] = 0, c[i] = 1; else { c[i-1] = A[i-1] * X \u0026gt; (m - A[i-1] + 1) * Y; if (A[i] \u0026lt; A[i-1]) L = A[i-1], R = A[i], c[i] = 1; else L = A[i], R = A[i-1], c[i] = 0; } else if (A[i] \u0026gt; L) L = A[i], c[i] = 0; else if (A[i] \u0026lt; R) R = A[i], c[i] = 1; else { ans = {0, 0}; goto O; } if (L \u0026lt; R \u0026amp;\u0026amp; t == n) c[n] = A[n] * X \u0026gt; (m - A[n] + 1) * Y, L = R = 0; ans = L \u0026gt;= R ? calcX(R, L) : calcN(); O : printf (\u0026#34;%d %d\\n\u0026#34;, ansc, anss); } } ","date":"2023-08-17T00:00:00Z","permalink":"https://littlereuben.github.io/study/solution-lgp9171/","title":"[题解] lgP9171 [省选联考 2023] 染色数组"},{"content":"这是一篇学习笔记。\r同学打月赛后告诉我有道很离谱的题，遂做，确实挺离谱的，这里讲一下自己做的思路。\n题意 给定 $n$，平面直角坐标系上有点 $(0,0)\\sim(0,n-1),(1,0)\\sim(1,n-1)$。对于一个 $n$ 排列 $p$，对每个 $i$ 连线段 $(0,i)-(1,p_i)$。 考虑从每个横坐标为 $0$ 的点出发，依附于这些线段各走一条折线（或线段）到达一个横坐标为 $1$ 的点，这些折线（或线段）仅能在原先 $n$ 条线段的交点上重合。 求所有 $p$ 的方案数之积${}\\bmod{335544323}$。 $n\\le 10^6$。 Step 1 方便起见称原题中完美匹配（简称匹配）的连线为 “线段”，染色的折线（或线段）为 “路径”。\n模拟一些例子，发现三点：\n路径不会 “往回折” 且线段没有任何部分不被经过。 选择一条路径在（最后）一个交点的走向，剩余的东西并没有本质不同，感性地说像是有一个乘法原理。 三线段交于同一点和三线段交于三个点的方案数是不同的，也就是说这个几何背景是有用的。 可以证明第一点：考虑任一横坐标 $x_0$ 满足原先 $n$ 条线段的交点均不在 $x=x_0$ 上，这时原图有 $n$ 个点在 $x=x_0$ 上，而每一条路径至少穿过一次 $x=x_0$。如果有一条路径往回折，那就穿过某个 $x=x_0$ 大于一次，这就不可能存在 $n$ 条两两交长度 $=0$ 的路径了。\n进一步分析，发现一个 “$k$ 线共点” 的情况会对答案贡献 $k!$。因为这个局部相当于一个 $k$ 阶匹配以决定每条路径的走向，且每种方案显然都是合法的。因此最有可能的思路大概就是对于每个可能的交点，求出每种匹配情况下有几条线段经过它，然后阶乘乘起来贡献给答案。当然不能像这样直接算。\n显然贡献值只取决于该交点最多被几条线段经过（显然这些线段的端点均不同，所以相当于是一个选择问题），故可以求出 $w_k$ 表示将所有可能的 $n^2$ 条线段画出后 $k$ 线共点的情况数，$p_k$ 表示一个至多作为 $k$ 条线段交点的点在所有匹配情况下对答案的总贡献。就有：\n$$ ans=\\prod_{k=2}^n p_k^{w_k} $$\nStep 2 求 $w_k$。考虑刻画线段交于一点的情况。\n（为了美观横过来了）由图中相似关系可见，两边选的相邻点距离要对应成比例。\n第一反应是直接硬着对极大共点选择（一些线段交于同一点，且不能再多选一条经过该交点的线段。显然这些线段的端点均不同）计数，官方解法有更方便的容斥做法，这里就算给一个备选方案了。极大共点选择的条件为：\n两边选的点纵坐标分别成等差数列； 不能再往左右扩展； 公差互质。 首先发现互质条件无法直接处理，因此莫反，枚举公差的公因数 $g$，贡献乘 $\\mu(g)$ 即可。如果考虑左右部分别长为 $x$ 和 $y$ 的极长等差数列，那么画图可得它们能构成的极大共点选择包括：$2$ 个 $2$ 线共点，$2$ 个 $3$ 线共点，……，$2$ 个 $\\min(x,y)-1$ 线共点，$\\lvert x-y\\rvert+1$ 个 $\\min(x,y)$ 线共点。\n那么只需对于每个 $g$，把每种为 $g$ 倍数的公差所能形成的极长等差数列长度及其数量求出来，统计并扫描处理即可。由于一个公差 $d$ 至多只能产生 $\\lfloor (n-1)/d\\rfloor+1$ 与 $\\lfloor (n-1)/d\\rfloor$ 两种长度，而扫描可以优化到线性（枚举长较小者，部分细节略去），故这部分可以做到 $\\mathrm{O}(n\\log n)$。\nStep 3 直接求 $p_k$ 的思路为：对于每个 $i=1,\\cdots,k$，求出有多少种匹配恰好出现 $i$ 条线段经过该点，记为 $f_i$，则：\n$$ p_k=\\prod_{i=1}^k (i!)^{f_i} $$\n$f_i$ 无法直接计算，记 $g_i$ 表示钦定 $i$ 条线段经过该点，其他随便匹配的方案数（可能会算重）。则：\n$$ \\binom ki(n-i)!=g_i=\\sum_{j=i}^k\\binom jif_i $$\n二项式反演得：\n$$ f_i=\\sum_{j=i}^k(-1)^{j-i}\\binom ji\\binom kj(n-j)! $$\n然后就会发现没法快速求出 $p_i$（如果有大佬会的能教一下吗/kel\nStep 4 既然没法快速求 $p_i$，那么考虑利用最终只需求一个积这个性质，把所有 $k$ 放在一起求。记：\n$$ c_i=\\sum_{k=i}^nw_k\\sum_{j=i}^k(-1)^{j-i}\\binom ji\\binom kj(n-j)! $$\n则：\n$$ ans=\\prod_{i=2}^n(i!)^{c_i} $$\n而 $c_i$ 是可以快速求的：\n$$ c_i=\\sum_{j=i}^n(-1)^{j-i}\\binom ji(n-j)!\\left(\\sum_{k=j}^n w_k\\binom kj\\right) $$\n两次差卷积即可。细节略去。\nStep 5 最后一个问题是 $c_i$ 是在指数上的。注意到原模数为质数 $335544323=2^{26}\\times 5+3$，因此如果能求出 $c_i$ 模 NTT 质数 $2^{25}\\times 5+1$ 与 $c_i$ 的奇偶性即可用 CRT 的思路还原 $c_i\\bmod (2^{26}\\times 5+2)$。\n一个性质是 $w_i\\equiv[i=n]\\pmod 2$（显然 $w_n=1$）。这是因为除了两部公差均为 $1$ 的情况，其余所有极大共点选择可以对应其两部交换后的另一个极大共点选择。那么：\n$$ \\begin{aligned}c_i\u0026amp;\\equiv\\sum_{j=i}^n\\binom ji\\binom nj(n-j)!\\\\ \u0026amp;\\equiv n\\binom{n-1}i+\\binom ni\\\\ \u0026amp;\\equiv(n-i+1)[i\\subseteq n]\\pmod 2\\end{aligned} $$\n最终时间复杂度为 $\\mathrm{O}(n\\log n)$。\n代码 一个优化：两次卷积分别要求类似于 $\\text{DFT}(\\mathrm{e}^x)$ 以及 $\\text{DFT}(\\mathrm{e}^{-x})$ 形式的东西，可以省掉一次。共 $5$ 次 DFT。\nvoid NTT(int n, int *a, int o) { for (int i=0; i\u0026lt;n; i++) if (i \u0026lt; f[i]) swap(a[i], a[f[i]]); for (int i=1, _; i\u0026lt;n; i\u0026lt;\u0026lt;=1) for (int j=0; j\u0026lt;n; j+=i\u0026lt;\u0026lt;1) for (int k=j; k\u0026lt;j+i; k++) _ = 1ll * g[i][k-j] * a[k+i] % P, a[k+i] = R(a[k], P - _), a[k] = R(a[k], _); if (o) { reverse (a+1, a+n); for (int i=0; i\u0026lt;n; i++) a[i] = 1ll * a[i] * I % P; } } int main() { cin \u0026gt;\u0026gt; n; for (int i=mu[1]=1; i\u0026lt;=n; i++) if (mu[i]) for (int j=i\u0026lt;\u0026lt;1; j\u0026lt;=n; j+=i) mu[j] -= mu[i]; for (int i=1; i\u0026lt;n; i++) L[i] = (n - 1) / i + 1, C[i] = (n - 1) % i + 1; for (int g=1; g\u0026lt;n; g++) { if (! mu[g]) continue; int m = 0, sl = 0, sc = 0; for (int i=g; i\u0026lt;n; i+=g) { if (m \u0026amp;\u0026amp; l[m-1] == L[i]) c[m-1] = R(c[m-1], C[i]); else if (l[m] == L[i]) c[m] = R(c[m], C[i]); else l[++m] = L[i], c[m] = C[i]; if (C[i] \u0026lt; i \u0026amp;\u0026amp; L[i] \u0026gt; 2) if (l[m] == L[i] - 1) c[m] = R(c[m], i - C[i]); else l[++m] = L[i] - 1, c[m] = i - C[i]; } for (int i=1; i\u0026lt;=m; i++) { w[l[i]] = (w[l[i]] + ((sl + 1ll * (P - l[i] + 1) * sc \u0026lt;\u0026lt; 1) + c[i]) % P * (~ mu[g] ? c[i] : P - c[i])) % P; d[l[i]-1] = (d[l[i]-1] + (2ll * sc + c[i]) * (~ mu[g] ? c[i] : P - c[i])) % P; sl = (sl + 1ll * l[i] * c[i]) % P, sc = R(sc, c[i]); } } for (int i=n; i\u0026gt;1; i--) d[i] = R(d[i], d[i+1]), w[i] = R(w[i], R(d[i], d[i])); for (int i=F[0]=1; i\u0026lt;=n; i++) F[i] = 1ll * F[i-1] * i % P; IF[n] = qpow(F[n], P - 2); for (int i=n-1; ~i; i--) IF[i] = 1ll * IF[i+1] * (i+1) % P; while (m \u0026lt; (n \u0026lt;\u0026lt; 1) - 3) m \u0026lt;\u0026lt;= 1; I = qpow(m, P - 2); for (int i=0; i\u0026lt;m; i++) f[i] = f[i\u0026gt;\u0026gt;1] \u0026gt;\u0026gt; 1 | (i \u0026amp; 1 ? m \u0026gt;\u0026gt; 1 : 0); for (int i=1; i\u0026lt;m; i\u0026lt;\u0026lt;=1) { g[i] = new int [i] {1}; if (i \u0026gt; 1) { g[i][1] = qpow(3, (P - 1) / (i \u0026lt;\u0026lt; 1)); for (int j=2; j\u0026lt;i; j++) g[i][j] = 1ll * g[i][j-1] * g[i][1] % P; } } for (int i=0; i\u0026lt;n-1; i++) a[i] = 1ll * F[n-i] * w[n-i] % P, b[i] = IF[i]; NTT(m, a, 0), NTT(m, b, 0); for (int i=0; i\u0026lt;m; i++) a[i] = 1ll * a[i] * b[i] % P; NTT(m, a, 1); for (int i=0; i\u0026lt;m; i++) a[i] = i \u0026lt; n - 1 ? 1ll * F[i] * a[i] % P : 0; for (int i=0; i\u0026lt;m\u0026gt;\u0026gt;1; i++) swap(b[i], b[i|m\u0026gt;\u0026gt;1]); NTT(m, a, 0); for (int i=0; i\u0026lt;m; i++) a[i] = 1ll * a[i] * b[i] % P; NTT(m, a, 1); for (int i=0; i\u0026lt;n-1; i++) c[n-i] = 1ll * IF[n-i] * a[i] % P; for (int i=2; i\u0026lt;=n; i++) if ((i \u0026amp; n) == i \u0026amp; n - i - 1 \u0026amp; 1 ^ c[i] \u0026amp; 1) c[i] += P; for (int i=n; i\u0026gt;1; i--) { if ((c[i] += c[i+1]) \u0026gt;= P2 - 1) c[i] -= P2 - 1; ans = 1ll * ans * qpow_(i, c[i]) % P2; } cout \u0026lt;\u0026lt; ans; } ","date":"2023-05-24T00:00:00Z","permalink":"https://littlereuben.github.io/study/solution-lgp9159/","title":"[题解] lgP9159 [GLR-R4] 大暑"}]